# Hadoop


Hadoop



Anlik islem yapan (online) veri tabanlarinda anahtar-deger kavramina bir gidis oldugundan bahsettik; Aynen bu gidiste oldugu gibi, arka planda (offline) veri isleyen, analitik tabanlarda da benzer bir gidisat goruluyor. Google, Yahoo ve Facebook gibi sirketler devasa boyutlarda veriyi analiz etmek icin artik SQL, RDBMS kullanmiyorlar. Hadoop adli, yine anahtar-deger teknigini kullanan bir urunu kullaniyorlar.Hadoop'un temelindeki teknik "esle/indirge (map/reduce)" adindaki bir tekniktir. Bu teknik Apache tarafindan open source ortama getirildi, ve Hadoop bu sekilde dunyaya geldi. Teknolojinin cikis noktasi Google; bu sirketin Web'den cektigi terabaytlarca veriyi analiz etmesi gerektigi icin, esle/indirge teknolojisini gelistirdiler, gelistirmeye mecbur oldular.Esle/indirge nedir? Online tabanlarda anahtar degeri belli bir makinaya yonlendirmek icin kullaniliyor, bunu isledik. Esle/indirge tabanlarinda ise, anahtar degeri esle surecinde her nod uzerindeki veriye bakilarak bir "ozet" cikarmak icin kullaniliyor. Indirge surecinde ise her ayri nod'daki anahtar-deger ciftleri alinarak uyusan anahtarlar bir daha birlestiriliyor. Bu son birlesim bize nihai sonucu veriyor.Hadoop, yatay olarak olceklenebilen bir teknoloji, bu sebeple kumedeki her makina kendi verisine sahip, yani tum islem o makinaya yerel. Ayni online dunyada oldugu gibi (mesela Voldemort) her nod kendi verisini cokusten kurtulmak amaciyla kumede birkac diger bilgisayara yedek olarak gonderebilmekte. Hadoop'ta degisik olan bir "idare edici" yani "gorev verici" makinanin olmasi. Burada bir mahsur yok; Esle/indirge arka planda calisan bir teknoloji oldugu icin dagitici konduktor sistem, eger iyi tasarlanmissa, bir hassas nokta haline gelmez. Isin en agir kismi zaten kumedeki islemci nodlar tarafindan ustlenmekte. Hadoop'ta yapilacak islemler tipik olarak bir "Job" olarak yaziliyor. Job'inizi yaziyorsunuz, ve Hadoop kumenize veriyorsunuz.Bir ornek dusunelim: Elimizde koca bir dosya var, bu dosyada her satirda bir meyve ismi, ve o meyve satin alindiginda ne kadar para odenmis oldugu yazili olsun (alttaki koca bir dosya degil ama oldugunu dusunelim). Amacimiz her meyve icin toplam ne kadar harcandigini bulmak.armut 10portakal 3incir 9armut 9armut 10incir 3mandalin 2erik 29Burada anahtar degerleri meyve isimleri olacak. Diyelim ki Hadoop kumemizde 2 nod var, ve ustteki dosyayi Hadoop'a verdik.Hadoop bu dosyayi iki esit parcaya bolecektir (anahtar degerlerine hic bakmadan, burasi online'dan farkli), ve diyelim ki bolunme tam ortadan yapildi:armut 10portakal 3incir 9armut 9----armut 10incir 3mandalin 2incir 29Her nod, kendi icinde "esle" yaparken, benzer anahtar degerlerini ayni toplama yazacak.  Bolum 1) armut = 19, portakal = 3, incir = 9. Bolum 2) armut 10, incir = 32, mandalin = 2.Her bolumun isi boylece bitiyor, yani esle sahfasi sona eriyor. Bundan sonra "indirge" kisminda her bolumdeki anahtarlar bir de kendi aralarinda toplaniyorlar. Boylece armut = 29, portakal = 3, incir = 41, mandalin = 2. Bu en son sonuc. Bu son derece basitlestirilmis bir ornektir, fakat isin ozunu anlatabildik zannediyorum.Aktarilan bilgilere gore, sasirtici derecede cok sayidaki analiz islemi, ustteki esle/indirge mentalitesine uyarlanabilmektedir.Haberdar olunmasi gereken muthis orneklerden biri, makina ogrenimi algoritmalarinin ayni esle/indirge sistemine uyarlanabilmis olmasidir. Mahout projesi bunu open source ortamina tasimaya aday oldu. Rapor edilen sonuclara gore eklenen her mikroislemci kor'u (Hadoop nod'u gibi) esle/indirge ile kodlanmis makina ogrenimi algoritmasini bir o kadar hizlandirmaktadir. Yani performans kazinimi "lineer" sekilde artabilmektedir. Her eklenen kor bir o kadar hizlanma getirmektedir.Bir diger haber: Amazon sirketinin EC2 servisini biliyoruz. EC2'nin en son servisi, hazir pisirilmis bir Hadoop kumesi servisi vermeye baslamasi. Amazon bu Hadoop sistemini universitelere ogretim amacli olarak ucretsiz olarak ta sunmakta.Anahtar-deger yaklasiminin basarisinin sebebi onun kavramsal basitliginde yatiyor olmali. Bu sebeple cok rahat bir sekilde yatay sekilde dagitilabilen veri yapilariyla islem yapmamiza izin veriyor.Hadoop projesi uyelerinden Christophe Bisciglia ile yapilan bir roportajin ses kaydi surada bulunabilir.




