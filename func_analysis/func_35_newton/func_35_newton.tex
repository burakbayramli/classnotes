\documentclass[12pt,fleqn]{article}\usepackage{../../common}
\begin{document}
Newton'un Metodu (Newton's Method)

([2] dersinden aldýðýmýz notlar). Newton birazdan bahsedeceðimiz yöntemi
tek boyutlu problemler için kullandý. Rhapson adlý bilimci yöntemi çok
boyutlu problemler için geniþletti. Biz bu yönteme optimizasyon
çerçevesinde bakacaðýz.  Konunun tarihinden biraz bahsetmek istiyorum, bu
dersi öðretmeye baþladýðýmda 1986 senesiydi, Newton'un metodunu nasýl
gördüðümüz o zamandan beri deðiþime uðradý. NM o zamanlar son baþvurulan
metot diye öðretiliyordu, çünkü metodu kullanmak için ``büyük'' bir denklem
sistemi çözmek gerekiyordu, 500 x 500 bir sistem mesela. Bugüne gelelim
artýk NM ilk baþvurulan metot haline geldi, 50,000 x 50,000 boyutlarýnda
bir sistem çözmek ``yetiyor'' ve böyle bir sistem artýk idare edilebilen
bir boyut haline geldi. Yani hesapsal kapasite NM'in optimizasyon alanýnda
oynadýðý rolü tamamen deðiþtirdi.

Diðer bir faktör ileride öðreneceðimiz iç nokta (interior-point)
metotlarýnýn Newton'un metodunu kullanýyor olmalarý. Ýç nokta metotlarý
icbukey optimizayonda çok popüler, onlar için NM gerekiyor, bu da NM'in
popülaritesini arttýrýyor.

NM nedir? Elimde bir kýsýtlanmamýþ (unconstrained) problemim var diyelim,

$$
\min f(x), \quad \textrm{ öyle ki } \quad x \in X = \mathbb{R}^n
$$

Bir Taylor açýlýmý yapabilirim,

$$
f(x) \approx 
f(\bar{x}) + 
\nabla f(\bar{x})^T (x-\bar{x}) + 
\frac{1}{2} (x-\bar{x})^T H (x-\bar{x}) 
$$

ki $H$ Hessian matrisi. Üstteki formüle $h(x)$ diyelim. Böylece bir karesel
model ortaya çýkartmýþ oldum, formülün sað tarafýndaki çarpým onu karesel
yapýyor, ve þimdi onu kesin olarak çözmek istiyorum. Bunu nasýl yaparým?
Formülün gradyanýný sýfýra eþitleyebilirim. Üstteki fonksiyonun $x$'tei
gradyaný nedir? 

Gradyaný $x$'e göre aldýðýmýzý unutmayalým, $h(x)$'in ikinci terimi
$\nabla f(\bar{x})^T$ bir sabit sayý, ikinci gradyan alýnýrken sýfýrlanýr,
ve tüm ikinci terim sýfýrlanýr. Üçüncü terimin gradyanýný almak bir nevi
$\frac{\partial (x^TAx)}{\partial x} $ almak gibi [1], $A$ simetrik olunca
gradyan $2Ax$ sonucunu veriyordu, o zaman üçüncü terimde $H$ kalýr, 2 ve
$1/2$ birbirini iptal eder, sonuç

$$
\nabla h() = \nabla f(\bar{x}) + H(\bar{x})(x-\bar{x})
$$

Ýki üstteki karesel yaklaþýksal ifadenin gradyaný bu iþte. Onu sýfýra
eþitleriz ve çözeriz, 

















[devam edecek]

Kaynaklar 

[1] Bayramli, Cok Boyutlu Calculus, {\em Vektör Calculus, Kurallar, Matris Türevleri}

[2] Freund, {\em MIT OCW Nonlinear Programming Lecture},
    \url{https://ocw.mit.edu/courses/sloan-school-of-management/15-084j-nonlinear-programming-spring-2004/}

\end{document}



