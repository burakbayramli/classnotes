\documentclass[12pt,fleqn]{article}\usepackage{../../common}
\begin{document}
Log-Bariyer Yöntemi

[Newton yöntemi özeti atlandý]

Þimdiye kadar kýsýtlanmamýþ Newton yönteminden bahsettik [1, 53:18]. Þimdi
lineer olarak kýsýtlanmýþ, $Ax=b$ ile, olan duruma bakalým, çünkü ileride
faydalý olacak.

En bariz yaklaþým $Ax=b$'nin bir doðrusal (affine) uzay yaratmasý, ve
optimizasyonun bu daha ufak uzayda iþ yapmasý. Bir deðiþken deðiþimi
yaparýz, $x = Fy + x_0$, ki $F$, $A$'nin sýfýr uzayýný kapsýyor, ardýndan
optimizasyon problemini $y$ bazlý bir probleme indirge. Bu yaklaþýma
``indirgenmiþ uzay yaklaþýmý'' deniyor. Tarif edilen gayet doðal, basit bir
yaklaþým aslýnda, fakat bir bedeli de var. Eðer orijinal problem seyrek ise
deðiþim sonrasý çok miktarda yapý kaybý (yaý seyreklik) olacak.

Bir diðer seçenek eþitlikle kýsýtlanmýþ Newton (equality constrained
Newton). Bu yöntemle $x^+ = x + t v$ adýmýnda $v$ karesel
yaklaþýksallamanýn çözümü, fakat bu çözüm sýnýrlanmýþ bir problemin çözümü,
bir sonraki $x^+$'yi olurlu halde tutacak bir sýnýrlama bu.

Çözülen problem 

$$
v = \arg\min_{Az = 0} \nabla f(x)^T (z-x) + \frac{1}{2} (z-x)^T \nabla^2 f(x)(z-x)
$$

Üstteki $x^+$'i olurlu kümede tutar çünkü 

$$
Ax^+ = Ax + tAv = b + 0 = b
$$

KKT koþullarý üzerinden çözüm

$$
\left[\begin{array}{cc}
\nabla^2 f(x) & A^T \\
A & 0
\end{array}\right]
\left[\begin{array}{c}
v \\
w
\end{array}\right] = 
- 
\left[\begin{array}{c}
\nabla f(x) \\
Ax - b
\end{array}\right]
$$

ile belirtilebilir. KKT bölümünde karesel problem örneðindeki gördüðümüz
$Q$ burada $\nabla^2 f(x)$ oluyor, atýlan adým sonrasý gelinen yerin ne
olacaðý da kýsýtlama içinde görülebilir.

Olurlu noktadan basliyorsak, ozel durum $Ax = b$, tabii o zaman 

$$
\left[\begin{array}{cc}
\nabla^2 f(x) & A^T \\
A & 0
\end{array}\right]
\left[\begin{array}{c}
v \\
w
\end{array}\right] = 
- 
\left[\begin{array}{c}
\nabla f(x) \\
0
\end{array}\right]
$$

O zaman bariyer metotu nedir? Bu metotla yine Newton metotunu uzatacaðýz,
ve eþitsizlik olan problemlerle uðraþacaðýz. 

$$
\min_x f(x) \quad \textrm{oyle ki}
$$
$$
Ax = b
$$
$$
h_i(x) \le 0, \quad i=1,..,m
$$

Kriter dýþbükey, sýnýrlamalar lineer, ve dýþbükey eþitsizlik
sýnýrlamalarý, $h_i(x) \le 0$ ile.

Bariyer metotu eþitsizliklerle baþetmenin bir yolu. Eþitsizlik içeren
programlarýn en büyük problemi sýnýrlarda ne yapýlacaðýna karar vermek,
yani olurlu kümenin sýnýrlarýnda. Baþetmek için olurlu küme 
$C \equiv \{ x: h_i(x) \le 0 , i=1,..,m\}$ 

$$
\min_x f(x) + I_C(x)
$$
$$
Ax = b
$$

ile kritere dahil edilir, ki $I_C$ göstergeç fonksiyonudur. Ana fikir sýnýr
noktalarýnda iþler zorlaþýyorsa niye oralardan uzak durmuyoruz? Fakat
göstergeç fonksiyonu ile çalýþmak zor, onu da yaklaþýksal olarak temsil
ederiz, iþte bariyer fonksiyonu budur. Öyle bir fonksiyon seçeriz ki
sýnýrlarda aþýrý büyük deðerler vererek bizi minimizasyon baðlamýnda
oralardan ``geri iter''. Sanki sýnýrlara bir manyetik alan koyuyoruz,
oralara yaklaþýnca geri itiliyoruz. 

Tabii bir yandan Newton metotu da kullanabilmek istiyoruz, ideal olarak
pürüzsüz bir metot olursa elimizde iyi olur. Log bariyer fonksiyonu böyle
bir fonksiyon

$$
\phi(x) = -\sum_{i=1}^{m} \log(-h_i(x))
$$

Böylece ana problemi þu hale getirebiliriz,

$$
\min_x f(x) + \frac{1}{t} \phi(x) \quad \textrm{öyle ki}
$$
$$
Ax = b
$$

ki $t>0$. Görülen $1/t$ dýþarýdan bizim tanýmladýðýmýz bir parametre,
optimizasyonu ayarlamak için kullanýyoruz onu. Eðer $t$ küçükse, sýfýra
yakýnsa o zaman bariyer baskýn haldedir (daha büyüktür), tabii o zaman
sýnýrlardan kaçmak optimizasyon için daha önemli hale gelir. 








[devam edecek]

Kaynaklar

[1] Tibshirani, {\em Convex Optimization, Lecture Video 14}, 
\url{https://www.youtube.com/channel/UCIvaLZcfz3ikJ1cD-zMpIXg}   

[2] Tibshirani, {\em Convex Optimization, Lecture Video 15}, 
\url{https://www.youtube.com/channel/UCIvaLZcfz3ikJ1cD-zMpIXg}   

\end{document}



