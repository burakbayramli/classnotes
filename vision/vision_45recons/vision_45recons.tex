\documentclass[12pt,fleqn]{article}\usepackage{../../common}
\begin{document}
Ýki Ýmaj Kullanarak 3 Boyutta Tekrar Oluþturmak (3D Reconstruction from Two Images)

Temel Matris (Fundamental Matrix)

8. derste vazgeçilmez matris (essential matrix) konusunu görmüþtük. Þimdi
bu bölümdeki eþkutupsal kýsýtlamanýn (epipolar contraint) bir daha
üzerinden geçelim, ama bu sefer temel matrisi merkez alalým. Aslýnda
vazgeçilmez ve temel matrisler birbirine çok yakýnlar, temel matris
vazgeçilmezin içinden kalibre edilme faraziyesinin çýkartýlmýþ hali. [1,
sf. 257] diyor ki vazgeçilmez matriste her þey vazgeçilmez deðilmiþ demek
ki (!).

Kalibrasyon, yani $K$ nasýl çýkartýlýr? Diyelim ki bir kamera matrisi
$P = K[R | t]$ olarak tanýmlý ve $x = PX$ görüntüdeki bir piksel
noktasý. Bilinen bir $K$ varsa onun tersini $x$'e uygulayarak
$\hat{x} = K ^{-1}x$ noktasýný elde edebiliriz, o zaman
$\hat{x} = [R | t]X$ olur. Burada $\hat{x}$'i bir tür ``normalize edilmiþ''
kordinat sistemindeki bir görüntü pikseli olarak düþünebiliriz, bu sistem
sanki kalibrasyonu birim matris, yani $I$ olan bir kamera sistemidir. Ayný
þekilde $K ^{-1} P = [R|t]$ normalize kamera matrisi olarak adlandýrýlýr.

Þimdi eþkutupsal kýsýtlamaya tekrar bakalým. Altta soldaki resimde üç
boyutlu gerçek dünyada bir $X$ noktasý var, bu noktadan merkezi $C_1$'de
olan kameraya bir çizgi çekiyoruz. Bu çizgi üzerindeki her nokta aslýnda
ayný piksel noktasýna tekabül ediyor. Deðil mi? Bu aslýnda bir bilgi
kaybýdýr, o çizgi üzerindeki tüm noktalar ayný piksele yansýrsa bir þeyler
kaybediliyor. Bu kaybedilen derinlik bilgisi. Neyse, þimdi bu çizgi
üzerindeki tüm o noktalarýn ikinci bir kameradaki yansýmalarýný
düþünelim. Bu tüm deðiþik yansýmalar ikinci kameranýn görüntüsünde bir
çizgi oluþtururlar (ayný piksel deðil bu sefer, çünkü baþka bir
kameradayýz), bu çizgiye eþkutupsal çizgi diyoruz (alt saðda).

\includegraphics[width=17em]{vision_20recons_04.png}
\includegraphics[width=17em]{vision_20recons_05.png}

Ayný duruma tek bir $X$ için bakalým,

\includegraphics[width=22em]{vision_20recons_06.png}

Demek ki ilk kameradaki iki boyutlu bir $x$'i alýp ikinci kameradaki $x'$
noktasýna transfer eden bir fonksiyon var, buna $H_{\pi}$ diyelim. Tranfer
2D-2D, yani iki boyuttan iki boyuta bir geçiþ, bir homografi, ve $\pi$
düzlemi üzerinde bu geçiþ oluyor. Ýkinci kameradaki eþkutupsal çizgi
$l' = [e']_x x'$ ile elde edilir, çünkü hatýrlarsak iki noktadan çizgi elde
etmek için çapraz çarpým lazým, ya da vektörlerden birinin eksi bakýþýmlý
hali ile normal çarpým (altsimge $_x$ eksi bakýþýmlýlýk dönüþümünü temsil
ediyor). O zaman, ve $x' = H_\pi x$ olduðu için,

$$ l' = [e']_x x' = l' = [e']_x H x = F x $$

de denebilir. Ýþte bu denklemin $[e']_xH$ kýsmýna temel matris $F$ denir.

Eþkutupsal kýsýtlama nedir? Bu kýsýtlama

$$ x'^T F x = 0$$

ifadesidir. Bu ifade doðru çünkü eðer $x$ ve $x'$ birbirlerine karþýlýk
noktalar iseler, o zaman $x'$ eþkutupsal çizgi $l' = Fx$ üzerinde olmalý,
yani $0 = x'^T l' = x'^T F x$.

Nokta Karþýlýklarý ve 8-Nokta Algoritmasý

Ýki resimden üç boyutta tekrar oluþturma için önce $F$ matrisini hesaplamak
gerekiyor. Oradan vazgeçilmez matris $E$'ye geçeceðiz, sonra $E$ içinden
$R,T$ matrislerini çýkartabiliriz.

$F$'den $E$'ye geçiþ basit, $E = K^TFK$. Ýspat: Eðer eþkutupsal kýsýtlama
türetiminde normalize edilmiþ noktalarý kullansaydýk
$\hat{x}'E \hat{x} = 0$ elde ederdik, ve $\hat{x}$ ve $\hat{x}'$ yerine $x$
ve $x'$ kullanýrsak, $\hat{x} = K ^{-1}x, \hat{x'} = K ^{-1}x'$, o zaman
$x'^TK^{-T}E K ^{-1}x = 0$ elde ederiz, bu demektir ki $E = K ^T F K$.

$F$ hesabýna dönelim. Elimizde iki imaj var, Alkatraz adasýnýn iki deðiþik
yerden fotoðrafý [2,3]. Bu iki imaj üzerinde önce birbirine tekabül eden
noktalarý bulacaðýz. Bu iþ için OpenCV'nin ORB adý verilen nokta özelliði
(feature) çýkartan iþlevini kullanabiliriz, onun yerine SIFT, SURF te
olabilirdi.

\begin{minted}[fontsize=\footnotesize]{python}
from mpl_toolkits.mplot3d import axes3d
import scipy.linalg as lin
import cv2

dir = "/home/burak/Documents/Dropbox/Public/data/pcv_data"
img1 = cv2.imread(dir + "/alcatraz1.jpg")
img2 = cv2.imread(dir + "/alcatraz2.jpg")

detector = cv2.ORB_create( nfeatures = 10000 )

def detect_features(frame):
    keypoints, descrs = detector.detectAndCompute(frame, None)
    if descrs is None: descrs = []
    return keypoints, descrs

FLANN_INDEX_LSH    = 6
flann_params= dict(algorithm = FLANN_INDEX_LSH,
                   table_number = 6, # 12
                   key_size = 12,     # 20
                   multi_probe_level = 1) #2


kp1, des1 = detect_features(img1)
kp2, des2 = detect_features(img2)

matcher = cv2.FlannBasedMatcher(flann_params, {})
matches = matcher.knnMatch(des1, des2, k = 2)

matches = [m[0] for m in matches \
           if len(m) == 2 and m[0].distance < m[1].distance * 0.75]

print 'uyan noktalar', len(matches)

pts1 = []; pts2 = []

for i in range(len(matches)):
    pt_a = kp1[matches[i].queryIdx].pt
    pt_b = kp2[matches[i].trainIdx].pt
    pt_a = np.array(pt_a).astype(int)
    pt_b = np.array(pt_b).astype(int)
    if np.sqrt(np.dot(pt_b-pt_a,pt_b-pt_a)) < 200:
        pts1.append(pt_a)
        pts2.append(pt_b)
        cv2.line(img1, tuple(pt_a), tuple(pt_b), (255, 0, 0), 5)
        cv2.circle(img1,tuple(pt_b), 5, (0,0,255), -1)

h,w,d = img1.shape
tmp = cv2.resize(img1, (int(w/4),int(h/4)))
cv2.imwrite('vision_20recons_01.jpg',tmp)

for pt in pts2: cv2.circle(img2,tuple(pt),5,(0,0,255),-1)
tmp = cv2.resize(img2, (int(w/4),int(h/4)))
cv2.imwrite('vision_20recons_02.jpg',tmp)

pts1 = np.array(pts1)
pts2 = np.array(pts2)

h,w,dum = img1.shape
pts1[:,1] = h-pts1[:,1]
pts2[:,1] = h-pts2[:,1]
\end{minted}

\begin{verbatim}
uyan noktalar 1298
\end{verbatim}

\includegraphics[width=30em]{vision_20recons_01.jpg}

\includegraphics[width=30em]{vision_20recons_02.jpg}

Birinci resimde saptanan ORB noktalarýnýn ikinci resimdeki noktalara nasýl
nasýl eþleþtiðini (yine birinci resimde) gösterdik, ikinci resimde o
resimdeki eþleþme noktalarý görülüyor. Noktalardaki kayma kameranýnýn
hareketi hakkýnda bir ipucu veriyor bize, hareketi çýplak gözle bile
görebiliyoruz. Temel matrisi hesaplayýnca daha net bir sonuç alacaðýz
tabii.

8-Nokta Algoritmasý

Daha önce $E$ için 8-nokta algoritmasýný gördük, benzer bir hesap $F$ için
de var. Bu arada 8 nokta dedik daha fazlasýna da izin veren bir çözüm
yöntemi SVD ile mümkün. Çözülecek sistem eþkutupsal kýsýtlamadan baþlar,
$i=1,2,..$ olacak þekilde her $x_1^i,x_2^i$ eþleþmelerini bir
$x_1^i F x_2^i = 0$ hesabýný içinde barýndýran bir $Af = 0$ sistemi
yaratabiliriz, $x_1^i = (x_1^i,y_1^i,w_1^i)$ ve $x_2^i=(x_2^i,y_2^i,w_2^i)$
olacak þekilde,

$$ 
\left[\begin{array}{ccccc}
x_2^1x_1^1 & x_2^1y_1^1 & x_2^1w_1^1 & \dots & w_2^1w_1^1 \\
x_2^2x_1^2 & x_2^2y_1^2 & x_2^2w_1^2 & \dots & w_2^2w_1^2 \\
\vdots & \vdots & \vdots & \vdots & \vdots  \\
x_2^nx_1^n & x_2^ny_1^n & x_2^nw_1^n & \dots & w_2^nw_1^n
\end{array}\right]
\left[\begin{array}{c}
F_{11} \\ F_{12} \\ F_{13} \\ \vdots \\ F_{33} 
\end{array}\right] = 0
$$

ki $f$ içinde $F$'nin öðeleri var. Üstteki çarpým yapýlýnca teker teker her
satýrda eþkutupsal kýsýtlamayý elde edebileceðimizi görebiliriz. $Af = 0$
sistemi yaklaþýk olarak SVD ile çözülebilir.

\begin{minted}[fontsize=\footnotesize]{python}
def compute_fundamental(x1, x2):
  n = x1.shape[1]
  A = np.zeros((n, 9))
  for i in range(n):
    A[i] = [x1[0, i] * x2[0, i],  x1[0, i] * x2[1, i],  x1[0, i] * x2[2, i],
            x1[1, i] * x2[0, i],  x1[1, i] * x2[1, i],  x1[1, i] * x2[2, i],
            x1[2, i] * x2[0, i],  x1[2, i] * x2[1, i],  x1[2, i] * x2[2, i],
           ]

  U, S, V = np.linalg.svd(A)
  F = V[-1].reshape(3, 3)

  U, S, V = np.linalg.svd(F)
  S[2] = 0
  F = np.dot(U, np.dot(np.diag(S), V))
  return F / F[2, 2]
\end{minted}

Eðer biraz önce bulunan noktalar üzerinde uygularsak,

\begin{minted}[fontsize=\footnotesize]{python}
def make_homog(points):
  return np.vstack((points, np.ones((1, points.shape[1]))))
print compute_fundamental(make_homog(pts1.T),make_homog(pts2.T))
\end{minted}

\begin{verbatim}
[[  1.30375335e-07   1.65553204e-07  -9.29038216e-04]
 [  5.01128878e-07   8.40553282e-07  -3.40774405e-03]
 [  3.28488982e-05   1.58554327e-03   1.00000000e+00]]
\end{verbatim}

Dahasý da var. Bu hesap fena deðildir, fakat $F$ gibi kritik bir hesap için
daha saðlam bir yaklaþým tercih ediliyor. RANSAC adý verilen metotla
verilen tüm eþleþme noktalarýndan ufak örneklemler toplanýr, her örneklem
üzerinde üstteki hesap uygulanýr, ve elde edilen sonuçlara bakýlarak gerçek
$F$'e yaklaþýp yaklaþýlmadýðý kararlarlaþtýrýlmaya çalýþýlýr, en iyi,
stabil olan nihai sonuç elde tutulur. Detaylar için [1, sf. 291]. OpenCV
\verb!cv2.findFundamentalMat! çaðrýsý $F$'yi RANSAC ile
hesaplayabilir. Sonra $E$, onu $R,t$ parçalarýna ayýrýrýz, vs., böyle devam
ederiz.

\begin{minted}[fontsize=\footnotesize]{python}
# kamera matrisi biliniyor
K = np.array([[2394,0,932],[0,2398,628],[0,0,1]])

F, mask = cv2.findFundamentalMat(pts1,pts2,method=cv2.RANSAC, param1=3., param2=0.99)
print 'F', F
E = K.T.dot(F).dot(K)
print 'E', E
R1,R2,t = cv2.decomposeEssentialMat(E)
print 'R1',R1
print 'R2',R2
print 't',t
\end{minted}

\begin{verbatim}
F [[  5.96322112e-08   5.60043096e-06  -2.04058699e-03]
 [ -5.99484026e-06   1.84659966e-07   1.51380328e-02]
 [  1.78053340e-03  -1.63463214e-02   1.00000000e+00]]
E [[  0.34176628  32.15102128   3.66775373]
 [-34.41525089   1.0618694   23.18100597]
 [ -4.61718585 -26.40378644  -0.10739647]]
R1 [[-0.29336175 -0.1052158   0.95019394]
 [-0.13001529 -0.98029957 -0.14869019]
 [ 0.94711927 -0.16715975  0.27390274]]
R2 [[ 0.9950157  -0.02174197  0.09731924]
 [ 0.02293629  0.99967452 -0.01117018]
 [-0.09704471  0.01334665  0.99519053]]
t [[ 0.63358512]
 [-0.09669105]
 [ 0.76760715]]
\end{verbatim}

Üçgenleme (Triangulation) 

Yer deðiþtirme, rotasyon matrislerini biliyoruz, oradan her kamera için
yansýtma matrisleri $P,P'$'yi oluþturabiliriz. Peki bu matrisleri
kullanarak üç boyutta gerçek nokta $X$'leri nasýl hesaplarýz?  Halen
elimizde sadece iki boyutlu imaj noktalarý var, 3D dünya noktalarý
yok. $X$'leri hesaplamak için daha önce gördüðümüz direk lineer transform
metotunun benzerini uygularýz. Bu gerekli çünkü her iki kameradaki
yansýmadan oluþan hatalar, vs. sonucu mesela iki kameradan direk çizgi
çekerek kesiþtikleri yeri bulmaya çalýþsak, alttaki durum ortaya çýkar,

\includegraphics[width=20em]{vision_20recons_07.png}

O zaman yaklaþýksal bir çözüm gerekli, üstteki hata ortaya çýksa da, bu
hatayý olabildiðince minimize etmeye uðraþmalýyýz. 

Birbirinin eþi olan iki piksel noktasý için elimizde $x = PX, x' = P'X$
denklemleri var, bu denklemde $X$ ayný dikkat edersek, çünkü ayný 3D
noktasýnýn iki kameradaki deðiþik yansýmalarý var. Bu denklemleri
birleþtirerek bir $AX=0$ sistemi ortaya çýkartabiliriz [1, sf. 312], ve bu
sistem minimize edilebilir. Çapraz çarpým ile homojen ölçek faktörünü
çýkartýrsak, mesela ilk imaj için

$$ x \times (PX) = 0$$

Bu bize üç denklem verir, 

$$ x(p^{3T}X) - (p^{1T}X) = 0 $$

$$ y(p^{3T}X) - (p^{2T}X) = 0 $$

$$ x(p^{2T}X) - (p^{1T}X) = 0 $$

ki $p^{iT}$ $P$ matrisinin satýrlarýdýr. Bu denklemler $X$'in öðelerine göre
lineerdir. Bu sistemden hareketle $AX=0$'daki $A$ þöyle, 

$$ A = \left[\begin{array}{c}
xp^{3T} - p^{1T} \\ 
yp^{3T} - p^{2T} \\
x'p'^{3T} - p'^{1T} \\
y'p'^{3T} - p'^{2T} 
\end{array}\right]$$

Her iki imajdan iki denklem alýndý, toplam 4 denklem oldu. Bu denklem SVD
ile, ya da $AX=b$ þeklinde tekrar düzenlenip 2. derste gördüðümüz sözde ters
(pseudoinverse) ile çözülebilir. Altta bu yöntem takip edildi,

\begin{minted}[fontsize=\footnotesize]{python}
import scipy.linalg as lin

def triangulate_point(u1, u2, P1, P2):
  A = [[u1[0]*P1[2,0]-P1[0,0],u1[0]*P1[2,1]-P1[0,1],u1[0]*P1[2,2]-P1[0,2]],
       [u1[1]*P1[2,0]-P1[1,0],u1[1]*P1[2,1]-P1[1,1],u1[1]*P1[2,2]-P1[1,2]],
       [u2[0]*P2[2,0]-P2[0,0],u2[0]*P2[2,1]-P2[0,1],u2[0]*P2[2,2]-P2[0,2]],
       [u2[1]*P2[2,0]-P2[1,0],u2[1]*P2[2,1]-P2[1,1],u2[1]*P2[2,2]-P2[1,2]]]
  B = [[-(u1[0]*P1[2,3]-P1[0,3])],
       [-(u1[1]*P1[2,3]-P1[1,3])],
       [-(u2[0]*P2[2,3]-P2[0,3])],
       [-(u2[1]*P2[2,3]-P2[1,3])]]
  A = np.array(A)
  B = np.array(B)
  X = lin.lstsq(A,B)[0].T[0]
  res = np.array([X[0],X[1],X[2],1])
  return res

def triangulate(x1, x2, P1, P2):
  X = [triangulate_point(x1[i, :], x2[i, :], P1, P2) for i in range(len(x1))]
  return np.array(X).T
\end{minted}

Test amaçlý olarak bilinen \verb!P1,P2! ve yine iki boyutta eþliði bilinen
noktalarla üçgenleme yapalým, sonra elde edilen üç boyutlu noktalarý
kameralara yansýtalým ve baþladýðýmýz imaj noktalarýna uyuyor mu kontrol
edelim.

\begin{minted}[fontsize=\footnotesize]{python}
P1 = np.eye(4)
P2 = np.array([[ 0.878, -0.01 ,  0.479, -1.995],
              [ 0.01 ,  1.   ,  0.002, -0.226],
              [-0.479,  0.002,  0.878,  0.615],
              [ 0.   ,  0.   ,  0.   ,  1.   ]])
# Homogeneous arrays
x1real = np.array([[ 0.091,  0.167,  0.231,  0.083,  0.154],
                   [ 0.364,  0.333,  0.308,  0.333,  0.308],
                   [ 1.   ,  1.   ,  1.   ,  1.   ,  1.   ]])
x2real = np.array([[ 0.42 ,  0.537,  0.645,  0.431,  0.538],
                   [ 0.389,  0.375,  0.362,  0.357,  0.345],
                   [ 1.   ,  1.   ,  1.   ,  1.   ,  1.   ]])
X = triangulate( x1real.T, x2real.T, P1, P2 )
X /= X[3]
x1 = np.dot(P1[:3],X)
x2 = np.dot(P2[:3],X)
x1 /= x1[2]
x2 /= x2[2]
 
print 'X', X
print 'x', x1
print 'x2', x2
\end{minted}

\begin{verbatim}
X [[  1.00277411   2.00859585   3.01259205   1.00350223   2.01053989]
 [  4.01217675   4.01023497   4.01743619   4.02955748   4.01893278]
 [ 11.01977032  12.02833872  13.04162674  12.0914948   13.05493008]
 [  1.           1.           1.           1.           1.        ]]
x [[ 0.09099773  0.16698863  0.23099818  0.0829924   0.15400618]
 [ 0.36408896  0.33339891  0.30804717  0.33325553  0.3078479 ]
 [ 1.          1.          1.          1.          1.        ]]
x2 [[ 0.4200205   0.53709008  0.64501081  0.43105574  0.5379661 ]
 [ 0.38890029  0.37453124  0.36194221  0.35671322  0.34517828]
 [ 1.          1.          1.          1.          1.        ]]
\end{verbatim}

Ana problemimize dönelim; þimdi ikinci kamera için ayrýþtýrmadan elde
edilen $R,t$ sonuçlarýný kamera matrisi $K$ ile çarparak $P_2$ oluþturulmak
lazým ($P_1$ birim matrisi, o biliniyor), ve böylece her imaj nokta eþleri
için üçgenleme yapacaðýz. Fakat 8. derste bahsedildiði gibi $E$'nin
ayrýþtýrmasýndan dört türlü farklý $R,t$ olasýlýðý ortaya çýkýyor, bu
sonuçlarýn her biri denenmeli. Altta bunu yapýyoruz, yani her seçenek için
bir üç boyutta tekrar oluþturma yapacaðýz, ve sonuçlarý farklý grafiklerde
göstereceðiz.

\begin{minted}[fontsize=\footnotesize]{python}
for i,P in enumerate(((R1,t),(R1,-t),(R2,t),(R2,-t))):

    P1 = K.dot(np.hstack(P))
    P00 = np.float64([ [1,0,0,0],
                       [0,1,0,0],
                       [0,0,1,0]])
    P0 = K.dot(P00) 

    X = triangulate(pts1, pts2, P0, P1)

    fig = plt.figure()
    ax = fig.gca(projection='3d')    
    ax.plot(X[0], X[2], X[1], 'r.')
    ax.view_init(elev=23., azim=-67)
    plt.savefig('vision_20recons_03_%d.png' % i)
\end{minted}

\includegraphics[width=20em]{vision_20recons_03_0.png}
\includegraphics[width=20em]{vision_20recons_03_1.png}
\includegraphics[width=20em]{vision_20recons_03_2.png}
\includegraphics[width=20em]{vision_20recons_03_3.png}

Galiba alt saðdaki resim Alkatraz'a daha çok benziyor. Gerçek dünya
uygulamalarýnda ``kamera önüne düþen en çok nokta hangisinde'' gibi ek
kodlar geliþtirip gerçek 3D sonucu bu þekilde elenebiliyor. 

Kaynaklar

[1] Zisserman, {\em Multiple View Geometry in Computer Vision 2nd Edition}

[2] Bayramlý, {\em Resim 1}, \url{https://www.dropbox.com/s/luuymnbh1njmz1v/alcatraz1.jpg?dl=1}

[3] Bayramlý, {\em Resim 2}, \url{https://www.dropbox.com/s/ms3cp4htkxd8pw8/alcatraz2.jpg?dl=1}


\end{document}

