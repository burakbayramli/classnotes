<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
    <script type="text/x-mathjax-config">
    MathJax.Hub.Register.StartupHook("TeX Jax Ready",function () {
      MathJax.Hub.Insert(MathJax.InputJax.TeX.Definitions.macros,{
        cancel: ["Extension","cancel"], cancelto: ["Extension","cancel"]
      });
    });
    </script>  
   
  <title>Ortalama Kaydırma ile Kümeleme (Mean Shift Clustering)</title>
  <style type="text/css">code{white-space: pre;}</style>
  <style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
  </style>
</head>
<body>
<div id="header">
</div>
<h1 id="ortalama-kaydırma-ile-kümeleme-mean-shift-clustering">Ortalama
Kaydırma ile Kümeleme (Mean Shift Clustering)</h1>
<p>Kümeleme yapmak için bir metot daha: Ortalama Kaydırma metotu. Bu
metodun mesela GMM gibi bir metottan farkı, küme sayısının önceden
belirtilmeye ihtiyacı olmamasıdır, küme sayısı otomatik olarak metot
tarafından saptanır.</p>
<p>“Küme” olarak saptanan aslında veri içindeki tüm yoğunluk
bölgelerinin merkezleridir, yani alttaki resmin sağ kısmındaki
bölgeler.</p>
<p><img src="dist.png" /></p>
<p>Başlangıç neresidir? Başlangıç tüm noktalardır, yani her noktadan
başlanarak</p>
<ol type="1">
<li><p>O nokta etrafında (yeterince büyük) bir pencere tanımla</p></li>
<li><p>Bu pencere içine düşen tüm noktaları hesaba katarak bir ortalama
yer hesapla</p></li>
<li><p>Pencereyi yeni ortalama noktayı merkezine alacak şekilde
kaydır</p></li>
</ol>
<p>Metotun ismi buradan geliyor, çünkü pencere yeni ortalamaya doğru
“kaydırılıyor”. Altta bir noktadan başlanarak yapılan hareketi
görüyoruz. Kaymanın sağa doğru olması mantıklı çünkü tek pencere içinden
bakınca bile yoğunluğun “sağ tarafa doğru” olduğu görülmekte. Yöntemin
püf noktası burada.</p>
<p><img src="mean_2.png" /> <img src="mean_3.png" /></p>
<p><img src="mean_4.png" /> <img src="mean_5.png" /></p>
<p><img src="mean_6.png" /> <img src="mean_7.png" /></p>
<p>Eğer yoğunluk merkezine çok yakın bir noktadan / noktalardan
başlamışsak ne olur?</p>
<p>O zaman ilerleme o başlangıç noktası için anında bitecek, çünkü hemen
yoğunluk merkezine gelmiş olacağız. Diğer yönlerden gelen pencereler de
aynı yere gelecekler tabii, o zaman aynı / yakın yoğunluk merkezlerini
aynı küme olarak kabul etmemiz gerekir. Bu “aynı küme irdelemesi”
sayısal hesaplama açısından ufak farklar gösterebilir tabii, ve bu ufak
farkı gözönüne alarak “küme birleştirme” mantığını da eklemek
gerekiyor.</p>
<p>Ortalama Kaydırma sisteminde pencere büyüklüğü kullanıcı tarafından
tanımlanır. Optimal pencere büyüklüğünü nasıl buluruz? Deneme yanılma
yöntemi, verinin tarifsel istatistiklerine kestirme bir hesap (estimate)
etmek, ya da kullanıcının aynı istatistiklere bakarak tahminde
bulunması. Birkaç farklı pencere büyüklüğü de denenebilir. Bu konu
literatürde (İng. bandwidth selection) adı altında uzun uzadıya
tartışılmaktadır.</p>
<p>Eğer yoğunluk merkezine çok yakın bir noktadan / noktalardan
başlamışsak ne olur?</p>
<p>O zaman ilerleme o başlangıç noktası için anında bitecek, çünkü hemen
yoğunluk merkezine gelmiş olacağız. Diğer yönlerden gelen pencereler de
aynı yere gelecekler tabii, o zaman aynı / yakın yoğunluk merkezlerini
aynı küme olarak kabul etmemiz gerekir. Bu “aynı küme irdelemesi”
sayısal hesaplama açısından ufak farklar gösterebilir tabii, ve bu ufak
farkı gözönüne alarak “küme birleştirme” mantığını da eklemek
gerekiyor.</p>
<p><img src="start.png" /></p>
<p>Altta örnek veri ve kodu bulunabilir. Metot küme sayısı 17’yi
otomatik olarak buluyor (gerçek küme sayısı 20, bkz [7] yazısı).</p>
<p>Alternatif bir kod <code>meanshift_alternatıve.py</code> dosyasında
bulunabilir, bu kod pencereler kaydırırken onların üzerinden geçtiği
noktaları “sahiplenen” türden bir kod. Yani [encere hareketini
durdurduğunda hem küme merkezini hem de o kümenin altındaki noktaları
bulmuş oluyoruz. Tabii sonraki pencereler bazı noktaları önceki
kümelerden çalabilirler. Neyse, işlemin normal işleyişine göre bir
sonraki pencere seçilecektir ve bu pencere “geriye kalan noktalar”
üzerinden işlem yapacaktır. Beklenir ki, işlem ilerledikçe işlenmesi
gereken noktalar azalacaktır ve yöntemin bu sebeple klasik yönteme göre
daha hızlı işleyeceği tahmin edilebilir. Hakikaten de böyledir.</p>
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pandas <span class="im">import</span> <span class="op">*</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> read_csv(<span class="st">&quot;../algs_080_kmeans/synthetic2.txt&quot;</span>,comment<span class="op">=</span><span class="st">&#39;#&#39;</span>,header<span class="op">=</span><span class="va">None</span>,sep<span class="op">=</span><span class="st">&quot;;&quot;</span>)</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (data.shape)</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> np.array(data)</span></code></pre></div>
<pre class="text"><code>(3000, 2)</code></pre>
<div class="sourceCode" id="cb3"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>plt.scatter(data[:,<span class="dv">0</span>],data[:,<span class="dv">1</span>])</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>plt.savefig(<span class="st">&#39;meanshift_1.png&#39;</span>)</span></code></pre></div>
<p><img src="meanshift_1.png" /></p>
<div class="sourceCode" id="cb4"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.neighbors <span class="im">import</span> NearestNeighbors</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy.linalg <span class="im">as</span> lin</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> mean_shift(X, bandwidth<span class="op">=</span><span class="va">None</span>, max_iterations<span class="op">=</span><span class="dv">300</span>):</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>    seeds <span class="op">=</span> X</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>    n_samples, n_features <span class="op">=</span> X.shape</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>    stop_thresh <span class="op">=</span> <span class="fl">1e-3</span> <span class="op">*</span> bandwidth  <span class="co"># when mean has converged</span></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>    center_intensity_dict <span class="op">=</span> {}</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>    nbrs <span class="op">=</span> NearestNeighbors(radius<span class="op">=</span>bandwidth).fit(X)</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># For each seed, climb gradient until convergence or max_iterations</span></span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> my_mean <span class="kw">in</span> seeds:</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>        completed_iterations <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>        <span class="cf">while</span> <span class="va">True</span>:</span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Find mean of points within bandwidth</span></span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>            i_nbrs <span class="op">=</span> nbrs.radius_neighbors([my_mean], bandwidth,</span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>                                           return_distance<span class="op">=</span><span class="va">False</span>)[<span class="dv">0</span>]</span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>            points_within <span class="op">=</span> X[i_nbrs]</span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> <span class="bu">len</span>(points_within) <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a>                <span class="cf">break</span>  <span class="co"># Depending on seeding strategy this condition may occur</span></span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a>            my_old_mean <span class="op">=</span> my_mean  <span class="co"># save the old mean</span></span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a>            my_mean <span class="op">=</span> np.mean(points_within, axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a>            <span class="co"># If converged or at max_iterations, addS the cluster</span></span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> (lin.norm(my_mean <span class="op">-</span> my_old_mean) <span class="op">&lt;</span> stop_thresh <span class="kw">or</span></span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a>                    completed_iterations <span class="op">==</span> max_iterations):</span>
<span id="cb4-27"><a href="#cb4-27" aria-hidden="true" tabindex="-1"></a>                center_intensity_dict[<span class="bu">tuple</span>(my_mean)] <span class="op">=</span> <span class="bu">len</span>(points_within)</span>
<span id="cb4-28"><a href="#cb4-28" aria-hidden="true" tabindex="-1"></a>                <span class="cf">break</span></span>
<span id="cb4-29"><a href="#cb4-29" aria-hidden="true" tabindex="-1"></a>            completed_iterations <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb4-30"><a href="#cb4-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-31"><a href="#cb4-31" aria-hidden="true" tabindex="-1"></a>    <span class="co"># POST PROCESSING: remove near duplicate points</span></span>
<span id="cb4-32"><a href="#cb4-32" aria-hidden="true" tabindex="-1"></a>    <span class="co"># If the distance between two kernels is less than the bandwidth,</span></span>
<span id="cb4-33"><a href="#cb4-33" aria-hidden="true" tabindex="-1"></a>    <span class="co"># then we have to remove one because it is a duplicate. Remove the</span></span>
<span id="cb4-34"><a href="#cb4-34" aria-hidden="true" tabindex="-1"></a>    <span class="co"># one with fewer points.</span></span>
<span id="cb4-35"><a href="#cb4-35" aria-hidden="true" tabindex="-1"></a>    sorted_by_intensity <span class="op">=</span> <span class="bu">sorted</span>(center_intensity_dict.items(),</span>
<span id="cb4-36"><a href="#cb4-36" aria-hidden="true" tabindex="-1"></a>                                 key<span class="op">=</span><span class="kw">lambda</span> tup: tup[<span class="dv">1</span>], reverse<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb4-37"><a href="#cb4-37" aria-hidden="true" tabindex="-1"></a>    sorted_centers <span class="op">=</span> np.array([tup[<span class="dv">0</span>] <span class="cf">for</span> tup <span class="kw">in</span> sorted_by_intensity])</span>
<span id="cb4-38"><a href="#cb4-38" aria-hidden="true" tabindex="-1"></a>    unique <span class="op">=</span> np.ones(<span class="bu">len</span>(sorted_centers), dtype<span class="op">=</span>np.<span class="bu">bool</span>)</span>
<span id="cb4-39"><a href="#cb4-39" aria-hidden="true" tabindex="-1"></a>    nbrs <span class="op">=</span> NearestNeighbors(radius<span class="op">=</span>bandwidth).fit(sorted_centers)</span>
<span id="cb4-40"><a href="#cb4-40" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i, center <span class="kw">in</span> <span class="bu">enumerate</span>(sorted_centers):</span>
<span id="cb4-41"><a href="#cb4-41" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> unique[i]:</span>
<span id="cb4-42"><a href="#cb4-42" aria-hidden="true" tabindex="-1"></a>            neighbor_idxs <span class="op">=</span> nbrs.radius_neighbors([center],</span>
<span id="cb4-43"><a href="#cb4-43" aria-hidden="true" tabindex="-1"></a>                                                  return_distance<span class="op">=</span><span class="va">False</span>)[<span class="dv">0</span>]</span>
<span id="cb4-44"><a href="#cb4-44" aria-hidden="true" tabindex="-1"></a>            unique[neighbor_idxs] <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb4-45"><a href="#cb4-45" aria-hidden="true" tabindex="-1"></a>            unique[i] <span class="op">=</span> <span class="dv">1</span>  <span class="co"># leave the current point as unique</span></span>
<span id="cb4-46"><a href="#cb4-46" aria-hidden="true" tabindex="-1"></a>    cluster_centers <span class="op">=</span> sorted_centers[unique]</span>
<span id="cb4-47"><a href="#cb4-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-48"><a href="#cb4-48" aria-hidden="true" tabindex="-1"></a>    <span class="co"># ASSIGN LABELS: a point belongs to the cluster that it is closest to</span></span>
<span id="cb4-49"><a href="#cb4-49" aria-hidden="true" tabindex="-1"></a>    nbrs <span class="op">=</span> NearestNeighbors(n_neighbors<span class="op">=</span><span class="dv">1</span>).fit(cluster_centers)</span>
<span id="cb4-50"><a href="#cb4-50" aria-hidden="true" tabindex="-1"></a>    labels <span class="op">=</span> np.zeros(n_samples, dtype<span class="op">=</span><span class="bu">int</span>)</span>
<span id="cb4-51"><a href="#cb4-51" aria-hidden="true" tabindex="-1"></a>    distances, idxs <span class="op">=</span> nbrs.kneighbors(X)</span>
<span id="cb4-52"><a href="#cb4-52" aria-hidden="true" tabindex="-1"></a>    labels <span class="op">=</span> idxs.flatten()</span>
<span id="cb4-53"><a href="#cb4-53" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb4-54"><a href="#cb4-54" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> cluster_centers, labels</span>
<span id="cb4-55"><a href="#cb4-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-56"><a href="#cb4-56" aria-hidden="true" tabindex="-1"></a>cluster_centers, labels <span class="op">=</span> mean_shift(np.array(data), <span class="dv">4000</span>)</span>
<span id="cb4-57"><a href="#cb4-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-58"><a href="#cb4-58" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (<span class="bu">len</span>(cluster_centers))</span></code></pre></div>
<pre class="text"><code>17</code></pre>
<div class="sourceCode" id="cb6"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>plt.scatter(data[:,<span class="dv">0</span>],data[:,<span class="dv">1</span>])</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> x <span class="kw">in</span> np.array(cluster_centers): plt.plot(x[<span class="dv">0</span>],x[<span class="dv">1</span>],<span class="st">&#39;rd&#39;</span>)</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>plt.savefig(<span class="st">&#39;meanshift_2.png&#39;</span>)</span></code></pre></div>
<p><img src="meanshift_2.png" /></p>
<p>Teorik Konular</p>
<p>Bu metotu teorik bir yapıya oturtmak için onu yazının ilk başındaki
resimde olduğu gibi görmek gerekiyor, yani mesela o ilk resmin sağındaki
2 boyuttaki veri dağılımı (ki ayrıksal, sayısal), 3 boyuttaki sürekli
(continuous) bir başka dağılımın yansıması sanki, ki o zaman 2 boyuttaki
yoğunluk bölgeleri sürekli dağılımdaki tepe noktalarını temsil
ediyorlar, ve biz o sürekli versiyondaki tepe noktalarını bulmalıyız.
Fakat kümeleme işleminin elinde sadece 2 boyuttaki veriler var, o zaman
sürekli dağılımı bir şekilde yaratmak lazım.</p>
<p>Bunu yapmak için problem / veri önce bir Çekirdek Yoğunluk Kestirimi
(Kernel Density Estimation -KDE-) problemi gibi görülüyor, ki her nokta
üzerine bir çekirdek fonksiyonu koyularak ve onların toplamı alınarak
sayısal dağılım pürüzsüz bir hale getiriliyor. Ortalama Kaydırma için
gerekli kayma “yönü” ise işte bu yeni sürekli fonksiyonun gradyanıdır
deniyor (elimizde bir sürekli fonksiyon olduğu için türev rahatlıkla
alabiliyoruz), ve gradyan yerel tepe noktasını gösterdiği için o yöne
yapılan hareket bizi yavaş yavaş tepeye götürecektir. Bu hareketin yerel
tepeleri bulacağı, ve tüm yöntemin nihai olarak sonuca yaklaşacağı
(convergence) matematiksel olarak ispat edilebilir.</p>
<p>KDE ile elde edilen teorik dağılım fonksiyonunun içbükey olup
olmadığı önemli değil (ki mesela lojistik regresyonda bu önemliydi),
çünkü nihai tepe noktasını değil, birkaç yerel tepe noktasından birini
(hatta hepsini) bulmakla ilgileniyoruz. Gradyan bizi bu noktaya
taşıyacaktır.</p>
<p>Kaynaklar</p>
<p>[1] Babu, <em>Mean-Shift : Theory</em>, <a
href="http://www.serc.iisc.ernet.in/~venky/SE263/slides/Mean-Shift-Theory.pdf">http://www.serc.iisc.ernet.in/~venky/SE263/slides/Mean-Shift-Theory.pdf</a></p>
<p>[2] Thirumuruganathan, <em>Introduction To Mean Shift Algorithm</em>,
<a
href="http://saravananthirumuruganathan.wordpress.com/2010/04/01/introduction-to-mean-shift-algorithm/">http://saravananthirumuruganathan.wordpress.com/2010/04/01/introduction-to-mean-shift-algorithm/</a></p>
<p>[3] Derpanis, <em>Mean Shift Clustering</em>, <a
href="http://www.cse.yorku.ca/~kosta/CompVis_Notes/mean_shift.pdf">http://www.cse.yorku.ca/~kosta/CompVis_Notes/mean_shift.pdf</a></p>
<p>[4] Fisher, <em>Mean Shift Clustering</em>, <a
href="http://homepages.inf.ed.ac.uk/rbf/CVonline/LOCAL_COPIES/TUZEL1/MeanShift.pdf">http://homepages.inf.ed.ac.uk/rbf/CVonline/LOCAL_COPIES/TUZEL1/MeanShift.pdf</a></p>
<p>[5] Scikit Learn, <em>Documentation</em>, <a
href="http://scikit-learn.org">http://scikit-learn.org</a></p>
<p>[6] Gingold, <a
href="http://yotamgingold.com/code/MeanShiftCluster.py">http://yotamgingold.com/code/MeanShiftCluster.py</a></p>
<p>[7] Bayramlı, Istatistik, <em>GMM ile Kümelemek</em></p>
<p>
  <a href="..">Yukarı</a>
</p>
</body>
</html>
