<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
    <script type="text/x-mathjax-config">
    MathJax.Hub.Register.StartupHook("TeX Jax Ready",function () {
      MathJax.Hub.Insert(MathJax.InputJax.TeX.Definitions.macros,{
        cancel: ["Extension","cancel"], cancelto: ["Extension","cancel"]
      });
    });
    </script>  
   
  <title>Optik Karakter Tanıma, Yazı Tanıma (Optical Character Recognition -OCR-)</title>
  <style type="text/css">code{white-space: pre;}</style>
  <style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
  </style>
  <script
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS_HTML-full"
  type="text/javascript"></script>
</head>
<body>
<div id="header">
</div>
<h1
id="optik-karakter-tanıma-yazı-tanıma-optical-character-recognition--ocr-">Optik
Karakter Tanıma, Yazı Tanıma (Optical Character Recognition -OCR-)</h1>
<p>OCR, iki dizini birbiriyle uyuşturma problemi olarak görülebilir.
Dizi derken neden bahsetmek istediğimi anlatmaya uğrasayım. Çoğunlukla
tanımak istediğimiz görüntü bir kelime, bir sayı dizisidir, ve bu dizi
ufak ya da büyük bir kelime olabilir. Girdi ise boyutları önceden
tanımlanan görüntüyü temsil eden veri parçaları olacaktır, bu görüntü
bir kelimeye odaklanabilir, görüntü aktarılmadan önce o kelime bir kare
içine alınmaya çalışır.</p>
<p>Kelime görüntüsünü bir evrişim tabakası üzerinden mesela işlenmiş
veriler olarak parça parça, kesitler olarak alabiliriz. Ardından veri
parçalarının zamansal ilintilerini yakalayabilmek için onları bir LSTM
katmanına verebiliriz, ve her zaman adımındaki alfabe boyutundaki
çıktılar, bir vektör olarak, her hücrede belli bir harfin olma olasılığı
olarak ayarlanabilir. Eğer en son katmandan sonra uygun bir hata
fonksiyonu tanımlayabilirsek bilinen etiketli kelimeler, onların
görüntüsünü içeren eğitim verisi üzerinden tüm bu yapıyı
eğitebiliriz.</p>
<p><img src="ocr_01.png" /></p>
<p>Üstteki figürde İngilizce apple (elma) kelimesini görüyoruz. Girdi
görüntü (input image) genişliği 128, yüksekliği 64 ve üç kanal var, bu
kanallar her renk için R,G,B olabilir. İlk önce evrişimsel sinir ağı
özellik çıkartma (CNN feature extraction) katmanı ile özellik bulmaya
uğraşılıyor, buradan (4,8,4) boyutunda bir tensor elde ediliyor. Bu
tensor (16,8) boyutuna getiriliyor, bu yeni tensor’daki her kolon (biri
yeşille işaretli) önceki tensorda bir parçaya tekabül eder, yani kelime
görüntüsünün bir parçasına.</p>
<p>Ardından şekillendirme (reshape) sonrası alınan yeni tensoru parça
parça LSTM tabakasına veriyoruz, ilk LSTM hücresi mesela alttaki
gibi,</p>
<p><img src="ocr_02.png" /></p>
<p>LSTM sonrası tamamen bağlanmış (fully-connected) tabaka ve softmax
ile alfabe tahmini üretiliyor. Bu örnekte alfabede 6 karakter var, bu
sebeple vektör (6,1) boyutlu, karakterler ‘a’,‘e’,‘l’,‘p’,‘z’,‘-’. En
son ‘-’ karakteri “boş karakter’’ demek, boş karakterin niye lazım
olduğunu göreceğiz. Vektördeki ilk hücre <span
class="math inline">\(y_a^1\)</span> yani ‘a’, o noktada ‘a’
karakterinin olma olasılığı. Diğerleri o birinci hücre için aşağı doğru
<span class="math inline">\(y_e^1\)</span>, <span
class="math inline">\(y_l^1\)</span>, vs. diye devam edecek. Şimdi tüm
LSTM hücrelerini iceren resme bakalım,</p>
<p><img src="ocr_03.png" /></p>
<p>Şimdi elimizde 8 tane 6 boyutlu softmax vektörü var.</p>
<p>Bu noktada iki sorumuz var: ilki YSA eğitimi bağlamında nasıl bir
kayıp fonksiyonu bulalım ki uyan kelimeler için az, kötü uyanlar için
yüksek rakam üretsin, ikincisi farklı boyutlardaki iki vektörün
birbirine uyması ne demektir? Tüm bunlar tabii ki üstteki softmax
vektörlerini nasıl dekode edip bir kelime üretiriz sorusu ile yakın
alakalı.</p>
<p>Uyum konusu önemli çünkü el yazısı, ya da font seçimi dolasıyla bazı
karakterler diğerlerinden daha fazla yer tutuyor olabilir. Aynı şey ses
tanıma için de geçerli, “merhaba’’ derken kimisi”meeeerhaba’’ demiş
olabilir, burada ‘e’ harfinden daha fazla ses verisi alınacaktır, ama o
noktada üzerinde olunan harf değişmemiştir.</p>
<p>Dekode için akla gelebilecek ilk yaklaşım her vektör için en yüksek
olasılıktaki hücreye tekabül eden karakteri seçmek (find the most
probable symbol), sonra bir ek işlem tabakasına giderek bazı elemeler,
düzeltmeler yaparak bir kelimeye erişmeye uğraşmak. Mesela en olasılı
karakter seçimi sonrası arka arka gelen tekrar eden harfleri çıkartırız,
sonra boş karakteri çıkartırız,</p>
<p><img src="ocr_04.png" /></p>
<p>Tüm bunlar oldukca basit görünüyor. Fakat tüm bu işlemleri bir kayıp
fonksiyonu olarak kullanmak istersek işler karışıyor. Çünkü kelime
bulmaya uğraşırken softmax’lerde başlangıçtan sona pek çok farklı gidiş
yolu var, tüm kombinasyonları işlemek zor.</p>
<p><img src="ocr_05.png" /></p>
<p>Ayrıca üstteki kısaltma algoritması en iyi sonucu da her zaman
vermeyebilir. Kombinasyon derken üstteki örnek için bile <span
class="math inline">\(6^8 = 1,679,616\)</span> tane seçenekten
bahsediyoruz. Daha büyük bir sözlük, ve daha fazla LSTM adımı için bu
sayı astronomik boyutlara varabilir.</p>
<p>Çözüm nedir? Seçenekler arasından uygun yolu bulup hesaplayan, ya da
verili bir etiket için olurluk (likelihood) hesabı yapan bir yaklaşım
var, buna bağlantısal zamansal bedel (connectionist temporal cost) adı
veriliyor, detaylar için [1,2,3]. CTC dinamik programlama kullanır,
ayrıca yolu hesaplarken Gizli Markov Modellerine benzer <span
class="math inline">\(\alpha,\beta\)</span> fonksiyonları yaratır, ve
YSA öğrenimi bağlamında bu fonksiyonlar üzerinden gradyan hesabı mümkün
oluyor, ve farklı boyuttaki girdi / çıktı arasındaki uyuşma, eğitim işte
bu şekilde yapılıyor.</p>
<p>TensorFlow ile CTC</p>
<p>TF ile CTC hesabını görelim. Alttaki çıktının daha önce şemasını
verdiğimiz YSA’ya benzer bir yapının son adımından çıkan softmax
olasılıkları olduğunu düşünelim. Verinin satırları her LSTM adımı, her
kolon alfabedeki farklı bir karakter.</p>
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>train_inputs_0 <span class="op">=</span> np.asarray(</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>    [[<span class="fl">0.633766</span>, <span class="fl">0.221185</span>, <span class="fl">0.0917319</span>, <span class="fl">0.0129757</span>, <span class="fl">0.0142857</span>, <span class="fl">0.0260553</span>],</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>     [<span class="fl">0.111121</span>, <span class="fl">0.588392</span>, <span class="fl">0.278779</span>, <span class="fl">0.0055756</span>, <span class="fl">0.00569609</span>, <span class="fl">0.010436</span>],</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>     [<span class="fl">0.0357786</span>, <span class="fl">0.633813</span>, <span class="fl">0.321418</span>, <span class="fl">0.00249248</span>, <span class="fl">0.00272882</span>, <span class="fl">0.0037688</span>],</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>     [<span class="fl">0.0663296</span>, <span class="fl">0.643849</span>, <span class="fl">0.280111</span>, <span class="fl">0.00283995</span>, <span class="fl">0.0035545</span>, <span class="fl">0.00331533</span>],</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>     [<span class="fl">0.458235</span>, <span class="fl">0.396634</span>, <span class="fl">0.123377</span>, <span class="fl">0.00648837</span>, <span class="fl">0.00903441</span>, <span class="fl">0.00623107</span>]],</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>    dtype<span class="op">=</span>np.float32)</span></code></pre></div>
<p>Bu yapı üzerinde için mesela <code>[0, 1, 2, 1, 0]</code> dizisini
kontrol etmemiz istense dizinin kaybı / hatası nedir?</p>
<div class="sourceCode" id="cb2"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tensorflow <span class="im">as</span> tf</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> sparse_tuple_from(sequences, dtype<span class="op">=</span>np.int32):</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>    indices <span class="op">=</span> []</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>    values <span class="op">=</span> []</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> n, seq <span class="kw">in</span> <span class="bu">enumerate</span>(sequences):</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>        indices.extend(<span class="bu">zip</span>([n] <span class="op">*</span> <span class="bu">len</span>(seq), <span class="bu">range</span>(<span class="bu">len</span>(seq))))</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>        values.extend(seq)</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>    indices <span class="op">=</span> np.asarray(indices, dtype<span class="op">=</span>np.int64)</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>    values <span class="op">=</span> np.asarray(values, dtype<span class="op">=</span>dtype)</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>    shape <span class="op">=</span> np.asarray([<span class="bu">len</span>(sequences), np.asarray(indices).<span class="bu">max</span>(<span class="dv">0</span>)[<span class="dv">1</span>] <span class="op">+</span> <span class="dv">1</span>], dtype<span class="op">=</span>np.int64)</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> indices, values, shape</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>train_seq_len <span class="op">=</span> [<span class="dv">5</span>]</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>num_features <span class="op">=</span> <span class="dv">6</span></span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>tf.reset_default_graph()</span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a>targets <span class="op">=</span> tf.sparse_placeholder(tf.int32)</span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a>logits1 <span class="op">=</span> tf.placeholder(tf.float32, [<span class="va">None</span>, num_features] )</span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a>logits2 <span class="op">=</span> tf.reshape(logits1, [<span class="dv">1</span>, <span class="op">-</span><span class="dv">1</span>, num_features])</span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a>logits3 <span class="op">=</span> tf.transpose(logits2, (<span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">2</span>))</span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a>seq_len <span class="op">=</span> tf.placeholder(tf.int32, [<span class="va">None</span>])</span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a>loss <span class="op">=</span> tf.nn.ctc_loss(targets, logits3, seq_len)</span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a>decoded, log_prob <span class="op">=</span> tf.nn.ctc_greedy_decoder(logits3, seq_len)</span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> tf.Session() <span class="im">as</span> sess:</span>
<span id="cb2-28"><a href="#cb2-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-29"><a href="#cb2-29" aria-hidden="true" tabindex="-1"></a>     sess.run(tf.global_variables_initializer())</span>
<span id="cb2-30"><a href="#cb2-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-31"><a href="#cb2-31" aria-hidden="true" tabindex="-1"></a>     train_targets <span class="op">=</span> sparse_tuple_from([[<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">1</span>, <span class="dv">0</span>]])     </span>
<span id="cb2-32"><a href="#cb2-32" aria-hidden="true" tabindex="-1"></a>     feed_t <span class="op">=</span> { logits1: train_inputs_0, </span>
<span id="cb2-33"><a href="#cb2-33" aria-hidden="true" tabindex="-1"></a>                targets: train_targets, </span>
<span id="cb2-34"><a href="#cb2-34" aria-hidden="true" tabindex="-1"></a>                seq_len: train_seq_len }</span>
<span id="cb2-35"><a href="#cb2-35" aria-hidden="true" tabindex="-1"></a>     res <span class="op">=</span> sess.run(loss, feed_t)     </span>
<span id="cb2-36"><a href="#cb2-36" aria-hidden="true" tabindex="-1"></a>     <span class="bu">print</span> <span class="st">u&#39;kayıp&#39;</span>, res</span></code></pre></div>
<pre><code>kayıp [ 7.27719784]</code></pre>
<p>Farklı veri, farklı çıktı,</p>
<div class="sourceCode" id="cb4"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>train_inputs_1 <span class="op">=</span> np.asarray(</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>    [[<span class="fl">0.30176</span>, <span class="fl">0.28562</span>, <span class="fl">0.0831517</span>, <span class="fl">0.0862751</span>, <span class="fl">0.0816851</span>, <span class="fl">0.161508</span>],</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>     [<span class="fl">0.24082</span>, <span class="fl">0.397533</span>, <span class="fl">0.0557226</span>, <span class="fl">0.0546814</span>, <span class="fl">0.0557528</span>, <span class="fl">0.19549</span>],</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>     [<span class="fl">0.230246</span>, <span class="fl">0.450868</span>, <span class="fl">0.0389607</span>, <span class="fl">0.038309</span>, <span class="fl">0.0391602</span>, <span class="fl">0.202456</span>],</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>     [<span class="fl">0.280884</span>, <span class="fl">0.429522</span>, <span class="fl">0.0326593</span>, <span class="fl">0.0339046</span>, <span class="fl">0.0326856</span>, <span class="fl">0.190345</span>],</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>     [<span class="fl">0.423286</span>, <span class="fl">0.315517</span>, <span class="fl">0.0338439</span>, <span class="fl">0.0393744</span>, <span class="fl">0.0339315</span>, <span class="fl">0.154046</span>]],</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>    dtype<span class="op">=</span>np.float32)</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> tf.Session() <span class="im">as</span> sess:</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>     sess.run(tf.global_variables_initializer())</span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>     train_targets <span class="op">=</span> sparse_tuple_from([[<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">0</span>]])     </span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>     feed_t <span class="op">=</span> { logits1: train_inputs_1, </span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>                targets: train_targets, </span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>                seq_len: train_seq_len }</span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>     res <span class="op">=</span> sess.run(loss, feed_t)     </span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>     <span class="bu">print</span> <span class="st">u&#39;kayıp&#39;</span>, res</span></code></pre></div>
<pre><code>kayıp [ 8.08572388]</code></pre>
<p>Şimdi ilginç bir veri, burada veri direk 2. karakter olsun diyor. O
zaman buna uyan çıktılar alçak (kayıp az), uymayanlar yüksek sonuç
vermeli,</p>
<div class="sourceCode" id="cb6"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>train_inputs_2 <span class="op">=</span> np.asarray(</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>    [[<span class="fl">0.0</span>, <span class="fl">0.0</span>, <span class="fl">1.0</span>, <span class="fl">0.0</span>, <span class="fl">0.0</span>, <span class="fl">0.0</span>],</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>     [<span class="fl">0.0</span>, <span class="fl">0.0</span>, <span class="fl">1.0</span>, <span class="fl">0.0</span>, <span class="fl">0.0</span>, <span class="fl">0.0</span>],</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>     [<span class="fl">0.0</span>, <span class="fl">0.0</span>, <span class="fl">1.0</span>, <span class="fl">0.0</span>, <span class="fl">0.0</span>, <span class="fl">0.0</span>],</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>     [<span class="fl">0.0</span>, <span class="fl">0.0</span>, <span class="fl">1.0</span>, <span class="fl">0.0</span>, <span class="fl">0.0</span>, <span class="fl">0.0</span>],</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>     [<span class="fl">0.0</span>, <span class="fl">0.0</span>, <span class="fl">1.0</span>, <span class="fl">0.0</span>, <span class="fl">0.0</span>, <span class="fl">0.0</span>]],</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>    dtype<span class="op">=</span>np.float32)</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> tf.Session() <span class="im">as</span> sess:</span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>     sess.run(tf.global_variables_initializer())</span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>     train_targets <span class="op">=</span> sparse_tuple_from([[<span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">2</span>]]) </span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>     feed_t <span class="op">=</span> { logits1: train_inputs_2, </span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a>                targets: train_targets, </span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a>                seq_len: train_seq_len }</span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a>     res <span class="op">=</span> sess.run(loss, feed_t)     </span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a>     <span class="bu">print</span> <span class="st">u&#39;kayıp&#39;</span>, res</span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a>     train_targets <span class="op">=</span> sparse_tuple_from([[<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">0</span>]]) </span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a>     feed_t <span class="op">=</span> { logits1: train_inputs_2, </span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a>                targets: train_targets, </span>
<span id="cb6-23"><a href="#cb6-23" aria-hidden="true" tabindex="-1"></a>                seq_len: train_seq_len }</span>
<span id="cb6-24"><a href="#cb6-24" aria-hidden="true" tabindex="-1"></a>     res <span class="op">=</span> sess.run(loss, feed_t)     </span>
<span id="cb6-25"><a href="#cb6-25" aria-hidden="true" tabindex="-1"></a>     <span class="bu">print</span> <span class="st">u&#39;kayıp&#39;</span>, res</span></code></pre></div>
<pre><code>kayıp [ 7.21795845]
kayıp [ 10.21795845]</code></pre>
<p>Dekode</p>
<p>TF CTC ile dekode işlemi de yapılabilir,</p>
<div class="sourceCode" id="cb8"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> tf.Session() <span class="im">as</span> sess:</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>     sess.run(tf.global_variables_initializer())</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>     feed_dec <span class="op">=</span> { logits1: train_inputs_0, seq_len: train_seq_len }</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>     decoded_res <span class="op">=</span> sess.run(decoded, feed_dec)     </span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>     <span class="bu">print</span> <span class="st">&#39;dekode&#39;</span>, decoded_res</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>     </span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>     feed_dec <span class="op">=</span> { logits1: train_inputs_1, seq_len: train_seq_len }</span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>     decoded_res <span class="op">=</span> sess.run(decoded, feed_dec)     </span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>     <span class="bu">print</span> <span class="st">&#39;dekode&#39;</span>, decoded_res</span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>     </span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>     feed_dec <span class="op">=</span> { logits1: train_inputs_2, seq_len: train_seq_len }</span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a>     decoded_res <span class="op">=</span> sess.run(decoded, feed_dec)     </span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a>     <span class="bu">print</span> <span class="st">&#39;dekode&#39;</span>, decoded_res</span></code></pre></div>
<pre><code>dekode [SparseTensorValue(indices=array([[0, 0],
       [0, 1],
       [0, 2]]), values=array([0, 1, 0]), dense_shape=array([1, 3]))]
dekode [SparseTensorValue(indices=array([[0, 0],
       [0, 1],
       [0, 2]]), values=array([0, 1, 0]), dense_shape=array([1, 3]))]
dekode [SparseTensorValue(indices=array([[0, 0]]), values=array([2]), dense_shape=array([1, 1]))]</code></pre>
<p>En son örnekte <code>values=array([2])</code> sonucu geldi, yani
dekode işlemi doğru bir şekilde tüm adımlar için tek bir seçim olan 2
seçimini yaptı. Bu seçim arka arkaya tekrarlanmış olacaktı tabii ki bu
sebeple bir kez gösteriliyor, appleeee yerine apple demek gibi.</p>
<p>Ağ Yapısı ve Kod</p>
<p>Şimdi örnek veriyi, alfabeyi genişletelim ve ağ yapısını daha
derinleştirelim. Altta gösterilen ağ yapısı [4] tezi ve onun esinlendiği
[5] kütüphanesini baz alıyor. Nihai kodda teze göre bazı boyut
değişiklikleri var, okur bunu akılda tutarak diyagramları, işlemleri
takip edebilir. Mimaride ilk evrişim tabakasında arka arkaya iki evrişim
ve max pool operasyonları var, sonra bir boyut değiştirme sonrası
tamamen bağlanmış (fully connected) bir tabakaya sonuç geçiliyor, oradan
çıkan sonuç iki yönlü (bi-directional) GRU tabakasına veriliyor. Bu
zamansal YSA ilk başta görülen tek LSTM seviyesinden daha çetrefil yani.
GRU hücreleri, LSTM hücre yapısının biraz daha basitleştirilmiş halidir.
Devam edelim, buradan çıkan sonuçlar bir başka yoğun tabakaya oradan da
softmax aktivasyonuna veriliyor, kayıp fonksiyonu CTC.</p>
<p><img src="ocr_07.png" /></p>
<div class="sourceCode" id="cb10"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># -*- coding: utf-8 -*-</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os, util</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> datetime</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> keras <span class="im">import</span> backend <span class="im">as</span> K</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> keras.layers.convolutional <span class="im">import</span> Conv2D, MaxPooling2D</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> keras.layers <span class="im">import</span> Input, Dense, Activation</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> keras.layers <span class="im">import</span> Reshape, Lambda</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> keras.layers.merge <span class="im">import</span> add, concatenate</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> keras.models <span class="im">import</span> Model</span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> keras.layers.recurrent <span class="im">import</span> GRU</span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> keras.optimizers <span class="im">import</span> SGD</span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> keras.utils.data_utils <span class="im">import</span> get_file</span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> keras.preprocessing <span class="im">import</span> image</span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> keras.callbacks</span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> ctc_lambda_func(args):</span>
<span id="cb10-18"><a href="#cb10-18" aria-hidden="true" tabindex="-1"></a>    y_pred, labels, input_length, label_length <span class="op">=</span> args</span>
<span id="cb10-19"><a href="#cb10-19" aria-hidden="true" tabindex="-1"></a>    <span class="co"># the 2 is critical here since the first couple outputs of the RNN</span></span>
<span id="cb10-20"><a href="#cb10-20" aria-hidden="true" tabindex="-1"></a>    <span class="co"># tend to be garbage:</span></span>
<span id="cb10-21"><a href="#cb10-21" aria-hidden="true" tabindex="-1"></a>    y_pred <span class="op">=</span> y_pred[:, <span class="dv">2</span>:, :]</span>
<span id="cb10-22"><a href="#cb10-22" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> K.ctc_batch_cost(labels, y_pred, input_length, label_length)</span>
<span id="cb10-23"><a href="#cb10-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-24"><a href="#cb10-24" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_model(img_w,img_h,minibatch_size,pool_size):</span>
<span id="cb10-25"><a href="#cb10-25" aria-hidden="true" tabindex="-1"></a>    conv_filters <span class="op">=</span> <span class="dv">20</span></span>
<span id="cb10-26"><a href="#cb10-26" aria-hidden="true" tabindex="-1"></a>    kernel_size <span class="op">=</span> (<span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb10-27"><a href="#cb10-27" aria-hidden="true" tabindex="-1"></a>    time_dense_size <span class="op">=</span> <span class="dv">32</span></span>
<span id="cb10-28"><a href="#cb10-28" aria-hidden="true" tabindex="-1"></a>    rnn_size <span class="op">=</span> <span class="dv">256</span></span>
<span id="cb10-29"><a href="#cb10-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-30"><a href="#cb10-30" aria-hidden="true" tabindex="-1"></a>    input_shape <span class="op">=</span> (img_w, img_h, <span class="dv">1</span>)</span>
<span id="cb10-31"><a href="#cb10-31" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb10-32"><a href="#cb10-32" aria-hidden="true" tabindex="-1"></a>    img_gen <span class="op">=</span> util.TextImageGenerator(minibatch_size<span class="op">=</span>minibatch_size,</span>
<span id="cb10-33"><a href="#cb10-33" aria-hidden="true" tabindex="-1"></a>                                      img_w<span class="op">=</span>img_w,</span>
<span id="cb10-34"><a href="#cb10-34" aria-hidden="true" tabindex="-1"></a>                                      img_h<span class="op">=</span>img_h,</span>
<span id="cb10-35"><a href="#cb10-35" aria-hidden="true" tabindex="-1"></a>                                      downsample_factor<span class="op">=</span>(pool_size <span class="op">**</span> <span class="dv">2</span>),</span>
<span id="cb10-36"><a href="#cb10-36" aria-hidden="true" tabindex="-1"></a>                                      absolute_max_string_len<span class="op">=</span><span class="dv">12</span></span>
<span id="cb10-37"><a href="#cb10-37" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb10-38"><a href="#cb10-38" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb10-39"><a href="#cb10-39" aria-hidden="true" tabindex="-1"></a>    act <span class="op">=</span> <span class="st">&#39;relu&#39;</span></span>
<span id="cb10-40"><a href="#cb10-40" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb10-41"><a href="#cb10-41" aria-hidden="true" tabindex="-1"></a>    input_data <span class="op">=</span> Input(name<span class="op">=</span><span class="st">&#39;the_input&#39;</span>, shape<span class="op">=</span>input_shape, dtype<span class="op">=</span><span class="st">&#39;float32&#39;</span>)</span>
<span id="cb10-42"><a href="#cb10-42" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb10-43"><a href="#cb10-43" aria-hidden="true" tabindex="-1"></a>    inner <span class="op">=</span> Conv2D(conv_filters, kernel_size, padding<span class="op">=</span><span class="st">&#39;same&#39;</span>,</span>
<span id="cb10-44"><a href="#cb10-44" aria-hidden="true" tabindex="-1"></a>                   activation<span class="op">=</span>act, kernel_initializer<span class="op">=</span><span class="st">&#39;he_normal&#39;</span>,</span>
<span id="cb10-45"><a href="#cb10-45" aria-hidden="true" tabindex="-1"></a>                   name<span class="op">=</span><span class="st">&#39;conv1&#39;</span>)(input_data)</span>
<span id="cb10-46"><a href="#cb10-46" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb10-47"><a href="#cb10-47" aria-hidden="true" tabindex="-1"></a>    inner <span class="op">=</span> MaxPooling2D(pool_size<span class="op">=</span>(pool_size, pool_size), name<span class="op">=</span><span class="st">&#39;max1&#39;</span>)(inner)</span>
<span id="cb10-48"><a href="#cb10-48" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb10-49"><a href="#cb10-49" aria-hidden="true" tabindex="-1"></a>    inner <span class="op">=</span> Conv2D(conv_filters, kernel_size, padding<span class="op">=</span><span class="st">&#39;same&#39;</span>,</span>
<span id="cb10-50"><a href="#cb10-50" aria-hidden="true" tabindex="-1"></a>                   activation<span class="op">=</span>act, kernel_initializer<span class="op">=</span><span class="st">&#39;he_normal&#39;</span>,</span>
<span id="cb10-51"><a href="#cb10-51" aria-hidden="true" tabindex="-1"></a>                   name<span class="op">=</span><span class="st">&#39;conv2&#39;</span>)(inner)</span>
<span id="cb10-52"><a href="#cb10-52" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb10-53"><a href="#cb10-53" aria-hidden="true" tabindex="-1"></a>    inner <span class="op">=</span> MaxPooling2D(pool_size<span class="op">=</span>(pool_size, pool_size), name<span class="op">=</span><span class="st">&#39;max2&#39;</span>)(inner)</span>
<span id="cb10-54"><a href="#cb10-54" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb10-55"><a href="#cb10-55" aria-hidden="true" tabindex="-1"></a>    conv_to_rnn_dims <span class="op">=</span> (img_w <span class="op">//</span> (pool_size <span class="op">**</span> <span class="dv">2</span>), (img_h <span class="op">//</span> (pool_size <span class="op">**</span> <span class="dv">2</span>))</span>
<span id="cb10-56"><a href="#cb10-56" aria-hidden="true" tabindex="-1"></a>                        <span class="op">*</span> conv_filters)</span>
<span id="cb10-57"><a href="#cb10-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-58"><a href="#cb10-58" aria-hidden="true" tabindex="-1"></a>    inner <span class="op">=</span> Reshape(target_shape<span class="op">=</span>conv_to_rnn_dims, name<span class="op">=</span><span class="st">&#39;reshape&#39;</span>)(inner)</span>
<span id="cb10-59"><a href="#cb10-59" aria-hidden="true" tabindex="-1"></a>    inner <span class="op">=</span> Dense(time_dense_size, activation<span class="op">=</span>act, name<span class="op">=</span><span class="st">&#39;dense1&#39;</span>)(inner)</span>
<span id="cb10-60"><a href="#cb10-60" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb10-61"><a href="#cb10-61" aria-hidden="true" tabindex="-1"></a>    gru_1 <span class="op">=</span> GRU(rnn_size, return_sequences<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb10-62"><a href="#cb10-62" aria-hidden="true" tabindex="-1"></a>                kernel_initializer<span class="op">=</span><span class="st">&#39;he_normal&#39;</span>, name<span class="op">=</span><span class="st">&#39;gru1&#39;</span>)(inner)</span>
<span id="cb10-63"><a href="#cb10-63" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb10-64"><a href="#cb10-64" aria-hidden="true" tabindex="-1"></a>    gru_1b <span class="op">=</span> GRU(rnn_size, return_sequences<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb10-65"><a href="#cb10-65" aria-hidden="true" tabindex="-1"></a>                 go_backwards<span class="op">=</span><span class="va">True</span>, kernel_initializer<span class="op">=</span><span class="st">&#39;he_normal&#39;</span>,</span>
<span id="cb10-66"><a href="#cb10-66" aria-hidden="true" tabindex="-1"></a>                 name<span class="op">=</span><span class="st">&#39;gru1_b&#39;</span>)(inner)</span>
<span id="cb10-67"><a href="#cb10-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-68"><a href="#cb10-68" aria-hidden="true" tabindex="-1"></a>    gru1_merged <span class="op">=</span> add([gru_1, gru_1b])</span>
<span id="cb10-69"><a href="#cb10-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-70"><a href="#cb10-70" aria-hidden="true" tabindex="-1"></a>    gru_2 <span class="op">=</span> GRU(rnn_size, return_sequences<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb10-71"><a href="#cb10-71" aria-hidden="true" tabindex="-1"></a>                kernel_initializer<span class="op">=</span><span class="st">&#39;he_normal&#39;</span>, name<span class="op">=</span><span class="st">&#39;gru2&#39;</span>)(gru1_merged)</span>
<span id="cb10-72"><a href="#cb10-72" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb10-73"><a href="#cb10-73" aria-hidden="true" tabindex="-1"></a>    gru_2b <span class="op">=</span> GRU(rnn_size, return_sequences<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb10-74"><a href="#cb10-74" aria-hidden="true" tabindex="-1"></a>                 go_backwards<span class="op">=</span><span class="va">True</span>, kernel_initializer<span class="op">=</span><span class="st">&#39;he_normal&#39;</span>,</span>
<span id="cb10-75"><a href="#cb10-75" aria-hidden="true" tabindex="-1"></a>                 name<span class="op">=</span><span class="st">&#39;gru2_b&#39;</span>)(gru1_merged)</span>
<span id="cb10-76"><a href="#cb10-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-77"><a href="#cb10-77" aria-hidden="true" tabindex="-1"></a>    inner <span class="op">=</span> Dense(img_gen.get_output_size(),</span>
<span id="cb10-78"><a href="#cb10-78" aria-hidden="true" tabindex="-1"></a>                  kernel_initializer<span class="op">=</span><span class="st">&#39;he_normal&#39;</span>,</span>
<span id="cb10-79"><a href="#cb10-79" aria-hidden="true" tabindex="-1"></a>                  name<span class="op">=</span><span class="st">&#39;dense2&#39;</span>)(concatenate([gru_2, gru_2b]))</span>
<span id="cb10-80"><a href="#cb10-80" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb10-81"><a href="#cb10-81" aria-hidden="true" tabindex="-1"></a>    y_pred <span class="op">=</span> Activation(<span class="st">&#39;softmax&#39;</span>, name<span class="op">=</span><span class="st">&#39;softmax&#39;</span>)(inner)</span>
<span id="cb10-82"><a href="#cb10-82" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb10-83"><a href="#cb10-83" aria-hidden="true" tabindex="-1"></a>    Model(inputs<span class="op">=</span>input_data, outputs<span class="op">=</span>y_pred).summary()</span>
<span id="cb10-84"><a href="#cb10-84" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-85"><a href="#cb10-85" aria-hidden="true" tabindex="-1"></a>    labels <span class="op">=</span> Input(name<span class="op">=</span><span class="st">&#39;the_labels&#39;</span>,</span>
<span id="cb10-86"><a href="#cb10-86" aria-hidden="true" tabindex="-1"></a>                   shape<span class="op">=</span>[img_gen.absolute_max_string_len],</span>
<span id="cb10-87"><a href="#cb10-87" aria-hidden="true" tabindex="-1"></a>                   dtype<span class="op">=</span><span class="st">&#39;float32&#39;</span>)</span>
<span id="cb10-88"><a href="#cb10-88" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-89"><a href="#cb10-89" aria-hidden="true" tabindex="-1"></a>    input_length <span class="op">=</span> Input(name<span class="op">=</span><span class="st">&#39;input_length&#39;</span>, shape<span class="op">=</span>[<span class="dv">1</span>], dtype<span class="op">=</span><span class="st">&#39;int64&#39;</span>)</span>
<span id="cb10-90"><a href="#cb10-90" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-91"><a href="#cb10-91" aria-hidden="true" tabindex="-1"></a>    label_length <span class="op">=</span> Input(name<span class="op">=</span><span class="st">&#39;label_length&#39;</span>, shape<span class="op">=</span>[<span class="dv">1</span>], dtype<span class="op">=</span><span class="st">&#39;int64&#39;</span>)</span>
<span id="cb10-92"><a href="#cb10-92" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-93"><a href="#cb10-93" aria-hidden="true" tabindex="-1"></a>    loss_out <span class="op">=</span> Lambda(ctc_lambda_func, output_shape<span class="op">=</span>(<span class="dv">1</span>,), name<span class="op">=</span><span class="st">&#39;ctc&#39;</span>)([y_pred,</span>
<span id="cb10-94"><a href="#cb10-94" aria-hidden="true" tabindex="-1"></a>                                                                       labels,</span>
<span id="cb10-95"><a href="#cb10-95" aria-hidden="true" tabindex="-1"></a>                                                                       input_length,</span>
<span id="cb10-96"><a href="#cb10-96" aria-hidden="true" tabindex="-1"></a>                                                                       label_length])</span>
<span id="cb10-97"><a href="#cb10-97" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-98"><a href="#cb10-98" aria-hidden="true" tabindex="-1"></a>    sgd <span class="op">=</span> SGD(lr<span class="op">=</span><span class="fl">0.02</span>, decay<span class="op">=</span><span class="fl">1e-6</span>, momentum<span class="op">=</span><span class="fl">0.9</span>, nesterov<span class="op">=</span><span class="va">True</span>, clipnorm<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb10-99"><a href="#cb10-99" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-100"><a href="#cb10-100" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> Model(inputs<span class="op">=</span>[input_data,</span>
<span id="cb10-101"><a href="#cb10-101" aria-hidden="true" tabindex="-1"></a>                          labels,</span>
<span id="cb10-102"><a href="#cb10-102" aria-hidden="true" tabindex="-1"></a>                          input_length,</span>
<span id="cb10-103"><a href="#cb10-103" aria-hidden="true" tabindex="-1"></a>                          label_length], outputs<span class="op">=</span>loss_out)</span>
<span id="cb10-104"><a href="#cb10-104" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-105"><a href="#cb10-105" aria-hidden="true" tabindex="-1"></a>    model.<span class="bu">compile</span>(loss<span class="op">=</span>{<span class="st">&#39;ctc&#39;</span>: <span class="kw">lambda</span> y_true, y_pred: y_pred}, optimizer<span class="op">=</span>sgd)</span>
<span id="cb10-106"><a href="#cb10-106" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-107"><a href="#cb10-107" aria-hidden="true" tabindex="-1"></a>    test_func <span class="op">=</span> K.function([input_data], [y_pred])</span>
<span id="cb10-108"><a href="#cb10-108" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-109"><a href="#cb10-109" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> model, test_func</span>
<span id="cb10-110"><a href="#cb10-110" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb10-111"><a href="#cb10-111" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-112"><a href="#cb10-112" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="va">__name__</span> <span class="op">==</span> <span class="st">&#39;__main__&#39;</span>:</span>
<span id="cb10-113"><a href="#cb10-113" aria-hidden="true" tabindex="-1"></a>    pool_size <span class="op">=</span> <span class="dv">3</span></span>
<span id="cb10-114"><a href="#cb10-114" aria-hidden="true" tabindex="-1"></a>    img_w <span class="op">=</span> <span class="dv">256</span></span>
<span id="cb10-115"><a href="#cb10-115" aria-hidden="true" tabindex="-1"></a>    img_h <span class="op">=</span> <span class="dv">64</span></span>
<span id="cb10-116"><a href="#cb10-116" aria-hidden="true" tabindex="-1"></a>    minibatch_size <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb10-117"><a href="#cb10-117" aria-hidden="true" tabindex="-1"></a>    img_gen <span class="op">=</span> util.TextImageGenerator(minibatch_size<span class="op">=</span>minibatch_size,</span>
<span id="cb10-118"><a href="#cb10-118" aria-hidden="true" tabindex="-1"></a>                                      img_w<span class="op">=</span>img_w,</span>
<span id="cb10-119"><a href="#cb10-119" aria-hidden="true" tabindex="-1"></a>                                      img_h<span class="op">=</span>img_h,</span>
<span id="cb10-120"><a href="#cb10-120" aria-hidden="true" tabindex="-1"></a>                                      downsample_factor<span class="op">=</span>(pool_size <span class="op">**</span> <span class="dv">2</span>),</span>
<span id="cb10-121"><a href="#cb10-121" aria-hidden="true" tabindex="-1"></a>                                      absolute_max_string_len<span class="op">=</span><span class="dv">12</span></span>
<span id="cb10-122"><a href="#cb10-122" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb10-123"><a href="#cb10-123" aria-hidden="true" tabindex="-1"></a>    model, dummy <span class="op">=</span> get_model(img_w,img_h,minibatch_size,pool_size)</span>
<span id="cb10-124"><a href="#cb10-124" aria-hidden="true" tabindex="-1"></a>    mfile <span class="op">=</span> <span class="st">&quot;/tmp/ocr.h5&quot;</span></span>
<span id="cb10-125"><a href="#cb10-125" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> os.path.isfile(mfile):</span>
<span id="cb10-126"><a href="#cb10-126" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span> <span class="st">&#39;Loaded&#39;</span>, mfile</span>
<span id="cb10-127"><a href="#cb10-127" aria-hidden="true" tabindex="-1"></a>        model.load_weights(mfile)</span>
<span id="cb10-128"><a href="#cb10-128" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-129"><a href="#cb10-129" aria-hidden="true" tabindex="-1"></a>    model.fit_generator(generator<span class="op">=</span>img_gen.next_train(),</span>
<span id="cb10-130"><a href="#cb10-130" aria-hidden="true" tabindex="-1"></a>                        steps_per_epoch<span class="op">=</span><span class="dv">1000</span>,</span>
<span id="cb10-131"><a href="#cb10-131" aria-hidden="true" tabindex="-1"></a>                        epochs<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb10-132"><a href="#cb10-132" aria-hidden="true" tabindex="-1"></a>                        validation_steps<span class="op">=</span><span class="dv">0</span>,</span>
<span id="cb10-133"><a href="#cb10-133" aria-hidden="true" tabindex="-1"></a>                        callbacks<span class="op">=</span>[img_gen],</span>
<span id="cb10-134"><a href="#cb10-134" aria-hidden="true" tabindex="-1"></a>                        initial_epoch<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb10-135"><a href="#cb10-135" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-136"><a href="#cb10-136" aria-hidden="true" tabindex="-1"></a>    model.save(mfile)</span>
<span id="cb10-137"><a href="#cb10-137" aria-hidden="true" tabindex="-1"></a>    </span></code></pre></div>
<p>Eğitim verisi ne olacak? Burada ilginç bir teknik kullanacağız, bir
kelimenin imajını üretebilen yazılımlar var, yani masaüstünde Paint ya
da Gimp ile bir imaj içine yazı yazmak gibi, bu kodlardan birini
kullanıp, hatta üretilen imajı deforme bile ederek tanıma algoritmasının
işini bilerek zorlaştırabiliriz, ve eğitime bu verileri sokarak, hiç ek
eğitim verisi diskte tutmadan eğitim operasyonunu istediğimiz şekilde
gerçekleştiririz. Bir örnek kelime imajı üretelim mesela,</p>
<div class="sourceCode" id="cb11"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> util</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>img_w <span class="op">=</span> <span class="dv">256</span></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>img_h <span class="op">=</span> <span class="dv">64</span></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>img_gen <span class="op">=</span> util.TextImageGenerator(minibatch_size<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>                                  img_w<span class="op">=</span>img_w,</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>                                  img_h<span class="op">=</span>img_h,</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>                                  downsample_factor<span class="op">=</span><span class="dv">4</span>,</span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a>                                  absolute_max_string_len<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> x <span class="kw">in</span> img_gen.next_train(): <span class="cf">break</span></span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a>img <span class="op">=</span> x[<span class="dv">0</span>][<span class="st">&#39;the_input&#39;</span>].reshape(img_w,img_h).T</span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> x[<span class="dv">0</span>][<span class="st">&#39;source_str&#39;</span>],</span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a>plt.imshow(img,cmap<span class="op">=</span><span class="st">&#39;gray&#39;</span>,interpolation<span class="op">=</span><span class="st">&quot;none&quot;</span>)</span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a>plt.savefig(<span class="st">&#39;ocr_06.png&#39;</span>)    </span></code></pre></div>
<pre><code>[u&#39;daxco7mu1&#39;]</code></pre>
<p>İmaj neye benziyor?</p>
<p><img src="ocr_06.png" /></p>
<p>Eğitim verisini üreteç (generator) tekniği [6] üzerinden yaratıyoruz
dikkat edildiyse, üreteç eğitim verisini bir gezici arayüzü üzerinden
eğitim rutinine vermemizi sağlıyor. Üreteç, döngüsünde her dönüldüğünde
ve çağıran veri istendiğinde rasgele bir kelime üretir, bu kelimeyi
imaja çevirip etiketi ile birlikte çağrıyı yapana veriyor. Üreteç
yapısını kullanmanın güzel tarafı çağıran tarafın döngü sözdizimini
kullanabilmesi. Üstte tek bir kere dönüp çıktık (tek imaj istiyorduk),
eğitim mekanizması istediği kadar dönerek istediği kadar eğtim verisi
alabilir.</p>
<p>Görüldüğü gibi imaj biraz aşağı doğru eğimli çıktı, bu iyi, çünkü
gerçek dünyada olan şartları tekrarlamak istiyoruz, belki bir cep
telefonunun çektiği resimdeki kelimeleri tanıyacağız ve telefonu
mükemmel şekilde tutmak mümkün değil, farklı açılardan kelimeleri
tanıyabilmek çok iyi olur. Ayrıca kullandığımız rutin suni “gürültü’’
bile ekliyor, karlandırma yapıyor mesela, hatta kelimenin imajın çok
farklı yerlerinden başlatabiliyor.</p>
<p>Neyse, işte bu şekilde üretilen veri üzerinden eğitimi yapıp
raporlanan kaybı belli bir seviyeye indirdikten sonra (5,6 civarı
mesela, fakat uzun süre sonra 2 seviyesi de mümkün), YSA hazır demektir.
Bizim önceden eğittiğimiz YSA’yı yükleyelim,</p>
<div class="sourceCode" id="cb13"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> train</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>mfile <span class="op">=</span> <span class="st">&#39;/tmp/ocr.h5&#39;</span></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>pool_size <span class="op">=</span> <span class="dv">3</span></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>img_w <span class="op">=</span> <span class="dv">256</span></span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>img_h <span class="op">=</span> <span class="dv">64</span></span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>minibatch_size <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>model, test_func <span class="op">=</span> train.get_model(img_w,img_h,minibatch_size,pool_size)</span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>model.load_weights(mfile)</span></code></pre></div>
<pre><code>____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
the_input (InputLayer)           (None, 256, 64, 1)    0                                            
____________________________________________________________________________________________________
conv1 (Conv2D)                   (None, 256, 64, 20)   100         the_input[0][0]                  
____________________________________________________________________________________________________
max1 (MaxPooling2D)              (None, 85, 21, 20)    0           conv1[0][0]                      
____________________________________________________________________________________________________
conv2 (Conv2D)                   (None, 85, 21, 20)    1620        max1[0][0]                       
____________________________________________________________________________________________________
max2 (MaxPooling2D)              (None, 28, 7, 20)     0           conv2[0][0]                      
____________________________________________________________________________________________________
reshape (Reshape)                (None, 28, 140)       0           max2[0][0]                       
____________________________________________________________________________________________________
dense1 (Dense)                   (None, 28, 32)        4512        reshape[0][0]                    
____________________________________________________________________________________________________
gru1 (GRU)                       (None, 28, 256)       221952      dense1[0][0]                     
____________________________________________________________________________________________________
gru1_b (GRU)                     (None, 28, 256)       221952      dense1[0][0]                     
____________________________________________________________________________________________________
add_1 (Add)                      (None, 28, 256)       0           gru1[0][0]                       
                                                                   gru1_b[0][0]                     
____________________________________________________________________________________________________
gru2 (GRU)                       (None, 28, 256)       393984      add_1[0][0]                      
____________________________________________________________________________________________________
gru2_b (GRU)                     (None, 28, 256)       393984      add_1[0][0]                      
____________________________________________________________________________________________________
concatenate_1 (Concatenate)      (None, 28, 512)       0           gru2[0][0]                       
                                                                   gru2_b[0][0]                     
____________________________________________________________________________________________________
dense2 (Dense)                   (None, 28, 40)        20520       concatenate_1[0][0]              
____________________________________________________________________________________________________
softmax (Activation)             (None, 28, 40)        0           dense2[0][0]                     
====================================================================================================
Total params: 1,258,624
Trainable params: 1,258,624
Non-trainable params: 0
____________________________________________________________________________________________________</code></pre>
<p>Şimdi üstteki örnek imajı tanımaya uğraşalım,</p>
<div class="sourceCode" id="cb15"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> itertools</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> labels_to_text(labels):</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>    ret <span class="op">=</span> []</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> c <span class="kw">in</span> labels:</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> c <span class="op">==</span> <span class="bu">len</span>(util.alphabet):  <span class="co"># CTC Blank</span></span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>            ret.append(<span class="st">&quot;&quot;</span>)</span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a>            ret.append(util.alphabet[c])</span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="st">&quot;&quot;</span>.join(ret)</span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> decode_batch(test_func, word_batch):</span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a>    out <span class="op">=</span> test_func([word_batch])[<span class="dv">0</span>]</span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a>    ret <span class="op">=</span> []</span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(out.shape[<span class="dv">0</span>]):</span>
<span id="cb15-17"><a href="#cb15-17" aria-hidden="true" tabindex="-1"></a>        out_best <span class="op">=</span> <span class="bu">list</span>(np.argmax(out[j, <span class="dv">2</span>:], <span class="dv">1</span>))</span>
<span id="cb15-18"><a href="#cb15-18" aria-hidden="true" tabindex="-1"></a>        out_best <span class="op">=</span> [k <span class="cf">for</span> k, g <span class="kw">in</span> itertools.groupby(out_best)]</span>
<span id="cb15-19"><a href="#cb15-19" aria-hidden="true" tabindex="-1"></a>        outstr <span class="op">=</span> labels_to_text(out_best)</span>
<span id="cb15-20"><a href="#cb15-20" aria-hidden="true" tabindex="-1"></a>        ret.append(outstr)</span>
<span id="cb15-21"><a href="#cb15-21" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> ret</span>
<span id="cb15-22"><a href="#cb15-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-23"><a href="#cb15-23" aria-hidden="true" tabindex="-1"></a>pred_result <span class="op">=</span> decode_batch(test_func, x[<span class="dv">0</span>][<span class="st">&#39;the_input&#39;</span>])[<span class="dv">0</span>]</span>
<span id="cb15-24"><a href="#cb15-24" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> pred_result</span></code></pre></div>
<pre><code>qaxco7mu4</code></pre>
<p>Fena değil.</p>
<p>Kaynaklar</p>
<p>[1] Graves, <em>Supervised Sequence Labelling with Recurrent Neural
Networks</em>, <a
href="https://www.cs.toronto.edu/~graves/preprint.pdf">https://www.cs.toronto.edu/~graves/preprint.pdf</a></p>
<p>[2] Graves, <em>How to build a recognition system (Part 2): CTC
Loss</em>, <a
href="https://docs.google.com/presentation/d/12gYcPft9_4cxk2AD6Z6ZlJNa3wvZCW1ms31nhq51vMk">https://docs.google.com/presentation/d/12gYcPft9_4cxk2AD6Z6ZlJNa3wvZCW1ms31nhq51vMk</a></p>
<p>[3] Graves, <em>How to build a recognition system (Part 1): CTC
Loss</em>, <a
href="https://docs.google.com/presentation/d/1AyLOecmW1k9cIbfexOT3dwoUU-Uu5UqlJZ0w3cxilkI">https://docs.google.com/presentation/d/1AyLOecmW1k9cIbfexOT3dwoUU-Uu5UqlJZ0w3cxilkI</a></p>
<p>[4] Troller, <em>Practical OCR system based on state of art neural
networks</em>, <a
href="https://support.dce.felk.cvut.cz/mediawiki/images/2/24/Bp_2017_troller_milan.pdf">https://support.dce.felk.cvut.cz/mediawiki/images/2/24/Bp_2017_troller_milan.pdf</a></p>
<p>[5] Chollet, <em>Keras</em>, <a
href="https://github.com/fchollet/keras/blob/master/examples/image_ocr.py">https://github.com/fchollet/keras/blob/master/examples/image_ocr.py</a></p>
<p>[6] Bayramlı, <em>Fonksiyon Gezmek ve Yield</em>, <a
href="https://burakbayramli.github.io/dersblog/sk/2011/02/fonksiyon-gezmek-ve-yield.html">https://burakbayramli.github.io/dersblog/sk/2011/02/fonksiyon-gezmek-ve-yield.html</a></p>
<p>
  <a href="..">Yukarı</a>
</p>
</body>
</html>
