<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
    <script type="text/x-mathjax-config">
    MathJax.Hub.Register.StartupHook("TeX Jax Ready",function () {
      MathJax.Hub.Insert(MathJax.InputJax.TeX.Definitions.macros,{
        cancel: ["Extension","cancel"], cancelto: ["Extension","cancel"]
      });
    });
    </script>  
   
  <title>Konuşma Tanıma (Speech Recognition)</title>
  <style type="text/css">code{white-space: pre;}</style>
  <style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
  </style>
</head>
<body>
<div id="header">
</div>
<h1 id="konuşma-tanıma-speech-recognition">Konuşma Tanıma (Speech
Recognition)</h1>
<p>Frekans Üzerinden Özellik Çıkartımı, RNN, LSTM, GRU</p>
<p>1 saniyelik ses dosyaları var, bu dosyalardaki ses kayıtları dört
farklı komutu içeriyor, İngilizce up, down, yes, no (yukarı, aşağı,
evet, hayır) komutları. Ses kayıtları aslında zaman serileridir, tek
boyutlu bir veri, mesela 1 saniyelik 16,000 sayı içeren bir vektör.
Örnek bir ‘down’ kaydının neye benzediğini görelim,</p>
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> util</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> scipy.io.wavfile, zipfile</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> io, time, os, random, re</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>f <span class="op">=</span> util.train_dir <span class="op">+</span> <span class="st">&#39;/down/004ae714_nohash_0.wav&#39;</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>wav <span class="op">=</span> io.BytesIO(<span class="bu">open</span>(f).read())</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>v <span class="op">=</span> scipy.io.wavfile.read(wav)</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> v[<span class="dv">1</span>]</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>plt.plot(v[<span class="dv">1</span>])</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>plt.savefig(<span class="st">&#39;speech_01.png&#39;</span>)</span></code></pre></div>
<pre><code>train 8537 val 949
[-130 -135 -131 ..., -154 -190 -224]</code></pre>
<p><img src="speech_01.png" /></p>
<p>Yapay öğrenme bağlamında zaman serileri için daha önce [7] yazısında
LSTM yapısını görmüştük. Örnek olarak zaman serilerini sınıfladık, zaman
serisindeki tüm veriler LSTM’e verilmişti, o zaman bir şeride 150 kusur
veri noktası varsa, o kadar LSTM hücresi yaratılacaktı. Fakat içinde
binlerce öğe olan seriler için bu iyi olmayabilir. Çözüm seriyi bir
şekilde özetleyerek bu daha az olan veriyi LSTM’e vermek. Bu özetlere
ses işleme alanında parmak izi (fingerprint) ismi de verilmekte.</p>
<p>Ses verilerini frekans üzerinden özetlemek bilinen bir teknik, ses
verisi ufak pencerelere bölünür, bu pencereler üzerinde Fourier
transformu işletilir, ve oradaki frekans bilgileri, hangi frekansın ne
kadar önemli olduğu elde edilir. Spektogram bu bilgiyi renkli olarak
göstermenin bir yolu, üstteki ses için,</p>
<div class="sourceCode" id="cb3"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>plt.specgram(v[<span class="dv">1</span>], Fs<span class="op">=</span>util.fs, NFFT<span class="op">=</span><span class="dv">1024</span>)</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>plt.savefig(<span class="st">&#39;speech_02.png&#39;</span>)</span></code></pre></div>
<p><img src="speech_02.png" /></p>
<p>Spektogramın örüntü tanıma için kullanılabileceğini anlamak için bir
tane daha farklı ‘down’ sesi, bir de ‘no’ sesinin spektogramına
bakalım,</p>
<div class="sourceCode" id="cb4"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>f1 <span class="op">=</span> util.train_dir <span class="op">+</span> <span class="st">&#39;/down/0f3f64d5_nohash_2.wav&#39;</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>wav1 <span class="op">=</span> io.BytesIO(<span class="bu">open</span>(f1).read())</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>v1 <span class="op">=</span> scipy.io.wavfile.read(wav1)</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>plt.specgram(v1[<span class="dv">1</span>], Fs<span class="op">=</span>util.fs, NFFT<span class="op">=</span><span class="dv">1024</span>)</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>plt.savefig(<span class="st">&#39;speech_03.png&#39;</span>)</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>f2 <span class="op">=</span> util.train_dir <span class="op">+</span> <span class="st">&#39;/no/01bb6a2a_nohash_0.wav&#39;</span></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>wav2 <span class="op">=</span> io.BytesIO(<span class="bu">open</span>(f2).read())</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>v2 <span class="op">=</span> scipy.io.wavfile.read(wav2)</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>plt.specgram(v2[<span class="dv">1</span>], Fs<span class="op">=</span>util.fs, NFFT<span class="op">=</span><span class="dv">1024</span>)</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>plt.savefig(<span class="st">&#39;speech_04.png&#39;</span>)</span></code></pre></div>
<p><img src="speech_03.png" /> <img src="speech_04.png" /></p>
<p>Görüyoruz ki ‘down’ seslerinin spektogramları birbirine benziyor.
Öğrenme için bu yapıyı kullanabiliriz. Bu arada spektogram “grafiği’’
y-ekseninde frekansları, x-ekseni zaman adımları gösterir, grafikleme
kodu her zaman penceresindeki belli frekans kuvvetlerinin hangi frekans
kutucuğuna düştüğüne bakar ve o kutucukta o kuvvete göre renklendirme
yapar. Şimdi bu grafikleme amaçlı, ama bazıları bu grafiğe bakarak”ben
çıplak gözle bunu tanıyabiliyorum, o zaman görsel tanımayla üstteki
imajla sesi tanıyacak bir DYSA kullanayım’’ diye düşünebiliyor. Bu
işleyen bir metot, zaten DYSA’nın görsel tanıma tarihi eski, orada
bilinen bir sürü teknik var. Her neyse bazıları üstteki görsel
spektogram grafiği, yani R,G,B kanallı çıktı üzerinde görsel tanıma
yapmayı da seçebiliyor, fakat bu şart değil, bir spektogram, bir veri
durumunda iki boyutlu bir matriste gösterilebilir. TensorFlow ile bu
hesabı örnek rasgele bir veri üzerinde yapalım,</p>
<div class="sourceCode" id="cb5"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tensorflow <span class="im">as</span> tf</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>init_op <span class="op">=</span> tf.global_variables_initializer()</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> tf.placeholder(tf.float32, [<span class="dv">1</span>, <span class="dv">16000</span>])</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> data</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>stfts <span class="op">=</span> tf.contrib.signal.stft(data, frame_length<span class="op">=</span><span class="dv">400</span>, </span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>                               frame_step<span class="op">=</span><span class="dv">100</span>, fft_length<span class="op">=</span><span class="dv">512</span>)</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>spec <span class="op">=</span> tf.<span class="bu">abs</span>(stfts)</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> spec</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>s <span class="op">=</span> np.random.rand(<span class="dv">1</span>,<span class="dv">16000</span>) <span class="co"># rasgele bir zaman serisi uret</span></span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> tf.Session() <span class="im">as</span> sess:</span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>     sess.run(tf.global_variables_initializer())</span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>     res <span class="op">=</span> sess.run(spec, feed_dict<span class="op">=</span>{data: s })  </span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> res</span></code></pre></div>
<pre><code>Tensor(&quot;Placeholder_1:0&quot;, shape=(1, 16000), dtype=float32)
Tensor(&quot;Abs_1:0&quot;, shape=(1, 157, 257), dtype=float32)
[[[  99.39490509   65.10092163   12.84116936 ...,    5.39213753
      3.90902305    1.35875702]
  [ 100.60041809   66.32343292   12.92744541 ...,    4.64194965
      1.80256999    2.0458374 ]
  [ 104.70896149   70.13975525   15.93750095 ...,    3.21846962
      1.70909929    1.34316254]
  ..., 
  [  97.82588196   63.51060867   11.62135887 ...,    3.23712349
      1.94706416    0.41742325]
  [ 105.89834595   71.85715485   17.83632851 ...,    4.6476922
      2.42140603    1.37829971]
  [ 106.46664429   71.12073517   16.69457436 ...,    6.58148479
x      3.24354243    3.80913925]]]</code></pre>
<p>Cok Katmanlı LSTM</p>
<p>LSTM, ya da diğer her RNN çeşidi çok katmanlı olarak
kullanılabilir.</p>
<p><img src="stacked-rnn.png" /></p>
<p>Girdiler en alttaki LSTM hücrelerine geçiliyor, bu hücreler
birbirlerine konum aktarımı yaptıkları gibi bir sonraki LSTM katmanına
girdi de sağlıyorlar, bu aktarım en üst tabakaya kadar gidiyor. Peki o
zaman sınıflama amaçlı olarak kullanılan “en son’’ hücre hangisi
olacaktır? Bunun için tipik olarak katmanlı LSTM’de en üst ve en sondaki
hücre kullanılır.</p>
<p>Her hücrede 200 nöron var, o zaman her katman (124,200) boyutunda
çünkü spektogramdan 124 zaman boyutu geldi, ve LSTM’in en sondaki
hücreden alınan vektör 200 boyutunda olacak, bu çıktı bir tam bağlanmış
(fully-connected) katmana verilerek buradan 4 tane etiket için olasılık
üretilecek, ve tahmin için kullanılan sonuçlar bunlar olacak. O
sayılardan en büyük olanı en olası olan ses komutudur.</p>
<p>Tüm modeli görelim,</p>
<div class="sourceCode" id="cb7"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># model_lstm.py</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tensorflow <span class="im">as</span> tf, util, os</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Model:</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>                </span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.<span class="bu">file</span> <span class="op">=</span> os.path.basename(<span class="va">__file__</span>).replace(<span class="st">&quot;.pyc&quot;</span>,<span class="st">&quot;&quot;</span>).replace(<span class="st">&quot;.py&quot;</span>,<span class="st">&quot;&quot;</span>)</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.mfile <span class="op">=</span> <span class="st">&quot;/tmp/&quot;</span> <span class="op">+</span> <span class="va">self</span>.<span class="bu">file</span> <span class="op">+</span> <span class="st">&quot;.ckpt&quot;</span></span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.batch_size <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.num_epochs <span class="op">=</span> <span class="dv">200</span></span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.dop_param <span class="op">=</span> <span class="fl">0.0</span> <span class="co"># dropout olasiligi</span></span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.num_layers <span class="op">=</span> <span class="dv">4</span></span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.num_cell <span class="op">=</span> <span class="dv">200</span></span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true" tabindex="-1"></a>        tf.reset_default_graph()</span>
<span id="cb7-22"><a href="#cb7-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-23"><a href="#cb7-23" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.dop <span class="op">=</span> tf.placeholder(tf.float32) <span class="co"># dropout olasiligi (probability)</span></span>
<span id="cb7-24"><a href="#cb7-24" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb7-25"><a href="#cb7-25" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.data <span class="op">=</span> tf.placeholder(tf.float32, [<span class="va">None</span>, util.fs])</span>
<span id="cb7-26"><a href="#cb7-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-27"><a href="#cb7-27" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span> <span class="va">self</span>.data </span>
<span id="cb7-28"><a href="#cb7-28" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb7-29"><a href="#cb7-29" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.stfts <span class="op">=</span> tf.contrib.signal.stft(<span class="va">self</span>.data, frame_length<span class="op">=</span><span class="dv">256</span>,</span>
<span id="cb7-30"><a href="#cb7-30" aria-hidden="true" tabindex="-1"></a>                                            frame_step<span class="op">=</span><span class="dv">128</span>, fft_length<span class="op">=</span><span class="dv">256</span>)</span>
<span id="cb7-31"><a href="#cb7-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-32"><a href="#cb7-32" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span> <span class="va">self</span>.stfts</span>
<span id="cb7-33"><a href="#cb7-33" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb7-34"><a href="#cb7-34" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fingerprint <span class="op">=</span> tf.<span class="bu">abs</span>(<span class="va">self</span>.stfts)</span>
<span id="cb7-35"><a href="#cb7-35" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb7-36"><a href="#cb7-36" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span> <span class="va">self</span>.fingerprint</span>
<span id="cb7-37"><a href="#cb7-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-38"><a href="#cb7-38" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.y <span class="op">=</span> tf.placeholder(tf.float32, shape<span class="op">=</span>[<span class="va">None</span>, <span class="bu">len</span>(util.labels)])</span>
<span id="cb7-39"><a href="#cb7-39" aria-hidden="true" tabindex="-1"></a>        cells <span class="op">=</span> []</span>
<span id="cb7-40"><a href="#cb7-40" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(<span class="va">self</span>.num_layers):</span>
<span id="cb7-41"><a href="#cb7-41" aria-hidden="true" tabindex="-1"></a>            cell <span class="op">=</span> tf.contrib.rnn.LSTMCell(<span class="va">self</span>.num_cell)</span>
<span id="cb7-42"><a href="#cb7-42" aria-hidden="true" tabindex="-1"></a>            cell <span class="op">=</span> tf.contrib.rnn.DropoutWrapper(cell, output_keep_prob<span class="op">=</span><span class="dv">1</span><span class="op">-</span><span class="va">self</span>.dop)</span>
<span id="cb7-43"><a href="#cb7-43" aria-hidden="true" tabindex="-1"></a>            cells.append(cell)</span>
<span id="cb7-44"><a href="#cb7-44" aria-hidden="true" tabindex="-1"></a>        cell <span class="op">=</span> tf.contrib.rnn.MultiRNNCell(cells)</span>
<span id="cb7-45"><a href="#cb7-45" aria-hidden="true" tabindex="-1"></a>        output, states <span class="op">=</span> tf.nn.dynamic_rnn(cell, <span class="va">self</span>.fingerprint, dtype<span class="op">=</span>tf.float32)</span>
<span id="cb7-46"><a href="#cb7-46" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span> output</span>
<span id="cb7-47"><a href="#cb7-47" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> x <span class="kw">in</span> states: <span class="bu">print</span> x</span>
<span id="cb7-48"><a href="#cb7-48" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.last <span class="op">=</span> states[<span class="op">-</span><span class="dv">1</span>][<span class="dv">0</span>] <span class="co"># en ust sagdaki son hucre</span></span>
<span id="cb7-49"><a href="#cb7-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-50"><a href="#cb7-50" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span> <span class="va">self</span>.last</span>
<span id="cb7-51"><a href="#cb7-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-52"><a href="#cb7-52" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.logits <span class="op">=</span> tf.contrib.layers.fully_connected(inputs<span class="op">=</span><span class="va">self</span>.last,</span>
<span id="cb7-53"><a href="#cb7-53" aria-hidden="true" tabindex="-1"></a>                                                        num_outputs<span class="op">=</span><span class="bu">len</span>(util.labels),</span>
<span id="cb7-54"><a href="#cb7-54" aria-hidden="true" tabindex="-1"></a>                                                        activation_fn<span class="op">=</span><span class="va">None</span>)</span>
<span id="cb7-55"><a href="#cb7-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-56"><a href="#cb7-56" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span> <span class="va">self</span>.logits</span>
<span id="cb7-57"><a href="#cb7-57" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb7-58"><a href="#cb7-58" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.softmax <span class="op">=</span> tf.nn.softmax_cross_entropy_with_logits(logits<span class="op">=</span><span class="va">self</span>.logits,</span>
<span id="cb7-59"><a href="#cb7-59" aria-hidden="true" tabindex="-1"></a>                                                               labels<span class="op">=</span><span class="va">self</span>.y) </span>
<span id="cb7-60"><a href="#cb7-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-61"><a href="#cb7-61" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.cross_entropy <span class="op">=</span> tf.reduce_mean(<span class="va">self</span>.softmax)</span>
<span id="cb7-62"><a href="#cb7-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-63"><a href="#cb7-63" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.train_step <span class="op">=</span> tf.train.AdamOptimizer(<span class="fl">0.001</span>).minimize(<span class="va">self</span>.cross_entropy)</span>
<span id="cb7-64"><a href="#cb7-64" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb7-65"><a href="#cb7-65" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.correct_prediction <span class="op">=</span> tf.equal(tf.argmax(<span class="va">self</span>.y,<span class="dv">1</span>),</span>
<span id="cb7-66"><a href="#cb7-66" aria-hidden="true" tabindex="-1"></a>                                           tf.argmax(<span class="va">self</span>.logits,<span class="dv">1</span>))</span>
<span id="cb7-67"><a href="#cb7-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-68"><a href="#cb7-68" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.evaluation_step <span class="op">=</span> tf.reduce_mean(tf.cast(<span class="va">self</span>.correct_prediction,</span>
<span id="cb7-69"><a href="#cb7-69" aria-hidden="true" tabindex="-1"></a>                                                      tf.float32))</span>
<span id="cb7-70"><a href="#cb7-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-71"><a href="#cb7-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-72"><a href="#cb7-72" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.saver <span class="op">=</span> tf.train.Saver()</span>
<span id="cb7-73"><a href="#cb7-73" aria-hidden="true" tabindex="-1"></a>                </span>
<span id="cb7-74"><a href="#cb7-74" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb7-75"><a href="#cb7-75" aria-hidden="true" tabindex="-1"></a><span class="co"># training 0.91 validation 0.926238</span></span></code></pre></div>
<p>Modelin girdi tensor’un boyutlarını nasıl değiştirdiği altta (üstteki
resim iki katman gösterdi, bizim modelde 4 katman var),</p>
<div class="sourceCode" id="cb8"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> model_lstm</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>m <span class="op">=</span> model_lstm.Model()</span></code></pre></div>
<pre><code>Tensor(&quot;Placeholder_1:0&quot;, shape=(?, 16000), dtype=float32)
Tensor(&quot;stft/rfft:0&quot;, shape=(?, 124, 129), dtype=complex64)
Tensor(&quot;Abs:0&quot;, shape=(?, 124, 129), dtype=float32)
Tensor(&quot;rnn/transpose:0&quot;, shape=(?, 124, 200), dtype=float32)
LSTMStateTuple(c=&lt;tf.Tensor &#39;rnn/while/Exit_2:0&#39; shape=(?, 200) dtype=float32&gt;, h=&lt;tf.Tensor &#39;rnn/while/Exit_3:0&#39; shape=(?, 200) dtype=float32&gt;)
LSTMStateTuple(c=&lt;tf.Tensor &#39;rnn/while/Exit_4:0&#39; shape=(?, 200) dtype=float32&gt;, h=&lt;tf.Tensor &#39;rnn/while/Exit_5:0&#39; shape=(?, 200) dtype=float32&gt;)
LSTMStateTuple(c=&lt;tf.Tensor &#39;rnn/while/Exit_6:0&#39; shape=(?, 200) dtype=float32&gt;, h=&lt;tf.Tensor &#39;rnn/while/Exit_7:0&#39; shape=(?, 200) dtype=float32&gt;)
LSTMStateTuple(c=&lt;tf.Tensor &#39;rnn/while/Exit_8:0&#39; shape=(?, 200) dtype=float32&gt;, h=&lt;tf.Tensor &#39;rnn/while/Exit_9:0&#39; shape=(?, 200) dtype=float32&gt;)
Tensor(&quot;rnn/while/Exit_8:0&quot;, shape=(?, 200), dtype=float32)
Tensor(&quot;fully_connected/BiasAdd:0&quot;, shape=(?, 4), dtype=float32)</code></pre>
<p>Eğitim kodu,</p>
<div class="sourceCode" id="cb10"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd, sys</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np, util</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tensorflow <span class="im">as</span> tf</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> scipy.io.wavfile, zipfile</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> io, time, os, random, re</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> model_lstm</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>m <span class="op">=</span> model_lstm.Model()</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a>sess <span class="op">=</span> tf.Session()</span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a>sess.run(tf.global_variables_initializer())</span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a>saver <span class="op">=</span> tf.train.Saver()</span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true" tabindex="-1"></a><span class="co"># eger model diskte varsa yukle</span></span>
<span id="cb10-18"><a href="#cb10-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> m.mfile</span>
<span id="cb10-19"><a href="#cb10-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> <span class="st">&#39;model file exists&#39;</span>, os.path.isfile(m.mfile <span class="op">+</span> <span class="st">&quot;.index&quot;</span>)</span>
<span id="cb10-20"><a href="#cb10-20" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> os.path.isfile(m.mfile <span class="op">+</span> <span class="st">&quot;.index&quot;</span>):</span>
<span id="cb10-21"><a href="#cb10-21" aria-hidden="true" tabindex="-1"></a>     <span class="bu">print</span> <span class="st">&#39;restoring&#39;</span></span>
<span id="cb10-22"><a href="#cb10-22" aria-hidden="true" tabindex="-1"></a>     saver.restore(sess, m.mfile)</span>
<span id="cb10-23"><a href="#cb10-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-24"><a href="#cb10-24" aria-hidden="true" tabindex="-1"></a>train_files, val_files <span class="op">=</span> util.init_files()</span>
<span id="cb10-25"><a href="#cb10-25" aria-hidden="true" tabindex="-1"></a>     </span>
<span id="cb10-26"><a href="#cb10-26" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(m.num_epochs):</span>
<span id="cb10-27"><a href="#cb10-27" aria-hidden="true" tabindex="-1"></a>    train_x, train_y <span class="op">=</span> util.get_minibatch(m.batch_size, train_files, val_files)</span>
<span id="cb10-28"><a href="#cb10-28" aria-hidden="true" tabindex="-1"></a>    d <span class="op">=</span> { m.data:train_x, m.y:train_y, m.dop:m.dop_param}</span>
<span id="cb10-29"><a href="#cb10-29" aria-hidden="true" tabindex="-1"></a>    acc, _ <span class="op">=</span> sess.run([m.evaluation_step, m.train_step], feed_dict<span class="op">=</span>d)</span>
<span id="cb10-30"><a href="#cb10-30" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span> i, <span class="st">&#39;accuracy&#39;</span>, acc </span>
<span id="cb10-31"><a href="#cb10-31" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> i <span class="op">%</span> <span class="dv">5</span> <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb10-32"><a href="#cb10-32" aria-hidden="true" tabindex="-1"></a>         d <span class="op">=</span> { m.data:train_x, m.y:train_y, m.dop:m.dop_param }</span>
<span id="cb10-33"><a href="#cb10-33" aria-hidden="true" tabindex="-1"></a>         tacc <span class="op">=</span> sess.run(m.evaluation_step, feed_dict<span class="op">=</span>d)</span>
<span id="cb10-34"><a href="#cb10-34" aria-hidden="true" tabindex="-1"></a>     val_x, val_y <span class="op">=</span> util.get_minibatch(m.batch_size,train_files, val_files,validation<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb10-35"><a href="#cb10-35" aria-hidden="true" tabindex="-1"></a>         d <span class="op">=</span> { m.data:val_x, m.y:val_y, m.dop:<span class="dv">0</span>}</span>
<span id="cb10-36"><a href="#cb10-36" aria-hidden="true" tabindex="-1"></a>         vacc <span class="op">=</span> sess.run(m.evaluation_step, feed_dict<span class="op">=</span>d)</span>
<span id="cb10-37"><a href="#cb10-37" aria-hidden="true" tabindex="-1"></a>         <span class="bu">print</span> i, <span class="st">&#39;training&#39;</span>, tacc, <span class="st">&#39;validation&#39;</span>, vacc</span>
<span id="cb10-38"><a href="#cb10-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-39"><a href="#cb10-39" aria-hidden="true" tabindex="-1"></a><span class="co"># modeli diske yaz</span></span>
<span id="cb10-40"><a href="#cb10-40" aria-hidden="true" tabindex="-1"></a>saver.save(sess, m.mfile)</span></code></pre></div>
<p>Eğitim sonrası modelin başarısı eğitim verisi üzerinde yüzde 91,
doğrulama verisinde yüzde 92. Kullanılan veri [6]’da.</p>
<p>Dropout</p>
<p>TF ile katmanlararası her noktada dropout kullanılabilir. Dropout ile
bir katmandan çıkan ya da ona giren bağlantıların bir kısmı yoksayılır,
ve model elde kalanlar ile iş yapmaya uğraşır, aşırı uygunluk
problemlerinden böylece kaçınılmış olur. Üstteki kodda hangi olasılıkla
dropout yapılacağının olasılığı bir yer tutucu (placeholder) ile TF
çizitinin parçası haline getirildi, niye? Böylece son üründeki
kullanımda bu parametre 0 yapılarak hiç dropout yapılmaması
sağlanabiliyor. Eğitim sırasında bu değer 0.5, 0.2, vs yapılabilir, o
zaman dropout devrede olur. Gerçi biz eğitim sırasında da 0 ile eğittik,
yani dropout kullanmadık, ama lazım olduğu yerler olabilir, referans
açısından burada dursun.</p>
<p>Uygulama</p>
<p>Mikrofondan 1 saniyelik ses parçalarını alıp onu model üzerinde
işletip dört komuttan birini seçen örnek kod <code>mic.py</code>’da
bulunabilir. Performans gerçek zamanlı kullanım için yeterliydi, DYSA
ufak bir şey değil aslında, kaç parametre olduğuna bakalım,</p>
<div class="sourceCode" id="cb11"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> util.network_parameters(), <span class="st">&#39;tane degisken var&#39;</span></span></code></pre></div>
<pre><code>1227204 tane degisken var</code></pre>
<p>1 milyon küsur parametreli bir DYSA , yani potansiyel olarak her
saniye en az bir milyon işlem yapılıyor demektir. Görünüşe göre hesap
işliyor, TF bazı optimizasyonlar yapmış belki, ve mikroişlemciler
yeterince hızlı. Teknoloji güzel şey.</p>
<p>CTC</p>
<p>Ses tanıma için bir diğer yaklaşım optik karakter tanıma yazısında
görülen CTC kullanımı [4,5]. Alttaki kodun kullandığı veri [1]’de,
yaklaşımın detayları [2]’de görülebilir. Bu ses verisi koca kelimeler,
cümleleri içeriyor, çok daha uzun veriler bunlar, ve kayıp fonksiyonu
artık basit, belli sayıda komut arasından seçim bazlı değil, büyük bir
alfabeden gelen öğelerin yanyana gelişini kontrol ediyor.</p>
<div class="sourceCode" id="cb13"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> python_speech_features <span class="im">import</span> mfcc</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tensorflow <span class="im">as</span> tf</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> glob <span class="im">import</span> glob</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> time, re, os, random</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> librosa</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>num_epochs <span class="op">=</span> <span class="dv">1000</span></span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a>num_hidden <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a>num_layers <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a>batch_size <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a>num_batches_per_epoch <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a>sample_rate<span class="op">=</span><span class="dv">8000</span></span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a>num_features <span class="op">=</span> <span class="dv">13</span></span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Accounting the 0th index +  space + blank label = 28 characters</span></span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a>num_classes <span class="op">=</span> <span class="bu">ord</span>(<span class="st">&#39;z&#39;</span>) <span class="op">-</span> <span class="bu">ord</span>(<span class="st">&#39;a&#39;</span>) <span class="op">+</span> <span class="dv">1</span> <span class="op">+</span> <span class="dv">1</span> <span class="op">+</span> <span class="dv">1</span></span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (<span class="st">&#39;num_classes </span><span class="sc">%d</span><span class="st">&#39;</span> <span class="op">%</span> num_classes)</span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-20"><a href="#cb13-20" aria-hidden="true" tabindex="-1"></a>SPACE_TOKEN <span class="op">=</span> <span class="st">&#39;&lt;space&gt;&#39;</span></span>
<span id="cb13-21"><a href="#cb13-21" aria-hidden="true" tabindex="-1"></a>SPACE_INDEX <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb13-22"><a href="#cb13-22" aria-hidden="true" tabindex="-1"></a>FIRST_INDEX <span class="op">=</span> <span class="bu">ord</span>(<span class="st">&#39;a&#39;</span>) <span class="op">-</span> <span class="dv">1</span>  <span class="co"># 0 is reserved to space</span></span>
<span id="cb13-23"><a href="#cb13-23" aria-hidden="true" tabindex="-1"></a>mfile <span class="op">=</span> <span class="st">&quot;/tmp/speech.ckpt&quot;</span></span>
<span id="cb13-24"><a href="#cb13-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-25"><a href="#cb13-25" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> convert_inputs_to_ctc_format(audio, fs, target_text):</span>
<span id="cb13-26"><a href="#cb13-26" aria-hidden="true" tabindex="-1"></a>    <span class="co">#print(&#39;convert_inputs_to_ctc_format target_text:&#39; + target_text)</span></span>
<span id="cb13-27"><a href="#cb13-27" aria-hidden="true" tabindex="-1"></a>    inputs <span class="op">=</span> mfcc(audio, samplerate<span class="op">=</span>fs, numcep<span class="op">=</span>num_features)</span>
<span id="cb13-28"><a href="#cb13-28" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Transform in 3D array</span></span>
<span id="cb13-29"><a href="#cb13-29" aria-hidden="true" tabindex="-1"></a>    train_inputs <span class="op">=</span> np.asarray(inputs[np.newaxis, :])</span>
<span id="cb13-30"><a href="#cb13-30" aria-hidden="true" tabindex="-1"></a>    train_inputs <span class="op">=</span> (train_inputs <span class="op">-</span> np.mean(train_inputs)) <span class="op">/</span> np.std(train_inputs)</span>
<span id="cb13-31"><a href="#cb13-31" aria-hidden="true" tabindex="-1"></a>    train_seq_len <span class="op">=</span> [train_inputs.shape[<span class="dv">1</span>]]</span>
<span id="cb13-32"><a href="#cb13-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-33"><a href="#cb13-33" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Get only the words between [a-z] and replace period for none</span></span>
<span id="cb13-34"><a href="#cb13-34" aria-hidden="true" tabindex="-1"></a>    original <span class="op">=</span> <span class="st">&#39; &#39;</span>.join(target_text.strip().lower().split(<span class="st">&#39; &#39;</span>)).<span class="op">\</span></span>
<span id="cb13-35"><a href="#cb13-35" aria-hidden="true" tabindex="-1"></a>               replace(<span class="st">&#39;.&#39;</span>, <span class="st">&#39;&#39;</span>).<span class="op">\</span></span>
<span id="cb13-36"><a href="#cb13-36" aria-hidden="true" tabindex="-1"></a>               replace(<span class="st">&#39;?&#39;</span>, <span class="st">&#39;&#39;</span>).<span class="op">\</span></span>
<span id="cb13-37"><a href="#cb13-37" aria-hidden="true" tabindex="-1"></a>               replace(<span class="st">&#39;,&#39;</span>, <span class="st">&#39;&#39;</span>).<span class="op">\</span></span>
<span id="cb13-38"><a href="#cb13-38" aria-hidden="true" tabindex="-1"></a>               replace(<span class="st">&quot;&#39;&quot;</span>, <span class="st">&#39;&#39;</span>).<span class="op">\</span></span>
<span id="cb13-39"><a href="#cb13-39" aria-hidden="true" tabindex="-1"></a>               replace(<span class="st">&#39;!&#39;</span>, <span class="st">&#39;&#39;</span>).<span class="op">\</span></span>
<span id="cb13-40"><a href="#cb13-40" aria-hidden="true" tabindex="-1"></a>               replace(<span class="st">&#39;-&#39;</span>, <span class="st">&#39;&#39;</span>)</span>
<span id="cb13-41"><a href="#cb13-41" aria-hidden="true" tabindex="-1"></a>    <span class="co">#print(&#39;original:&#39; + original)</span></span>
<span id="cb13-42"><a href="#cb13-42" aria-hidden="true" tabindex="-1"></a>    targets <span class="op">=</span> original.replace(<span class="st">&#39; &#39;</span>, <span class="st">&#39;  &#39;</span>)</span>
<span id="cb13-43"><a href="#cb13-43" aria-hidden="true" tabindex="-1"></a>    targets <span class="op">=</span> targets.split(<span class="st">&#39; &#39;</span>)</span>
<span id="cb13-44"><a href="#cb13-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-45"><a href="#cb13-45" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Adding blank label</span></span>
<span id="cb13-46"><a href="#cb13-46" aria-hidden="true" tabindex="-1"></a>    targets <span class="op">=</span> np.hstack([SPACE_TOKEN <span class="cf">if</span> x <span class="op">==</span> <span class="st">&#39;&#39;</span> <span class="cf">else</span> <span class="bu">list</span>(x) <span class="cf">for</span> x <span class="kw">in</span> targets])</span>
<span id="cb13-47"><a href="#cb13-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-48"><a href="#cb13-48" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Transform char into index</span></span>
<span id="cb13-49"><a href="#cb13-49" aria-hidden="true" tabindex="-1"></a>    targets <span class="op">=</span> np.asarray([SPACE_INDEX <span class="cf">if</span> x <span class="op">==</span> SPACE_TOKEN <span class="cf">else</span> <span class="bu">ord</span>(x) <span class="op">-</span> FIRST_INDEX</span>
<span id="cb13-50"><a href="#cb13-50" aria-hidden="true" tabindex="-1"></a>                          <span class="cf">for</span> x <span class="kw">in</span> targets])</span>
<span id="cb13-51"><a href="#cb13-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-52"><a href="#cb13-52" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Creating sparse representation to feed the placeholder</span></span>
<span id="cb13-53"><a href="#cb13-53" aria-hidden="true" tabindex="-1"></a>    train_targets <span class="op">=</span> sparse_tuple_from([targets])</span>
<span id="cb13-54"><a href="#cb13-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-55"><a href="#cb13-55" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> train_inputs, train_targets, train_seq_len, original</span>
<span id="cb13-56"><a href="#cb13-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-57"><a href="#cb13-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-58"><a href="#cb13-58" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> sparse_tuple_from(sequences, dtype<span class="op">=</span>np.int32):</span>
<span id="cb13-59"><a href="#cb13-59" aria-hidden="true" tabindex="-1"></a>    indices <span class="op">=</span> []</span>
<span id="cb13-60"><a href="#cb13-60" aria-hidden="true" tabindex="-1"></a>    values <span class="op">=</span> []</span>
<span id="cb13-61"><a href="#cb13-61" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> n, seq <span class="kw">in</span> <span class="bu">enumerate</span>(sequences):</span>
<span id="cb13-62"><a href="#cb13-62" aria-hidden="true" tabindex="-1"></a>        indices.extend(<span class="bu">zip</span>([n] <span class="op">*</span> <span class="bu">len</span>(seq), <span class="bu">range</span>(<span class="bu">len</span>(seq))))</span>
<span id="cb13-63"><a href="#cb13-63" aria-hidden="true" tabindex="-1"></a>        values.extend(seq)</span>
<span id="cb13-64"><a href="#cb13-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-65"><a href="#cb13-65" aria-hidden="true" tabindex="-1"></a>    indices <span class="op">=</span> np.asarray(indices, dtype<span class="op">=</span>np.int64)</span>
<span id="cb13-66"><a href="#cb13-66" aria-hidden="true" tabindex="-1"></a>    values <span class="op">=</span> np.asarray(values, dtype<span class="op">=</span>dtype)</span>
<span id="cb13-67"><a href="#cb13-67" aria-hidden="true" tabindex="-1"></a>    shape <span class="op">=</span> np.asarray([<span class="bu">len</span>(sequences),</span>
<span id="cb13-68"><a href="#cb13-68" aria-hidden="true" tabindex="-1"></a>                        np.asarray(indices).<span class="bu">max</span>(<span class="dv">0</span>)[<span class="dv">1</span>] <span class="op">+</span> <span class="dv">1</span>],</span>
<span id="cb13-69"><a href="#cb13-69" aria-hidden="true" tabindex="-1"></a>                       dtype<span class="op">=</span>np.int64)</span>
<span id="cb13-70"><a href="#cb13-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-71"><a href="#cb13-71" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> indices, values, shape</span>
<span id="cb13-72"><a href="#cb13-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-73"><a href="#cb13-73" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> read_audio_from_filename(filename, sample_rate):</span>
<span id="cb13-74"><a href="#cb13-74" aria-hidden="true" tabindex="-1"></a>    audio, _ <span class="op">=</span> librosa.load(filename, sr<span class="op">=</span>sample_rate, mono<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb13-75"><a href="#cb13-75" aria-hidden="true" tabindex="-1"></a>    audio <span class="op">=</span> audio.reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb13-76"><a href="#cb13-76" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> audio</span>
<span id="cb13-77"><a href="#cb13-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-78"><a href="#cb13-78" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> find_files(directory, pattern<span class="op">=</span><span class="st">&#39;.wav&#39;</span>):</span>
<span id="cb13-79"><a href="#cb13-79" aria-hidden="true" tabindex="-1"></a>    <span class="co">&quot;&quot;&quot;Recursively finds all files matching the pattern.&quot;&quot;&quot;</span></span>
<span id="cb13-80"><a href="#cb13-80" aria-hidden="true" tabindex="-1"></a>    files <span class="op">=</span> []</span>
<span id="cb13-81"><a href="#cb13-81" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> root, directories, filenames <span class="kw">in</span> os.walk(directory):</span>
<span id="cb13-82"><a href="#cb13-82" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> filename <span class="kw">in</span> filenames: </span>
<span id="cb13-83"><a href="#cb13-83" aria-hidden="true" tabindex="-1"></a>            path <span class="op">=</span> os.path.join(root,filename)</span>
<span id="cb13-84"><a href="#cb13-84" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> pattern <span class="kw">in</span> path: files.append(path)    </span>
<span id="cb13-85"><a href="#cb13-85" aria-hidden="true" tabindex="-1"></a>    res <span class="op">=</span> <span class="bu">sorted</span>(files)</span>
<span id="cb13-86"><a href="#cb13-86" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> res</span>
<span id="cb13-87"><a href="#cb13-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-88"><a href="#cb13-88" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> run_ctc():</span>
<span id="cb13-89"><a href="#cb13-89" aria-hidden="true" tabindex="-1"></a>    graph <span class="op">=</span> tf.Graph()</span>
<span id="cb13-90"><a href="#cb13-90" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> graph.as_default():</span>
<span id="cb13-91"><a href="#cb13-91" aria-hidden="true" tabindex="-1"></a>        <span class="co"># e.g: log filter bank or MFCC features</span></span>
<span id="cb13-92"><a href="#cb13-92" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Has size [batch_size, max_step_size, num_features], but the</span></span>
<span id="cb13-93"><a href="#cb13-93" aria-hidden="true" tabindex="-1"></a>        <span class="co"># batch_size and max_step_size can vary along each step</span></span>
<span id="cb13-94"><a href="#cb13-94" aria-hidden="true" tabindex="-1"></a>        inputs <span class="op">=</span> tf.placeholder(tf.float32, [<span class="va">None</span>, <span class="va">None</span>, num_features])</span>
<span id="cb13-95"><a href="#cb13-95" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-96"><a href="#cb13-96" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Here we use sparse_placeholder that will generate a</span></span>
<span id="cb13-97"><a href="#cb13-97" aria-hidden="true" tabindex="-1"></a>        <span class="co"># SparseTensor required by ctc_loss op.</span></span>
<span id="cb13-98"><a href="#cb13-98" aria-hidden="true" tabindex="-1"></a>        targets <span class="op">=</span> tf.sparse_placeholder(tf.int32)</span>
<span id="cb13-99"><a href="#cb13-99" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-100"><a href="#cb13-100" aria-hidden="true" tabindex="-1"></a>        <span class="co"># 1d array of size [batch_size]</span></span>
<span id="cb13-101"><a href="#cb13-101" aria-hidden="true" tabindex="-1"></a>        seq_len <span class="op">=</span> tf.placeholder(tf.int32, [<span class="va">None</span>])</span>
<span id="cb13-102"><a href="#cb13-102" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-103"><a href="#cb13-103" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Defining the cell</span></span>
<span id="cb13-104"><a href="#cb13-104" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Can be:</span></span>
<span id="cb13-105"><a href="#cb13-105" aria-hidden="true" tabindex="-1"></a>        cell <span class="op">=</span> tf.contrib.rnn.LSTMCell(num_hidden, state_is_tuple<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb13-106"><a href="#cb13-106" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-107"><a href="#cb13-107" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Stacking rnn cells</span></span>
<span id="cb13-108"><a href="#cb13-108" aria-hidden="true" tabindex="-1"></a>        stack <span class="op">=</span> tf.contrib.rnn.MultiRNNCell([cell] <span class="op">*</span> num_layers,</span>
<span id="cb13-109"><a href="#cb13-109" aria-hidden="true" tabindex="-1"></a>                                            state_is_tuple<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb13-110"><a href="#cb13-110" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-111"><a href="#cb13-111" aria-hidden="true" tabindex="-1"></a>        <span class="co"># The second output is the last state and we will no use that</span></span>
<span id="cb13-112"><a href="#cb13-112" aria-hidden="true" tabindex="-1"></a>        outputs, _ <span class="op">=</span> tf.nn.dynamic_rnn(stack, inputs, seq_len, dtype<span class="op">=</span>tf.float32)</span>
<span id="cb13-113"><a href="#cb13-113" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-114"><a href="#cb13-114" aria-hidden="true" tabindex="-1"></a>        shape <span class="op">=</span> tf.shape(inputs)</span>
<span id="cb13-115"><a href="#cb13-115" aria-hidden="true" tabindex="-1"></a>        batch_s, max_time_steps <span class="op">=</span> shape[<span class="dv">0</span>], shape[<span class="dv">1</span>]</span>
<span id="cb13-116"><a href="#cb13-116" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-117"><a href="#cb13-117" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Reshaping to apply the same weights over the timesteps</span></span>
<span id="cb13-118"><a href="#cb13-118" aria-hidden="true" tabindex="-1"></a>        outputs <span class="op">=</span> tf.reshape(outputs, [<span class="op">-</span><span class="dv">1</span>, num_hidden])</span>
<span id="cb13-119"><a href="#cb13-119" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-120"><a href="#cb13-120" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Truncated normal with mean 0 and stdev=0.1</span></span>
<span id="cb13-121"><a href="#cb13-121" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Tip: Try another initialization</span></span>
<span id="cb13-122"><a href="#cb13-122" aria-hidden="true" tabindex="-1"></a>        W <span class="op">=</span> tf.Variable(tf.truncated_normal([num_hidden,</span>
<span id="cb13-123"><a href="#cb13-123" aria-hidden="true" tabindex="-1"></a>                                             num_classes],</span>
<span id="cb13-124"><a href="#cb13-124" aria-hidden="true" tabindex="-1"></a>                                            stddev<span class="op">=</span><span class="fl">0.1</span>))</span>
<span id="cb13-125"><a href="#cb13-125" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Zero initialization</span></span>
<span id="cb13-126"><a href="#cb13-126" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Tip: Is tf.zeros_initializer the same?</span></span>
<span id="cb13-127"><a href="#cb13-127" aria-hidden="true" tabindex="-1"></a>        b <span class="op">=</span> tf.Variable(tf.constant(<span class="fl">0.</span>, shape<span class="op">=</span>[num_classes]))</span>
<span id="cb13-128"><a href="#cb13-128" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-129"><a href="#cb13-129" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Doing the affine projection</span></span>
<span id="cb13-130"><a href="#cb13-130" aria-hidden="true" tabindex="-1"></a>        logits <span class="op">=</span> tf.matmul(outputs, W) <span class="op">+</span> b</span>
<span id="cb13-131"><a href="#cb13-131" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-132"><a href="#cb13-132" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Reshaping back to the original shape</span></span>
<span id="cb13-133"><a href="#cb13-133" aria-hidden="true" tabindex="-1"></a>        logits <span class="op">=</span> tf.reshape(logits, [batch_s, <span class="op">-</span><span class="dv">1</span>, num_classes])</span>
<span id="cb13-134"><a href="#cb13-134" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-135"><a href="#cb13-135" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Time major</span></span>
<span id="cb13-136"><a href="#cb13-136" aria-hidden="true" tabindex="-1"></a>        logits <span class="op">=</span> tf.transpose(logits, (<span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">2</span>))</span>
<span id="cb13-137"><a href="#cb13-137" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-138"><a href="#cb13-138" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> tf.nn.ctc_loss(targets, logits, seq_len)</span>
<span id="cb13-139"><a href="#cb13-139" aria-hidden="true" tabindex="-1"></a>        cost <span class="op">=</span> tf.reduce_mean(loss)</span>
<span id="cb13-140"><a href="#cb13-140" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-141"><a href="#cb13-141" aria-hidden="true" tabindex="-1"></a>        optimizer <span class="op">=</span> tf.train.MomentumOptimizer(learning_rate<span class="op">=</span><span class="fl">0.005</span>,</span>
<span id="cb13-142"><a href="#cb13-142" aria-hidden="true" tabindex="-1"></a>                                               momentum<span class="op">=</span><span class="fl">0.9</span>).minimize(cost)</span>
<span id="cb13-143"><a href="#cb13-143" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-144"><a href="#cb13-144" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Option 2: tf.contrib.ctc.ctc_beam_search_decoder</span></span>
<span id="cb13-145"><a href="#cb13-145" aria-hidden="true" tabindex="-1"></a>        <span class="co"># (it&#39;s slower but you&#39;ll get better results)</span></span>
<span id="cb13-146"><a href="#cb13-146" aria-hidden="true" tabindex="-1"></a>        decoded, log_prob <span class="op">=</span> tf.nn.ctc_greedy_decoder(logits, seq_len)</span>
<span id="cb13-147"><a href="#cb13-147" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-148"><a href="#cb13-148" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Inaccuracy: label error rate</span></span>
<span id="cb13-149"><a href="#cb13-149" aria-hidden="true" tabindex="-1"></a>        ler <span class="op">=</span> tf.reduce_mean(tf.edit_distance(tf.cast(decoded[<span class="dv">0</span>], tf.int32),</span>
<span id="cb13-150"><a href="#cb13-150" aria-hidden="true" tabindex="-1"></a>                                              targets))</span>
<span id="cb13-151"><a href="#cb13-151" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-152"><a href="#cb13-152" aria-hidden="true" tabindex="-1"></a>    files <span class="op">=</span> find_files(<span class="st">&quot;/home/burak/Downloads/vctk-p225-small/wav48/p225&quot;</span>)</span>
<span id="cb13-153"><a href="#cb13-153" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb13-154"><a href="#cb13-154" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> tf.Session(graph<span class="op">=</span>graph) <span class="im">as</span> session:</span>
<span id="cb13-155"><a href="#cb13-155" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-156"><a href="#cb13-156" aria-hidden="true" tabindex="-1"></a>        tf.global_variables_initializer().run()</span>
<span id="cb13-157"><a href="#cb13-157" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-158"><a href="#cb13-158" aria-hidden="true" tabindex="-1"></a>        saver <span class="op">=</span> tf.train.Saver()                </span>
<span id="cb13-159"><a href="#cb13-159" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-160"><a href="#cb13-160" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> curr_epoch <span class="kw">in</span> <span class="bu">range</span>(num_epochs):</span>
<span id="cb13-161"><a href="#cb13-161" aria-hidden="true" tabindex="-1"></a>            train_cost <span class="op">=</span> train_ler <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb13-162"><a href="#cb13-162" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> batch <span class="kw">in</span> <span class="bu">range</span>(num_batches_per_epoch):</span>
<span id="cb13-163"><a href="#cb13-163" aria-hidden="true" tabindex="-1"></a>                filename <span class="op">=</span> random.choice(files)</span>
<span id="cb13-164"><a href="#cb13-164" aria-hidden="true" tabindex="-1"></a>                txtfile <span class="op">=</span> filename.replace(<span class="st">&quot;wav48&quot;</span>,<span class="st">&quot;txt&quot;</span>)</span>
<span id="cb13-165"><a href="#cb13-165" aria-hidden="true" tabindex="-1"></a>                txtfile <span class="op">=</span> txtfile.replace(<span class="st">&quot;.wav&quot;</span>,<span class="st">&quot;.txt&quot;</span>)</span>
<span id="cb13-166"><a href="#cb13-166" aria-hidden="true" tabindex="-1"></a>                txt <span class="op">=</span> <span class="bu">open</span>(txtfile).read()</span>
<span id="cb13-167"><a href="#cb13-167" aria-hidden="true" tabindex="-1"></a>                audio <span class="op">=</span> read_audio_from_filename(filename, sample_rate)</span>
<span id="cb13-168"><a href="#cb13-168" aria-hidden="true" tabindex="-1"></a>                out <span class="op">=</span> convert_inputs_to_ctc_format(audio,sample_rate,txt)</span>
<span id="cb13-169"><a href="#cb13-169" aria-hidden="true" tabindex="-1"></a>                train_inputs, train_targets, train_seq_len, original <span class="op">=</span> out</span>
<span id="cb13-170"><a href="#cb13-170" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-171"><a href="#cb13-171" aria-hidden="true" tabindex="-1"></a>                feed <span class="op">=</span> {inputs: train_inputs,</span>
<span id="cb13-172"><a href="#cb13-172" aria-hidden="true" tabindex="-1"></a>                        targets: train_targets,</span>
<span id="cb13-173"><a href="#cb13-173" aria-hidden="true" tabindex="-1"></a>                        seq_len: train_seq_len}</span>
<span id="cb13-174"><a href="#cb13-174" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-175"><a href="#cb13-175" aria-hidden="true" tabindex="-1"></a>                batch_cost, _ <span class="op">=</span> session.run([cost, optimizer], feed)</span>
<span id="cb13-176"><a href="#cb13-176" aria-hidden="true" tabindex="-1"></a>                train_ler <span class="op">+=</span> session.run(ler, feed_dict<span class="op">=</span>feed)</span>
<span id="cb13-177"><a href="#cb13-177" aria-hidden="true" tabindex="-1"></a>                </span>
<span id="cb13-178"><a href="#cb13-178" aria-hidden="true" tabindex="-1"></a>                <span class="bu">print</span> <span class="st">&#39;batch_cost&#39;</span>, batch_cost, <span class="st">&#39;train_ler&#39;</span>, train_ler</span>
<span id="cb13-179"><a href="#cb13-179" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-180"><a href="#cb13-180" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Decoding</span></span>
<span id="cb13-181"><a href="#cb13-181" aria-hidden="true" tabindex="-1"></a>            d <span class="op">=</span> session.run(decoded[<span class="dv">0</span>], feed_dict<span class="op">=</span>feed)</span>
<span id="cb13-182"><a href="#cb13-182" aria-hidden="true" tabindex="-1"></a>            str_decoded <span class="op">=</span> <span class="st">&#39;&#39;</span>.join([<span class="bu">chr</span>(x) <span class="cf">for</span> x <span class="kw">in</span> np.asarray(d[<span class="dv">1</span>]) <span class="op">+</span> FIRST_INDEX])</span>
<span id="cb13-183"><a href="#cb13-183" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Replacing blank label to none</span></span>
<span id="cb13-184"><a href="#cb13-184" aria-hidden="true" tabindex="-1"></a>            str_decoded <span class="op">=</span> str_decoded.replace(<span class="bu">chr</span>(<span class="bu">ord</span>(<span class="st">&#39;z&#39;</span>) <span class="op">+</span> <span class="dv">1</span>), <span class="st">&#39;&#39;</span>)</span>
<span id="cb13-185"><a href="#cb13-185" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Replacing space label to space</span></span>
<span id="cb13-186"><a href="#cb13-186" aria-hidden="true" tabindex="-1"></a>            str_decoded <span class="op">=</span> str_decoded.replace(<span class="bu">chr</span>(<span class="bu">ord</span>(<span class="st">&#39;a&#39;</span>) <span class="op">-</span> <span class="dv">1</span>), <span class="st">&#39; &#39;</span>)</span>
<span id="cb13-187"><a href="#cb13-187" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-188"><a href="#cb13-188" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">&#39;Original: </span><span class="sc">%s</span><span class="st">&#39;</span> <span class="op">%</span> original)</span>
<span id="cb13-189"><a href="#cb13-189" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">&#39;Decoded: </span><span class="sc">%s</span><span class="st">&#39;</span> <span class="op">%</span> str_decoded)</span>
<span id="cb13-190"><a href="#cb13-190" aria-hidden="true" tabindex="-1"></a>                </span>
<span id="cb13-191"><a href="#cb13-191" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> curr_epoch <span class="op">%</span> <span class="dv">10</span> <span class="op">==</span> <span class="dv">0</span>: saver.save(session, mfile)</span>
<span id="cb13-192"><a href="#cb13-192" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb13-193"><a href="#cb13-193" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-194"><a href="#cb13-194" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="va">__name__</span> <span class="op">==</span> <span class="st">&#39;__main__&#39;</span>:</span>
<span id="cb13-195"><a href="#cb13-195" aria-hidden="true" tabindex="-1"></a>    run_ctc()</span></code></pre></div>
<p>Kaynaklar</p>
<p>[1] Bayramlı, <em>VCTK Ses Tanima Verisi, Konusmaci 225</em>, <a
href="https://drive.google.com/uc?export=view&amp;id=1zK-mgG6Q8N8OuOGpexbxVkES3DuQhGOk">https://drive.google.com/uc?export=view&amp;id=1zK-mgG6Q8N8OuOGpexbxVkES3DuQhGOk</a></p>
<p>[2] Remy, <em>Application of Connectionist Temporal Classification
(CTC) for Speech Recognition</em>,<a
href="https://github.com/philipperemy/tensorflow-ctc-speech-recognition">https://github.com/philipperemy/tensorflow-ctc-speech-recognition</a></p>
<p>[3] Graves, <em>Supervised Sequence Labelling with Recurrent Neural
Networks</em>, <a
href="https://www.cs.toronto.edu/~graves/preprint.pdf">https://www.cs.toronto.edu/~graves/preprint.pdf</a></p>
<p>[4] Graves, <em>How to build a recognition system (Part 1): CTC
Loss</em>, <a
href="https://docs.google.com/presentation/d/1AyLOecmW1k9cIbfexOT3dwoUU-Uu5UqlJZ0w3cxilkI">https://docs.google.com/presentation/d/1AyLOecmW1k9cIbfexOT3dwoUU-Uu5UqlJZ0w3cxilkI</a></p>
<p>[5] Graves, <em>How to build a recognition system (Part 2): CTC
Loss</em>, <a
href="https://docs.google.com/presentation/d/12gYcPft9_4cxk2AD6Z6ZlJNa3wvZCW1ms31nhq51vMk">https://docs.google.com/presentation/d/12gYcPft9_4cxk2AD6Z6ZlJNa3wvZCW1ms31nhq51vMk</a></p>
<p>[6] Bayramlı, <em>Ses Komut Verisi</em>, <a
href="https://drive.google.com/open?id=1BIGj3NtUZfSrXMaJ8hCqsz0UzS01MSrF">https://drive.google.com/open?id=1BIGj3NtUZfSrXMaJ8hCqsz0UzS01MSrF</a></p>
<p>[7] Bayramlı, Bilgisayar Bilim, <em>Uzun Kısa-Vade Hafıza
Ağları</em></p>
<p>
  <a href="..">Yukarı</a>
</p>
</body>
</html>
