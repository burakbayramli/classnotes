\documentclass[12pt,fleqn]{article}\usepackage{../../common}
\begin{document}
Uzun Kýsa-Vade Hafýza Aðlarý (Long Short-Term Memory Networks, LSTM)

Kendini tekrarlayan YSA (RNN) yapýlarýnýn içindeki gizli konum $s_t$ bir
zaman diliminden bir diðerine aktarýlabiliyordu, ve bu sýrada bir matris
çarpýmý üzerinden deðiþime uðrayabiliyordu. Böylece her zaman diliminde
yeni görülen verinin ``hafýza'' olarak ta görülebilecek $s_t$'ye etkisi
olabiliyordu. RNN dýþ dünya hakkýndaki iç modelini böyle güncelliyordu.

Fakat RNN ile tarif edilen bu güncellemeye hiç bir sýnýr getirmedik. Biraz
düþünürsek bu güncellemenin biraz kaotik bir hal alabileceðini görebiliriz
[1]. Mesela bir filmi kare kare izleyerek filmde neler olduðunu tarif
etmeye uðraþan bir RNN düþünelim. Bir karede bir karakterin ABD'de olduðunu
düþünebilir, ama sonraki karede karakterin suþi yediðini görüyor ve
Japonya'da olduðuna karar verebilir, sonra Panda ayýsý görüyor ve karakteri
kuzey kutbunda zannediyor olabilir.

Bu tarif edilen kaos enformasyonun çok hýzlý etki ettiðini ve ayný hýzda
yokolduðuna iþaret. Bu tür bir yapýda modelin uzun vadeli hafýza tutmasý
oldukca zor. Bize gereken modelin sadece güncelleme yapmasý deðil,
güncelleme yapmayý da öðrenmesi. Ali adlý bir karakter film karesinde yoksa
o kareler Ali hakkýndaki bilgiyi güncellemek için kullanýlmamalý, ayný
þekilde Ayþe'nin içinde olmadýðý kareler onun hakkýndaki bilgiyi
güncellemek için kullanýlmamalý. 

Çözüm için þöyle bir yaklaþým kullanabiliriz. 

1) Bir ``unutma'' mekanizmasý ekle. Film seyrediyoruz, bir sahne bitiyor, o
sahnenin hangi gün, saat kaçta, nerede olduðunu unutuyoruz. Fakat bir
karakter o sahnede olmuþse, bunu hatýrlýyoruz. Modelin ne zaman
hatýrlayacaðýný, ne zaman unutacaðýný öðrenmesini istiyoruz (dikkat sadece
belli bir þekilde unutmasý, hatýrlamasý deðil, tüm bunlarý ne zaman
yapacaðýný öðrenmesi).

2) Bir belleðe yazma (zulaya atma?) mekanizmasý. Model yeni bir kare
gördüðünde o karedeki bilginin kaydetmeye deðer olup olmadýðýna karar
vermesi lazým, ve bu öðrenilse iyi olur.

3) .. ki yeni bir girdi gelince model ihtiyacý olmadýðý bilgiyi
unutacak. Sonra girdinin hangi kýsmýnýn faydalý olduðuna karar verecek ve o
kýsmý uzun-vadeli hafýzasýna kaydedecek.

4) Bir odaklanma mekanizmasý. Uzun-vadeli hafýzanýn hangi kýsmý sýk
kullaným gerekiriyor, iþlem hafýzasý (working memory) hangisi, buna karar
vermek.

Bize gereken bir uzun kýsa-vade hafýza aðýdýr, teknik ismiyle LSTM. RNN her
zaman adýmýnda hafýzasýný kontrolsüz bir þekilde güncelleyebiliyorken, bir
LSTM hafýzasýný çok daha seçici, kararlý bir þekilde günceller, bunu
yaparken spesifik öðrenme mekanizmalarý kullanýr ki bu mekanizma ona
görülen bilginin hangi kýsmýnýn hatýrlanmaya deðer, hangisinin
güncellenmesinin gerekli olduðunu, ve hangisinin daha fazla odaklanýlmaya
ihtiyaç duyduðunu belirler.

Matematiksel olarak $t$ anýnda bir $x_t$ girdisi alýyoruz, uzun-vadeli ve
iþlem hafýzasý $c_{t-1}$ ve $h_{t-1}$ bir önceki zaman diliminden bir
önceki bu zamana aktarýlýyor ve onlarý bir þekilde güncellemek
istiyoruz. Bize gereken bir tür hatýrlama geçidi (remember gate), bu
elektronik devrelerdeki gibi bir geçit, 0 ile 1 arasýnda olacak $n$ tane
sayý, bu sayý $n$ hafýza ögesinin ne kadar hatýrlanacaðýný, yani ne kadar
uzun-vadeli olup olmayacaðýný belirleyecek. 1 tut, 0 unut demek olacak.

Ufak bir YSA kullanarak bu geçidi öðrenebiliriz,

$$ f_t = \sigma (W_r x_t + U_r h_{t-1}) $$

Bu basit, sýð (derin olmayan) bir YSA, $\sigma$ sigmoid aktivasyonu. Sigmoid
kullandýk çünkü 0 ile 1 arasýnda çýktýya ihtiyacýmýz var. Þimdi girdiden
öðreneceðimiz bilgiyi hesaplamamýz lazým, bu bilgi uzun-vadeli hafýzamýz
için bir aday olacak. 

$$ c_t' = \phi(W_l x_t + U_l h_{t-1})$$

$\phi$ bir aktivasyon fonksiyonu, çoðunlukla $\tanh$ olarak seçilir. 

Fakat bir adayý hafýzamýza eklemeden önce hangi bölümlerinin kullanýma,
kaydetmeye deðer olduðunu öðrenmemiz gerekir. Web'de bir þey okurken kendi
zihnimizde neler olduðunu düþünelim. Bir haber makalesi okuduðumuzu
düþünelim, Trabzonspor'un hep kötüyü gittiðini, yanlýþ tranferler yaptýðýný
anlatan bir haber okuyoruz, bu haberi fenerbahçe.org sitesinde okuyorsak o
habere daha az önem verebiliriz.

$$ i_t = \sigma (W_s x_t + U_s h_{t-1} $$

Þimdi tüm bu basamaklarý birleþtirelim. Ýhtiyaçýmiz olmayan hafýzalarý
unuttuktan ve bilgilerin faydalý olabilecek kýsýmlarýný sakladýktan sonra,
elimizde bir güncellenmiþ uzun-vadeli bellek geçer, 

$$ c_t = f_t \circ c_{t-1} \circ i_t \circ c_t' $$

ki $\circ$ operasyonu her iki taraftaki deðiþkenlerin içindeki her ögenin
birer birer çarpýlmasý (element-wise multiplication)  demek. 

Sonra iþlem hafýzasýný güncellememiz lazým, uzun-vade belleðimizi anlýk
iþlem için faydalý olabilecek þekilde nasýl odaklarýz, onu öðrenmek
istiyoruz. O zaman bir odaklanma vektörü öðreniriz,

$$ o_t = \sigma (W_f x_t + U_f h_{t-1} $$

O zaman iþlem hafýzamýz

$$ h_t = o_t \circ \phi (c_t)$$

Yani odak deðeri 1 olan öðelere tam dikkatimizi veriyoruz, 0 olanlara hiç
dikkat etmiyoruz. 

Kuþbakýþý ile bakarsak kendini tekrar eden LSTM yapýsý suna benzer,

\includegraphics[width=30em]{lstm_02.png}

Sol ve saðdaki hücreler ortadakinin kopyasý. 

Kýyasla RNN'nin iç yapýsý çok daha basittir, 

\includegraphics[width=30em]{lstm_03.png}

LSTM resmindeki her birimin formülleriyle beraber teker teker tekrar
üzerinden geçmek gerekirse [2]:

Ýlk adým hücre bilgisinden neleri atacaðýmýza karar vermek. Bu karar unutma
karar tabakasý adý verilen bir sigmoid tabakasý tarafýndan
kararlaþtýrýlýyor, bu tabaka $h_{t-1}$ ve $x_t$'ye bakýyor ve $c_{t-1}$
hücre konumundaki her deðer için 0 ile 1 arasýnda bir sayý üretiyor. 1 bu
deðeri tamamen tut, 0 bu deðeri tamamen unut anlamýna geliyor.

\includegraphics[width=30em]{lstm_04.png}

Bir sonraki adým hücrede hangi yeni bilgiyi depolayacaðýmýza karar
vermek. Bu kararýn iki parçasý var, önce girdi geçit tabakasý (input gate
layer) adý verilen hangi deðerleri güncelleyeceðimize karar
veriyor. Ardýndan bir $\tanh$ tabakasý bir ``aday vektörü'' $c_t'$
üretiyor, bu vektör, adý üzerinde, hücre konumuna eklenmeye aday
bilgiler. Ardýndan bu iki vektör birleþtirilip konumu güncellemek için yeni
bir vektör yaratýlýyor. 

\includegraphics[width=30em]{lstm_05.png}


\begin{minted}[fontsize=\footnotesize]{python}
import tensorflow as tf
import numpy as np
from pprint import pprint
import datetime
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

np.random.seed(1)

LSTM_SIZE = 30
t_min, t_max = 0, 30
resolution = 0.1
sequence_length = 5
instruction_count = 1
epoch = 500

def f(t):
    return t * np.sin(t) / 3 + 2 * np.sin(t*5)

def next_batch(batch_size, n_steps):
    t0 = np.random.rand(batch_size, 1) * (t_max - t_min - n_steps * resolution)
    Ts = t0 + np.arange(0., n_steps + 1) * resolution
    ys = f(Ts)
    X = ys[:, :-1].reshape(-1, n_steps, 1)
    y = ys[:, 1:].reshape(-1, n_steps, 1)
    y = y[:,-1,:]
    y = y.flatten()
    print y.shape    
    return list(X),y

reference_input_data,reference_output_data = next_batch(400, sequence_length)
   
NUM_EXAMPLES = len(reference_input_data) / 4 

test_input = reference_input_data[NUM_EXAMPLES:]
test_output = reference_output_data[NUM_EXAMPLES:] 
train_input = reference_input_data[:NUM_EXAMPLES]
train_output = reference_output_data[:NUM_EXAMPLES]

print train_input[1]
print train_output[1]

data = tf.placeholder(tf.float32, [None, sequence_length, instruction_count], name='data')
target = tf.transpose(tf.placeholder(tf.float32, [None], name='target'))

FEATURE_SIZE = 1 

def default_weights_and_bias():
    Weights = tf.Variable(tf.truncated_normal([LSTM_SIZE, LSTM_SIZE + FEATURE_SIZE], -0.2, 0.1))
    bias = tf.Variable(tf.constant(0.0, shape = [LSTM_SIZE, 1]))
    
    return Weights, bias

W_f, _ = default_weights_and_bias()

b_f = tf.Variable(tf.constant(1.0, shape = [LSTM_SIZE, 1]))

# Unutma tabakasi
def f_t(ht_minus_1_and_xt):
    return tf.sigmoid(tf.matmul(W_f, ht_minus_1_and_xt) + b_f)

W_i, b_i = default_weights_and_bias()

# Girdi gecidi tabakasi
def i_t(ht_minus_1_and_xt):
    return tf.sigmoid(tf.matmul(W_i, ht_minus_1_and_xt) + b_i)

W_C, b_c = default_weights_and_bias()

def candidate_C_t(ht_minus_1_and_xt):
    return tf.tanh(tf.matmul(W_C, ht_minus_1_and_xt) + b_c)

def C_t(ht_minus_1_and_xt, Conveyor, CandidateConveyor):
    return f_t(ht_minus_1_and_xt) * Conveyor + i_t(ht_minus_1_and_xt) * CandidateConveyor

W_o, b_o = default_weights_and_bias()

def h_t(ht_minus_1_and_xt, FinalConveyor):
    o_t = tf.sigmoid(tf.matmul(W_o, ht_minus_1_and_xt) + b_o)    
    return o_t * tf.tanh(FinalConveyor)

def lstm_cell(ht_minus_1_and_Conveyor, xt):
    ht_minus_1, Conveyor = ht_minus_1_and_Conveyor
    
    ht_minus_1_and_xt = tf.transpose(tf.concat([ht_minus_1, xt], 1))
    
    CandidateConveyor = candidate_C_t(ht_minus_1_and_xt)
    
    FinalConveyor = C_t(ht_minus_1_and_xt, Conveyor, CandidateConveyor)
    
    lstm_prediction = tf.transpose(h_t(ht_minus_1_and_xt, FinalConveyor))
    
    return(lstm_prediction, FinalConveyor)

data_length = tf.shape(data)[0]

def lstm_loop(last_lstm_prediction, last_state, step):
    lstm_prediction, state = lstm_cell((last_lstm_prediction, last_state),
                                       data[:, step, :])
    return lstm_prediction, state, tf.add(step, 1)

initial_Conveyor = tf.zeros([LSTM_SIZE, data_length])

initial_prediction = tf.zeros([data_length, LSTM_SIZE])

timesteps = sequence_length

for_each_time_step = lambda a, b, step: tf.less(step, timesteps)

arg = (initial_prediction, initial_Conveyor, 0)
lstm_prediction, lstm_state, _ = tf.while_loop(for_each_time_step,
                                               lstm_loop, arg,
                                               parallel_iterations=32)

weight = tf.Variable(tf.truncated_normal([LSTM_SIZE, 1]))

bias = tf.Variable(tf.constant(0.0, shape=[1]))

prediction = tf.matmul(lstm_prediction, weight) + bias

with tf.name_scope('mean_square_error'):
    mean_square_error = tf.reduce_sum(tf.square(tf.subtract(target, tf.unstack(prediction, axis = 1))))
    
tf.summary.scalar('mean_square_error', mean_square_error)

optimizer = tf.train.AdamOptimizer()

minimize = optimizer.minimize(mean_square_error)

with tf.name_scope('error'):
    with tf.name_scope('mistakes'):
        mistakes = tf.not_equal(target, tf.round(tf.unstack(prediction, axis = 1)))

sess = tf.InteractiveSession()

merged = tf.summary.merge_all()

date = str(datetime.datetime.now())

init_op = tf.global_variables_initializer()

saver = tf.train.Saver() 

sess.run(init_op)

for i in range(epoch):
    if (i + 1) % 20 == 0:
        summary, mean_squ_err = sess.run([merged, mean_square_error], {data: test_input, target: test_output})        
        print('Epoch {:4d} | mean squ error {: 3.1f}'.format(i + 1, mean_squ_err))
    
    sess.run(minimize,{data: train_input, target: train_output})

\end{minted}

\begin{verbatim}
(400,)
[[ 3.71134228]
 [ 4.12646883]
 [ 4.52614447]
 [ 4.67751103]
 [ 4.39857443]]
3.60413751202
Epoch   20 | mean squ error  4373.3
Epoch   40 | mean squ error  2624.0
Epoch   60 | mean squ error  2007.1
Epoch   80 | mean squ error  1474.9
Epoch  100 | mean squ error  989.3
Epoch  120 | mean squ error  657.5
Epoch  140 | mean squ error  476.4
Epoch  160 | mean squ error  367.4
Epoch  180 | mean squ error  296.0
Epoch  200 | mean squ error  244.6
Epoch  220 | mean squ error  205.1
Epoch  240 | mean squ error  174.6
Epoch  260 | mean squ error  151.6
Epoch  280 | mean squ error  134.1
Epoch  300 | mean squ error  120.5
Epoch  320 | mean squ error  109.5
Epoch  340 | mean squ error  100.3
Epoch  360 | mean squ error  92.3
Epoch  380 | mean squ error  85.1
Epoch  400 | mean squ error  78.6
Epoch  420 | mean squ error  72.7
Epoch  440 | mean squ error  67.2
Epoch  460 | mean squ error  62.2
Epoch  480 | mean squ error  57.7
Epoch  500 | mean squ error  53.5
\end{verbatim}


\begin{minted}[fontsize=\footnotesize]{python}
def f(t):
    return t * np.sin(t) / 3 + 2 * np.sin(t*5)

t = np.linspace(t_min, t_max, int((t_max - t_min) / resolution))
y = f(t)

newx = list(t[-sequence_length:])
newy = list(y[-sequence_length:])

for i in range(40): # bu kadar daha uret
   tst_input = np.array(newy[-sequence_length:]).reshape(sequence_length,1)   
   res = sess.run(prediction, { data: [ tst_input ]  } )
   newy.append(res)
   newx.append(t_max + (i*resolution))

plt.plot(t,y)
plt.plot(newx,newy,'g')
plt.savefig('lstm_01.png')
\end{minted}


\includegraphics[width=20em]{lstm_01.png}


[devam edecek]



Zaman Serisi Sýnýflandýrmak

\begin{minted}[fontsize=\footnotesize]{python}
import pandas as pd, zipfile
import tensorflow as tf
from tensorflow.contrib import rnn

learning_rate = 0.001
training_iters = 100000
batch_size = 25
display_step = 10

n_input = 1 
n_steps = 152 
n_hidden = 128 
n_classes = 2

with zipfile.ZipFile('wafer.zip', 'r') as z:
      df_train =  pd.read_csv(z.open('Wafer/wafer_TRAIN.txt'),header=None)
      df_test =  pd.read_csv(z.open('Wafer/wafer_TEST.txt'),header=None)

def minibatches(batch_size,input="train"):
      df = None
      if input=="train": df=df_train
      if input=="test": df=df_test
      df = np.array(df)
      for i in range(len(df)):
            batch_x = []; batch_y = []
            for j in range(batch_size):
                  batch_x.append(list(df[i,1:]))
                  batch_y.append([int(df[i,0]==-1), int(df[i,0]==1) ])
            batch_x = np.array(batch_x).reshape(batch_size,n_steps,1)
            batch_y = np.array(batch_y).reshape(batch_size,2)
            yield batch_x, batch_y                  

\end{minted}


\begin{minted}[fontsize=\footnotesize]{python}
def reset_graph(seed=42):
    tf.reset_default_graph()
    tf.set_random_seed(seed)
    np.random.seed(seed)

reset_graph()

x = tf.placeholder("float", [None, n_steps, n_input])
y = tf.placeholder("float", [None, n_classes])

weights = {
    'out': tf.Variable(tf.random_normal([n_hidden, n_classes]))
}
biases = {
    'out': tf.Variable(tf.random_normal([n_classes]))
}

def LSTM(x, weights, biases):
    x = tf.unstack(x, n_steps, 1)
    lstm_cell = rnn.BasicLSTMCell(n_hidden)
    outputs, states = rnn.static_rnn(lstm_cell, x, dtype=tf.float32)
    return tf.matmul(outputs[-1], weights['out']) + biases['out']

pred = LSTM(x, weights, biases)

correct_pred = tf.equal(tf.argmax(pred,1), tf.argmax(y,1))
accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))
new_pred = tf.argmax(y,1)

print 'cost'
scf = tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y)
cost = tf.reduce_mean(scf)
print 'optimizer'
optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)

mfile = "/tmp/time_series_classif"

init = tf.global_variables_initializer()
saver = tf.train.Saver()
with tf.Session() as sess:
    sess.run(init)
    step = 1
    # Keep training until reach max iterations
    b_it = minibatches(batch_size)
    while step < int(1000 / batch_size):
          batch_x, batch_y = next(b_it)
          sess.run(optimizer, feed_dict={x: batch_x, y: batch_y})
          if step % display_step == 0:
                # Calculate batch accuracy
                acc = sess.run(accuracy, feed_dict={x: batch_x, y: batch_y})
                # Calculate batch loss
                loss = sess.run(cost, feed_dict={x: batch_x, y: batch_y})
                print("Iter " + str(step) + ", Minibatch Loss= " + \
                      "{:.6f}".format(loss) + ", Training Accuracy= " + \
                      "{:.5f}".format(acc))
          step += 1

    print("Optimization Finished!")
    saver.save(sess, mfile) # not shown in the book
\end{minted}

\begin{verbatim}
cost
optimizer
Iter 10, Minibatch Loss= 1.847300, Training Accuracy= 0.00000
Iter 20, Minibatch Loss= 0.049264, Training Accuracy= 1.00000
Iter 30, Minibatch Loss= 0.176535, Training Accuracy= 1.00000
Optimization Finished!
\end{verbatim}

\begin{minted}[fontsize=\footnotesize]{python}
saver = tf.train.Saver()
from sklearn import metrics
real = []
pred = []
with tf.Session() as sess:
    saver.restore(sess, mfile)
    for batch_x, batch_y in minibatches(1,input="test"):
      res = sess.run(new_pred, feed_dict={x: batch_x, y: batch_y})
      pred.append(res[0])
      real.append(np.argmax(batch_y[0]))
    fpr, tpr, thresholds = metrics.roc_curve(np.array(real), np.array(pred))
    print 'AUC', metrics.auc(fpr, tpr)      
\end{minted}                    

\begin{verbatim}
AUC 1.0
\end{verbatim}










Kaynaklar

[1] Chen, {\em Exploring LSTMs: Understanding Basics (Part One)}, \url{https://www.topbots.com/exploring-lstm-tutorial-part-1-recurrent-neural-network-deep-learning/}

[2] Shell, {\em Do It Yourself LSTM with TensorFlow}, \url{https://chrisschell.de/2017/07/10/do_it_yourself_lstm_with_tensorflow.html}

\end{document}

