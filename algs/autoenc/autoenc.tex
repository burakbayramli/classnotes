\documentclass[12pt,fleqn]{article}\usepackage{../../common}
\begin{document}
Özkodlama (Autoencoding)

Özkodlamanýn yaptýðýnýn bir tür "veriyi sýkýþtýrma" iþlemi
söylenebilir. Yapay öðrenmede algoritmalarýn denetimli ve denetimsiz
olarak ikiye ayrýldýðýndan bahsetmiþtik, özkodlama denetimsiz çalýþýr
yani ortada etiket yoktur, daha doðrusu özkodlama verinin kendisini
etiket olarak kullanýr.

\includegraphics[width=30em]{autoenc_02.png}

Yani girdi olarak verilen veriyi çýktý olarak ta kullanýrsak, YSA'yý
kendi çýktýsýný tekrar oluþturmayý öðrenmeye zorlamýþ oluruz, bu
YSA'yý veriyi özetlemeye doðru yöneltecektir, ve bu tekrar oluþturma
için ileri besleme sýrasýnda veriyi dar bir noktadan geçmeye zorlarsak
(üstteki resimde görülüyor, 7 nöronluk girdi 5 nöronluk "daha dar" bir
katmandan geçmeye zorlanýyor), bu YSA'yý "sýkýþtýrma" yapmaya daha da
meyýllendirecektir.

\inputminted[fontsize=\footnotesize]{python}{mnist_autoenc.py}

\begin{minted}[fontsize=\footnotesize]{python}
from keras.datasets import mnist
import mnist_autoenc

(x_train, _), (x_test, _) = mnist.load_data()
x_test = x_test.astype('float32') / 255.
autoencoder, encoder, decoder = mnist_autoenc.get_model()
encoder.load_weights("mod-enc-1.h5")
decoder.load_weights("mod-dec-1.h5")
\end{minted}

\begin{minted}[fontsize=\footnotesize]{python}
tmp = x_test[1090, :, :].reshape(1,28*28)
encoded = encoder.predict(tmp)
print (encoded.shape)
decoded = decoder.predict(encoded).reshape(28,28)
print (decoded.shape)
plt.imshow(decoded)
plt.gray()
plt.savefig('autoenc_01.png')
\end{minted}

\includegraphics[width=20em]{autoenc_01.png}

\inputminted[fontsize=\footnotesize]{python}{mnist_autoenc_rnn_simple.py}

\begin{minted}[fontsize=\footnotesize]{python}
import mnist_autoenc_rnn_simple

seq_autoencoder, encoder = mnist_autoenc_rnn_simple.get_model()
seq_autoencoder.load_weights("mod-rnn-autoenc-sim.h5")
encoder.load_weights("mod-rnn-enc-sim.h5")
\end{minted}

\begin{minted}[fontsize=\footnotesize]{python}
decoded = seq_autoencoder.predict(tmp).reshape(28,28)
print (decoded.shape)
plt.imshow(decoded)
plt.gray()
plt.savefig('autoenc_03.png')
\end{minted}

\includegraphics[width=20em]{autoenc_03.png}

Varyasyonel Özkodlayýcýlar

Standard özkodlayýcýlarýn bir problemi kodlama yaptýklarý daralmýþ
alandaki vektörlerin sürekli olmayabileceði, ve buradaki deðerlerin
kolay bir þekilde interpolasyon yapýlmasýndaki bazý zorluklar.


[5]'ten 
Given a random variable z with one distribution, we can create another random
variable X = g(z) with a completely different distribution.  Left: samples from
a gaussian distribution. Right: those same samples mapped through the function
g(z) = z/10 + z/||z|| to form a ring. This is the strategy that VAEs use to
create arbitrary distributions: the deterministic function g is learned from
data .

Biliyoruz ki herhangi bir dagilima sahip rasgele degisken $z$'yi bir $g$
fonksiyonu kullanarak $X=g(z)$ ile baska bir dagilima cevirebiliyoruz. Altta
ornegi goruluyor, soldaki resim Gaussian dagilimdan, sagdaki resim soldaki
verilerin $g(z) = z/10 + z/||z||$ ile baska bir dagilima eslenmis hali ve bu
yeni dagilim bir cember seklini olusturmus. VAE'nin rasgele dagilimlar
yaratabilmesinin arkasinda yatan gizem bu iste. Egitim ile VAE $g$'yi ogrenmis
oluyor, ki bu bir determinstik fonksiyon. 

\begin{minted}[fontsize=\footnotesize]{python}
import random, numpy.linalg as lin, pandas as pd
x = np.random.randn(1000,2)
x = pd.DataFrame(x)
x['n'] = np.sqrt(x[0]*x[0] + x[1]*x[1])
x['g0'] = (x[0]/10.0) + x[0]/x['n']
x['g1'] = (x[1]/10.0) + x[1]/x['n']
plt.figure()
ax = plt.subplot(1, 2, 1)
plt.plot(x[0],x[1],'.')
ax = plt.subplot(1, 2, 2)
plt.plot(x['g0'],x['g1'],'.')
plt.xlim(-4,4)
plt.ylim(-4,4)
plt.savefig('autoenc_10.png')
\end{minted}

\includegraphics[width=40em]{autoenc_10.png}


\includegraphics[width=40em]{autoenc_06.png}

\includegraphics[width=20em]{autoenc_07.png}

\inputminted[fontsize=\footnotesize]{python}{mnist_lstm_vae.py}

\begin{minted}[fontsize=\footnotesize]{python}
import mnist_lstm_vae

vae, enc, gen = mnist_lstm_vae.create_lstm_vae(mnist_lstm_vae.input_dim, 
    timesteps=mnist_lstm_vae.timesteps, 
    batch_size=mnist_lstm_vae.batch_size, 
    intermediate_dim=mnist_lstm_vae.latent_dim,
    latent_dim=mnist_lstm_vae.latent_dim,
    epsilon_std=1.)
vae.load_weights('mnist_lstm_vae.h5')
enc.load_weights('mnist_lstm_enc.h5')
\end{minted}

\begin{minted}[fontsize=\footnotesize]{python}
import random
idx = 400 # herhangi bir imaji sec
print (tmp.shape)
x_test_tmp = x_test[idx]
res = vae.predict(x_test_tmp.reshape((1, 28, 28)))

plt.figure()
ax = plt.subplot(1, 2, 1)
pixels = res.reshape((28, 28))
plt.imshow(pixels)
plt.gray()
ax = plt.subplot(1, 2, 2)
plt.imshow(x_test_tmp)
plt.gray()

plt.savefig('autoenc_04.png')
\end{minted}

\includegraphics[width=20em]{autoenc_04.png}

Hasimsal Ozkodlayici (Adverserial Autoencoder -AA-)

Uretici Hasimsal Aglar (Generative Adverserial Networks -GAN-) kavraminin
ozkodlayicilara uygulanmis hali AA olur. 

\includegraphics[width=20em]{autoenc_09.png}

Burada bir kodlayici / kodçözücü yapisi var (ust blok) bu yapidan kodlanmis ara
tabaka $z \sim q(z)$ ``kotu'' ornekler cekilip $p(z)$'den gelen ``iyi'' ornekler
ile birlestiriliyor ve ayirdedici yine bu iki grup arasinda ayirim yapmayi
ogreniyor. Bu durumda ust bloktaki kodcozucu GAN'deki uretici gibi olur, ona
donusur bir bakima, cunku oyle iyi uretim yapmaya calisacaktir ki $p(z)$
gurultusu ile onun aldigi kodlanmis tabaka verisi ayiredilemez hale gelmelidir.
Tabii ki ust soldaki kodlayici bu ara tabakaya o sekilde temsili veri uretmeye
calisacaktir, bu arada kodlayici / kodcozucu yapisi da egitilmis olur. Yani $z$
bir anlamda alt soldaki gercek gurultuye yaklasir, bu gurultuden sayi uretebilir
hale geliriz, bu klasik GAN, ayrica bu ``kodlanmis'' gurultuyu ureten kodlayici
/ kodcozucu tabaka da ayri bir sekilde kendini optimize eder ve kodlama isini
yapar hale gelir.

\inputminted[fontsize=\footnotesize]{python}{aae_normal.py}

\begin{minted}[fontsize=\footnotesize]{python}
import aae_normal
latent_dim = 100
input_shape = (28, 28)
encoder = aae_normal.model_encoder(latent_dim, input_shape)
encoder.load_weights('aae-norm-encoder.h5')
generator = aae_normal.model_generator(latent_dim, input_shape)
generator.load_weights('aae-norm-generator.h5')
\end{minted}

\begin{minted}[fontsize=\footnotesize]{python}
idx = 100 # herhangi bir imaji sec
print (x_test[idx, :].shape)
res = encoder.predict(x_test[idx, :].reshape(1,28,28))
print (res.shape)
pixels = generator.predict(res)
pixels = pixels.reshape((28, 28))
plt.imshow(pixels)
plt.gray()
plt.savefig('autoenc_05.png')
\end{minted}

\includegraphics[width=20em]{autoenc_05.png}

\inputminted[fontsize=\footnotesize]{python}{aae_lstm.py}


\begin{minted}[fontsize=\footnotesize]{python}
import aae_lstm
latent_dim = 200
input_shape = (28, 28)
encoder = aae_lstm.model_encoder(latent_dim, input_shape)
encoder.load_weights('aae-lstm-encoder.h5')
generator = aae_lstm.model_generator(latent_dim, input_shape)
generator.load_weights('aae-lstm-generator.h5')
\end{minted}

\begin{minted}[fontsize=\footnotesize]{python}
idx = 1030 # herhangi bir imaji sec
res = encoder.predict(x_test[idx, :].reshape(1, 28,28))
pixels = generator.predict(res)
pixels = pixels.reshape((28, 28))
plt.imshow(pixels)
plt.gray()
plt.savefig('autoenc_08.png')
\end{minted}

\includegraphics[width=20em]{autoenc_08.png}



Kaynaklar

[1] \url{https://blog.keras.io/building-autoencoders-in-keras.html}

[2] adverserial autoencoder keras \url{https://github.com/bstriner/keras-adversarial/blob/master/examples/example_aae.py}

[3] \url{https://towardsdatascience.com/intuitively-understanding-variational-autoencoders-1bfe67eb5daf}

[4] \url{https://hsaghir.github.io/data_science/denoising-vs-variational-autoencoder/}

[5] Doersch, Tutorial on Variational Autoencoders, \url{https://arxiv.org/pdf/1606.05908.pdf}

[6] Goodfellow, Adversarial Autoencoders, \url{https://arxiv.org/pdf/1511.05644.pdf}

[7] What is Adversarial Autoencoder?, \url{https://www.quora.com/What-is-Adversarial-Autoencoder}

[8] \url{http://www.inference.vc/adversarial-autoencoders/}


\end{document}
