<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
    <script type="text/x-mathjax-config">
    MathJax.Hub.Register.StartupHook("TeX Jax Ready",function () {
      MathJax.Hub.Insert(MathJax.InputJax.TeX.Definitions.macros,{
        cancel: ["Extension","cancel"], cancelto: ["Extension","cancel"]
      });
    });
    </script>  
   
  <title>Otomatik Tercüme, Makine Tercümesi (Machine Translation)</title>
  <style type="text/css">code{white-space: pre;}</style>
  <style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
  </style>
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>
</head>
<body>
<div id="header">
</div>
<h1 id="otomatik-tercüme-makine-tercümesi-machine-translation">Otomatik Tercüme, Makine Tercümesi (Machine Translation)</h1>
<p>Dizin-Dizin İlişkisini Öğrenmek (Sequence to Sequence Learning)</p>
<p>Dillerarası otomatik tercüme yazılımı Google Translate ile popüler hale geldi. Google bu servisi ilk kodladığında parça parça, istatistiki bir yaklaşım kullanarak kodlamış, fakat 2017 yılında bu servis tamamen derin öğrenme üzerinden işleyecek şekilde değiştirildi, kod satır sayısı 500,000'den 500'e indi!</p>
<p>DO bazlı tercüme sistemleri nasıl işler?</p>
<div class="figure">
<img src="seq_02.png" />

</div>
<p>Not: kaynak cümlesi ters şekilde girilmiş, bu mimarı ilk teklif edildiğinde bu şekilde yapılıyordu, fakat [3]'e göre her eğitim verisi için dinamik şekilde yaratılabilen RNN hücreleri durumunda buna gerek yok.</p>
<p>Servisin temelinde, üstte görüldüğü gibi bir RNN tabakası var. Fakat bu RNN yapısında ilk (soldaki) bölüm kodlayıcı, ikinci (sağdaki) bölüm kod çözücü olarak planlanmış. Eğitim verisinde kaynak ve hedef cümle beraber, yanyana olarak hem girdi olarak veriliyor, ayrıca tercüme sonuç cümlesi alınıp bir de etiket verisi olarak kullanılıyor, bir farkla, etiketteki cümle zaman indisinde eğitimdeki sonuç cümlenin bir geri kaydırılmış hali.</p>
<p>Kaynak, sonuç tercüme cümleleri farklı boylarda olabilir, hem aynı eğitim noktası içinde birbirlerinden, hem de değişik eğitim noktalarında kendilerinden bile farklı boyutlarda olabilirler, bu sebeple RNN öğe sayıları dinamik şekilde, her eğitim verisine göre farklı olacak. Fakat bu farklı boyutlar karışıklık yaratmıyor, çünkü tercüme için önemli olan şey kodlayıcı bloktan kod çözücü bloğa geçen gizli konum.</p>
<p>Bu konuma daha önceki yazılarda <span class="math inline">\(h\)</span> adı vermiştik. Eğitim süreci şöyle, tüm cümleler + tüm kelimeler üzerinden bir sözlük oluştururuz, bu sözlüğe göre her kelimeye bir tam sayı indis değeri atarız, sonra kelimeleri tam sayılara çevirip gömme tabakasına veririz, bu tabaka reel sayı içeren vektörlere dönüşür, ve eğitim ilerledikçe referans gömme matrisinde kelimelerin temsil değerleri iyileşir. Bunlar otomatik oluyor tabii, biz soldan sağa YSA'ya her eğitim veri noktasındaki kelimeleri teker teker geçiyoruz, bir eğitim noktası için önce birinci kelimeyi ilk RNN öğesine, oradan çıkan <span class="math inline">\(h\)</span>'yi ve ikinci kelimeyi ikinci RNN öğesine, böyle devam ediyor.</p>
<p>Kodlayıcıdan çıkış olduğu anda (dikkat hala tek bir eğitim noktasını işliyoruz) elimizde olan <span class="math inline">\(h\)</span>'nin özel bir anlamı var. Üstteki mimariye göre bu gizli katman tüm kaynak cümleyi temsil eden bir <span class="math inline">\(h\)</span>'dir. Başta pek değildir ama zaman geçtikçe öyle olacaktır. <span class="math inline">\(h\)</span> boyutu önceden planlanan şekilde, yani cümleye göre küçülüp büyüyen bir şey değil. Neyse tabii ileri besleme orada durmuyor, kod çözücüye devam ediliyor, burada kelimeler sonuç tercümeden geliyor, şimdi onun kelimelerini almaya başlıyoruz ve etikette bahsettiğimiz şekilde kaydırılan kelimelere tekabül edecek şekilde eğitime devam ediyoruz, ve sağa en sona gelince bir eğitim noktası ile işimiz bitiyor.</p>
<p>Hedef kelimeleri softmax olarak planlanmış, yani kod çözücüdeki RNN öğeleri mümkün tüm kelimeler üzerinden bir olasılık vektörü üretiyor. Gerçek dünya uygulamalarında bu yaklaşım külfetli olabilir, çünkü sözlük çok büyük ise softmax boyutu tek bir kelime çıktısı için olasılıkları temsil etmek için çok fazla boyutlu olmalıdır, burada performansı iyileştirebilecek başka bazı yaklaşımlar var, ama kavramsal olarak çıktının sanki her mümkün kelime üzerinden bir softmax olduğunu düşünebiliriz.</p>
<p>Eğitim bittikten sonra hiç görülmemiş yeni test verisi için tercüme nasıl yaparız? Biraz önce gördüğümüz gibi kaynak cümlenin kelimeleri soldan sağa YSA'ya verilir, kod çözücüye geldiğimizde <span class="math inline">\(h\)</span> ile beraber Go sembolü verilecektir, ve bu sembol sonuç tercümede ilk kelimeyi üretir. Tercümenin ilk kelimesini bu şekilde elde etmiş oluruz. Eğer eğitim iyi yapılmışsa derin YSA ilk kelimeyi güzel bir şekilde üretecektir (daha doğrusu softmax tüm kelimelerin olasılıklarını hesaplar, biz bu olasılıklara göre en olası kelimeyi örnekleme yaparak alırız). Sonra bu üretilen kelimeyi alıp alttan YSA'ya (artık kod çözücüde tabii) beslemeye devam ederiz, mesela Go sonucu &quot;içeri'' kelimesi verilmiş, biz &quot;içeri'' kelimesini alttan ikinci RNN öğesine veririz, bu bize üstten &quot;girmesine'' kelimesini üretebilir, böyle devam ederiz.</p>
<p>Dikkat Etme Vektörü (Attention Vector)</p>
<p>Bazı yaklaşımlara göre kodlayıcı bloktan çıkan <span class="math inline">\(h\)</span> bir cümleyi temsil etmek için yeterli görülmüyor, kod çözücü bloğundaki RNN öğelerinden kaynak cümledeki tüm kelimelere giden bir dikkat etme vektörü üzerinden bağlantı koyuluyor. Detaylar [2]'de bulunabilir. Alttaki örnekte İngilizce &quot;I am a student'', yani ben bir öğrenciyim cümlesinin Fransızca karşılığı &quot;Je suis etuidant'' gösterilmiş.</p>
<div class="figure">
<img src="attention.jpg" />

</div>
<p>Ayrıca RNN katmanı tek bir zincir olmayabilir, üst üste konulmuş birkaç katmandan da oluşuyor olabilir. Resimde istiflenmiş iki RNN seviyesi görüyoruz mesela.</p>
<p>Not: Bilgisayar ile söyleşi yapılmasını sağlayan chatbot teknolojisi aslında üstteki tercüme teknolojisinin değişik bir kullanımı sadece. Eğer kaynak ve sonuç cümleler aynı cümlenin iki farklı dildeki karşılığı yerine iki kişi arasındaki konuşmalar olsaydı, YSA yapısı gömme tabakası, cümleler alakası üzerinden &quot;bir konuşmayı'' öğrenmeye başlardı. &quot;Nasılsın'' cümlesine &quot;çok iyiyim'' karşılığı veriliyor, bu iki cümle ve onun gibi cümleleri üstteki teknikle eğitince yavaş yavaş YSA nasıl karşılık vereceğini öğrenebilmeye başlıyor.</p>
<p>Örnek kod [1] alttadır, veri [4]'ten.</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="co"># translate.py</span>
<span class="im">import</span> pickle
<span class="im">import</span> tensorflow <span class="im">as</span> tf
<span class="im">import</span> numpy <span class="im">as</span> np, os

checkpoint_path <span class="op">=</span> <span class="st">&quot;/home/burak/Downloads/model.ckpt&quot;</span>

<span class="im">from</span> data_utils <span class="im">import</span> (
    process_data,split_data,generate_epoch,generate_batch,
)

<span class="kw">def</span> rnn_cell(FLAGS, dropout, scope):

    <span class="cf">with</span> tf.variable_scope(scope):
        rnn_cell_type <span class="op">=</span> tf.nn.rnn_cell.BasicLSTMCell
        single_cell <span class="op">=</span> rnn_cell_type(FLAGS.num_hidden_units)
        single_cell <span class="op">=</span> tf.nn.rnn_cell.DropoutWrapper(single_cell,
            output_keep_prob<span class="op">=</span><span class="dv">1</span><span class="op">-</span>dropout)
        stacked_cell <span class="op">=</span> tf.nn.rnn_cell.MultiRNNCell(
            [single_cell] <span class="op">*</span> FLAGS.num_layers)

    <span class="cf">return</span> stacked_cell

<span class="kw">def</span> rnn_inputs(FLAGS, input_data, vocab_size, scope):

    <span class="cf">with</span> tf.variable_scope(scope, reuse<span class="op">=</span><span class="va">True</span>):
        W_input <span class="op">=</span> tf.get_variable(<span class="st">&quot;W_input&quot;</span>,
            [vocab_size, FLAGS.num_hidden_units])

    <span class="co"># embeddings will be shape [input_data dimensions, num_hidden units]</span>
    embeddings <span class="op">=</span> tf.nn.embedding_lookup(W_input, input_data)
    <span class="cf">return</span> embeddings

<span class="kw">def</span> rnn_softmax(FLAGS, outputs, scope):
    <span class="cf">with</span> tf.variable_scope(scope, reuse<span class="op">=</span><span class="va">True</span>):
        W_softmax <span class="op">=</span> tf.get_variable(<span class="st">&quot;W_softmax&quot;</span>,
            [FLAGS.num_hidden_units, FLAGS.sp_vocab_size])
        b_softmax <span class="op">=</span> tf.get_variable(<span class="st">&quot;b_softmax&quot;</span>, [FLAGS.sp_vocab_size])

    logits <span class="op">=</span> tf.matmul(outputs, W_softmax) <span class="op">+</span> b_softmax
    <span class="cf">return</span> logits

<span class="kw">class</span> model(<span class="bu">object</span>):

    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, FLAGS):

        <span class="va">self</span>.encoder_inputs <span class="op">=</span> tf.placeholder(tf.int32, shape<span class="op">=</span>[<span class="va">None</span>, <span class="va">None</span>],
            name<span class="op">=</span><span class="st">&#39;encoder_inputs&#39;</span>)
        <span class="va">self</span>.decoder_inputs <span class="op">=</span> tf.placeholder(tf.int32, shape<span class="op">=</span>[<span class="va">None</span>, <span class="va">None</span>],
            name<span class="op">=</span><span class="st">&#39;decoder_inputs&#39;</span>)
        <span class="va">self</span>.targets <span class="op">=</span> tf.placeholder(tf.int32, shape<span class="op">=</span>[<span class="va">None</span>, <span class="va">None</span>],
            name<span class="op">=</span><span class="st">&#39;targets&#39;</span>)
        <span class="va">self</span>.en_seq_lens <span class="op">=</span> tf.placeholder(tf.int32, shape<span class="op">=</span>[<span class="va">None</span>, ],
            name<span class="op">=</span><span class="st">&quot;en_seq_lens&quot;</span>)
        <span class="va">self</span>.sp_seq_lens <span class="op">=</span> tf.placeholder(tf.int32, shape<span class="op">=</span>[<span class="va">None</span>, ],
            name<span class="op">=</span><span class="st">&quot;sp_seq_lens&quot;</span>)
        <span class="va">self</span>.dropout <span class="op">=</span> tf.placeholder(tf.float32)

        <span class="cf">with</span> tf.variable_scope(<span class="st">&#39;encoder&#39;</span>) <span class="im">as</span> scope:

            <span class="co"># Encoder RNN cell</span>
            <span class="va">self</span>.encoder_stacked_cell <span class="op">=</span> rnn_cell(FLAGS, <span class="va">self</span>.dropout,
                scope<span class="op">=</span>scope)

            <span class="co"># Embed encoder inputs</span>
            W_input <span class="op">=</span> tf.get_variable(<span class="st">&quot;W_input&quot;</span>,
                [FLAGS.en_vocab_size, FLAGS.num_hidden_units])
            <span class="va">self</span>.embedded_encoder_inputs <span class="op">=</span> rnn_inputs(FLAGS,
                <span class="va">self</span>.encoder_inputs, FLAGS.en_vocab_size, scope<span class="op">=</span>scope)

            <span class="co"># Outputs from encoder RNN</span>
            <span class="va">self</span>.all_encoder_outputs, <span class="va">self</span>.encoder_state <span class="op">=</span> tf.nn.dynamic_rnn(
                cell<span class="op">=</span><span class="va">self</span>.encoder_stacked_cell,
                inputs<span class="op">=</span><span class="va">self</span>.embedded_encoder_inputs,
                sequence_length<span class="op">=</span><span class="va">self</span>.en_seq_lens, time_major<span class="op">=</span><span class="va">False</span>,
                dtype<span class="op">=</span>tf.float32)

        <span class="cf">with</span> tf.variable_scope(<span class="st">&#39;decoder&#39;</span>) <span class="im">as</span> scope:

            <span class="co"># Initial state is last relevant state from encoder</span>
            <span class="va">self</span>.decoder_initial_state <span class="op">=</span> <span class="va">self</span>.encoder_state

            <span class="co"># Decoder RNN cell</span>
            <span class="va">self</span>.decoder_stacked_cell <span class="op">=</span> rnn_cell(FLAGS, <span class="va">self</span>.dropout,
                scope<span class="op">=</span>scope)

            <span class="co"># Embed decoder RNN inputs</span>
            W_input <span class="op">=</span> tf.get_variable(<span class="st">&quot;W_input&quot;</span>,
                [FLAGS.sp_vocab_size, FLAGS.num_hidden_units])
            <span class="va">self</span>.embedded_decoder_inputs <span class="op">=</span> rnn_inputs(FLAGS, <span class="va">self</span>.decoder_inputs,
                FLAGS.sp_vocab_size, scope<span class="op">=</span>scope)

            <span class="co"># Outputs from encoder RNN</span>
            <span class="va">self</span>.all_decoder_outputs, <span class="va">self</span>.decoder_state <span class="op">=</span> tf.nn.dynamic_rnn(
                cell<span class="op">=</span><span class="va">self</span>.decoder_stacked_cell,
                inputs<span class="op">=</span><span class="va">self</span>.embedded_decoder_inputs,
                sequence_length<span class="op">=</span><span class="va">self</span>.sp_seq_lens, time_major<span class="op">=</span><span class="va">False</span>,
                initial_state<span class="op">=</span><span class="va">self</span>.decoder_initial_state)

            <span class="co"># Softmax on decoder RNN outputs</span>
            W_softmax <span class="op">=</span> tf.get_variable(<span class="st">&quot;W_softmax&quot;</span>,
                [FLAGS.num_hidden_units, FLAGS.sp_vocab_size])
            b_softmax <span class="op">=</span> tf.get_variable(<span class="st">&quot;b_softmax&quot;</span>, [FLAGS.sp_vocab_size])

            <span class="co"># Logits</span>
            <span class="va">self</span>.decoder_outputs_flat <span class="op">=</span> tf.reshape(<span class="va">self</span>.all_decoder_outputs,
                [<span class="op">-</span><span class="dv">1</span>, FLAGS.num_hidden_units])
            <span class="va">self</span>.logits_flat <span class="op">=</span> rnn_softmax(FLAGS, <span class="va">self</span>.decoder_outputs_flat,
                scope<span class="op">=</span>scope)

            <span class="co"># Loss with masking</span>
            targets_flat <span class="op">=</span> tf.reshape(<span class="va">self</span>.targets, [<span class="op">-</span><span class="dv">1</span>])
            losses_flat <span class="op">=</span> tf.nn.sparse_softmax_cross_entropy_with_logits(
                logits<span class="op">=</span><span class="va">self</span>.logits_flat, labels<span class="op">=</span>targets_flat
            )
            mask <span class="op">=</span> tf.sign(tf.to_float(targets_flat))
            masked_losses <span class="op">=</span> mask <span class="op">*</span> losses_flat
            masked_losses <span class="op">=</span> tf.reshape(masked_losses,  tf.shape(<span class="va">self</span>.targets))
            <span class="va">self</span>.loss <span class="op">=</span> tf.reduce_mean(
                tf.reduce_sum(masked_losses, reduction_indices<span class="op">=</span><span class="dv">1</span>))

        <span class="co"># Optimization</span>
        <span class="va">self</span>.lr <span class="op">=</span> tf.Variable(<span class="fl">0.0</span>, trainable<span class="op">=</span><span class="va">False</span>)
        trainable_vars <span class="op">=</span> tf.trainable_variables()
        <span class="co"># clip the gradient to avoid vanishing or blowing up gradients</span>
        grads, _ <span class="op">=</span> tf.clip_by_global_norm(
            tf.gradients(<span class="va">self</span>.loss, trainable_vars), FLAGS.max_gradient_norm)
        optimizer <span class="op">=</span> tf.train.AdamOptimizer(<span class="va">self</span>.lr)
        <span class="va">self</span>.train_optimizer <span class="op">=</span> optimizer.apply_gradients(
            <span class="bu">zip</span>(grads, trainable_vars))

        <span class="co">#self.saver = tf.train.Saver(tf.all_variables())</span>

    <span class="kw">def</span> step(<span class="va">self</span>, sess, FLAGS, batch_encoder_inputs, batch_decoder_inputs,
        batch_targets, batch_en_seq_lens, batch_sp_seq_lens, dropout):

        input_feed <span class="op">=</span> {<span class="va">self</span>.encoder_inputs: batch_encoder_inputs,
            <span class="va">self</span>.decoder_inputs: batch_decoder_inputs,
            <span class="va">self</span>.targets: batch_targets,
            <span class="va">self</span>.en_seq_lens: batch_en_seq_lens,
            <span class="va">self</span>.sp_seq_lens: batch_sp_seq_lens,
            <span class="va">self</span>.dropout: dropout}
        output_feed <span class="op">=</span> [<span class="va">self</span>.loss, <span class="va">self</span>.train_optimizer]
        outputs <span class="op">=</span> sess.run(output_feed, input_feed)

        <span class="cf">return</span> outputs[<span class="dv">0</span>], outputs[<span class="dv">1</span>]

<span class="kw">class</span> parameters(<span class="bu">object</span>):

    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):
        <span class="va">self</span>.max_en_vocab_size <span class="op">=</span> <span class="dv">30000</span>
        <span class="va">self</span>.max_sp_vocab_size <span class="op">=</span> <span class="dv">30000</span>
        <span class="va">self</span>.num_epochs <span class="op">=</span> <span class="dv">100</span>
        <span class="va">self</span>.batch_size <span class="op">=</span> <span class="dv">20</span>
        <span class="va">self</span>.num_hidden_units <span class="op">=</span> <span class="dv">300</span>
        <span class="va">self</span>.num_layers <span class="op">=</span> <span class="dv">3</span>
        <span class="va">self</span>.dropout <span class="op">=</span> <span class="fl">0.2</span>
        <span class="va">self</span>.learning_rate <span class="op">=</span> <span class="fl">1e-3</span>
        <span class="va">self</span>.learning_rate_decay_factor <span class="op">=</span> <span class="fl">0.99</span>
        <span class="va">self</span>.max_gradient_norm <span class="op">=</span> <span class="fl">5.0</span>

<span class="kw">def</span> create_model(sess, FLAGS):
    tf_model <span class="op">=</span> model(FLAGS)
    <span class="bu">print</span> <span class="st">&quot;Created a new model&quot;</span>
    sess.run(tf.initialize_all_variables())
    <span class="cf">return</span> tf_model

<span class="kw">def</span> restore_model(sess, FLAGS):
    tf_model <span class="op">=</span> model(FLAGS)
    tf_model.saver.restore(sess, checkpoint_path) 
    <span class="cf">return</span> tf_model

<span class="kw">def</span> train(FLAGS):

    <span class="co"># Load the data</span>
    en_token_ids, en_seq_lens, en_vocab_dict, en_rev_vocab_dict <span class="op">=</span> <span class="op">\</span>
        process_data(<span class="st">&#39;data/tst2013.en&#39;</span>, max_vocab_size<span class="op">=</span><span class="dv">30000</span>, target_lang<span class="op">=</span><span class="va">False</span>)
    sp_token_ids, sp_seq_lens, sp_vocab_dict, sp_rev_vocab_dict <span class="op">=</span> <span class="op">\</span>
        process_data(<span class="st">&#39;data/tst2013.tr&#39;</span>, max_vocab_size<span class="op">=</span><span class="dv">30000</span>, target_lang<span class="op">=</span><span class="va">True</span>)

    <span class="co"># Split into train and validation sets</span>
    train_encoder_inputs, train_decoder_inputs, train_targets, <span class="op">\</span>
        train_en_seq_lens, train_sp_seq_len, <span class="op">\</span>
        valid_encoder_inputs, valid_decoder_inputs, valid_targets, <span class="op">\</span>
        valid_en_seq_lens, valid_sp_seq_len <span class="op">=</span> <span class="op">\</span>
        split_data(en_token_ids, sp_token_ids, en_seq_lens, sp_seq_lens,
            train_ratio<span class="op">=</span><span class="fl">0.8</span>)
    
    output <span class="op">=</span> <span class="bu">open</span>(<span class="st">&#39;data/vocab_en.pkl&#39;</span>, <span class="st">&#39;wb&#39;</span>)
    pickle.dump(en_vocab_dict, output)
    output.close()
    output <span class="op">=</span> <span class="bu">open</span>(<span class="st">&#39;data/vocab_sp.pkl&#39;</span>, <span class="st">&#39;wb&#39;</span>)
    pickle.dump(sp_vocab_dict, output)
    output.close()

    <span class="co"># Update parameters</span>
    FLAGS.en_vocab_size <span class="op">=</span> <span class="bu">len</span>(en_vocab_dict)
    FLAGS.sp_vocab_size <span class="op">=</span> <span class="bu">len</span>(sp_vocab_dict)

    <span class="bu">print</span> <span class="st">&#39;len(en_vocab_dict)&#39;</span>, <span class="bu">len</span>(en_vocab_dict)
    <span class="bu">print</span> <span class="st">&#39;len(sp_vocab_dict)&#39;</span>, <span class="bu">len</span>(sp_vocab_dict)
    
    <span class="co"># Start session</span>
    <span class="cf">with</span> tf.Session() <span class="im">as</span> sess:
        model <span class="op">=</span> <span class="va">None</span>
        <span class="co"># Create new model or load old one</span>
        f <span class="op">=</span> checkpoint_path <span class="op">+</span> <span class="st">&quot;.index&quot;</span>
        <span class="bu">print</span> f
        exit()
        <span class="cf">if</span> os.path.isfile(f):
            model <span class="op">=</span> restore_model(sess)
        <span class="cf">else</span>:
            model <span class="op">=</span> create_model(sess, FLAGS)

        <span class="co"># Training begins</span>
        losses <span class="op">=</span> []
        <span class="cf">for</span> epoch_num, epoch <span class="kw">in</span> <span class="bu">enumerate</span>(generate_epoch(train_encoder_inputs,
            train_decoder_inputs, train_targets,
            train_en_seq_lens, train_sp_seq_len,
            FLAGS.num_epochs, FLAGS.batch_size)):

            <span class="bu">print</span> <span class="st">&quot;EPOCH: </span><span class="sc">%i</span><span class="st">&quot;</span> <span class="op">%</span> (epoch_num)
            <span class="co"># Decay learning rate</span>
            sess.run(tf.assign(model.lr, FLAGS.learning_rate <span class="op">*</span> <span class="op">\</span>
                (FLAGS.learning_rate_decay_factor <span class="op">**</span> epoch_num)))

            batch_loss <span class="op">=</span> []

            <span class="cf">for</span> batch_num, (batch_encoder_inputs, batch_decoder_inputs,
                batch_targets, batch_en_seq_lens,
                batch_sp_seq_lens) <span class="kw">in</span> <span class="bu">enumerate</span>(epoch):

                loss, _ <span class="op">=</span> model.step(sess, FLAGS,
                    batch_encoder_inputs, batch_decoder_inputs, batch_targets,
                    batch_en_seq_lens, batch_sp_seq_lens,
                    FLAGS.dropout)
                <span class="bu">print</span> loss
                batch_loss.append(loss)
            <span class="bu">print</span> <span class="st">&#39;mean: &#39;</span>, np.mean(batch_loss)

            <span class="bu">print</span> <span class="st">&quot;Saving the model.&quot;</span>
            model.saver.save(sess, checkpoint_path)
            
<span class="cf">if</span> <span class="va">__name__</span> <span class="op">==</span> <span class="st">&#39;__main__&#39;</span>:
    FLAGS <span class="op">=</span> parameters()
    train(FLAGS)</code></pre></div>
<p>Kaynaklar</p>
<p>[1] Mohandas, <em>The Neural Perspective, RNN - Part 3 - Encoder - Decoder</em>,<a href="https://theneuralperspective.com/2016/11/20/recurrent-neural-networks-rnn-part-3-encoder-decoder/" class="uri">https://theneuralperspective.com/2016/11/20/recurrent-neural-networks-rnn-part-3-encoder-decoder/</a></p>
<p>[2] TensorFlow, <em>TensorFlow Neural Machine Translation Tutorial</em>, <a href="https://github.com/tensorflow/nmt" class="uri">https://github.com/tensorflow/nmt</a></p>
<p>[3] Géron, <em>Hands-On Machine Learning with Scikit-Learn and TensorFlow</em></p>
<p>[4] ManyThings Verisi, İngilizce-Türkçe, <em>Tab-delimited Bilingual Sentence Pairs</em>, <a href="https://drive.google.com/uc?export=view&amp;id=16fsAVPaPgp9gW9mdLmKz0OOR9lQ1M9WU" class="uri">https://drive.google.com/uc?export=view&amp;id=16fsAVPaPgp9gW9mdLmKz0OOR9lQ1M9WU</a></p>
<p>
  <a href="..">Yukarı</a>
</p>
</body>
</html>
