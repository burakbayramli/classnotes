\documentclass[12pt,fleqn]{article}\usepackage{../../common}
\begin{document}
Uzun Kýsa-Vade Hafýza Aðlarý (Long Short-Term Memory Networks, LSTM)

Kendini tekrarlayan YSA (RNN) yapýlarýnýn içindeki gizli konum $h_t$
(önceki yazýda $s_t$) olarak bir zaman diliminden bir diðerine
aktarýlabiliyordu, ve bu sýrada bir matris çarpýmý üzerinden deðiþime
uðrayabiliyordu. Böylece her zaman diliminde yeni görülen verinin
``hafýza'' olarak ta tanýmlanabilen $h_t$'ye etkisi olabiliyordu. RNN dýþ
dünya hakkýndaki iç modelini böyle güncelliyordu.

Fakat RNN ile tarif edilen bu güncellemeye hiç bir sýnýr getirmedik. Biraz
düþünürsek bu güncellemenin biraz kaotik bir hal alabileceðini görebiliriz
[1]. Mesela bir filmi kare kare izleyerek filmde neler olduðunu tarif
etmeye uðraþan bir RNN düþünelim. Bir karede bir karakterin ABD'de olduðunu
düþünebilir, ama sonraki karede karakterin suþi yediðini görüyor ve
Japonya'da olduðuna karar verebilir, sonra Panda ayýsý görüyor ve karakteri
kuzey kutbunda zannediyor.

Bu tarif edilen kaos enformasyonun çok hýzlý etki ettiðini ve ayný hýzda
yokolduðuna iþaret. Bu tür bir yapýda modelin uzun vadeli hafýza tutmasý
oldukça zor. Bize gereken modelin sadece güncelleme yapmasý deðil,
güncelleme yapmayý da öðrenmesi. Ali adlý bir karakter film karesinde yoksa
o kareler Ali hakkýndaki bilgiyi güncellemek için kullanýlmamalý, ayný
þekilde Ayþe'nin içinde olmadýðý kareler onun hakkýndaki bilgiyi
güncellemek için kullanýlmamalý. 

Çözüm için þöyle bir yaklaþým kullanabiliriz. 

1) Bir ``unutma'' mekanizmasý ekle. Film seyrediyoruz, bir sahne bitiyor, o
sahnenin hangi gün, saat kaçta, nerede olduðunu unutuyoruz. Fakat bir
karakter o sahnede ölmüþse, bunu hatýrlýyoruz. Modelin ne zaman
hatýrlayacaðýný, ne zaman unutacaðýný öðrenmesini istiyoruz (dikkat sadece
belli bir þekilde unutmasý, hatýrlamasý deðil, tüm bunlarý nasýl, ne zaman
yapacaðýný öðrenmesi).

2) Bir belleðe yazma (zulaya atma?) mekanizmasý. Modelin yeni bir kare
gördüðünde o karedeki bilginin kaydetmeye deðer olup olmadýðýna karar
vermesi lazým, ve bu öðrenilse iyi olur.

3) .. ki yeni bir girdi gelince model ihtiyacý olmadýðý bilgiyi
unutacak. Sonra girdinin hangi kýsmýnýn faydalý olduðuna karar verecek ve o
kýsmý uzun-vadeli hafýzasýna kaydedecek.

4) Bir odaklanma mekanizmasý. Uzun-vadeli hafýzanýn hangi kýsmý sýk
kullaným gerekiriyor, iþlem hafýzasý (working memory) hangisi, buna karar
vermek.

Bize gereken bir uzun kýsa-vade hafýza aðýdýr, teknik ismiyle LSTM. RNN her
zaman adýmýnda hafýzasýný kontrolsüz bir þekilde güncelleyebiliyorken, bir
LSTM hafýzasýný çok daha seçici, kararlý bir þekilde günceller, bunu
yaparken spesifik öðrenme mekanizmalarý kullanýr ki bu mekanizma ona
görülen bilginin hangi kýsmýnýn hatýrlanmaya deðer, hangisinin
güncellenmesinin gerekli olduðunu, ve hangisinin daha fazla odaklanýlmaya
ihtiyaç duyduðunu belirler.

Matematiksel olarak $t$ anýnda bir $x_t$ girdisi alýyoruz, uzun-vadeli ve
iþlem hafýzasý $C_{t-1}$ ve $h_{t-1}$ bir önceki zaman diliminden bir
önceki bu zamana aktarýlýyor ve onlarý bir þekilde güncellemek
istiyoruz. Bize gereken bir tür hatýrlama geçidi (remember gate), bu
elektronik devrelerdeki gibi bir geçit, 0 ile 1 arasýnda olacak $n$ tane
sayý, bu sayý $n$ hafýza ögesinin ne kadar hatýrlanacaðýný, yani ne kadar
uzun-vadeli olup olmayacaðýný belirleyecek. 1 tut, 0 unut demek olacak.

Ufak bir YSA kullanarak bu geçidi öðrenebiliriz,

$$ f_t = \sigma (W_r x_t + U_r h_{t-1}) $$

Bu basit, sýð (derin olmayan) bir YSA, $\sigma$ sigmoid aktivasyonu. Sigmoid
kullandýk çünkü 0 ile 1 arasýnda çýktýya ihtiyacýmýz var. Þimdi girdiden
öðreneceðimiz bilgiyi hesaplamamýz lazým, bu bilgi uzun-vadeli hafýzamýz
için bir aday olacak. 

$$ C_t' = \phi(W_l x_t + U_l h_{t-1})$$

$\phi$ bir aktivasyon fonksiyonu, çoðunlukla $\tanh$ olarak seçilir. 

Fakat bir adayý hafýzamýza eklemeden önce hangi bölümlerinin kullanýma,
kaydetmeye deðer olduðunu öðrenmemiz gerekir. Web'de bir þey okurken kendi
zihnimizde neler olduðunu düþünelim. Bir haber makalesi okuyoruz mesela,
Trabzonspor'un hep kötüye gittiðini, hep yanlýþ tranferler yaptýðýný
anlatan bir haber okuyoruz, ama bu haberi fenerbahce.org sitesinde
okuyorsak o habere daha az önem verebiliriz.

$$ i_t = \sigma (W_s x_t + U_s h_{t-1}) $$

Þimdi tüm bu basamaklarý birleþtirelim. Ýhtiyacýmýz olmayan hafýzalarý
unuttuktan ve bilgilerin faydalý olabilecek kýsýmlarýný sakladýktan sonra,
elimize bir güncellenmiþ uzun-vadeli bellek geçer, 

$$ C_t = f_t \circ c_{t-1} \circ i_t \circ \tilde{C}_t $$

ki $\circ$ operasyonu her iki taraftaki deðiþkenin içindeki her ögenin
birer birer çarpýlmasý (element-wise multiplication) demek.

Sonra iþlem hafýzasýný güncellememiz lazým, uzun-vade belleðimizi anlýk
iþlem için faydalý olabilecek þekilde nasýl odaklarýz, onu öðrenmek
istiyoruz. O zaman bir odaklanma vektörü öðreniriz,

$$ o_t = \sigma (W_f x_t + U_f h_{t-1}) $$

O zaman iþlem hafýzamýz

$$ h_t = o_t \circ \phi (C_t)$$

Yani odak deðeri 1 olan öðelere tam dikkatimizi veriyoruz, 0 olanlara hiç
dikkat etmiyoruz. 

Kuþbakýþý ile tüm resmi görelim, kendini tekrar eden LSTM yapýsý alttaki gibi,

\includegraphics[width=35em]{lstm_02.png}

Sol ve saðdaki hücreler ortadakinin kopyasý. 

Kýyasla bir RNN'nin iç yapýsý çok daha basittir, 

\includegraphics[width=35em]{lstm_03.png}

LSTM resmindeki her birimin formülleriyle beraber teker teker tekrar
üzerinden geçmek gerekirse [2] - ilk adým hücre bilgisinden neleri
atacaðýmýza karar vermek. Bu karar unutma karar tabakasý adý verilen bir
sigmoid tabakasýnda veriliyor, tabaka $h_{t-1}$ ve $x_t$'ye bakýyor ve
$C_{t-1}$ hücre konumundaki her deðer için 0 ile 1 arasýnda bir sayý
üretiyor. 1 deðeri tamamen tut, 0 deðeri tamamen unut anlamýna geliyor (tüm
$b$ deðerleri yanlýlýk -bias- için).

\includegraphics[width=35em]{lstm_04.png}

Bir sonraki adým hücrede hangi yeni bilgiyi depolayacaðýmýza karar
vermek. Bu kararýn iki parçasý var, önce girdi geçit tabakasý (input gate
layer) hangi deðerleri güncelleyeceðimize karar veriyor, ardýndan bir
$\tanh$ tabakasý bir ``aday vektörü'' $\tilde{C}_t$ üretiyor, bu vektör,
adý üzerinde, hücre konumuna eklenmeye aday bilgiler. Ardýndan bu iki
vektör birleþtirilip konumu güncellemek için yeni bir vektör yaratýlýyor.

\includegraphics[width=35em]{lstm_05.png}

Sýra güncelleme iþ bantýna (update conveyor) geldi. Herhalde bu isim
verilmiþ çünkü hücrenin en üstünde direk soldan saða giden bu ok bir tür
fabrika iþ bantý gibi, bir ana akým hattý. Bir kaç bilgi akýmý bu ana kola
giriyor. Bu iþ bantýnýn görevi hücrenin eski konum bilgisini güncellemek,
$C_{t-1}$'i $C_t$ haline getirmek. Önceki adýmlar ne yapýlmasý gerektiðine
karar vermiþti, þimdi bu kararlarý eyleme geçirme zamaný. Eski konum
bilgisini $f_t$ ile çarpýyoruz, böylece unutmak istediklerimizi
unutuyoruz. Sonra $i_t * C_t'$'yi ekliyoruz, bunlar yeni konumu ne kadar
güncellemek istediðimizi belirleyen aðýrlýklarla ölçeklenmiþ yeni aday
deðerler.

\includegraphics[width=35em]{lstm_06.png}

En son adým tahmin adýmý, bu adýmda artýk çýktýnýn ne olacaðýna karar
veriyoruz. Çýktý mevcut hücre konumunu baz alacak, ama onun filtrelenmiþ
bir hali olacak. Ýlk önce bir sigmoid iþleterek konumun hangi kýsmýnýn
çýktýya verileceðini kararlaþtýrýyoruz. Ardýndan mevcut konum bilgisini bir
$\tanh$'e veriyoruz, ki bu deðerlerin $-1,+1$ arasýnda gelmesini
saðlýyoruz, ve bu sonucu sigmoid'den gelen deðer ile çarpýyoruz, ki sadece
istediðimiz kýsmýn dýþarý verilmesini saðlayalým. 

\includegraphics[width=35em]{lstm_07.png}

Þimdi üstteki formülleri kullanarak TensorFlow ile sýfýrdan bir LSTM
kodlayalým. Amacýmýz daha önce RNN için gördüðümüz zaman serisini öðrenmek,
bu seriyi 5'er 5'er okuyacaðýz, yani yanyana 5 seri öðesini okuyacaðýz, ve
6. seri deðeri hedef deðeri olacak, seri içinden bu þekilde örneklem
yaparak bir ufak toptan eðitim seti yaratacaðýz. Sonra serinin hiç
görmediðimiz ``geleceðini'' tahmin etmeye uðraþacaðýz.

\begin{minted}[fontsize=\footnotesize]{python}
import tensorflow as tf
import numpy as np
from pprint import pprint
import datetime
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

tf.reset_default_graph()
np.random.seed(1)
tf.set_random_seed(1)

LSTM_SIZE = 30
t_min, t_max = 0, 30
resolution = 0.1
sequence_length = 4
instruction_count = 1
epoch = 500

def f(t):
    return t * np.sin(t) / 3 + 2 * np.sin(t*5)

def next_batch(batch_size, n_steps):
    t0 = np.random.rand(batch_size, 1) * (t_max - t_min - n_steps * resolution)
    Ts = t0 + np.arange(0., n_steps + 1) * resolution
    ys = f(Ts)
    X = ys[:, :-1].reshape(-1, n_steps, 1)
    y = ys[:, 1:].reshape(-1, n_steps, 1)
    y = y[:,-1,:]
    y = y.flatten()
    print y.shape    
    return list(X),y

reference_input_data,reference_output_data = next_batch(400, sequence_length)
   
# verinin 1/4'u egitim gerisi test
NUM_EXAMPLES = len(reference_input_data) / 4 
test_input = reference_input_data[NUM_EXAMPLES:]
test_output = reference_output_data[NUM_EXAMPLES:] 
train_input = reference_input_data[:NUM_EXAMPLES]
train_output = reference_output_data[:NUM_EXAMPLES]

print train_input[1]
print train_output[1]

data = tf.placeholder(tf.float32, 
                      [None, sequence_length, instruction_count], 
                      name='data')

target = tf.transpose(tf.placeholder(tf.float32, [None], name='target'))

FEATURE_SIZE = 1 

def default_weights_and_bias():
    Weights = tf.Variable(tf.truncated_normal([LSTM_SIZE, 
                                               LSTM_SIZE + FEATURE_SIZE], 
                                               -0.2, 0.1))
    bias = tf.Variable(tf.constant(0.0, shape = [LSTM_SIZE, 1]))
    
    return Weights, bias

W_f, _ = default_weights_and_bias()

b_f = tf.Variable(tf.constant(1.0, shape = [LSTM_SIZE, 1]))

# Unutma tabakasi
def f_t(ht_minus_1_and_xt):
    return tf.sigmoid(tf.matmul(W_f, ht_minus_1_and_xt) + b_f)

W_i, b_i = default_weights_and_bias()

# Girdi gecidi tabakasi
def i_t(ht_minus_1_and_xt):
    return tf.sigmoid(tf.matmul(W_i, ht_minus_1_and_xt) + b_i)

W_C, b_c = default_weights_and_bias()

# is banti icin adaylar
def candidate_C_t(ht_minus_1_and_xt):
    return tf.tanh(tf.matmul(W_C, ht_minus_1_and_xt) + b_c)

def C_t(ht_minus_1_and_xt, Conveyor, CandConv):
    return f_t(ht_minus_1_and_xt) * Conveyor + i_t(ht_minus_1_and_xt) * CandConv

W_o, b_o = default_weights_and_bias()

# guncellenmis is banti
def h_t(ht_minus_1_and_xt, FinalConveyor):
    o_t = tf.sigmoid(tf.matmul(W_o, ht_minus_1_and_xt) + b_o)    
    return o_t * tf.tanh(FinalConveyor)

def lstm_cell(ht_minus_1_and_Conveyor, xt):
    ht_minus_1, Conveyor = ht_minus_1_and_Conveyor
    
    ht_minus_1_and_xt = tf.transpose(tf.concat([ht_minus_1, xt], 1))
    
    CandidateConveyor = candidate_C_t(ht_minus_1_and_xt)
    
    FinalConveyor = C_t(ht_minus_1_and_xt, Conveyor, CandidateConveyor)
    
    lstm_prediction = tf.transpose(h_t(ht_minus_1_and_xt, FinalConveyor))
    
    return(lstm_prediction, FinalConveyor)

data_length = tf.shape(data)[0]

def lstm_loop(last_lstm_prediction, last_state, step):
    lstm_prediction, state = lstm_cell((last_lstm_prediction, last_state),
                                       data[:, step, :])
    return lstm_prediction, state, tf.add(step, 1)

initial_Conveyor = tf.zeros([LSTM_SIZE, data_length])

initial_prediction = tf.zeros([data_length, LSTM_SIZE])

timesteps = sequence_length

for_each_time_step = lambda a, b, step: tf.less(step, timesteps)

arg = (initial_prediction, initial_Conveyor, 0)
lstm_prediction, lstm_state, _ = tf.while_loop(for_each_time_step,
                                               lstm_loop, arg,
                                               parallel_iterations=32)

weight = tf.Variable(tf.truncated_normal([LSTM_SIZE, 1]))

bias = tf.Variable(tf.constant(0.0, shape=[1]))

prediction = tf.matmul(lstm_prediction, weight) + bias

with tf.name_scope('mean_square_error'):
    mean_square_error = tf.reduce_sum(tf.square(tf.subtract(target, tf.unstack(prediction, axis = 1))))
    
tf.summary.scalar('mean_square_error', mean_square_error)

optimizer = tf.train.AdamOptimizer()

minimize = optimizer.minimize(mean_square_error)

mistakes = tf.not_equal(target, tf.round(tf.unstack(prediction, axis = 1)))

sess = tf.InteractiveSession()

date = str(datetime.datetime.now())

init_op = tf.global_variables_initializer()

saver = tf.train.Saver() 

sess.run(init_op)

for i in range(epoch):
    if (i + 1) % 20 == 0:
        mean_squ_err = sess.run(mean_square_error, {data: test_input, target: test_output})
        print('Epoch {:4d} | mean squ error {: 3.1f}'.format(i + 1, mean_squ_err))
    
    sess.run(minimize,{data: train_input, target: train_output})
\end{minted}

\begin{verbatim}
(400,)
[[ 4.00159218]
 [ 4.4298434 ]
 [ 4.67217731]
 [ 4.52697138]]
3.87853505042
Epoch   20 | mean squ error  3181.8
Epoch   40 | mean squ error  1860.6
Epoch   60 | mean squ error  1307.7
Epoch   80 | mean squ error  903.1
Epoch  100 | mean squ error  628.8
Epoch  120 | mean squ error  477.8
Epoch  140 | mean squ error  390.5
Epoch  160 | mean squ error  323.5
Epoch  180 | mean squ error  271.9
Epoch  200 | mean squ error  233.8
Epoch  220 | mean squ error  204.4
Epoch  240 | mean squ error  180.8
Epoch  260 | mean squ error  161.2
Epoch  280 | mean squ error  144.9
Epoch  300 | mean squ error  131.7
Epoch  320 | mean squ error  121.4
Epoch  340 | mean squ error  113.0
Epoch  360 | mean squ error  105.7
Epoch  380 | mean squ error  99.0
Epoch  400 | mean squ error  92.6
Epoch  420 | mean squ error  86.6
Epoch  440 | mean squ error  80.9
Epoch  460 | mean squ error  75.4
Epoch  480 | mean squ error  70.1
Epoch  500 | mean squ error  64.9
\end{verbatim}

Tahminleri üretirken eðitim verisinin en sonundaki \verb!sequence_length!
kadar öðeyi alýp sonraki 1 deðeri üretiyoruz, bu deðeri alýp tahmin için
kullanýlan biraz önce kullandýðýmýz \verb!sequence_length! kadar deðerin
sonuna ekleyip son \verb!sequence_length! deðer üzerinden tekrar bir
tahmin üretiyoruz, böyle gidiyor, ve bu þekilde serinin hiç görmediðimiz
kýsmýný tahmin ediyoruz.

\begin{minted}[fontsize=\footnotesize]{python}
def f(t):
    return t * np.sin(t) / 3 + 2 * np.sin(t*5)

t = np.linspace(t_min, t_max, int((t_max - t_min) / resolution))
y = f(t)

newx = list(t[-sequence_length:])
newy = list(y[-sequence_length:])

for i in range(40): # bu kadar daha uret
   tst_input = np.array(newy[-sequence_length:]).reshape(sequence_length,1)   
   res = sess.run(prediction, { data: [ tst_input ]  } )
   newy.append(res)
   newx.append(t_max + (i*resolution))

plt.plot(t,y)
plt.plot(newx,newy,'g')
plt.savefig('lstm_01.png')
\end{minted}

\includegraphics[width=20em]{lstm_01.png}

Yeþil renkli kýsým tahmin. Fena deðil.

Zaman Serisi Sýnýflandýrmak

Þimdi TF'in kendi LSTM çaðrýsýný kullanarak zaman serisi sýnýflandýrmasý
yapalým. Ýki farklý sýnýfa ait olan zaman serisi verimiz var [3],
mikroelektronik yarý-iletken üretiminden gelen bir veri, fabrikasyon
sýrasýnda algýlayýcýlar bu iki türlü seriyi kaydediyor, onlarý ayýrtetmek
bizim görevimiz. Okuma yöntemi kodlayalým,

\begin{minted}[fontsize=\footnotesize]{python}
import pandas as pd, zipfile
import tensorflow as tf
from tensorflow.contrib import rnn

learning_rate = 0.001
training_iters = 100000
batch_size = 25
display_step = 10

n_input = 1 
n_steps = 152 
n_hidden = 128 
n_classes = 2

with zipfile.ZipFile('wafer.zip', 'r') as z:
      df_train =  pd.read_csv(z.open('Wafer/wafer_TRAIN.txt'),header=None)
      df_test =  pd.read_csv(z.open('Wafer/wafer_TEST.txt'),header=None)

def minibatches(batch_size,input="train"):
      df = None
      if input=="train": df=df_train
      if input=="test": df=df_test
      df = np.array(df)
      for i in range(len(df)):
            batch_x = []; batch_y = []
            for j in range(batch_size):
                  batch_x.append(list(df[i,1:]))
                  batch_y.append([int(df[i,0]==-1), int(df[i,0]==1) ])
            batch_x = np.array(batch_x).reshape(batch_size,n_steps,1)
            batch_y = np.array(batch_y).reshape(batch_size,2)
            yield batch_x, batch_y                  

\end{minted}

TF hesap çizitini kodlayalým ve eðitelim,

\begin{minted}[fontsize=\footnotesize]{python}
def reset_graph(seed=42):
    tf.reset_default_graph()
    tf.set_random_seed(seed)
    np.random.seed(seed)

reset_graph()

x = tf.placeholder("float", [None, n_steps, n_input])
y = tf.placeholder("float", [None, n_classes])

weights = {
    'out': tf.Variable(tf.random_normal([n_hidden, n_classes]))
}
biases = {
    'out': tf.Variable(tf.random_normal([n_classes]))
}

def LSTM(x, weights, biases):
    x = tf.unstack(x, n_steps, 1)
    lstm_cell = rnn.BasicLSTMCell(n_hidden)
    outputs, states = rnn.static_rnn(lstm_cell, x, dtype=tf.float32)
    return tf.matmul(outputs[-1], weights['out']) + biases['out']

pred = LSTM(x, weights, biases)

correct_pred = tf.equal(tf.argmax(pred,1), tf.argmax(y,1))
accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))
new_pred = tf.argmax(y,1)

print 'cost'
scf = tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y)
cost = tf.reduce_mean(scf)
print 'optimizer'
optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)

init = tf.global_variables_initializer()

with tf.Session() as sess:
    sess.run(init)
    step = 1
    # Keep training until reach max iterations
    b_it = minibatches(batch_size)
    while step < int(1000 / batch_size):
          batch_x, batch_y = next(b_it)
          sess.run(optimizer, feed_dict={x: batch_x, y: batch_y})
          if step % display_step == 0:
                # Calculate batch accuracy
                acc = sess.run(accuracy, feed_dict={x: batch_x, y: batch_y})
                # Calculate batch loss
                loss = sess.run(cost, feed_dict={x: batch_x, y: batch_y})
                print("Iter " + str(step) + ", Minibatch Loss= " + \
                      "{:.6f}".format(loss) + ", Training Accuracy= " + \
                      "{:.5f}".format(acc))
          step += 1

    print("Optimization Finished!")
\end{minted}

\begin{verbatim}
cost
optimizer
Iter 10, Minibatch Loss= 1.847300, Training Accuracy= 0.00000
Iter 20, Minibatch Loss= 0.049264, Training Accuracy= 1.00000
Iter 30, Minibatch Loss= 0.176535, Training Accuracy= 1.00000
Optimization Finished!
\end{verbatim}

\begin{minted}[fontsize=\footnotesize]{python}
saver = tf.train.Saver()
from sklearn import metrics
real = []
pred = []
with tf.Session() as sess:
    for batch_x, batch_y in minibatches(1,input="test"):
      res = sess.run(new_pred, feed_dict={x: batch_x, y: batch_y})
      pred.append(res[0])
      real.append(np.argmax(batch_y[0]))
    fpr, tpr, thresholds = metrics.roc_curve(np.array(real), np.array(pred))
    print 'AUC', metrics.auc(fpr, tpr)      
\end{minted}                    

\begin{verbatim}
AUC 1.0
\end{verbatim}

Sonuç yüzde 100. 

Kaynaklar

[1] Chen, {\em Exploring LSTMs: Understanding Basics (Part One)}, \url{https://www.topbots.com/exploring-lstm-tutorial-part-1-recurrent-neural-network-deep-learning/}

[2] Shell, {\em Do It Yourself LSTM with TensorFlow}, \url{https://chrisschell.de/2017/07/10/do_it_yourself_lstm_with_tensorflow.html}

[3] Olszewski, {\em Wafer Dataset}, \url{http://timeseriesclassification.com/description.php?Dataset=Wafer}

[4] Olah, {\em Understanding LSTM Networks}, \url{https://colah.github.io/posts/2015-08-Understanding-LSTMs}

\end{document}

