<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
  <title></title>
  <style type="text/css">code{white-space: pre;}</style>
  <style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
  </style>
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>
  
  
  
  
</head>
<body>
<h1 id="ders-29">Ders 29</h1>
<p>Nihayet en son ayrıştırma (decomposition) konusuna geldik, bu teknik Eşsiz Değer Ayrıştırma (Singular Value Decomposition -SVD-) tekniğidir. Ayrıştırma şu halde olacak</p>
<p><span class="math display">\[ A = U \Sigma V^T \]</span></p>
<p>Sağ tarafta ayrışma sonrası bir dikgen (orthogonal) matris, bir köşegen (diagonal) matris, ve tekrar bir dikgen matris olacak. Yani bildiğimiz, sevdiğimiz matris formları ayrışma sonrası parçalar olarak elimize geçecekler. İlginç olan iki tane dikgen matris elde etmemiz. Ayrıca <span class="math inline">\(A\)</span> her türden, her boyuttan bir matris olabilir (illa karesel olması gerekmez mesela).</p>
<p>SVD bu dersin pek çok kavramını da bir araya getirir. Mesela simetrik pozitif kesin matrisler. Hatırlarsak bu matrisler simetrik olduğu için özvektörleri dikgen idi. Yani normalde şu haldeki bir ayrışma</p>
<p><span class="math display">\[ A = S \Lambda S ^{-1}   \]</span></p>
<p>Su halde gorulebiliyordu</p>
<p><span class="math display">\[ A = Q \Lambda Q ^{T}   \]</span></p>
<p>Yani <span class="math inline">\(S\)</span>, dikgen vektörlü <span class="math inline">\(Q\)</span> oluyordu, pozitif kesinlik sayesinde de normal bir <span class="math inline">\(\Lambda\)</span>, içinde sadece pozitif değerler taşıyan bir <span class="math inline">\(\Lambda\)</span> oluyordu.</p>
<p>Özetle, eğer <span class="math inline">\(A\)</span> simetrik pozitif kesin ise onun SVD'si <span class="math inline">\(Q \Lambda Q ^{T}\)</span> olacaktır. Bu durumda tek <span class="math inline">\(Q\)</span> matrisi yeterli, diğer durumlarda <span class="math inline">\(U,V\)</span> gibi iki farklı matris lazım. Ayrıca şunu da vurgulayalım: SVD için dikgenlik aradığımız önemli bir şart, &quot;dikgen çarpı köşegen çarpı dikgen'' şeklinde bir form istiyorum özellikle.</p>
<div class="figure">
<img src="29_1.png" />

</div>
<p>SVD'den beklediğimiz işlemi yukarıdaki resim üzerinden anlamaya çalışalım. Soldaki düzlem satır uzayı (row space), sağdaki kolon uzayı (column space). Bir matrisi temsil eden satırlar ve kolonlar bu uzayların içinde. Şimdi eğer <span class="math inline">\(U \Sigma V^T\)</span> formunu düşünürsek, öyle bir köşegen matris arıyorum ki satır uzayındaki dikgen bazı (basis) uzayındaki bir dikgen baza transform etmeli. Bu hakikaten özel bir matris olmalı.</p>
<p>Soru: satır uzayının dikgen bazı var mıdır? Tabii ki vardır, Gram-Schmidt tekniğinde gördük, herhangi bir bazın dikgen bazını alabiliriz. Dikgen baz hesabı özgün değildir, aynı bazdan pek çok dikgen baz çıkartılabilir, ve satır uzayındaki &quot;herhangi'' bir dikgen bazı alıp kolon uzayına transform edersem onun illa dikgen kalacağı garanti değildir. Yani transform edildikten sonra da dikgen kalacak özel bir dikgen baz arıyorum. Yapmaya çalıştığım çarpım her vektörü gösterecek şekilde nasıldır?</p>
<p><span class="math display">\[ 
A \left[\begin{array}{rrrr}
&amp; &amp; &amp; \\ v_1 &amp; v_2 &amp; ... &amp; v_r 
\\ &amp; &amp; &amp; 
\end{array}\right] = 
\left[\begin{array}{rrrr}
&amp; &amp; &amp; \\ u_1 &amp; u_2&amp; ... &amp; u_r \\ 
&amp; &amp; &amp; 
\end{array}\right] 
\left[\begin{array}{rrrr}
\sigma_1 &amp; &amp; &amp; \\  
&amp; \sigma_2&amp;  &amp; \\ 
&amp; &amp; \ddots &amp; \\ 
&amp; &amp; &amp; \sigma_r
\end{array}\right] 
\]</span></p>
<p>Yani <span class="math inline">\(Av_1\)</span> çarpımı bana <span class="math inline">\(u_1 \sigma_1\)</span>'i vermeli. Matris olarak yukarıdaki</p>
<p><span class="math display">\[ AV = U\Sigma \]</span></p>
<p>Hatta dikgenlikten daha ileride birimdikliği (orthonormal) hesaplamak daha da iyi.</p>
<p>Örnek</p>
<p><span class="math display">\[ 
A = 
\left[\begin{array}{rr}
4 &amp; 4 \\ -3 &amp; 3
\end{array}\right]
 \]</span></p>
<p><span class="math inline">\(A\)</span> tersine çevirilebilir (invertible) o zaman kertesi (rank) 2. Aradıklarım</p>
<p><span class="math display">\[ v_1,v_2 \  \mathbb{R}^2 \textit{ satır uzayında }  \]</span></p>
<p><span class="math display">\[ u_1,u_2 \  \mathbb{R}^2 \textit{ kolon uzayında }  \]</span></p>
<p><span class="math display">\[ \sigma_1 &gt; 0, \sigma_2 &gt; 0 \]</span></p>
<p>Sıfır uzayı (nullspace) burada problem değil. Zorluklar neler? Matris simetrik olmayabilir, o zaman özvektörleri kullanamam, çünkü onlar dikgen değildir.</p>
<p><span class="math display">\[ A = U \Sigma V^{-1} \]</span></p>
<p><span class="math inline">\(V^{-1}\)</span>'yi başka nasıl yazabilirim? <span class="math inline">\(V\)</span> kare, dikgen olacağına göre, <span class="math inline">\(V^{-1} = V^{T}\)</span>. O zaman</p>
<p><span class="math display">\[ A = U \Sigma V^{T} \]</span></p>
<p>Şimdi hesabı düşünmeye başlayalım. İki tane ayrı dikgen matris bulmam lazım, ama bunların ikisini de aynı anda bulmak istemiyorum. Bir fikir: öyle bir numara yapayım ki <span class="math inline">\(U\)</span> yokolsun her şey <span class="math inline">\(V\)</span> üzerinden temsil edilsin.</p>
<p>Alttaki ifade ne zaman elimizde genel dikdörtgensel (kare olmayan) bir matris varsa karşımıza çıkan bir ifade, <span class="math inline">\(A^TA\)</span>. Bu matris kare, pozitif kesin, yani güzel özellikleri var. O zaman üstteki formülü <span class="math inline">\(A^T\)</span> ile soldan çarpacağız,</p>
<p><span class="math display">\[ A^T = V \Sigma^T U^{T}  \]</span></p>
<p>olduğuna göre,</p>
<p><span class="math display">\[ A^TA = V \Sigma^T U^{T}  U \Sigma V^{T}  \]</span></p>
<p><span class="math inline">\(U^TU = I\)</span> olduğuna göre</p>
<p><span class="math display">\[ A^TA = V \Sigma^T \Sigma V^{T}  \]</span></p>
<p>Kolaylaştırmalar bitmedi. <span class="math inline">\(\Sigma\)</span> köşegen olduğuna göre, <span class="math inline">\(\Sigma^T\Sigma\)</span> köşegendeki değerlerin karesinden ibarettir.</p>
<p><span class="math display">\[ = V 
\left[\begin{array}{rrrr}
\sigma_1^2 &amp;&amp;&amp; \\
 &amp; \sigma_2^2 &amp;  &amp; \\
&amp;&amp; \ddots &amp; \\
&amp;&amp;&amp; \sigma_r^2 
\end{array}\right] 
V^T
  \]</span></p>
<p>İşte, <span class="math inline">\(U\)</span>'lar yokoldu. Bu son ulaştığımız formda <span class="math inline">\(V\)</span>'ler nedir? Özvektörlerdir! Problem mükemmel bir özdeğer / özvektör problemine dönüştü, yani <span class="math inline">\(Q\Lambda Q\)</span> haline geldi. Bu kolaylığa, sonuca <span class="math inline">\(A\)</span> yerine <span class="math inline">\(A^TA\)</span>'yi kullanmak sayesinde eriştik.</p>
<p>Pekala bu şekilde <span class="math inline">\(V\)</span>'leri elde ediyoruz, ama <span class="math inline">\(U\)</span>'yu nasıl elde edeceğiz? Onu geçici bir süre için yokettik, ama <span class="math inline">\(U\)</span> hala hesaplamamız gereken bir büyüklük, vektörler. Onun da çaresi var, <span class="math inline">\(A^T\)</span> ile soldan çarpmak yerine ana formülü <span class="math inline">\(A^T\)</span> ile sağdan çarparsak, bu sefer <span class="math inline">\(V\)</span>'ler yokolur, ve yine benzer özdeğer / özvektör hesabına geliriz, ama bu sefer <span class="math inline">\(U\)</span> hesaplarız.</p>
<p><span class="math display">\[ AA^T = U\Sigma V^TV\Sigma^TU^T \]</span></p>
<p><span class="math display">\[  = U\Sigma \Sigma^TU^T \]</span></p>
<p>Örnek için tüm bu hesapları yapalım.</p>
<p><span class="math display">\[ 
A^TA = 
\left[\begin{array}{rr}
4 &amp; -3 \\ 4 &amp; 3
\end{array}\right]
\left[\begin{array}{rr}
4 &amp; 4 \\ -3 &amp; 3
\end{array}\right] = 
\left[\begin{array}{cc}
25 &amp; 7 \\ 7 &amp; 25
\end{array}\right]
\]</span></p>
<p>Özvektörler</p>
<p><span class="math display">\[ 
\left[\begin{array}{r}
1 \\ 1
\end{array}\right],
\left[\begin{array}{r}
-1 \\ 1
\end{array}\right]
 \]</span></p>
<p>Özdeğerler</p>
<p><span class="math inline">\(\lambda_1=32, \lambda_2=18\)</span>.</p>
<p>Özvektörleri normalize etmeli</p>
<p><span class="math display">\[ 
\left[\begin{array}{r}
1 / \sqrt{ 2} \\ 1/ \sqrt{ 2}
\end{array}\right],
\left[\begin{array}{r}
-1/ \sqrt{ 2} \\ 1/ \sqrt{ 2}
\end{array}\right]
 \]</span></p>
<p>o zaman</p>
<p><span class="math display">\[ 
\underbrace{
\left[\begin{array}{rr}
4 &amp; 4 \\ -3 &amp; 3
\end{array}\right] 
}_{A}
=
\underbrace{
\left[\begin{array}{rr}
 &amp;  \\  &amp; 
\end{array}\right]
}_{U}
\underbrace{
\left[\begin{array}{rr}
\sqrt{ 32} &amp;  \\  &amp; \sqrt{ 18}
\end{array}\right]
}_{\Sigma}
\underbrace{
\left[\begin{array}{rr}
1/\sqrt{ 2} &amp; 1/\sqrt{ 2} \\ -1/\sqrt{ 2} &amp; 1/\sqrt{ 2}
\end{array}\right]
}_{V^T}
 \]</span></p>
<p>Şimdi <span class="math inline">\(U\)</span>'nun sırası geldi. Onun için <span class="math inline">\(AA^T\)</span> lazım.</p>
<p><span class="math display">\[ A^TA = 
\left[\begin{array}{rr}
4 &amp; 4 \\ -3 &amp; 3
\end{array}\right] 
\left[\begin{array}{rr}
4 &amp; -3 \\ 4 &amp; 3
\end{array}\right] =
\left[\begin{array}{rr}
32 &amp; 0 \\ 0 &amp; 18
\end{array}\right]
 \]</span></p>
<p>Raslantı oldu yukarıdaki çarpım köşegen çıktı, iyi oldu tabii, çünkü bu tür matrislerin özvektörlerini, özdeğerlerini hesaplamak çok kolaydır. Özvektörler,</p>
<p><span class="math display">\[ 
\left[\begin{array}{r}
1 \\ 0
\end{array}\right],
\left[\begin{array}{r}
0 \\ 1
\end{array}\right]
 \]</span></p>
<p>Özdeğerler <span class="math inline">\(\lambda_1 = 32, \lambda_2 = 18\)</span></p>
<p>İlginci ki yine aynı özdeğerleri elde ettim, ama şaşırmamak lazım, çünkü mesela bir <span class="math inline">\(AB\)</span> çarpımının özdeğerleri <span class="math inline">\(BA\)</span> ile aynıdır.</p>
<p>Neyse <span class="math inline">\(U\)</span>'yu bulduk, yerine koyalım,</p>
<p><span class="math display">\[ 
\underbrace{
\left[\begin{array}{rr}
4 &amp; 4 \\ -3 &amp; 3
\end{array}\right] 
}_{A}
=
\underbrace{
\left[\begin{array}{rr}
1 &amp; 0 \\ 0 &amp; 1 
\end{array}\right]
}_{U}
\underbrace{
\left[\begin{array}{rr}
\sqrt{ 32} &amp; 0 \\ 0 &amp; \sqrt{ 18}
\end{array}\right]
}_{\Sigma}
\underbrace{
\left[\begin{array}{rr}
1/\sqrt{ 2} &amp; 1/\sqrt{ 2} \\ -1/\sqrt{ 2} &amp; 1/\sqrt{ 2}
\end{array}\right]
}_{V^T}
 \]</span></p>
<p>Örnek</p>
<p>Bu sefer <span class="math inline">\(A\)</span> eşsiz (singular) olsun, yani kertesi 1.</p>
<p><span class="math display">\[ A = \left[\begin{array}{rr}
4 &amp; 3 \\ 8 &amp; 6
\end{array}\right] \]</span></p>
<p>Şimdi, eğer SVD işlemi satır uzayı ve kolon uzayı için birimdik bir baz bulmak demek ise, <span class="math inline">\(A\)</span>'nin satır uzayında özvektör bulmak kolay (çünkü eşsiz satır uzayı</p>
<p><span class="math display">\[ 
\left[\begin{array}{r}
4 \\ 3
\end{array}\right]
 \]</span></p>
<p>Özvektör bu uzayda olmalı, bu uzayda tek eleman vardır, o zaman hesap kolay. Tek yapmamız gereken üstteki vektörü normalize etmek,</p>
<p><span class="math display">\[ 
v_1 = \left[\begin{array}{r}
.8 \\ .6
\end{array}\right]
 \]</span></p>
<p>Peki <span class="math inline">\(v_2\)</span>? <span class="math inline">\(v_1\)</span>'e dikgen olmalı.</p>
<p><span class="math display">\[ 
v_2 = \left[\begin{array}{r}
.8 \\ -.6
\end{array}\right]
 \]</span></p>
<p>Aynı işlem <span class="math inline">\(U\)</span> için,</p>
<p><span class="math display">\[ 
\left[\begin{array}{r}
4 \\ 8
\end{array}\right]
 \]</span></p>
<p>Birinci kolonu direk aldık (bu kolon ile ikinci kolon arasında kat farkı olduğu direk görülmüyor ama kesirli olarak var),</p>
<p><span class="math display">\[ 
u_1 = \left[\begin{array}{r}
1/\sqrt{ 5} \\ 2/\sqrt{ 5}
\end{array}\right]
 \]</span></p>
<p>Yani</p>
<p><span class="math display">\[ 
\underbrace{
\left[\begin{array}{rr}
4 &amp; 3 \\ 8 &amp; 6
\end{array}\right] 
}_{A}
=
\underbrace{
\left[\begin{array}{rr}
1/\sqrt{ 5} &amp;  \\ 2/\sqrt{ 5} &amp; 
\end{array}\right]
}_{U}
\underbrace{
\left[\begin{array}{rr}
 &amp; 0 \\ 0 &amp; 0
\end{array}\right]
}_{\Sigma}
\underbrace{
\left[\begin{array}{rr}
 &amp; \\
 &amp; 
\end{array}\right]
}_{V^T}
 \]</span></p>
<p><span class="math inline">\(\Sigma\)</span> içinde üç sıfır var, çünkü <span class="math inline">\(A\)</span> eşsiz. Eksik değer nedir? Şu çarpımın özdeğerlerini bulalım</p>
<p><span class="math display">\[ A^TA = 
\left[\begin{array}{rr}
4 &amp; 8 \\ 3 &amp; 6
\end{array}\right] 
\left[\begin{array}{rr}
4 &amp; 3 \\ 8 &amp; 6
\end{array}\right] =
\left[\begin{array}{rr}
80 &amp; 60 \\ 60 &amp; 45
\end{array}\right] 
 \]</span></p>
<p>Sonuç yine eşsiz, özdeğerlerin biri sıfır. Tüm özdeğerlerin toplamı matris izine (trace) eşit, özdeğerlerden biri sıfır, o zaman diğeri köşegenin toplamının ta kendisi, yani 125.</p>
<p><span class="math display">\[ 
\underbrace{
\left[\begin{array}{rr}
4 &amp; 3 \\ 8 &amp; 6
\end{array}\right] 
}_{A}
=
\underbrace{
\left[\begin{array}{rr}
1/\sqrt{ 5} &amp; 2/\sqrt{5} \\ 2/\sqrt{ 5} &amp; -1/\sqrt{5}
\end{array}\right]
}_{U}
\underbrace{
\left[\begin{array}{rr}
\sqrt{ 125} &amp; 0 \\ 0 &amp; 0
\end{array}\right]
}_{\Sigma}
\underbrace{
\left[\begin{array}{rr}
.8 &amp; -.6 \\
.8 &amp; .6 
\end{array}\right]
}_{V^T}
 \]</span></p>
<p>Örneklerimiz bunlar. Şimdi ne yaptığımızı biraz düşünelim. <span class="math inline">\(v_1,..,v_r\)</span> satır uzayı için birimdik bir bazdır. <span class="math inline">\(u_1,..,u_r\)</span> kolon uzayı için birimdik bir bazdır. Fakat eşsizlik var, o zaman <span class="math inline">\(v_{r+1},.,v_n\)</span> sıfır uzayı için birimdik bir bazdır, ve <span class="math inline">\(u_{r+1},..,u_n\)</span> <span class="math inline">\(A^T\)</span>'un sıfır uzayı için birimdik bir bazdır.</p>
<p>SVD üzerinden öyle bazlar seçiyoruz ki</p>
<p><span class="math display">\[ Av_i = \sigma_i u_i \]</span></p>
<p>doğru oluyor.</p>
<p>Artımsal SVD</p>
<p>Bir matris <span class="math inline">\(A\)</span> üzerinde SVD işlettikten sonra <span class="math inline">\(A\)</span>'ya yeni satırlar eklendi diyelim, bu durumda sadece eklenen matrislerin eski SVD sonucu üzerinde değişiklik yapması iyi olmaz mıydı? Sürekli akan verileri işlemesi gereken, canlı ortamda anlık analiz yapan kodlar için bu iyi bir kabiliyet olurdu. [1] yöntemiyle bu mümkündür.</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="co"># Wingate&#39;in matlab kodlarindan tercume edilmistir, matlab dizini</span>
<span class="co"># altinda orijinal kodlar var</span>
<span class="co"># http://pcc.byu.edu/resources.html</span>
<span class="im">import</span> numpy <span class="im">as</span> np
<span class="im">import</span> scipy.linalg <span class="im">as</span> lin

<span class="kw">def</span>  addblock_svd_update( Uarg, Sarg, Varg, Aarg, force_orth <span class="op">=</span> <span class="va">False</span>):
  U <span class="op">=</span> Varg
  V <span class="op">=</span> Uarg
  S <span class="op">=</span> np.eye(<span class="bu">len</span>(Sarg),<span class="bu">len</span>(Sarg))<span class="op">*</span>Sarg
  A <span class="op">=</span> Aarg.T
  
  current_rank <span class="op">=</span> U.shape[<span class="dv">1</span>]
  m <span class="op">=</span> np.dot(U.T,A)
  p <span class="op">=</span> A <span class="op">-</span> np.dot(U,m)
  P <span class="op">=</span> lin.orth(p)
  Ra <span class="op">=</span> np.dot(P.T,p)
  z <span class="op">=</span> np.zeros(m.shape)
  K <span class="op">=</span> np.vstack(( np.hstack((S,m)), np.hstack((z.T,Ra)) ))
  tUp,tSp,tVp <span class="op">=</span> lin.svd(K)<span class="op">;</span>
  tUp <span class="op">=</span> tUp[:,:current_rank]
  tSp <span class="op">=</span> np.diag(tSp[:current_rank])
  tVp <span class="op">=</span> tVp[:,:current_rank]
  Sp <span class="op">=</span> tSp
  Up <span class="op">=</span> np.dot(np.hstack((U,P)),tUp)
  Vp <span class="op">=</span> np.dot(V,tVp[:current_rank,:])
  Vp <span class="op">=</span> np.vstack((Vp, tVp[current_rank:tVp.shape[<span class="dv">0</span>], :]))
  
  <span class="cf">if</span> force_orth:
    UQ,UR <span class="op">=</span> lin.qr(Up,mode<span class="op">=</span><span class="st">&#39;economic&#39;</span>)
    VQ,VR <span class="op">=</span> lin.qr(Vp,mode<span class="op">=</span><span class="st">&#39;economic&#39;</span>)
    tUp,tSp,tVp <span class="op">=</span> lin.svd( np.dot(np.dot(UR,Sp),VR.T))<span class="op">;</span>
    tSp <span class="op">=</span> np.diag(tSp)
    Up <span class="op">=</span> np.dot(UQ,tUp)
    Vp <span class="op">=</span> np.dot(VQ,tVp)
    Sp <span class="op">=</span> tSp<span class="op">;</span>

  Up1 <span class="op">=</span> Vp<span class="op">;</span>
  Vp1 <span class="op">=</span> Up<span class="op">;</span>
    
  <span class="cf">return</span> Up1,Sp,Vp1
</code></pre></div>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="im">import</span> isvd

X <span class="op">=</span> [[ <span class="fl">2.180116</span>,   <span class="fl">2.493767</span>,  <span class="fl">-0.047867</span>],
     [<span class="op">-</span><span class="fl">1.562426</span>,  <span class="fl">2.292670</span>,   <span class="fl">0.139761</span>],
     [<span class="fl">0.919099</span>,  <span class="fl">-0.887082</span>,  <span class="fl">-1.197149</span>],
     [<span class="fl">0.333190</span>,  <span class="fl">-0.632542</span>,  <span class="fl">-0.013330</span>]]
X <span class="op">=</span> np.array(X)

<span class="co"># eklenen veri</span>
A <span class="op">=</span> np.array([[<span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>]])
X2 <span class="op">=</span> np.vstack((X,A))

<span class="co"># ilk matris uzerinde svd</span>
U,S,V <span class="op">=</span> np.linalg.svd(X, full_matrices<span class="op">=</span><span class="va">False</span>)

U <span class="op">=</span> np.array(U)
V <span class="op">=</span> np.array(V)

<span class="co"># sadece eklerle isvd</span>
Up,Sp,Vp <span class="op">=</span> isvd.addblock_svd_update(U, S, V, A, <span class="va">True</span>)
<span class="bu">print</span> <span class="st">&#39;isvd&#39;</span>
<span class="bu">print</span> Up
<span class="bu">print</span> Sp
<span class="bu">print</span> Vp

<span class="co"># eklenmis matris uzerinde pur svd</span>
<span class="bu">print</span>
<span class="bu">print</span> <span class="st">&#39;pur svd&#39;</span>
U2,S2,V2 <span class="op">=</span> np.linalg.svd(X2, full_matrices<span class="op">=</span><span class="va">False</span>)
<span class="bu">print</span> U2
<span class="bu">print</span> S2
<span class="bu">print</span> V2</code></pre></div>
<pre><code>isvd
[[-0.89212349  0.42001721  0.09058799]
 [-0.3729822  -0.78719172 -0.37768251]
 [-0.05078729  0.25050859 -0.76208235]
 [ 0.11796561  0.18780756  0.1085498 ]
 [-0.22023788 -0.32540515  0.50655422]]
[[ 3.79248135  0.          0.        ]
 [ 0.          3.09209248  0.        ]
 [ 0.          0.          1.15034338]]
[[ 0.1324264  -0.97641566 -0.170516  ]
 [ 0.94529671  0.17615382 -0.2745614 ]
 [ 0.29812309 -0.12482904  0.94632993]]

pur svd
[[-0.78116195 -0.47183754 -0.23031926]
 [-0.44651841  0.72266108 -0.36443757]
 [ 0.1972781  -0.44447025 -0.63490698]
 [ 0.12977978 -0.16651859  0.11049824]
 [-0.36694126 -0.17276591  0.6315232 ]]
[ 3.82671655  2.94889887  1.38833588]
[[-0.29993168 -0.939654   -0.1645945 ]
 [-0.94765048  0.27366694  0.16451435]
 [ 0.1095425  -0.20532112  0.97254495]]</code></pre>
<p>Kaynaklar</p>
<p>[1] Brand, <em>Fast low-rank modifications of the thin singular value decomposition</em></p>
</body>
</html>
