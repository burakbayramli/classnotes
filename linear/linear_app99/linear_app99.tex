\documentclass[12pt,fleqn]{article}\usepackage{../../common}
\begin{document}
Uzaklýklar, Norm, Benzerlik

Literatürdeki anlatým norm ve uzaklýk konusu etrafýnda biraz kafa karýþýklýðý
yaratabiliyor, bu yazýda biraz açýklýk getirmeye çalýþalým. Norm bir büyüklük
ölçüsüdür. Vektör uzaylarý ile olan alakasýný görmek için {\em Fonksiyonel
  Analiz} notlarýna bakýlabilir. Büyüklük derken bir $x$ vektörünün
büyüklüðünden bahsediyoruz, ki bu çoðunlukla $||x||$ gibi bir kullanýmda
görülür, eðer altsimge yok ise, o zaman 2 kabul edilir, yani $||x||_2$. Bu ifade
bir L2 norm'unu ifade eder. $||x||_1$ varsa L1 norm'ü olurdu.

L1,L2 normalarý, ya da genel olarak $p$ üzerinden $L_p$ normlarý þöyle gösterilir,

$$ ||x||_p = (\sum_i |x_i|^p)^{1/p} $$

ki $x_i$, $x$ vektörü içindeki öðelerdir. Eðer $p=2$ ise, L2 norm

$$ ||x||_2 = \bigg(\sum_i |x_i|^2 \bigg)^{1/2} $$

Üstel olarak $1/2$'nin karekök demek olduðunu hatýrlayalým, yani 

$$ ||x||_2 = \sqrt{\sum |x_i|^2} $$

Bu norm ayrýca Öklitsel (Euclidian) norm olarak ta bilinir, tabii ki bunun
Öklitsel uzaklýk ile yakýn baðlantýsý var (iki vektörü birbirinden çýkartýp
Öklit normunu alýrsak Öklit uzaklýðýný hesaplamýþ oluruz).

Eðer $p=1$ olsaydý, yani L1 norm, o zaman üstel olarak $1/1$ olur, yani hiçbir
üstel / köksel iþlem yapýlmasýna gerek yoktur, iptal olurlar,

$$ ||x||_1 = \sum |x_i|^2 $$

Örnek

$$ 
a = \left[\begin{array}{r}
3 \\ -2 \\ 1
\end{array}\right]
 $$

$$ ||a|| = \sqrt{3^2+(-2)^2+1^2} = 3.742 $$

Örnekte altsimge yok, demek ki L2 norm. 

Ek Notasyon, Ýþlemler

L1 normu için yapýlan iþlemi düþünelim, vektör öðeleri kendileri ile
çarpýlýyor ve sonuçlar toplanýyor. Bu iþlem

$||x||_1 = x^Tx$

olarak ta gösterilemez mi? Ya da $x \cdot x$ olarak ki bu noktasal çarpýmdýr.

Bazen de yapay öðrenim literatüründe $||x||^2$ þekilde bir kullaným
görebiliyorsunuz. Burada neler oluyor? Altsimge yok, demek ki L2
norm. Sonra L2 normun karesi alýnmýþ, fakat L2 normu tanýmýna göre bir
karekök almýyor muydu? Evet, fakat o zaman kare iþlemi karekökü iptal eder,
demek ki L2 normunun karesini almak bizi L1 normuna döndürür! Eh bu normu
da $x^Tx$ olarak hesaplayabildiðimize göre hemen o notasyona geçebiliriz,
demek ki $||x||^2 = x^Tx = x \cdot x$. 

Ýkisel Vektörlerde Benzerlik

Diðer ilginç bir kullaným ikisel deðerler içeren iki vektör arasýnda
çakýþan 1 deðerlerinin toplamýný bulmak. Mesela 

\begin{minted}[fontsize=\footnotesize]{python}
a = np.array([1,0,0,1,0,0,1,1])
b = np.array([0,0,1,1,0,1,1,0])
\end{minted}

Bu iki vektör arasýndaki 1 uyusumunu bulmak için noktasal çarpým yeterli,
çünkü 1 ve 0, 0 ve 1, 0 ve 0 çarpýmý sýfýr verir, ama 1 çarpý 1 = 1
sonucunu verir. O zaman L1 norm bize ikisel iki vektör arasýnda kabaca bir
benzerlik fikri verebilir.

\begin{minted}[fontsize=\footnotesize]{python}
print np.dot(a,b)
\end{minted}

\begin{verbatim}
2
\end{verbatim}

Matris Normlarý

Vektörlerin norm'ü hesaplanabildiði gibi matris norm'ü da hesaplanabilir. Bir
$A$ matrisi için matris norm'ü

$$ || A || = \sup \{ ||Ax|| : x \in \mathbb{R}^n, ||x||=1 \textrm{ olacak þekilde } \} $$

Bazen þöyle de gösterilir,

$$  || A || = \sup_{||x||=1} \{ ||Ax|| \} $$

ya da

$$ || A || = \sup \{ \frac{||Ax||}{||x||} : x \in \mathbb{R}^n, x \ne 0 \textrm{ olacak þekilde } \} $$

Daha genel formda p-norm'u

$$ || A || = \sup
\bigg\{
\frac{||Ax||_p}{||x||_p} : x \in \mathbb{R}^n, x \ne 0 \textrm{ olacak þekilde }
\bigg\} $$

Özel durum $p=2$ için ki bu yine, vektörler için olduðu gibi, Öklitsel norm
olarak biliniyor. Bu durumda $A$'nýn normu $A$'nýn en büyük eþsiz
deðeridir. Yaklaþýk olarak hesaplama açýsýndan þunu da verelim,

$$ ||A||_1 = \max_{1 \le j \le n} \sum _{i=1}^{m} |a_{ij}| $$

Yani tüm matris kolonlarýnýn hücrelerinin mutlak deðerleri toplanýyor, bu
toplamlar arasýnda en büyük sayýyý veren kolonun toplamý normun yaklaþýk
deðeridir.

Spektral (Operatör) ve Ýz (Trace) Norm

Bu normlar sýrasýyla matrisin en büyük eþsiz (singular) deðeri, ve tüm
eþsiz deðerlerinin toplamýyla hesaplanýr. Bir matris $X$ için operatör norm

$$
||X||_{op} = \sigma_1(X)
$$

Ýz normu

$$
||X||_{tr} = \sigma _{i=1}^{r} \sigma_i(X)
$$


\newpage

$$ (x-v)^TA(x-v) < 1 $$

Üstteki formülde $x$ yerine $Px$ geçirirsek, ki $P$ herhangi bir matris,
eþitsizliðin sol tarafýna ne olur?

$$ (P(x-v))^T A (P(x-v))$$

$$ (x-v)^T P^T A P (x-v)  $$

Bu formüle bir þekilde ulaþmamýz lazým. Ama nasýl? Basitleþtirme amaçlý olarak
$w = x-v$ tanýmlayalým, ki $x \ne v$ olacak þekilde. $X = \frac{1}{||w||^2} I$
tanýmlayalým, bu bir köþegen matris, köþegeninde $1/||w||^2$ deðerleri var. Bu
sayede

$$ w^T A W < 1  \Rightarrow w^T A W < w^T X w  $$

1 yerine üstteki en saðdaki terimi kullanmýþ olduk. Herhangi bir $x$ için
üstteki eþitsizlik her $w$ için doðru olacaktýr. Bu da $A - X$ negatif kesin
demektir (pozitif kesinliðin tersi), o zaman þunu da söyleyebiliriz,

$$ A - X < 0 \Rightarrow P^T(A-x)P < 0 \Rightarrow P^T AP < P^TXP $$

Soldan ve saðdan $w^T,w$ ile çarparsak,

$$ w^T P^T AP w < w^T P^TXP w = \frac{1}{||w||^2} w^T P^T P w = (Pu)^T Pu$$

ki $u = \frac{w}{||w||}$ $x-v$ yönünü gösteren birim vektördür. 

Þimdi matris normunun ne olduðunu hatýrlayalým,

$$ ||P|| = \sup_{||u||=1} || Pu || $$

O zaman emin bir þekilde diyebiliriz ki 

$$ (x-v)^TA(x-v) < 1 \Rightarrow (x-v)^T P^T A P (x-v) < ||P||^2 $$


\newpage 

Sherley-Morrison Formülü

Bu formülün temeli þu eþitlikten baþlýyor [1, sf. 124],

$$
(I+cd^T)^{-1} = I - \frac{cd^T}{1+d^Tc}
\mlabel{1}
$$

ki $c,d$ birer vektör, ve $1+d^Tc \ne 0$ olacak þekilde, üstteki eþitliðin
doðru olduðunu kontrol için iki tarafý $(I+cd^T)$ ile çarpabiliriz, eðer
sað tarafta birim matrisi elde edersek eþitlik doðru demektir,

$$
I + cd^T - \frac{cd^T (I + cd^T)}{1+d^Tc}
$$

$$
= I + cd^T - \frac{I cd^T (1+cd^T)}{1+d^Tc}
$$

$$
= I + cd^T - cd^T = I
$$

Eðer sýfýrdan baþlayarak türetmek istesek, öyle bir $\alpha$ arýyoruz ki
$(I + cd^T)$ ifadesini $(I + \alpha cd^T)$ ile çarpýnca bize birim matrisi
versin. Çarpýmý yaparsak,

$$
(I + cd^T) (I + \alpha cd^T) = I + cd^T + \alpha cd^T + \alpha cd^Tcd^T 
$$

$$
= I + (1 + \alpha + \alpha d^T c) cd^T
$$

Üsttekinin birim matrisi $I$ olmasý için $1 + \alpha + \alpha d^T c$ sýfýr
olmalý, onun sýfýr olmasý için de

$$\alpha = \frac{-1}{1 + d^Tc}$$

doðru olmalý. $\alpha$'yi yerine koyarsak, 

$$
(I + \alpha cd^T) = I - \frac{cd^T}{1+d^Tc}
$$

elde ederiz, yani $(I + \alpha cd^T)^{-1}$ açýlýmý budur. 

Sherman-Morrison formülü 

$$
(A + cd^T)^{-1} = A^{-1} - \frac{A^{-1} cd^T A^{-1} }{1 + d^TA^{-1}c}
$$

Bu formüle eriþmek için $(A + cd^T)^{-1}$ ile baþlayalým, $A$'yi parantez
dýþýna çekersek,

$$
(A + cd^T)^{-1} = \big( A ( I + A ^{-1} cd^T ) \big)^{-1} 
$$

$$
= ( I + A ^{-1} cd^T )^{-1} A^{-1} 
$$

Parantez içinin (1)'in sol tarafýna benzediðini görebiliriz, $b = A^{-1}c$ 
desek,  $( I + bd^T )^{-1} $ açýlýmýni yapýyor olurduk, 

$$
( I + bd^T )^{-1} 
= I - \frac{bd^T}{1+d^Tb} 
= I - \frac{A^{-1}cd^T}{1+d^TA^{-1}c}
$$

Bu sonucu iki üstteki parantez içindeki $A ( I + A ^{-1} cd^T$ yerine
koyarsak,

$$
(A + cd^T)^{-1} = I - \frac{A^{-1}cd^T}{1+d^TA^{-1}c} A^{-1} 
$$

sonucuna eriþmiþ oluyoruz. 

Sherman-Morrison-Woodburry

Bu son formül Sherman-Morrison formülünün daha genelleþtirilmiþ hali
[3]. Diyelim ki $A \in \mathbb{R}^{n \times n}$ eþsiz deðil, ve
$U,V \in \mathbb{R}^{n \times p}$ öyle ki 

$$
U + V^T A^{-1} U \in \mathbb{R}^{p \times p}
$$

O zaman 

$$B = A + UV^T$$

eþsiz deðildir, ve 

$$
B^{-1} = A^{-1} - A^{-1} U ( I + V^T A^{-1} U)^{-1} V^T A^{-1} 
$$

\newpage

Gereðinden Fazla Calculus

(MÝT üniversitesi Matematik hocasý Gilbert Strang'in MÝT üniversitesine hitaben
bir yazýsýndan [9] alýnmýþtýr)

Calculus I, Calculus II, Calculus III - öðretim sistemimizde ne kadar büyük bir
dengesizlik! Matematiðin geri kalan kýsmý Calculus tarafýndan boðuldu
denebilir. Bu kadar Calculus dersinden sonra takip eden ders herhalde Türevsel
Denklemler (gene Calculus), Calculus'tan önceki ders'te herhalde Calculus'a
Giriþ dersi idi. Arkadaþlar, bu dengesizliði düzeltmek bizim görevimiz, bunu
baþkasýndan bekleyemeyiz. Lineer cebir'in ne kadar önemli bir ders olduðunu
biliyoruz. Bu ders seçmeli/rasgele alýnan bir ders deðil, uygulama olarak birçok
öðrenciye Calculus'dan daha faydalý olacak bir ders. Artýk sayýsal bir dünyada
yaþýyoruz. Bu konu hakkýnda dünyadaki hocalara öncü ve örnek olmamýzý istediðim
için, Lineer Cebir'in faydalarýndan bahsetmek istiyorum. Özetle þöyle
düþünüyorum: Eðer þu ankinden daha fazla öðrenci Lineer Cebir öðreniyor ise,
matematik bölümü bir þeyleri doðru yapýyor demektir. Ýstatistik ve Ayrýksal
Matematik te lazým. Umarým bölüm baþkaný ve rektör onaylar. Ýnanýyorum ki bu
sayede öðrencilerimi için doðru þeyi yapmýþ olacaðýz.Ýzin verirseniz, lineer
cebir ders basamaklarýndan bahsedeyim. Mesela dersin her aþamasý belli
denklemlerin çözümüne, ya da o denklemleri çözmeye temel olan fikirlere ve
algoritmalara göre ayýrýlabilir. Bu safhalar birbirini tamamlamalýdýr. Mesela 4
denklemi merkez olarak alabiliriz.

$$
Ax = b, \quad A'Ax = A'b, \quad Ax = \lambda x, \quad \ud u / \ud t = Au
$$

En önemli nokta, herhangi bir uygulama için (gerçek dünyada) bir doðrusal
'sistemi' görebilmek. Þu bizim ünlü A matrisimizi bulabilmek, tanýmlayabilmek ne
kadar önemli deðil mi? Bunun sonrasýnda tabii ki o matris üzerinde iþlem
yapmamýza yardýmcý olacak fikirler takip edecek.

* Alt-uzaylar ve bazlar, izdüþümler ve dikgenlik, özvektörler ve özdeðerler

* Algoritmalar da çok önemli (matris çarpýmý da buna dahil)

* Ax = kolonlarýn katýþýmý, A = LU ile yokedilmesi, sonra Gram-Schmidt iþlemi

En mühim konu da 'doðrusal dönüþüm'. Eðer bir problem içinde matrisin bazýna ne
olduðunu biliyorsak, her þeyi biliyoruz demektir. Ben örneklere odaklanabilirim,
siz ispatlara odaklanabilirsiniz, ama sýnýfýn ne beklediðine her zaman
kulaðýmýzý açýk tutalým.Tekrar ana konuya döneyim, çünkü hepimizin yardýmýný ve
eylemini gerektiriyor. Lineer cebir hakkýnda çoðunlukla destek görüyoruz, ya da
aldýrmazlýk görüyoruz. Öteki hocalarýn da kendi yapacak iþleri var, hattâ ve
hattâ üst düzey mühendisler bile lineer cebiri istenmeyen bir þey olarak
görebiliyorlar. Belki de bilgisayarlarýn iþleri nasýl deðiþtirdiðinin farkýnda
deðiller. Fakat sonuçta öðrencileri önde tutarak doðru seçimi
yapacaklardýr. Öðrenciler durumu anladýðýnda hocalarýmýz da doðru seçimi
yaptýklarýný inanacaklarýna eminim. Calculus I, II ve III derslerinin kendisinin
reform edilmesi bu sunumun dýþýnda. Bu dersler de önemli, ama hayat-memat
seviyesinde deðil. Öðrencilerin çoðuna 'yararlý' olacak türden matematik
öðretmek bizim görevimiz.


Kaynaklar 

[1] Meyer, {\em Matrix Analysis and Applied Linear Algebra}

[2] Gadzinski, {How to Derive the Sherman-Morrison Base Formula, Math Stackexchange Sorusuna Cevap}, 
    \url{https://math.stackexchange.com/a/3462542/6786}

[3] Gockenbach, {\em Numerical Optimization MA 5630, Globalizing Newton's method: Descent Directions (II)}
    \url{https://pages.mtu.edu/~msgocken/ma5630spring2003/lectures.html}

[4] Marmer, {\em Economics 627 Econometric Theory II, Vector and Matrix Differentiation}, 
    \url{http://faculty.arts.ubc.ca/vmarmer/econ627/}
        
[5] Duda, Hart, {\em Pattern Classification}

[6] Bishop, {\em Pattern Recognition and Machine Learning}

[7] Wikipedia, {\em Matrix norm}, 
    \url{https://en.wikipedia.org/wiki/Matrix_norm}

[8] Thibshirani, {\em Convex Optimization}, 
    \url{https://www.stat.cmu.edu/~ryantibs/convexopt}

[9] Strang, {\em Too Much Calculus},
    \url{http://web.mit.edu/18.06/www/Essays/too-much-calculus.pdf}
    
\newpage 

Yunan Harfleri

\includegraphics[width=30em]{../../algs/algs_999_zapp/letters.png}

\end{document}





