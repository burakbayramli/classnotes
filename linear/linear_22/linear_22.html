<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
    <script type="text/x-mathjax-config">
    MathJax.Hub.Register.StartupHook("TeX Jax Ready",function () {
      MathJax.Hub.Insert(MathJax.InputJax.TeX.Definitions.macros,{
        cancel: ["Extension","cancel"], cancelto: ["Extension","cancel"]
      });
    });
    </script>  
   
  <title>Ders 22</title>
  <style type="text/css">code{white-space: pre;}</style>
  <style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
  </style>
  <script
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS_HTML-full"
  type="text/javascript"></script>
</head>
<body>
<div id="header">
</div>
<h1 id="ders-22">Ders 22</h1>
<p>Bu ders özdeğerler hakkındaki 2. dersimiz. İlk derste y<span
class="math inline">\(Ax = \lambda x\)</span> formülüne eriştik, <span
class="math inline">\(x\)</span> özvektör ve <span
class="math inline">\(\lambda\)</span> özdeğer, ve bu değerleri
hesaplayabilmeyi öğrendik. Şimdi onları kullanmayı göreceğiz. Bu
kullanımı görmenin iyi yollarından birisi, bir matrisi “köşegenleştirmek
(diagonalization)’’, ki bu formül <span class="math inline">\(S^{-1}AS
=\Lambda\)</span> olarak gösterilir, çok temel bir formüldür bu ve
bugünkü dersin merkez noktası.</p>
<p><span class="math inline">\(A\)</span>’nin özvektörleri <span
class="math inline">\(S\)</span>’in kolonlarını oluşturacak, ve bu <span
class="math inline">\(S\)</span>’i içeren <span
class="math inline">\(S^{-1}AS\)</span> sihirli formülüne bakacağız,
burada neler oluyor? Ortada bir tersi alma işlemi var, <span
class="math inline">\(S^{-1}\)</span> ile, demek ki özvektör matrisi
<span class="math inline">\(S\)</span>’in tersi alınabilir olması lazım,
o zaman bize <span class="math inline">\(n\)</span> tane bağımsız
özvektör lazım [ki onları içeren matris tersi alınabilir olsun].</p>
<p>Şu matris çarpımını düşünelim şimdi,</p>
<p><span class="math display">\[
AS =  
A \left[\begin{array}{rrrr}
\uparrow &amp; \uparrow &amp; &amp; \uparrow \\
x_1 &amp; x_2 &amp; \cdots &amp; x_n \\
\downarrow &amp; \downarrow &amp; &amp; \downarrow
\end{array}\right]
\]</span></p>
<p>Bu çarpımı her <span class="math inline">\(S\)</span> kolonu için
ayrı ayrı yaptığımı düşünebilirim, her kolonun <span
class="math inline">\(A\)</span>’yi çarpması ayrı bir kolon sonucunu
verirdi. Bu sonuçlar ne olurdu? Mesela <span
class="math inline">\(Ax_1\)</span>’i düşünelim, <span
class="math inline">\(x_1\)</span> bir özvektör olduğuna göre (çünkü
<span class="math inline">\(S\)</span>’i özvektörler ile oluşturmuştuk)
o zaman özdeğer/vektör <span class="math inline">\(Ax = \lambda
x\)</span> formülüne göre <span class="math inline">\(Ax_1 = \lambda_1
x_1\)</span> elde ederdik, ki <span
class="math inline">\(\lambda_1\)</span> 1. özdeğer olurdu, ardından,
2., 3., vs. özvektörler için bu aynı şekilde devam ederdi, ve buna
göre,</p>
<p><span class="math display">\[
= \left[\begin{array}{rrr}
&amp; &amp;  \\
\lambda_1x_1 &amp; \cdots &amp; \lambda_nx_n \\
&amp; &amp;
\end{array}\right]
\]</span></p>
<p>elde ederdik. Güzel duruyor. Daha da güzel olabilir! Bir sonraki
adımda üstteki kolonlardaki özdeğerleri dışarı çıkartmak istiyorum,</p>
<p><span class="math display">\[
= \left[\begin{array}{rrr}
&amp; &amp;  \\
x_1 &amp; \cdots &amp; x_n \\
&amp; &amp;
\end{array}\right]
\left[\begin{array}{rrr}
\lambda_1 &amp; &amp;  \\
&amp; \ddots &amp; \\
&amp; &amp; \lambda_n
\end{array}\right]
\]</span></p>
<p>İçinde <span class="math inline">\(\lambda\)</span>’lar olan matriste
köşegen haricindeki tüm diğer hücreler sıfır değerini taşıyor. Bu çarpım
bize istediğimiz sonucu verecek, hem de gayet temiz matris formları
kullanarak. Lineer Cebir ne güzel işliyor!</p>
<p>Ve nihayetinde üstteki çarpımı <span
class="math inline">\(S\Lambda\)</span> olarak gösterebilirim; Büyük
<span class="math inline">\(\lambda\)</span>, yani <span
class="math inline">\(\Lambda\)</span> işaretini “içinde özdeğerler
taşıyan matris’’ olarak belirttim böylece. Nihai formül <span
class="math inline">\(AS = S\Lambda\)</span>. Ardından bu eşitliğin iki
tarafını soldan <span class="math inline">\(S^{-1}\)</span> ile
çarparak</p>
<p><span class="math display">\[
S^{-1}AS = \Lambda
\]</span></p>
<p>diyebilirim. Tabii tekrar edelim, üstteki form sadece ve sadece <span
class="math inline">\(S\)</span> içinde birbirinden bağımsız özvektörler
var ise mümkündür. Bu olmayabilirdi, az miktarda matrisler için bu durum
geçerlidir, belki bir özvektör kendini tekrar edebilirdi, bu durumda
üstteki formu kullanamazdım. Fakat göreceğimiz çoğu matrisin <span
class="math inline">\(n\)</span> tane bağımsız özvektörü vardır, ve
onları köşegenleştirebiliriz (yani üstteki çarpım sonucu sağında <span
class="math inline">\(\Lambda\)</span> olan forma erişebiliriz).</p>
<p>Bu arada <span class="math inline">\(AS=S\Lambda\)</span>’yi sağdan
da <span class="math inline">\(S^{-1}\)</span> ile çarpabilirdim, o
zaman</p>
<p><span class="math display">\[
AS=S\Lambda
\]</span></p>
<p>ifadesi</p>
<p><span class="math display">\[
A = S \Lambda S^{-1}
\]</span></p>
<p>haline gelir. Hatırlamak bağlamında, mesela iki üstteki formül için,
<span class="math inline">\(A\)</span>’nin özvektörlerini çarptığını
düşünebilirim, yani <span class="math inline">\(Ax\)</span> formu, ama
bu sefer tüm özvektörler <span class="math inline">\(x\)</span> yerine
<span class="math inline">\(S\)</span> var, ve ardından, üç üstteki
formülde, sonucu <span class="math inline">\(S^{-1}\)</span> ile
çarpıyorum ve <span class="math inline">\(AS\)</span>’i köşegen haline
getirmiş oluyorum. Bir üstteki formül ise bu nihai sonucu ifade etmenin
değişik bir yolundan ibaret, <span class="math inline">\(S\)</span>’leri
karşı tarafa geçiriyoruz ve üstteki ifadeyi elde ediyoruz.</p>
<p>Üstte son ifade yeni bir ayrıştırma (factorization) olarak ta
görülebilir.. Eliminasyondaki <span
class="math inline">\(LU\)</span>’nun, ya da Gram-Schmidt’ten <span
class="math inline">\(QR\)</span>’in yerine geçebilecek bir tür
ayrıştırma yani. Form nedir? <span class="math inline">\(S\)</span>
çarpı köşegen matris çarpı <span class="math inline">\(S\)</span>’in
tersi. Bu kombinasyonu bu bölümde bol bol göreceğiz, ki bu kombinasyonda
<span class="math inline">\(S\)</span> ve onun tersi <span
class="math inline">\(S^{-1}\)</span>’in rol oynayacak.</p>
<p>Şimdi öğrendiklerimizi kullanmak istiyorum. Mesela <span
class="math inline">\(A^2\)</span>’i hesaplamak istiyorum. <span
class="math inline">\(A^2\)</span>’in özdeğer/vektörlerine ne olur? Bu
son derece temel bir soru. Alttaki formül ile başlangıç yapacağım, eğer
böyle bir formül ortaya konabiliyorsa tabii,</p>
<p><span class="math display">\[ Ax = \lambda x \]</span></p>
<p>Buradan <span class="math inline">\(A^2\)</span>’e ulaşmaya
çalışacağım. Üstteki formülün iki tarafını <span
class="math inline">\(A\)</span> ile çarpayım şimdi, böylece sol tarafta
<span class="math inline">\(A^2\)</span> elde ederim,</p>
<p><span class="math display">\[ AAx = A\lambda x \]</span></p>
<p><span class="math display">\[ A^2x = \lambda A x \]</span></p>
<p>Eğer <span class="math inline">\(Ax\)</span> yerine <span
class="math inline">\(\lambda x\)</span> kullanırsam, çünkü bu özvektör
denkleminden geliyor,</p>
<p><span class="math display">\[ A^2x = \lambda^2 x \]</span></p>
<p>Bu basit hesap arkasından sonuca bakınca şu yorumu yapabiliyorum;
<span class="math inline">\(A^2\)</span>’nin özdeğerleri <span
class="math inline">\(\lambda^2\)</span>’dir. Peki özvektörler?
Özvektörler <span class="math inline">\(A\)</span>’nin özvektörleri ile
aynıdır, çünkü <span class="math inline">\(x\)</span> değeri değişmeden
kaldı. Bunu <span class="math inline">\(A=SAS^{-1}\)</span>’i kullanarak
görebilir miyiz?</p>
<p><span class="math display">\[
A^2=S\Lambda S^{-1}S\Lambda S^{-1}
\]</span></p>
<p><span class="math display">\[
=S \Lambda \cancel{S^{-1}S} \Lambda S^{-1}
\]</span></p>
<p><span class="math display">\[
=S \Lambda \Lambda S^{-1}
\]</span></p>
<p><span class="math display">\[
=S \Lambda^2S^{-1}
\]</span></p>
<p>Bu bana ne söylüyor? Bir önceki metot ile aynı şeyi söylüyor,
özdeğerlerin karesi elde edilir ama özvektörler değişmez, bunu biliyoruz
çünkü yine aynı <span class="math inline">\(S\)</span> matrisini
bildiğimiz bir formda elde ettik.</p>
<p>Peki <span class="math inline">\(k\)</span> defa üst alma operasyonu
yapsaydım, yani <span class="math inline">\(A^k\)</span> hesaplasaydım
ne olurdu? Bu durumda en son metotta <span
class="math inline">\(S^{-1}S\)</span>’ların <span
class="math inline">\(k\)</span> çarpım içinde sürekli yanyana
geleceğini görebiliriz herhalde, ve tabii ki tüm bu yanyana gelen <span
class="math inline">\(S^{-1}S\)</span>’ler birbirini iptal edecektir.
Diğer yandan <span class="math inline">\(\Lambda\)</span> matrisi <span
class="math inline">\(k\)</span> defa kendisi ile çarpılacaktır,
yani</p>
<p><span class="math display">\[
A^k = S\Lambda^k S^{-1}
\]</span></p>
<p>Bu gayet temiz bir sonuç; demek ki özdeğerler/vektörler matrislerin
kendisi ile çarpılmış halini anlamak için biçilmiş kaftan. Kıyasla
matris katları alınırken, mesela pivotlar oradan oraya savrulurlar,
doğru dürüst analiz edilemezler. Eğer <span
class="math inline">\(A=LU\)</span> kullansaydım mesela <span
class="math inline">\(LU\)</span> çarpı <span
class="math inline">\(LU\)</span> çarpı <span
class="math inline">\(LU\)</span> böyle gidecekti, 100 defa ardından
<span class="math inline">\((LU)^{100}\)</span> elde edecektim, ve
bununla hiçbir analiz yapılamazdı. Fakat özdeğer/vektör durumunda <span
class="math inline">\(S\Lambda S^{-1}\)</span> 99 kere kendi kendisini
iptal edecek ve geri kalan semboller üzerinden bir analiz
yapabileceğim.</p>
<p>Özvektör/değer ile analiz edilebilecek ilginç bir diğer soru: bir
matrisin kendisiyle çarpımı ne zaman sıfıra gider? Yani stabilite sorusu
ile ilgileniyorum,</p>
<p>Teori</p>
<p><span class="math display">\[
A^k \to 0 \textrm{ , ki } k \to \infty  
\qquad (1)
\]</span></p>
<p>Ne zaman bu doğru olur? <span class="math inline">\(A\)</span>
matrisinin içinde bir yerlerde bu bilgi var. Bu bilgi matrisin
pivotlarından değil, onun özdeğerlerinde. <span
class="math inline">\(A\)</span>’nin ardı ardında çarpımını alırken bu
çarpımın küçülmesi ne demektir o zaman bunu cevaplayalım, özdeğer/vektör
formülüne bakarsak, <span class="math inline">\(S,S^{-1}\)</span>
oldukları gibi kaldıklarına göre tek değişecek olan <span
class="math inline">\(\Lambda^k\)</span> ve bu değer sürekli küçülmeli.
Bu ne demektir? Tüm özdeğerlerin 1’den küçük olması demektir. Tabii
özdeğerler eksi değerli olabilir, ya da karmaşık (complex) sayı
olabilirler, o yüzden özdeğerin salt değerini (absolute value)
kullanacağım, yani <span class="math inline">\(|\lambda_i| &lt;
1\)</span> ise diyeceğim.</p>
<p>Tabii bunları söylerken hep aklımın bir tarafında başta yaptığım
varsayım var, ki bu varsayım elimde <span
class="math inline">\(n\)</span> tane bağımsız özvektör olduğu. Eğer bu
yok ise üstteki yaklaşım kullanılamaz. Yani bu bağımsız özvektörler yok
ise <span class="math inline">\(A\)</span>’yi köşegenleştiremeyiz, çünkü
<span class="math inline">\(A^{-1}\)</span> hesaplanamaz.</p>
<p>Peki hangi matrisler kesinlikle köşegenleştirilebilir [hoca bu uzun
kelime için özür diliyorum dedi, İngilizcesi de uzun, diagonalizable].
Güzel durum tüm <span class="math inline">\(\lambda\)</span>’ların
farklı olduğu durum, ki bu durumda tekrar eden özvektör yoktur. Mesela
Python ile bir rasgele matris yaratsam, ve onların özdeğerlerine baksam,
bu değerlerin ayrı / farklı (distinct) olduklarını görürdüm. Bu teorinin
ispatı için [1, sf 300].</p>
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy.linalg <span class="im">as</span> lin</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>A <span class="op">=</span> np.random.randn(<span class="dv">10</span>,<span class="dv">10</span>)</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>evals,evecs <span class="op">=</span> lin.eig(A)</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> evals</span></code></pre></div>
<pre><code>[ 4.67859706+0.j         -2.11268898+3.12677439j -2.11268898-3.12677439j
 -2.25765724+0.j         -0.75108024+1.40493786j -0.75108024-1.40493786j
  0.26116597+1.43164683j  0.26116597-1.43164683j  0.28743712+0.j
  0.53952583+0.j        ]</code></pre>
<p>Üstteki durum için yani 10 tane ayrı özvektör olacaktır. Eğer tekrar
eden <span class="math inline">\(\lambda\)</span>’lar görseydim o zaman
matrise daha yakından bakardım, bu durumda da bağımsız özvektörler
olabilir, ama bu garanti değildir. Mesela (10,10) birim matris üzerinde
özdeğer/vektör hesabı yapsam tüm özdeğerler 1 olurdu, ama elimde bol bol
bağımsız özvektörler de olurdu (değişik hücresinde 1 taşıyan tüm
vektörler).</p>
<div class="sourceCode" id="cb3"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy.linalg <span class="im">as</span> lin</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>A <span class="op">=</span> np.eye(<span class="dv">10</span>,<span class="dv">10</span>)</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>evals,evecs <span class="op">=</span> lin.eig(A)</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> <span class="st">&#39;ozdegerler&#39;</span>, evals</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> <span class="st">&#39;ozvektor 1&#39;</span>, evecs[<span class="dv">0</span>]</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> <span class="st">&#39;ozvektor 2&#39;</span>, evecs[<span class="dv">1</span>]</span></code></pre></div>
<pre><code>ozdegerler [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]
ozvektor 1 [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]
ozvektor 2 [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]</code></pre>
<p>Sadece iki özvektör gösterdik, ama 10’u da bağımsız. Cebirsel olarak
ta bu sonuca erişebiliriz, eğer <span class="math inline">\(A\)</span>
birim matris ise, <span class="math inline">\(S^{-1}AS = I =
\Lambda\)</span> olur değil mi? <span
class="math inline">\(\Lambda\)</span>’nin köşegeninde tamamen bir
değerleri var, ki bunlar özdeğerler.</p>
<p>Peki üçgensel durumda?</p>
<p><span class="math display">\[ A = \left[\begin{array}{rr}
2 &amp;  1 \\ 0 &amp; 2
\end{array}\right] \]</span></p>
<p>Bu durum problemli. Özdeğerler nedir? Determinant ile</p>
<p><span class="math display">\[ \det (A-\lambda I) =
\left[\begin{array}{rr}
2-\lambda &amp;  1 \\ 0 &amp; 2-\lambda
\end{array}\right]
\]</span></p>
<p>Determinantı hesaplarız, buradan bir formül çıkar,</p>
<p><span class="math display">\[ (2-\lambda)^2 = 0 \]</span></p>
<p>O zaman <span class="math inline">\(\lambda=2,2\)</span>. Sonraki
adım özvektörler.</p>
<p><span class="math display">\[ A-2I =
\left[\begin{array}{rr}
0 &amp;  1 \\ 0 &amp; 0
\end{array}\right]
\]</span></p>
<p>ve burada sıfır uzayına bakıyorum, çünkü özvektörler <span
class="math inline">\(A-\lambda I\)</span>’in sıfır uzayında. Fakat
üstteki matrisin sıfır uzayı tek boyutlu. İşte bu durum elde yeterli
özdeğer olmadığı durum. Sebep polinomdaki çarpımın tekrarlanmış olması,
<span class="math inline">\(2-\lambda\)</span> kendisi ile çarpıldı bu
sebeple aynı <span class="math inline">\(\lambda\)</span>’yi iki kere
elde ettik. Sıfır uzayında sadece<span
class="math inline">\(\left[\begin{array}{cc} 1 &amp; 0
\end{array}\right]^T\)</span> var. Elimizdeki tek özvektör bu.</p>
<p>Şimdi (1)’i tekrar düşünelim, üstteki durum (1) teorisinin kapsamına
girmiyor çünkü bu durum tekrar eden özdeğer durumunu hesaba katmıyor,
(1) için birbirinden bağımsız <span class="math inline">\(n\)</span>
özvektör lazım, ki <span class="math inline">\(S^{-1}\)</span>
hesaplanabilsin. Yani bazı matrisler için köşegenleştirme mümkün
olmuyor, ama çoğunluğu için bu mümkün tabii.</p>
<p>Kaynaklar</p>
<p>[1] Strang, <em>Introduction to Linear Algebra</em>, 4th Edition</p>
<p>
  <a href="..">Yukarı</a>
</p>
</body>
</html>
