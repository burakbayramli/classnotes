\documentclass[12pt,fleqn]{article}\usepackage{../../common}
\begin{document}
Ders 22

Bu ders özdeðerler hakkýndaki 2. dersimiz. Ýlk derste y$Ax = \lambda x$
formülüne eriþtik, $x$ özvektör ve $\lambda$ özdeðer, ve bu deðerleri
hesaplayabilmeyi öðrendik. Þimdi onlarý kullanmayý göreceðiz. Bu kullanýmý
görmenin iyi yollarýndan birisi, bir matrisi ``köþegenleþtirmek
(diagonalization)'', ki bu formül $S^{-1}AS =\Lambda$ olarak gösterilir,
çok temel bir formüldür bu ve bugünkü dersin merkez noktasý.

$A$'nin özvektörleri $S$'in kolonlarýný oluþturacak, ve bu $S$'i içeren
$S^{-1}AS$ sihirli formülüne bakacaðýz, burada neler oluyor? Ortada bir
tersi alma iþlemi var, $S^{-1}$ ile, demek ki özvektör matrisi $S$'in tersi
alýnabilir olmasý lazým, o zaman bize $n$ tane baðýmsýz özvektör lazým [ki
onlarý içeren matris tersi alýnabilir olsun].

Þu matris çarpýmýný düþünelim þimdi, 

$$ 
AS =  
A \left[\begin{array}{rrrr}
\uparrow & \uparrow & & \uparrow \\
x_1 & x_2 & \cdots & x_n \\
\downarrow & \downarrow & & \downarrow
\end{array}\right]
$$

Bu çarpýmý her $S$ kolonu için ayrý ayrý yaptýðýmý düþünebilirim, her
kolonun $A$'yi çarpmasý ayrý bir kolon sonucunu verirdi. Bu sonuçlar ne
olurdu? Mesela $Ax_1$'i düþünelim, $x_1$ bir özvektör olduðuna göre (çünkü
$S$'i özvektörler ile oluþturmuþtuk) o zaman özdeðer/vektör $Ax = \lambda x$ 
formülüne göre $Ax_1 = \lambda_1 x_1$ elde ederdik, ki $\lambda_1$
1. özdeðer olurdu, ardýndan, 2., 3., vs. özvektörler için bu ayný 
þekilde devam ederdi, ve buna göre,

$$ 
= \left[\begin{array}{rrr}
& &  \\
\lambda_1x_1 & \cdots & \lambda_nx_n \\ 
& & 
\end{array}\right]
 $$

elde ederdik. Güzel duruyor. Daha da güzel olabilir! Bir sonraki adýmda üstteki
kolonlardaki özdeðerleri dýþarý çýkartmak istiyorum, 

$$ 
= \left[\begin{array}{rrr}
& &  \\
x_1 & \cdots & x_n \\ 
& & 
\end{array}\right]
\left[\begin{array}{rrr}
\lambda_1 & &  \\
& \ddots & \\
& & \lambda_n
\end{array}\right]
 $$

Ýçinde $\lambda$'lar olan matriste köþegen haricindeki tüm diðer hücreler
sýfýr deðerini taþýyor. Bu çarpým bize istediðimiz sonucu verecek, hem de
gayet temiz matris formlarý kullanarak. Lineer Cebir ne güzel iþliyor! 

Ve nihayetinde üstteki çarpýmý $S\Lambda$ olarak gösterebilirim; Büyük
$\lambda$, yani $\Lambda$ iþaretini ``içinde özdeðerler taþýyan matris''
olarak belirttim böylece. Nihai formül $AS = S\Lambda$. Ardýndan bu
eþitliðin iki tarafýný soldan $S^{-1}$ ile çarparak

$$ S^{-1}AS = \Lambda $$

diyebilirim. Tabii tekrar edelim, üstteki form sadece ve sadece $S$ içinde
birbirinden baðýmsýz özvektörler var ise mümkündür. Bu olmayabilirdi, az
miktarda matrisler için bu durum geçerlidir, belki bir özvektör kendini
tekrar edebilirdi, bu durumda üstteki formu kullanamazdým. Fakat
göreceðimiz çoðu matrisin $n$ tane baðýmsýz özvektörü vardýr, ve onlarý
köþegenleþtirebiliriz (yani üstteki çarpým sonucu saðýnda $\Lambda$ olan
forma eriþebiliriz).

Bu arada $AS=S\Lambda$'yi saðdan da $S^{-1}$ ile çarpabilirdim, o zaman 

$$AS=S\Lambda $$

ifadesi

$$ A = S \Lambda S^{-1} $$

haline gelir. Hatýrlamak baðlamýnda, mesela iki üstteki formül için,
$A$'nin özvektörlerini çarptýðýný düþünebilirim, yani $Ax$ formu, ama bu
sefer tüm özvektörler $x$ yerine $S$ var, ve ardýndan, üç üstteki formülde,
sonucu $S^{-1}$ ile çarpýyorum ve $AS$'i köþegen haline getirmiþ
oluyorum. Bir üstteki formül ise bu nihai sonucu ifade etmenin deðiþik bir
yolundan ibaret, $S$'leri karþý tarafa geçiriyoruz ve üstteki ifadeyi elde
ediyoruz.

Üstte son ifade yeni bir ayrýþtýrma (factorýzation) olarak ta
görülebilir.. Eliminasyondaki $LU$'nun, ya da Gram-Schmidt'ten $QR$'in
yerine geçebilecek bir tür ayrýþtýrma yani. Form nedir? $S$ çarpý köþegen
matris çarpý $S$'in tersi. Bu kombinasyonu bu bölümde bol bol göreceðiz, ki
bu kombinasyonda $S$ ve onun tersi $S^{-1}$'in rol oynayacak.

Þimdi öðrendiklerimizi kullanmak istiyorum. Mesela $A^2$'i hesaplamak
istiyorum. $A^2$'in özdeðer/vektörlerine ne olur? Bu son derece temel bir
soru. Alttaki formül ile baþlangýç yapacaðým, eðer böyle bir formül ortaya
konabiliyorsa tabii, 

$$ Ax = \lambda x $$

Buradan $A^2$'e ulaþmaya çalýþacaðým. Üstteki formülün iki tarafýný $A$ ile
çarpayým þimdi, böylece sol tarafta $A^2$ elde ederim,

$$ AAx = A\lambda x $$

$$ A^2x = \lambda A x $$

Eðer $Ax$ yerine $\lambda x$ kullanýrsam, çünkü bu özvektör denkleminden geliyor,

$$ A^2x = \lambda^2 x $$

Bu basit hesap arkasýndan sonuca bakýnca þu yorumu yapabiliyorum; $A^2$'nin
özdeðerleri $\lambda^2$'dir. Peki özvektörler? Özvektörler $A$'nin
özvektörleri ile aynýdýr, çünkü $x$ deðeri deðiþmeden kaldý. Bunu
$A=SAS^{-1}$'i kullanarak görebilir miyiz?

$$ A^2=S\Lambda S^{-1}S\Lambda S^{-1} $$

$$ =S \Lambda \cancel{S^{-1}S} \Lambda S^{-1} $$

$$ =S \Lambda \Lambda S^{-1} $$

$$ =S \Lambda^2S^{-1} $$

Bu bana ne söylüyor? Bir önceki metot ile ayný þeyi söylüyor, özdeðerlerin
karesi elde edilir ama özvektörler deðiþmez, bunu biliyouruz çünkü yine
ayný $S$ matrisini bildiðimiz bir formda elde ettik.

Peki $k$ defa üst alma operasyonu yapsaydým, yani $A^k$ hesaplasaydým ne
olurdu? Bu durumda en son metotta $S^{-1}S$'larýn $k$ çarpým içinde sürekli
yanyana geleceðini görebiliriz herhalde, ve tabii ki tüm bu yanyana gelen
$S^{-1}S$'ler birbirini iptal edecektir. Diðer yandan $\Lambda$ matrisi
$k$ defa kendisi ile çarpýlacaktýr, yani

$$ A^k = S\Lambda^k S^{-1} $$

Bu gayet temiz bir sonuç; demek ki özdeðerler/vektörler matrislerin kendisi
ile çarpýlmýþ halini anlamak için biçilmiþ kaftan. Kýyasla matris katlarý
alýnýrken, mesela pivotlar oradan oraya savrulurlar, doðru dürüst analiz
edilemezler. Eðer $A=LU$ kullansaydým mesela $LU$ çarpý $LU$ çarpý $LU$
böyle gidecekti, 100 defa ardýndan $(LU)^{100}$ elde edecektim, ve bununla
hiçbir analiz yapýlamazdý. Fakat özdeðer/vektör durumunda $S\Lambda S^{-1}$
99 kere kendi kendisini iptal edecek ve geri kalan semboller üzerinden bir
analiz yapabileceðim.

Özvektör/deðer ile analiz edilebilecek ilginç bir diðer soru: bir matrisin
kendisiyle çarpýmý ne zaman sýfýra gider? Yani stabilite sorusu ile
ilgileniyorum, 

Teori

$
A^k \to 0 \textrm{ , ki } k \to \infty  
\mlabel{1}
$ 

Ne zaman bu doðru olur? $A$ matrisinin içinde bir yerlerde bu bilgi var. Bu
bilgi matrisin pivotlarýndan deðil, onun özdeðerlerinde. $A$'nin ardý
ardýnda çarpýmýný alýrken bu çarpýmýn küçülmesi ne demektir o zaman bunu
cevaplayalým, özdeðer/vektör formülüne bakarsak, $S,S^{-1}$ olduklarý gibi
kaldýklarýna göre tek deðiþecek olan $\Lambda^k$ ve bu deðer sürekli
küçülmeli. Bu ne demektir? Tüm özdeðerlerin 1'den küçük olmasý
demektir. Tabii özdeðerler eksi deðerli olabilir, ya da karmaþýk (complex)
sayý olabilirler, o yüzden özdeðerin salt deðerini (absolute value)
kullanacaðým, yani $|\lambda_i| < 1$ iþe diyeceðim. 

Tabii bunlarý söylerken hep aklýmýn bir tarafýnda baþta yaptýðým varsayým
var, ki bu varsayým elimde $n$ tane baðýmsýz özvektör olduðu. Eðer bu yok
ise üstteki yaklaþým kullanýlamaz. Yani bu baðýmsýz özvektörler yok ise
$A$'yi köþegenleþtiremeyiz, çünkü $A^{-1}$ hesaplanamaz.

Peki hangi matrisler kesinlikle köþegenleþtirilebilir [hoca bu uzun kelime
için özür diliyorum dedi, Ýngilizcesi de uzun, diagonalizable]. Güzel durum
tüm $\lambda$'larýn farklý olduðu durum, ki bu durumda tekrar eden özvektör
yoktur. Mesela Python ile bir rasgele matris yaratsam, ve onlarýn
özdeðerlerine baksam, bu deðerlerin ayrý / farklý (dýþtýnct) olduklarýný
görürdüm. Bu teorinin ispatý için [1, sf 300]. 

\begin{minted}[fontsize=\footnotesize]{python}
import numpy.linalg as lin
A = np.random.randn(10,10)
evals,evecs = lin.eig(A)
print evals
\end{minted}

\begin{verbatim}
[ 4.67859706+0.j         -2.11268898+3.12677439j -2.11268898-3.12677439j
 -2.25765724+0.j         -0.75108024+1.40493786j -0.75108024-1.40493786j
  0.26116597+1.43164683j  0.26116597-1.43164683j  0.28743712+0.j
  0.53952583+0.j        ]
\end{verbatim}

Üstteki durum için yani 10 tane ayrý özvektör olacaktýr. Eðer tekrar eden
$\lambda$'lar görseydim o zaman matrise daha yakýndan bakardým, bu durumda
da baðýmsýz özvektörler olabilir, ama bu garanti deðildir. Mesela (10,10)
birim matris üzerinde özdeðer/vektör hesabý yapsam tüm özdeðerler 1 olurdu,
ama elimde bol bol baðýmsýz özvektörler de olurdu (deðiþik hücresinde 1
taþýyan tüm vektörler).

\begin{minted}[fontsize=\footnotesize]{python}
import numpy.linalg as lin
A = np.eye(10,10)
evals,evecs = lin.eig(A)
print 'ozdegerler', evals
print 'ozvektor 1', evecs[0]
print 'ozvektor 2', evecs[1]
\end{minted}

\begin{verbatim}
ozdegerler [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]
ozvektor 1 [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]
ozvektor 2 [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]
\end{verbatim}

Sadece iki özvektör gösterdik, ama 10'u da baðýmsýz. Cebirsel olarak ta bu
sonuca eriþebiliriz, eðer $A$ birim matris ise, $ S^{-1}AS = I = \Lambda $
olur deðil mi? $\Lambda$'nin köþegeninde tamamen bir deðerleri var, ki
bunlar özdeðerler. 

Peki üçgensel durumda? 

$$ A = \left[\begin{array}{rr}
2 &  1 \\ 0 & 2
\end{array}\right] $$

Bu durum problemli. Özdeðerler nedir? Determinant ile

$$ \det (A-\lambda I) = 
 \left[\begin{array}{rr}
2-\lambda &  1 \\ 0 & 2-\lambda
\end{array}\right]
$$

Determinantý hesaplarýz, buradan bir formül çýkar, 

$$ (2-\lambda)^2 = 0 $$

O zaman $\lambda=2,2$. Sonraki adým özvektörler.

$$ A-2I = 
\left[\begin{array}{rr}
0 &  1 \\ 0 & 0
\end{array}\right]
$$

ve burada sýfýr uzayýna bakýyorum, çünkü özvektörler $A-\lambda I$'in sýfýr
uzayýnda. Fakat üstteki matrisin sýfýr uzayý tek boyutlu. Ýþte bu durum
elde yeterli özdeðer olmadýðý durum. Sebep polinomdaki çarpýmýn
tekrarlanmýþ olmasý, $2-\lambda$ kendisi ile çarpýldý bu sebeple ayný
$\lambda$'yi iki kere elde ettik. Sýfýr uzayýnda sadece$\left[\begin{array}{cc} 1 & 0 \end{array}\right]^T$ var. Elimizdeki 
tek özvektör bu. 

Þimdi (1)'i tekrar düþünelim, üstteki durum (1) teorisinin kapsamýna
girmiyor çünkü bu durum tekrar eden özdeðer durumunu hesaba katmýyor, (1)
için birbirinden baðýmsýz $n$ özvektör lazým, ki $S^{-1}$
hesaplanabilsin. Yani bazý matrisler için köþegenleþtirme mümkün olmuyor,
ama çoðunluðu için bu mümkün tabii.


Kaynaklar 

[1] Strang, {\em Introduction to Linear Algebra}, 4th Edition



\end{document}




