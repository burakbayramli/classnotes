\documentclass[12pt,fleqn]{article}\usepackage{../../common}
\begin{document}
Google Nasýl Ýþler? 

Lineer Cebir hocalarý Google'a müteþekkir olmalý, çünkü bu ünlü arama
motorunun kullandýðý PageRank tekniðinin özü aslýnda lineer cebirin
temelini oluþturan kavramlardan özdeðer / özvektör hesabý. Öðrenciler
``niye bu kavramlarý öðreniyoruz hocam?''  diye sorunca artýk cevap
kolay: ``bu yöntemi Google da kullanýyor!''.

Þimdi arama motorunun yapmasý gerekenleri düþünelim: Google'a bir kelime
yazdýðýmýzda geri gelen sonuçlar nasýl kararlaþtýrýlýr? Ýlk akla gelen
yöntem tabii ki Web'deki tüm sayfalarýn (milyarlarca sayfa) sayfalar
üzerindeki kelimelerin o sayfa ile iliþkilendirilmesi ve arama yapýlýnca
kelimeye göre sayfa geri getirilmesi. Mesela alttaki örnekte ``book
(kitap)'' yazýnca geriye 1., 2. ve 5. sayfalar geri gelecek. Fakat hangi
sýrada? Bu sayfalardan hangisi diðerlerinden daha önemli?

\includegraphics[height=9cm]{pg2.png}

PageRank'in temelinde daha fazla referans edilen sayfalarýn daha üstte
çýkmasý yatar. Hatta o referans eden sayfalarýn kendilerine daha fazla
referans var ise bu etki ta en sondaki sayfaya kadar yansýtýlýr, hatta bu
zincir baþtan sona her seviyede hesaplanabilir. Peki bu nasýl
gerçekleþtirilir?

PageRank Web sayfalarýný bir Markov Zinciri olarak görür. Markov Zincirleri
seri halindeki $X_n, n=0,1,2,..$ rasgele deðiþkenini modeller ve bu
deðiþkenler belli sayýdaki konumlarýn birinde olabilirler. Mesela konumlarý
bir doðal sayý ile ilintilendirirsek $X_n = i$ olabilir ki $i=\{0,1,..\}$
diye kabul edelim.

Markov Zincirlerinde (MZ) $i$ konumundan $j$ konumuna geçiþ olasýlýðýný,
$P_{ij}$, biliriz ve bu $P(X_{n+1} = j | X_{n} = i)$ olarak açýlabilir. Açýlýmdan  
görüleceði üzere bir MZ sonraki adýma geçiþ olasýlýðý için sadece
bir önceki adýma bakar. Bu tür önce/sonra yapýsýndaki iki boyutlu hal, 
çok rahat bir þekilde matrisine çevirilebilir / gösterilebilir. Önceki konum 
satýrlar, sonraki konum kolonlar olarak betimlenir mesela. 

Örnek

Bir sonraki günde yaðmur yaðmayacaðýný bir MZ olarak tasarlayalým. Bir
sonraki günde yaðmur yaðmayacaðýný sadece bugün etkiliyor olsun. Eðer bugün
yaðmur yaðýyorsa yarýn yaðmur yaðmasý 0.7, eðer bugün yaðmýyor ise yarýn
yaðmasý 0.4. MZ þöyle

$$ 
P =
\left[\begin{array}{cc}
0.7 & 0.3 \\
0.4 & 0.6
\end{array}\right]
 $$

Geçiþ olasýlýklarýndan bahsettiðimize göre ve elimizde sýnýrlý / belli
sayýda konum var ise, bir MZ'nin her satýrýndaki olasýlýklarýn toplamý
tabii ki 1'e eþit olmalýdýr. 

MZ'lerin ilginç bir özelliði $n$ adým sonra $i,j$ geçiþinin $P^n$ hesabýyla
yapýlabilmesidir. Yani $P$'yi $n$ defa kendisiyle çarpýp $i,j$ kordinatýna 
bakarsak $n$ adým sonrasýný rahatça görebiliriz. Bunun ispatýný burada
vermeyeceðiz. 

Mesela üstteki örnekte, eðer bugün yaðmur yaðýyorsa 4 gün sonra yaðmur
yaðma olasýlýðý nedir? 

\begin{minted}[fontsize=\footnotesize]{python}
import numpy.linalg as lin
P = np.array([[0.7,0.3],[0.4,0.6]])
P4 = lin.matrix_power(P,4)
print P4
\end{minted}

\begin{verbatim}
[[ 0.5749  0.4251]
 [ 0.5668  0.4332]]
\end{verbatim}

Aradýðýmýz geçiþ için kordinat 0,0'a bakýyoruz ve sonuç 0.5749. Numpy
\verb!matrix_power! bir matrisi istediðimiz kadar kendisiyle çarpmamýzý
saðlýyor. 

Duraðan Daðýlým (Stationary Distribution)

Eðer yaðmur örneðindeki matrisi çarpmaya devam edersek, mesela 8 kere
kendisiyle çarpsak sonuç ne olurdu? 

\begin{minted}[fontsize=\footnotesize]{python}
import numpy.linalg as lin
P = np.array([[0.7,0.3],[0.4,0.6]])
P8 = lin.matrix_power(P,8)
print P8
\end{minted}

\begin{verbatim}
[[ 0.57145669  0.42854331]
 [ 0.57139108  0.42860892]]
\end{verbatim}

Dikkat edilirse, her satýr bir deðere yaklaþmaya baþladý. Bu deðer MZ'nin
duraðan daðýlýmýdýr, belli koþullara uyan her MZ'nin böyle bir duraðan
daðýlýmý vardýr. Bu koþullar MZ'nin periyodik olmayan (aperiodic) ve tekrar
eden (recurrent) olmasýdýr. Bu þartlar çok ``özel'' þartlar deðildir
aslýnda, daha çok ``normal'' bir MZ'yi tarif ediyor diyebiliriz. Tüm
konumlarý tekrar eden yapmak kolaydýr, MZ tek baðlý (singly connected) hale
getirilir, yani her konumdan her diðer konuma bir geçiþ olur, ve periyodik
olmamasý için ise MZ'ye olmadýðý zamanlarda bir konumdan kendisine geçiþ
saðlanýr (az bir gürültü üzerinden). 

Nihayet duraðanlýk þu denklemi ortaya çýkartýr,

$$ \pi = \pi P $$

Burada duraðan daðýlým $\pi$'dir. Bu denklem tanýdýk geliyor mu?  Devriðini
alarak þöyle gösterelim, belki daha iyi tanýnýr, 

$$ P^T\pi^T = \pi^T $$

Bir þey daha ekleyelim, 

$$ P^T\pi^T = 1 \cdot \pi^T $$

Bu özdeðer/vektör formuna benzemiyor mu? Evet! Bu form 

$$ Ax = \lambda x $$

MZ denklemi þunu söylüyor, 1 deðerindeki özdeðere ait özvektör bir MZ'nin
duraðan daðýlýmýdýr! Bu arada, MZ geçiþ matrisi $P$'nin en büyük
özdeðerinin her zaman 1 olduðunu biliyoruz (çünkü üstteki tarif ettiðimiz
özel þartlara sahip olan türden matrisler böyle özdeðerlere sahip
olmalý). Bu durumda en büyük özdeðere ait özvektörü hesaplamak yeterli
olacaktýr. Bunu yapmayý zaten {\em Lineer Cebir Ders 21}'de öðrenmiþtik,
üst metot (power method) sayesinde bu hesap kolayca yapýlabiliyor.

Þimdi en baþtaki Web sayfalarýna ait geçiþleri yazalým,

\begin{minted}[fontsize=\footnotesize]{python}
P = [[1./4, 2./4, 0, 0, 1./4],
     [1./6, 0, 2./6, 1./6, 2./6],
     [0, 0, 0, 2./4, 2./4],
     [1./8, 0, 0, 4./8, 3./8],
     [0, 1./2, 0, 1./2, 0]]

P = np.array(P)
print P
\end{minted}

\begin{verbatim}
[[ 0.25        0.5         0.          0.          0.25      ]
 [ 0.16666667  0.          0.33333333  0.16666667  0.33333333]
 [ 0.          0.          0.          0.5         0.5       ]
 [ 0.125       0.          0.          0.5         0.375     ]
 [ 0.          0.5         0.          0.5         0.        ]]
\end{verbatim}

Þimdi üst metotu kullanarak duraðan daðýlýmý hesaplayalým. Herhangi bir
baþlangýç vektörünü $P$ ile 20 kere  çarpmak yeterli olur.

\begin{minted}[fontsize=\footnotesize]{python}
import numpy.linalg as lin
x=np.array([.5, .3, .1, .1, 0]) # herhangi bir vektor
for i in range(20): 
    x = np.dot(x,P)
print 'pi = ', x
\end{minted}

\begin{verbatim}
pi =  [ 0.10526316  0.18421053  0.06140351  0.38596491  0.2631579 ]
\end{verbatim}

Not: Aslýnda cebirsel olarak $P$'yi 20 kere kendisiyle çarpmak ve sonucu
baþlangýç vektörü ile bir kere çarpmak ta düþünülebilirdi. Fakat 20 kere
vektör / matris çarpýmlarý yapmak, 20 kere matris / matris çarpýmý
yapmaktan daha verimli olacaktýr. Büyük Veri ortamý için de bu söylenebilir.

Neyse, eðer özvektör hesabýný kendimiz elle yapmak yerine direk kütüphane
çaðrýsý kullansaydýk,

\begin{minted}[fontsize=\footnotesize]{python}
import numpy.linalg as lin
evals,evec = lin.eig(P.T)
pi =  evec[:,0] / np.sum(evec[:,0])
print np.abs(pi)
\end{minted}

\begin{verbatim}
[ 0.10526316  0.18421053  0.06140351  0.38596491  0.26315789]
\end{verbatim}

Ayný sonuca ulaþtýk. Bu sonuç gösteriyor ki ``book'' yazdýðýzda Google bize
5. sayfayý en baþta olacak þekilde sonuç döndürmeli, çünkü onun duraðan
daðýlýmý 1,2,5 sayfalarýnýn arasýnda en yüksek.

Duraðan Daðýlýma Bakýþ

MZ ve duraðan daðýlýmýn PageRank'le alakasýný bir daha düþünelim. MZ ile
$n$ adým sonrasýný hesaplayabiliyoruz, duraðan daðýlým ise sonsuz adým
sonrasýný ifade ediyor. Ve bu daðýlým, bir anlamda, sonsuz yapýlan adýmlar
sýrasýnda {\em en fazla hangi konumlarda} zaman geçirileceðini
gösteriyor. Konum yerine sayfa dersek duraðan daðýlýmýn niye en önemli
sayfalarý belirlemek için önemli olduðunu anlarýz. 

Kullanýcý herhangi bir sayfada iken hangi diðer sayfalara gideceði o sayfa
üzerinde baðlantýlar üzerinden anlaþýlýr, PageRank bu baðlantýnýn
mevcudiyetine bakar sadece, o mevcudiyet üzerinden bir geçiþ olasýlýðý
hesaplar, ve bu olasýlýða göre (raslantýsal þekilde) baðlantýnýn takip
edileceði düþünülür. Bu arada çoðunlukla sayfalar arasýndaki baðlantýlarýn
aðýrlýðý 1 olacaktýr, fakat örnek amaçlý 2,3 gibi sayýlar da kullanýlýyor. 

Rasgele Sayfa Geçiþi

Google veri temsili üzerinde bazý ekler yapmaktadýr, mesela kullanýcýnýn
hiçbir baðlantý takip etmeyip tarayýcýya direk URL girerek baþka bir
sayfaya zýplamasý (teleporting) bir þekilde temsil edilmelidir. Ayrýca hiç
dýþa baðlantý vermeyen sayfalar (ölü noktalar) hesaba katýlmalýdýr. Þimdi
$\pi^T$ yerine $p$, $P$ yerine $N$ kullanalým, PageRank özyineli
algoritmasý

$$ p = N^Tp $$ 

olarak gösterilebilir. 

Bu her iki durum için formül þu þekilde ikiye ayýrýlýr,

$$ p = (1-d)N^Tp + dN_f^Tp $$

$$ = ((1-d)N^T + dN_f^T) p $$

$$ = M^Tp $$

ki,

$$M = (1-d)N^T + dN_f^T$$ 

olacaktýr. $N_f$ bir normalize edilmiþ ``zýplama'' matrisidir, yani her
sayfadan her diðer sayfaya bir baðlantý ``varmýþ gibi'' yapar, mesela 5x5
boyutunda tüm öðeleri 0.20 olacaktýr. $d$ bir aðýrlýk sabitidir, Google'ýn
bunu 0.85 olarak tanýmladýðý duyulmuþtur, ve gerçek baðlantý matrisi ve
rasgele zýplama matrisi arasýnda bir aðýrlýk tanýmlar, her ikisinde de
birazcýk alarak (daha çok ana $N$'den tabii) niahi matrisi oluþturur. Örnek
olarak þu grafiðe bakalým, 

\includegraphics[height=4cm]{pg3.png}

\begin{minted}[fontsize=\footnotesize]{python}
N = [[0, 0, 0, 1., 0],
     [0, 0, 1./2, 0, 1./2],
     [1, 0, 0, 0, 0],
     [0, 1./3, 1./3, 0, 1./3],
     [0, 1, 0, 0, 0]]

N = np.array(N)

Nf = 0.20 * np.ones((5,5))
d = 0.85
M = d*N + (1-d)*Nf
x=np.array([.5, .3, .1, .1, 0]) # herhangi bir vektor
for i in range(20): 
    x = np.dot(x,M)
print 'result = ', x 
\end{minted}

\begin{verbatim}
result =  [ 0.18959094  0.24375097  0.18775335  0.19115138  0.18775335]
\end{verbatim}

Sonuca göre $v_2$ en yüksek PageRank deðerine sahip. 

Mimari

Google tabii ki arama sonuçlarýný iyileþtirmek için yýllar içinde diðer ek
fonksiyonlarý motoruna ekledi. Duyumlarýmýza göre artýk PageRank gibi
onlarca ek kriter kullanýlmaktadýr; fakat PageRank hala çok önemli ve
þirketin kuruluþu baðlamýnda Google'ý Google yapan algoritmaydý, onun diðer
motorlara nazaran elindeki avantajý, en büyük ilerlemesiydi.

Sistem kodlamasý açýsýndan PageRank'e tüm Web sayfalarý ve onlarýn
arasýndaki iliþkiler verilmelidir, bu milyarlarca sayfa ve onlarýn
arasýndaki baðlantýlar demektir. Google bunu yapabilmek için Web ``aðýný''
örümcek (spider) programlarý ile sürekli geziyor, ve bu veriyi alýp,
PageRank'e hesap için aktarýyor.

Ülkelerin Ekonomik Kapasiteleri

Ekonomide her ürünün bir karmaþýklýðý var - bir cep telefonunu üretmek için
gereken bilgi düzeyi, koyun yünü üretmek için gereken bilgi düzeyinden daha
farklý.  Ýstatistiki fizik alanýndan ekonomiye geçiþ yapan araþtýrmacý
Hidalgo'ya göre ekonomiler için en önemli olan bilgi, yöntem bilgisi
(know-how), yani bilgiyi planlamaya, üretime yönelik kullanabilme yetisi ve
bu bilgilere sahip pek çok insanýn olduðu bir að. Mesela yazýlým alanýnda
Silikon Vadisi bu tür yoðun bir að. 

Peki ülkelerde bu aðlarýn kuvvetini nasýl ölçeriz?  Ürünlerin
karmaþýklýðýný kullanarak belki bunu yapabiliriz. Bir ülkenin ekonomisinin
onun ürettiði ürünleri ortalama karmaþýklýðýna oranlý olduðunu
düþünebiliriz, ters yöne de gidilebilir, bir ürünün karmaþýklýðý onu üreten
ülkelerin karmaþýklýðýna oranlýdýr. Fakat þimdi burada bir tavuk-yumurta
durumu var, ne ülke ne de ürün karmaþýklýðýný baþta biliyoruz. Bu problemi
nasýl çözeriz? Özdeðer ve özvektörler bu tür problemleri çözmek için
sürekli kullanýlýr.

Eðer bir ülke $i$ ürün $j$'yi üretiyor ise $m_{ij}=1$ olsun, üretmiyor ise
$m_{ij}=0$ olsun. Birazdan ortalama hesabý için gerekecek aðýrlýklarý
hesaplayalým [5] $v_{ij} = m_{ij} / d_i$, $w_{ij}=m_{ij}/u_j$. Burada $d$
kelimesi çeþitlilikten (diversification) geliyor, $u$ ise ürünün yaygýnlýðý
(ubiquity). Ülke $i$ ve ürün $j$ için bunlar $d_i = \sum_j m_{ij}$ ve
$u_j = \sum_i m_{ij}$.

O zaman ülke $i$'nin ekonomik karmaþýklýk / yetkinlik düzeyi $c_i$, ve ürün
$j$ karmaþýklýðý $p_j$ þöyle gösterilebilir,

$$
c_i = \alpha \sum_j v_{ij}p_j
$$

$$
p_j  = \beta \sum_i w_{ij} c_i
$$

ki $\alpha,\beta>0$. Tavuk-yumurta durumu artýk matematiksel olarak üstte
görülüyor. Þimdi $c$, $p$ deðiþkenlerini bir matris içine alalým,
$V=[v_{ij}]$ and $W=[w_{ij}]$. O zaman daha kýsaca $c = \alpha V p$ ve
$p = \beta W c$ diyebiliriz. 2. formülü 1. içine sokarsak
$c = \alpha \beta (V^T W) c $ olur, 1. formülü 2. içine sokarsak
$p = \alpha \beta (V W^T) p$. Bu demektir ki ülkelerin ve ürünlerin
çetrefilliði sýrasýyla $V^T W$'nin ve $V W^T$'nin özvektörü üzerinden
hesaplanabilir!

Not: hangi özvektör? [4]'e göre en büyük 1. özdeðere tekabül eden özvektör
kullanýþlý deðil, bu vektördeki aðýrlýklarýn hepsi eþit. Bu durumda
2. büyük özdeðerin özvektörü kullanýlýyor. 

Altta bu yaklaþýmý kullanan tüm ülkelerin 2014'te yaptýðý ihracat verisini
kullanan hesaplar bulunabilir, veri için [2]'yi temel aldýk, bizim
ek iþlemlerimiz sonrasý [3].

\begin{minted}[fontsize=\footnotesize]{python}
import pandas as pd, zipfile
with zipfile.ZipFile('/home/burak/Documents/Dropbox/Public/data/hidalgo.zip', 'r') as z:
      df =  pd.read_csv(z.open('hidalgo.csv'),sep='\t')
      gdp =  pd.read_csv(z.open('gdp1416.csv'),sep=',',index_col=0)
      hs =  pd.read_csv(z.open('hs.csv'),sep='|')
      hs2 =  pd.read_csv(z.open('hs2.csv'),sep=',',index_col='ProductCode_x')
\end{minted}

\begin{minted}[fontsize=\footnotesize]{python}
print len(df)
print df.tail(10)
\end{minted}

\begin{verbatim}
726013
        year origin    hs92  export_val  import_val  export_rca  import_rca
726003  2014    ven  961610     39395.0   2026297.0       0.011       0.947
726004  2014    ven  961620         NaN   1084958.0         NaN       2.413
726005  2014    ven  961700     29666.0   1701096.0       0.005       0.495
726006  2014    ven  961800      2066.0    113839.0       0.001       0.074
726007  2014    ven  970110    210867.0    385141.0       0.004       0.014
726008  2014    ven  970190    179993.0    118881.0       0.136       0.155
726009  2014    ven  970200    976805.0         NaN       0.563         NaN
726010  2014    ven  970300    717009.0    277338.0       0.068       0.045
726011  2014    ven  970500     12723.0         NaN       0.004         NaN
726012  2014    ven  970600         NaN      2484.0         NaN       0.000
\end{verbatim}

Ülkeler satýrlarda, ürünler kolonlarda olacak þekilde bir tablo oluþturalým,

\begin{minted}[fontsize=\footnotesize]{python}
cp = df.pivot_table('export_val', index='origin', columns='hs92')
print cp.shape
print len(np.unique(df.hs92)), 'urun'
\end{minted}

\begin{verbatim}
(220, 4858)
4858 urun
\end{verbatim}

\begin{minted}[fontsize=\footnotesize]{python}
cp2 = np.array(cp)
cp2[cp2 > 0.] = 1.0
cp2[cp2 != 1.0] = 0.0
cp3 = pd.DataFrame(cp2)
cp4 = cp3.apply(lambda x: x/cp3.sum(axis=1), axis=0)
cp4 = cp4.fillna(0)
cp5 = cp3.apply(lambda x: x/cp3.sum(axis=0), axis=1)
cp5 = cp5.fillna(0)
print cp4.shape, cp5.shape
\end{minted}

\begin{verbatim}
(220, 4858) (220, 4858)
\end{verbatim}

Özanaliz ile en ileri 10 ülkeye bakalým, ülkeler için hesaplanan vektöre
ECI adý veriliyor (economic complexity index -ekonomik çetrefillik
indisi-),

\begin{minted}[fontsize=\footnotesize]{python}
import scipy.linalg as lin
print cp4.shape
uc,vc = lin.eig(np.dot(cp4,cp5.T))
print vc.shape
eci = np.array(vc)[:,1]
print len(eci)
print np.argmax(eci)
top_countries = cp.index[np.argsort(eci)[-10:]]
print top_countries
\end{minted}

\begin{verbatim}
(220, 4858)
(220, 220)
220
38
Index([u'nld', u'jpn', u'blx', u'gbr', u'ita', u'esp', u'deu', u'fra', u'usa',
       u'chn'],
      dtype='object', name=u'origin')
\end{verbatim}

Þimdi ürünler, buna PCI deniyor (product complexity index -ürün çetrefillik
indisi-). En çetrefil 10 ürün (en saðdaki en yüksek olacak þekilde),

\begin{minted}[fontsize=\footnotesize]{python}
import scipy.sparse.linalg as lin
import scipy.sparse as sps

scp4 = sps.lil_matrix(cp4)
scp5 = sps.lil_matrix(cp5)

A = scp4.T.dot(scp5)
print A.shape
up,vp = lin.eigs(A,k=2)
print vp.shape
pci = np.array(vp)[:,1]
print len(pci)
print np.argmax(pci)
print np.argsort(pci)[-10:]
top_prods = cp.columns[np.argsort(pci)[-10:]]
print top_prods
\end{minted}

\begin{verbatim}
(4858, 4858)
(4858, 2)
4858
3206
[1441 2163 3119 3192 3172 1109  971 1083 3391 3206]
Int64Index([350290, 521129, 721141, 722692, 722012, 291430, 284160, 290960,
            750522, 722920],
           dtype='int64', name=u'hs92')
\end{verbatim}

Bu ürünler hangileri?

\begin{minted}[fontsize=\footnotesize]{python}
pd.set_option('expand_frame_repr', False)
top_prods2 = [str(x) for x in list(top_prods)]
print hs2.ix[top_prods2][['Product Description_y','Product Description_x']]
\end{minted}

\begin{verbatim}
                                           Product Description_y                              Product Description_x
ProductCode_x                                                                                                      
350290         Albumins (including concentrates of two or mor...                                            - Other
521129         Woven fabrics of cotton, containing less than ...                          (-2006)  -- Other fabrics
721141         Flat-rolled products of iron or non-alloy stee...  (-1995) Containing by weight less than 0,25 % ...
722692         Flat-rolled products of other alloy steel, of ...  -- Not further worked than cold-rolled (cold-r...
722012         Flat-rolled products of stainless steel, of a ...             -- Of a thickness of less than 4.75 mm
291430         Ketones and quinones, whether or not with othe...  (-1995) Aromatic ketones without other oxygen ...
284160             Salts of oxometallic or peroxometallic acids.   (-1995) Manganites, manganates and permanganates
290960         Ethers, ether-alcohols, ether-phenols, ether-a...  - Alcohol peroxides, ether peroxides, ketone p...
750522                     Nickel bars, rods, profiles and wire.                                -- Of nickel alloys
722920                                Wire of other alloy steel.                        - Of silico-manganese steel
\end{verbatim}

Kimya, metalurji ürünleri aðýrlýkta ilginç bir þekilde. Bu sonuç
Hidalgo'nun 2008 bazlý analizinden biraz farklý, veri öniþlemdeki bazý
farklýlýklar da rol oynamýþ olabilir. Fakat üstteki ürünlerin teknik olarak
çetrefil olduklarýný görebiliyoruz. 

Acaba ECI'yi 2014 yýlýnda ülkelerin kiþi baþýna gayrýsafi yurtiçi
hasýlasýný tahmin etmek için kullanabilir miyiz?

\begin{minted}[fontsize=\footnotesize]{python}
cindex = [x.upper() for x in cp.index]
ecigdp = pd.DataFrame(eci,index=cindex)
ecigdp = ecigdp.join(gdp)
print ecigdp.shape
ecigdp.columns = ['eci', u'gdp2014', u'gdp2016']
ecigdp['prods'] = np.array(cp3.sum(axis=1))
ecigdp = ecigdp.dropna()
print ecigdp.tail()

import statsmodels.formula.api as smf
results = smf.ols('np.log(gdp2014) ~ eci', data=ecigdp).fit()
print results.rsquared_adj
results = smf.ols('np.log(gdp2014) ~ prods', data=ecigdp).fit()
print results.rsquared_adj
results = smf.ols('np.log(gdp2014) ~ prods + eci', data=ecigdp).fit()
print results.summary()
\end{minted}

\begin{verbatim}
(220, 3)
          eci      gdp2014      gdp2016   prods
WSM -0.088245  3761.912686  3524.649880   374.0
YEM -0.056550   679.667360  1101.117444   995.0
ZAF  0.030545  7504.295250  7627.851926  4409.0
ZMB -0.029490  1622.409958  1620.823290  1856.0
ZWE -0.040179   908.829980   932.548383  1571.0
0.302005430646
0.370724391062
                            OLS Regression Results                            
==============================================================================
Dep. Variable:        np.log(gdp2014)   R-squared:                       0.427
Model:                            OLS   Adj. R-squared:                  0.420
Method:                 Least Squares   F-statistic:                     62.51
Date:                Thu, 24 Aug 2017   Prob (F-statistic):           5.09e-21
Time:                        15:29:21   Log-Likelihood:                -259.05
No. Observations:                 171   AIC:                             524.1
Df Residuals:                     168   BIC:                             533.5
Df Model:                           2                                         
Covariance Type:            nonrobust                                         
==============================================================================
                 coef    std err          t      P>|t|      [95.0% Conf. Int.]
------------------------------------------------------------------------------
Intercept      3.9544      0.864      4.575      0.000         2.248     5.661
prods          0.0016      0.000      5.943      0.000         0.001     0.002
eci          -33.9159      8.670     -3.912      0.000       -51.031   -16.800
==============================================================================
Omnibus:                        1.237   Durbin-Watson:                   1.823
Prob(Omnibus):                  0.539   Jarque-Bera (JB):                1.310
Skew:                           0.196   Prob(JB):                        0.519
Kurtosis:                       2.825   Cond. No.                     2.78e+05
==============================================================================

\end{verbatim}

Sonuç fena deðil. Dikkat edersek düz ürün sayýsýný kullanarak yapýlan
regresyon en son sonuç kadar baþarýlý deðil, ECI ve ürün sayýsýný beraber
kullanan regresyon en baþarýlýsý.  Demek ki ECI hakikaten bir niceliði
yakalayabilmiþ.

Bu alanda daha fazla okuma yapmak isteyenler için [4] güzel bir
kaynak. Üretime uygulanabilen bilgiden bahsedilirken mesela geliþmiþ
ekonomilerdeki kiþi aðlarýnda, o kiþilerde olan yazýlarak anlatýlmasý zor
olan bilgilerden (tacit knowledge) bahsediliyor. Bu ``tecrübe'' diye
sýnýflanabilecek bir bilgi ama tam o da deðil. Bu bilgi kiþinin çalýþma
þeklinden, neye, nasýl, nerede odaklanacaðýyla alakalý, günlük çalýþma
þekli, davranýþ þekliyle alakalý, yazýtsal olmayan bir tür
bilgi. Aktarýlmasý son derece zor, neredeyse tek yol o kiþiyle yanyana
çalýþmak. Yoðun bilgi aðlarýnýn belli yerlerde olmasýnýn bir diðer sebebi
de bu. 

Kaynaklar

[1] Ross, S., {\em Introduction to Probability Models, 8th Edition}

[2] Hidalgo, {\em Veri}, \url{http://atlas.media.mit.edu/en/resources/data/}

[3] Bayramli, {\em Urun Verisi}, \url{https://www.dropbox.com/s/wdg2x524h7ysldu/hidalgo.zip?dl=0}

[4] Hidalgo, {\em The Atlas of Economic Complexity}, \url{http://atlas.cid.harvard.edu}

[5] Inoua, {\em A Simple Measure of Economic Complexity}, \url{https://arxiv.org/abs/1601.05012}

\end{document}
