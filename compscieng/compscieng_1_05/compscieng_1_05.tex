\documentclass[12pt,fleqn]{article}\usepackage{../../common}
\begin{document}
Ders 5

Önceki derste $-u'' = \delta(x-a)$ denklemini çözmüþtük. Ayrýksal olarak bu
denklem sol tarafta matris $-K$, sað tarafta ise noktasal aðýrlýðý tek
hücre içinde 1 olan bir vektöre tekabül edecektir. K baðlamýnda 1 -2 1
formu, -1 2 -1 haline gelir, $u$ vektörü önceki gibi, sað tarafta ise
ayrýksal delta fonksiyonu. Aðýrlýðýn 2. hücrede olduðu örnek alttadýr. 

$$  
\left[\begin{array}{rrrr}
2 & -1 & 0 & 0 \\
-1 & 2 & -1 & 0 \\
0 & -1 & 2 & -1 \\
0 & 0 & -1 & 2 
\end{array}\right]
\left[\begin{array}{c}
u_1 \\
u_2 \\
u_3 \\
u_4
\end{array}\right]
=
\left[\begin{array}{c}
0 \\
1 \\
0 \\
0
\end{array}\right]
$$

Ortaya ilginç bir durum çýktý: sað taraftaki matrise bakarsak, aðýrlýk
2. hücrede ve orasý 1. Eðer 3. olsaydý 3. hücre 1 olurdu, vs. Tüm bu
vektörleri yanyana koysak, birim matrisini elde etmez miyiz? Evet. O zaman
bir kolaylýk ortaya çýktý. Aðýrlýk $j$ üzerinde ise o vektörü $\delta_j$
ile temsil edersek, 

$$ Ku = \delta_j $$

$\delta_j$ yerine $I$ kullanýrsak, ve $u$ vektörü yerine $U$ kullanýrsak,

$$ KK^{-1}U = I \cdot K^{-1}$$

$$ U = K^{-1} $$

olacaktýr. $U$ içinde her türlü $j$ olasýlýðý için bir çözüm içeriyor. Eðer
$j=2$ olasýlýðýnýn çözümünü görmek istiyorsak o zaman $K^{-1}$ matrisinin
yani $U$'nun 2. kolonuna bakmak yeterli.

Peki, eðer yük tek bir nokta yerine ``tüm'' noktalarda olsaydý ne yapardýk?
Tüm noktalardaki yük eþitliðin sað tarafýnýn tamamen 1 olmasý demektir. O
zaman bir baþka numara yaparak, tamamen 1 içeren bu vektörü ayrý ayrý
$\delta_j$'ler ``toplamý'' olarak görebiliriz, mesela

$$ 
\left[\begin{array}{c} 1 \\ 0 \\ 0 \\ 0  \end{array} \right] +
\left[\begin{array}{c} 0 \\ 1 \\ 0 \\ 0  \end{array} \right] +
\left[\begin{array}{c} 0 \\ 0 \\ 1 \\ 0  \end{array} \right] +
\left[\begin{array}{c} 0 \\ 0 \\ 0 \\ 1  \end{array} \right] = 
\left[\begin{array}{c} 1 \\ 1 \\ 1 \\ 1  \end{array} \right] 
 $$

Bu ne demektir? Eþitliðin sað tarafýnýn ``girdi'' olarak görülebildiðini de
biliyoruz. Lineer bir sistemde girdiler toplanýrsa, mümkün tüm çýktýlar da
toplanýr. Üstteki $K^{-1}$'in kolonlarý da bu mümkün tüm çýktýlarý zaten
verdiðine göre tek yapmamýz gereken bu kolonlarý birbiriyle toplamaktýr. 

Green'in Fonksiyonu

$-u''$'ya eþit olarak bir noktasal aðýrlýk (point load) yani delta
fonksiyonu varsa çýkan sonuç Green'in fonksiyonu olarak bilinir ve
bu fonksiyon $G(x,a)$ olarak ta gösterilebilir, çünkü Green'in fonksiyonu hem
$x$'e hem $a$'ya baðlýdýr. Ayrýksal, sürekli (continuous) baðlamýnda ise
Green'in fonksiyonu üstte gösterilen matris tersi iþleminin sürekli hali
olarak düþünülebilir. 

Özdeðerler ve Özvektörler (Eigenvalues and Eigenvectors)

Özdeðerler $Ay = \lambda y$ formunda ortaya çýkarlar. Eðer bir problemde bu
formu bulabilirsek, çözüm için müthiþ kolaylýk saðlayan bir
kavramdýrlar. Özdeðerler $\lambda$ içinde, özvektörler $y$ içinde bulunur. 

Bu kavram hakkýnda anlayýþ geliþtirelim. Mesela elimizde bir $v$ vektörü
var, ve $A$ matrisi ile çarpýlýyor. Sonuç yine bir vektör olacak, bu vektör
$Av$ vektörü. 

\includegraphics[height=3cm]{5_2.png}

Eðer o vektör yukarýdaki gibiyse, $v$ bir özvektör {\em deðil}
demektir. Niye? Çünkü özvektörler özel vektörlerdir (her $A$ için) , öyle
deðerlere sahiptirler ki $A$ ile çarpýlýnca, çizgisel {\em yönleri}
deðiþmez (ama boylarý deðiþebilir). Diyelim ki elimizde bir $y$ var,

\includegraphics[height=1cm]{5_3.png}

$Ay$ alttaki gibi olabilir

\includegraphics[height=3cm]{5_4.png}

$2y$ olabilir, ters yönde büyüyebilir, sýfýr haline de gelebilir, vs. Fakat
muhakkak ayný çizgi üzerinde kalýr, $\lambda$ deðeri de 2, sýfýr, vs gibi
büyümenin, küçülmenin ne kadar olduðunu belirten deðer olacaktýr. Fakat,
tekrarlamak gerekirse, özvektörler nadirdirler zaten tarif edildiði þekilde
davranan bir vektörün az rastlanan bir þey olmasý normal olmalýdýr.

Bunun faydasý, deðeri nedir? Özvektör bize öyle bir yön saðlar ki o yönde
$A$ bir sayý gibi davranýr. $A$, $y$ vektörünü ``deðiþtiren'', onu
transform eden bir fonksiyondur bir bakýma, ve bu fonksiyon ne kadar
çetrefil olursa olsun belli bir ``özel'' yönde sadece sayý etkisi
yapmaktadýr. Mesela

$$ \frac{du}{dt} = Au $$

diyelim ki $u$ 1000 boyutunda bir vektör, $A$ 1000 x 1000 boyutunda bir
matris. Denklem çok büyük, ama diyelim ki biz bu $A$ için öyle bir özvektör
ve özdeðer $u$ biliyoruz ki (eðer bu deðerler problem içinde mantýklý
deðerler de iseler) o zaman þunu da biliyoruz ki çözüm o yönde baþlarsa o
yönde kalýr.

O zaman elimizde bir skalar var demektir (çünkü $A$ yönde tek sayý etkisi
yapýyor) yani üstteki diferansiyel denklem $u' = Au$ yerine $u' = \lambda
u$ haline gelebilir.

Bu daha basit denklemin direk analitik çözümünü biliyoruz:

$$ u = ce^{\lambda t} $$

$\lambda$ özdeðer olarak belli bir yöndeki büyüme, küçülmeyi gösteriyorsa,
üstteki formül içinde de benzer anlamý taþýr: Artý $\lambda$ üstel deðer
üzerinden ona oranlý bir büyümeyi, eksi olaný o oranda bir küçülmeyi
gösterir. Güzel. Kavramlar birbiriyle baðlantýlý çýkýyor, demek ki doðru
yoldayýz.

Diðer kullanýmlar? Temel denklemi tekrar yazalým. 

$$ Ay = \lambda y $$

Soru þu: $A^2$ için öyle bir vektör arýyorum ki $A$ ile iki kez çarpýnca
yön deðiþtirmiyor. Cevap, yine özvektör $y$. Çünkü $y$'yi $A$ ile çarpýnca
$\lambda y$ çýkýyor, yön hala deðiþmedi, o zaman bir daha çarparsak, yön
hala ayný kalýr, bu sefer sonuç $\lambda^2y$.

$$ A^2 = \lambda^2 y $$

Özvektörler diferansiyel denklemler için, bir matrisin üstel deðerlerini
hesaplamak için çok faydalýdýrlar. Bir matrisin pivotlarý sabit konum
(steady-state) problemini incelerken de elimizdeki önemli
sayýlardýr. Hareket halindeki bir maddeyi incelerken yardýmcý olurlar,
salýnýmý (oscillate) olan, büyüyen, küçülen þeyleri incelemekte de
faydalýdýrlar.

Eðer $\lambda$ kompleks bir sayý olsaydý? O zaman $\lambda$'nin reel
bölümüne bakardýk, $< 0$ ise, stabil küçülme (decay), büyük ise stabil
olmayan büyüme (growth) olurdu. Eðer $e^{4it}$ gibi bir deðer olsaydý, bu
pür salýným olacaktý, çünkü açýlýmý $\cos(4t) + i\sin(4t)$ formülüdür.

Diðer bir soru: $k$ büyürken $A^k \to 0$ ise, yani $A$'yi sürekli kendisi
ile çarparken sonuç hep küçülüyorsa, bu durumu $\lambda$'ya bakarak nasýl
anlayabilirim? 

$A^ky$ ise $\lambda^ky$ demektir (üstte gördük), o zaman $A^ky$'nin nasýl
davranacaðýný $\lambda^ky$'a bakarak anlayabilirim. $\lambda^ky$ ne zaman
sýfýra gider? Cevap: $\lambda < 1$ olduðu zaman.

Kompleks $\lambda$'li Reel Matris

Diyelim ki elimizde bir vektörü 90 derece döndürebilen bir $A$ matrisi
var. 

$$ 
A = 
\left[
\begin{array}{rr}
0 & -1 \\
1 & 0
\end{array}
\right]
 $$

Bu matrisin reel özdeðerleri olamaz, çünkü bu matrisin uygulanýp yönü deðiþmeyen
hiçbir ``reel'' vektör olamaz. Gözle görülebilen her vektör 90 derece transform
edilir. Ýþte bu gibi örneklerde özdeðer bulmak için kompleks vektörler
gerekir. Þu vektörü deneyelim: $\left[\begin{array}{cc}1&i\end{array}\right]^T$.

$$ 
\left[\begin{array}{rr}
0 & -1 \\
1 & 0
\end{array}\right]
\left[\begin{array}{c}
1 \\
i
\end{array}\right]
= 
\left[\begin{array}{c}
-i \\
1
\end{array}\right]
= 
-i
\left[\begin{array}{c}
1 \\
i
\end{array}\right]
 $$

Vektör ise yaradý. Þimdi ana noktaya gelelim. Özdeðerleri nasýl
kullanýrýz? Ve onlardan kaç tane vardýr? ``Ýyi'' bir matris, ki bu tanýma
her simetrik matris dahildir, eðer mesela büyüklüðü 1000 ise, o zaman
1000 tane farklý özvektörü olacaktýr. Simetrik matrislerde de o
özvektörlerin hepsi reel olacaktýr. Mesela:

$$ 
\left[\begin{array}{rr}
2 & -1 \\
-1 & 2
\end{array}\right]
 $$

2 x 2 boyutunda bu matriste 2 tane özvektör bulmamýz lazým. Bu ufak bir matris,
özvektörleri tahmin yapa yapa bulmaya uðraþabiliriz.
$\left[\begin{array}{cc}1&0\end{array}\right]^T$ bir özvektör mü?  Çarpýmý
yaparsak,

$$ 
\left[\begin{array}{rr}
2 & -1 \\
-1 & 2
\end{array}\right]
\left[\begin{array}{c}
1 \\
0
\end{array}\right]
=
\left[\begin{array}{r}
2 \\
-1
\end{array}\right]
 $$

Olmadý. Saðdaki vektör $\left[\begin{array}{cc}1&0\end{array}\right]^T$'in bir
katý deðil. Not: Lineer cebirde kafadan iþlem yapmanýn yollarýndan biri,
$\left[\begin{array}{cc}1&0\end{array}\right]^T$ ile çarparken 1 görünce,
soldaki matrisin ``1. sol kolonunu olduðu gibi almak''. Peki $\left[\begin{array}{cc}1&1\end{array}\right]^T$ denersem?

$$ \left[\begin{array}{rr} 2 & -1 \\ -1 & 2
\end{array}\right]
\left[\begin{array}{c}
1 \\
1
\end{array}\right]
=
\left[\begin{array}{c}
1 \\
1
\end{array}\right]
 $$

Bu oldu. Ýkinci özvektör ne olabilir?
$\left[\begin{array}{cc}1&-1\end{array}\right]^T$ deneyelim.

$$ 
\left[\begin{array}{rr}
2 & -1 \\
-1 & 2
\end{array}\right]
\left[\begin{array}{r}
1 \\
-1
\end{array}\right]
=
\left[\begin{array}{r}
3 \\
-3
\end{array}\right]
 $$

Bu da oldu. O zaman $\lambda_1 = 1$, $\lambda_2 = 3$, özvektörler
$\left[\begin{array}{cc} 1 & 1 \end{array}\right]^T$ ve $\left[\begin{array}{cc}
    1 & -1 \end{array}\right]^T$. Bu özvektörlere bana ne söylüyor? Onlara
bakarak ana matris hakkýnda ne anlayabilirim? Bakalým, $\left[\begin{array}{cc}
    1 & 1 \end{array}\right]^T$ ve $\left[\begin{array}{cc} 1 &
    -1\end{array}\right]^T$ birbirine dikgen (orthogonal) vektörler.

\includegraphics[height=3cm]{5_5.png}

Cebirsel olarak bu dikliði anlamak için $y_1^Ty_2$, ya da $y_1 \cdot y_2$
hesabýný yapabilirdik, diklik var ise sonuç sýfýr çýkardý. Özvektörlerin
dikliði baþka bir þey daha söyler, simetrik matrislerin özvektörleri
birbirine diktir, o zaman sadece özvektörlere bakarak ana matrisin simetrik
olduðunu anlayabilirdik.

Söylemeye çalýþtýðýmýz özdeðer ve özvektörler matrisleri incelemenin,
onlarýn ``içine bakmanýn'' yollarýndan bir tanesidir. 

Peki üstteki simetrik olmayan matrise dönersek

$$ 
\left[
\begin{array}{rr}
0 & -1 \\
1 & 0
\end{array}
\right]
 $$

Bu matrisin özvektörleri kompleks çýkmýþtý, ki bu durum simetrik olmayan
matrislerin bir özelliðidir. Simetrik matrisleri bu sebeple tercih ederiz,
özvektörleri reel, birbirine dik.

Özdeðerler üzerinde güzel iki tane faydalý kontrol mekanizmasý: 
$\lambda_1 = 1$, $\lambda_2 = 3$ bulduðumuz örnekte iki özdeðer 
toplamý nedir? 4. Ana matrisin çaprazýndaki deðerleri toplarsak 
(buna matrisin ``izi'' -trace- adý da verilir)

$$ 
\left[\begin{array}{rr}
2 & -1 \\
-1 & 2
\end{array}\right]
 $$

Sonuç yine 4. Bu iki toplam her zaman eþit çýkmalýdýr. Bir numara: bir
tanesi hariç tüm özdeðerleri bulduksak matrisi izini kullanarak sonuncu
özdeðeri hýzla bulabiliriz, çünkü çapraz toplamýndan diðer özdeðer
toplamýný çýkartýrýz, kalan sonuncu özdeðer olmalýdýr.

Bir kontrol daha. Özdeðerleri birbiriyle çarparsam sonuç 3 çýkar. Ana
matrisin determinantýný alýrsam sonuç yine 3 çýkar. Bu iki kontrol
tekniðini, ispatýný göstermeden, burada vermiþ olalým. 

Kullanýma gelelim: Diyelim ki elimizde içinde 1000 tane denklem içeren bir
lineer denklem sistemi var. 

$$ \frac{du}{dt} = Au $$

katsayýlar sabit, baþlangýç noktasý $u(0)$. Özdeðer ve özvektörler burada
nasýl yardýmcý olabilir? Önce onlarý bulmamýz gerekir, 1000 tane özvektör
var, onlarý buluruz. Her $i$ için 

$$ Ay_i = \lambda_i y_i $$

yani elimizdeki özvektörler $y_1,..,y_{1000}$, özdeðerler
$\lambda_1,...,\lambda_{1000}$. 

Bu deðerleri diferansiyel denklemi çözmek için nasýl kullanýrým? 3 tane
basamak takip ederim.

1. $u(0)$'i özvektörlerin bir kombinasyonu olarak temsil et, yani
 $u(0) = c_1y_1 + ... + c_{1000}y_{1000}$. 

2. $e^{\lambda_1t}$'yi $c_1$ ile çarp, yani $c_1$'i onun büyümesi ile
çarp, genel olarak $e^{\lambda_it}$'yi $c_i$ ile çarp. 

3. Topla: $c_1e^{\lambda_1t}y_1 + .. + c_{1000}e^{\lambda_{1000}
  t}y_{1000}$. 

Not: Bunun niye iþlediðinin ispatý için [3]'e bakýlabilir.

Not: Konuyla ilgili bir problem bu notlarýn en altýnda.

Tabii bunu iþlemesi için $u(0)$'in özvektörlere, özdeðerlere göre
parçalanmasý gerekir, ayrýca tüm özvektörlerin bulunabiliyor olmasý
gerekir. Problemimiz bize simetrik bir matris saðlýyorsa sorun olmaz, ama
bazý problemlerde matris ``defolu'' olabilir, bazý özvektörler
birbirlerinin içine girerler (collapse) ve elde yeteri kadar özvektör
olmaz. Yani çözmeye çalýþtýðýmýz probleme göre bu tekniði kullanabilir ya
da kullanamayabiliriz. 

Not: Özvektörlerin birbirine yakýn, hatta eþit olma problemi ODE'lerdeki
kritik sönümlü (critically damped) koþulda köklerin birbirine eþit
çýkmasýyla ayný durum, bkz [2]. Orada yeni bir çözüm ``yaratmak'' için
$e^{-at}$ ile $t$'yi çarpmýþtýk. Burada da özdeðerleri aslýnda kökler
olarak görebiliriz, eðer iki özdeðer eþit ise, elimde sadece bir tane
özvektör olma riski de yüksek demektir. O zaman yeni bir çözüm yaratmak
için ODE dünyasýndakine benzer bir numara kullanýrým, $te^{\lambda t}$
hesabýný yapabilirim.

Ek Açýklamalar

$u(0)$'i $A$'nin özvektör lineer kombinasyonu olarak temsil edilirse,
sonucun $c_1e^{\lambda_1t}y_1 + .. + c_ne^{\lambda_n t}y_n$ þeklinde
olabileceðini nereden biliyoruz?  Çünkü $du/dt = Au$ ve $Au = \lambda u$
lineer denklemler. Bir sonraki adým için $u(0)$ deðiþtirildiðinde, bu
lineer bir þekilde, $A$ üzerinden olacak, ve $A$'ya ``girdi'' olarak
verilen vektörler eðer özdeðerlerin kombinasyonu ise, bu kombinasyon çýkýþa
da aynen, verildiði þekilde yansýyacak.

Bölüm 1.5 Örnek 4 (Kitaptan)

Diyelim ki vektörel formdaki bir $u(t)$ denklemi ABD'de Missisipi nehrinin
doðusu ve batýsýnda $t$ anýndaki nüfusu temsil ediyor. Þöyle:

$$ u(t+1) = Au(t) $$

Bu vektörel $u(t)$'yi bileþenleriyle þöyle açýklayalým

$$ 
\left[\begin{array}{r}
t+1 \textrm{ anýnda doðuda olanlar } \\
t+1 \textrm{ anýnda batýda olanlar } 
\end{array}\right]
=
\left[\begin{array}{rr}
.8 & .3 \\
.2 & .7
\end{array}\right]
\left[\begin{array}{r}
t \textrm{ anýnda doðuda olanlar } \\
t \textrm{ anýnda batýda olanlar } 
\end{array}\right]
 $$

Buradaki $A$ matrisi belli bir gözleme dayanarak modelleyicinin bulduðu bir
þey herhalde, problem onu bize veriyor. $A$ bir ``geçiþ fonksiyonu'', $t$
anýndan $t+1$'e geçiþi o yapýyor. Diyelim ki doðuda 1 milyon insanla
baþladýk, 1 sene sonra ($A$ ile çarpýyoruz) yeni rakamlar 800,000 ve
200,000 haline gelecektir. 

$A$ matrisi bir Markov matrisidir, Markov matrislerinin kolonlarýnýn iç
toplamlarý her zaman 1'e eþittir. Özdeðer / özvektör baðlamýnda Markov
matrislerinin ilginç bir yaný özdeðerlerinden birinin her zaman 1 olmasýdýr,
yani $\lambda = 1$ muhakkak olacaktýr. Ýki boyutlu $A$ matrisi durumunda bu çok
ise yarar, çünkü matris izine (trace) bakarak ve ondan 1 çýkartarak ikinci
özdeðeri hemen bulabiliriz. $A$'nin özvektörleri de $\lambda = 1$ için [600,000,
  400,000], $\lambda = 0.5$ için [400,000, -400,000] deðerleridir.

Þimdi ilginç bir numara: eðer baþlangýç deðeri [1,000,000 0]'i özvektörlerin
bir kombinasyonu olarak gösterirsek,

$$ u = [1,000,000 0] = 
a_1 \cdot [600,000, 400,000] + 
a_2 \cdot [400,000, -400,000] $$

$a_1$ ve $a_2$ 1 deðerine eþit. 

Soldan $A$ ile çarpalým

$$ Au = 
A \ a_1 \cdot [600,000, 400,000] + 
A \ a_2 \cdot [400,000, -400,000] $$

$$ Au = 
 a_1 \ A \cdot [600,000, 400,000] + 
 a_2 \ A \cdot [400,000, -400,000] $$

$$ Au = 
a_1 \ \lambda_1 \cdot [600,000, 400,000] + 
a_2 \ \lambda_2 \cdot [400,000, -400,000] $$

$\lambda_1$ ve $\lambda_2$ nereden geldi? Özvektörlerin tanýmýndan: $Ax =
\lambda x$. Üstteki 
kombinasyonda kullandýklarýmýz özvektör olduðuna göre, onlarýn $A$ ile
çarpýlmýþ hali onlarýn tekrar özdeðerle çarpýlmýþ halini verecektir. 

Ayrýca $\lambda_1=1$ olduðuna göre, onu denklemde göstermeye gerek bile
yoktur (Markov matrisi içeren problemlerin bir güzel yan etkisi oldu
bu). $a_1$ ve $a_2$ zaten 1 deðerine eþitti, onlarý da atabiliriz. Yani,

$$ Au = 
[600,000, 400,000] + 
\lambda_2 \cdot [400,000, -400,000] $$

Þimdi geçiþ iþlemini birkaç kere üst üste yapalým:

$$ A^2u = 
[600,000, 400,000] + 
\lambda_2^2 \cdot [400,000, -400,000] $$

$$ A^3u = 
[600,000, 400,000] + 
\lambda_2^3 \cdot [400,000, -400,000] $$

...

Böyle devam edecek. $\lambda_2=1/2$ olduðuna göre, ve bu deðer 1'den küçük
olduðu için $n$ büyüdükçe $\lambda_2^n$ çok küçük bir sayý haline gelir, ve
sýfýra yaklaþýr. Yani üstteki denklemin sabit konum (steady-state)
çözümü [600,000, 400,000] deðeridir.

Örnek Problem

$$ 
\frac{du}{dt} = Au
 $$

problemini çözdüðümüzü farzedelim, ki $u(t)$ þöyle tanýmlý

$$ 
u(t) =
\left[\begin{array}{r}
y(t) \\
z(t)
\end{array}\right]
 $$

Ayrý ayrý

$$ dy/dt = 2y - z $$

$$ dz/dt = -y + 2z $$

Matris formunda

$$ 
\frac{d}{dt}
\left[\begin{array}{r}
y \\
z
\end{array}\right]=
\left[\begin{array}{rr}
2 & -1 \\
-1 & 2
\end{array}\right]
\left[\begin{array}{r}
y \\
z
\end{array}\right]
 $$

ki yukarýdaki 2x2 matris $A$ matrisi olacak. {\em Lineer Cebir Ders 23}'te
görüldüðü gibi bu problemin çözümü 

$$ u = S e^{\Lambda t} S^{-1} u(0) $$

[1, sf. 53]'te bu problemin sadece 

$$ u = S e^{\Lambda t} v(0) $$

noktasýna kadar gelinip býrakýldýðý bir bölüm var, bu bölümün sonucunu üstteki
$u$ formülüne göre yineden türetelim. $v(0) = \left[\begin{array}{cc} C &
    D \end{array}\right]^T$ þeklinde bir vektör tanýmlayalým, bunlarý baþlangýç
deðerlerinin özvektörleri nasýl kombine ettiðini gösteriyor. $A$ matrisinin
özdeðerleri $\lambda_1=1$ ve $\lambda_2=3$, ona tekabül eden özvektörler
$\left[\begin{array}{cc} 1 & 1 \end{array}\right]^T$ ve $\left[\begin{array}{cc}
    1 & -1 \end{array}\right]^T$. O zaman

$$ 
u(t) =
\left[\begin{array}{rr}
1 & 1 \\
1 & -1
\end{array}\right]
\left[\begin{array}{rr}
e^{\lambda_1 t} & \\
& e^{\lambda_2 t} 
\end{array}\right]
\left[\begin{array}{r}
C \\
D
\end{array}\right]
= 
\left[\begin{array}{r}
y(t) \\
z(t)
\end{array}\right]
 $$

Bu çarpýmý ayrý ayrý yapýnca çözümün kitapta gösterildiði gibi

$$        
\left[\begin{array}{r}
y(t) \\
z(t)
\end{array}\right]
=
\left[\begin{array}{r}
Ce^t + De^{3t} \\
Ce^t - De^{3t} 
\end{array}\right]
$$

olarak çýktýðýný göreceðiz. 

Kaynaklar 

[1] Strang, {\em Computational Science}

[2] Bayramli, Diferansiyel Denklemler, {\em Ders 9}

[3] Bayramli, Lineer Cebir, {\em Ders 23}

\end{document}
