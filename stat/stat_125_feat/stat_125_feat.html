<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
    <script type="text/x-mathjax-config">
    MathJax.Hub.Register.StartupHook("TeX Jax Ready",function () {
      MathJax.Hub.Insert(MathJax.InputJax.TeX.Definitions.macros,{
        cancel: ["Extension","cancel"], cancelto: ["Extension","cancel"]
      });
    });
    </script>  
   
  <title>Özellik İşlemek (Feature Engineering)</title>
  <style type="text/css">code{white-space: pre;}</style>
  <style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
  </style>
  <script
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS_HTML-full"
  type="text/javascript"></script>
</head>
<body>
<div id="header">
</div>
<h1 id="özellik-işlemek-feature-engineering">Özellik İşlemek (Feature
Engineering)</h1>
<p>Veri madenciliğinde “veriden veri yaratma” tekniği çok kullanılıyor;
mesela bir sipariş veri satırında o siparişin hangi zamanda (timestamp)
olduğunu belirten bir kolon varsa (ki çoğu zaman vardır), bu kolonu
“parçalayarak” ek, daha genel, özetsel bilgi kolonları yaratılabilir. Ya
da kategoriksel verileri pek çok farklı şekilde sayısal hale
çevirebiliriz, mesela 1-hot kodlama ile N kategori N kolon haline gelir,
eldeki kategoriye tekabül eden öğe 1 diğerleri sıfır yapılır.</p>
<p>Özellik işlemenin önemi yapay öğrenme açısından önemi var, mesela bir
SVM sınıflayıcısını en basit haliyle siyah/beyaz görüntüden sayı tanıma
probleminde kullandık, ve diyelim yüzde 70 başarı elde ettik. Şimdi çok
basit bir yeni özellik yaratalım, görüntüyü dikey ikiye bölelim, ve
üstteki ve alttaki siyah noktaları toplayarak iki yeni kolon olarak
görüntü matrisine ekleyelim. Bu yeni özellikleri kullanınca basit
sınıflayıcının yüzde 20 kadar tanıma başarısında ilerleme kaydettiğini
göreceğiz!</p>
<p>Not: Derin yapay sınır ağları teknikleri ile özellik işlemeye artık
gerek olmadığı söylenir, bu büyük ölçüde doğru. Bir DYSA farklı
seviyelerdeki pek çok farklı nöronları üzerinden aslında üstte tarif
edilen türden yeni özellikleri otomatik olarak yaratır, ögrenir. Fakat
yine de yeni özellikleri elle yaratma tekniklerini bilmek iyi.</p>
<p>Şimdi farklı yöntemlere bakalım.</p>
<p>Zaman Kolonlarını Zenginleştirmek</p>
<p>Zaman kolonları çoğu zaman saniyeye kadar kaydedilir, bu bilgiyi alıp
mesela ay, mevsim, haftanın günü, saat, iş saati mi (9-5 arası), akşam
mı, sabah mı, öğlen mi, vs. gibi ek bilgiler çıkartılabilir. Tüm
kolonlar veri madenciliği algoritmasına verilir, ve algoritma belki
öğlen saati ile sipariş verilmiş olması arasında genel bir bağlantı
bulacaktır.</p>
<p>Python + Pandas ile bir zaman kolonu şöyle parçalanabilir, örnek veri
üzerinde görelim, sadece iki kolon var, müşteri no, ve sipariş
zamanı,</p>
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>pd.set_option(<span class="st">&#39;display.max_columns&#39;</span>, <span class="va">None</span>)</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> io <span class="im">import</span> StringIO</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>s <span class="op">=</span> <span class="st">&quot;&quot;&quot;customer_id;order_date</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="st">  299;2012-07-20 19:44:55.661000+01:00</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="st">  421;2012-02-17 21:54:15.013000+01:00</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="st">  437;2012-02-20 22:18:12.021000+01:00</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="st">  463;2012-02-20 23:46:21.587000+01:00</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="st">  482;2012-05-21 09:50:02.739000+01:00</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="st">  607;2012-02-21 11:57:12.462000+01:00</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="st">  641;2012-02-21 13:40:28.088000+01:00</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="st">  674;2012-08-21 14:53:15.851000+01:00</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="st">  780;2012-02-23 10:31:05.571000+01:00</span></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="st">  &quot;&quot;&quot;</span></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(StringIO(s),sep<span class="op">=</span><span class="st">&#39;;&#39;</span>, parse_dates<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> f(x):</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>  tmp <span class="op">=</span> pd.to_datetime(x[<span class="st">&#39;order_date&#39;</span>])</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>  tpl <span class="op">=</span> tmp.timetuple()<span class="op">;</span> yymm <span class="op">=</span> <span class="bu">int</span>(tmp.strftime(<span class="st">&#39;%m</span><span class="sc">%d</span><span class="st">&#39;</span>))</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>  spring <span class="op">=</span> <span class="bu">int</span>(yymm <span class="op">&gt;=</span> <span class="dv">321</span> <span class="kw">and</span> yymm <span class="op">&lt;</span> <span class="dv">621</span>)</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>  summer <span class="op">=</span> <span class="bu">int</span>(yymm <span class="op">&gt;=</span> <span class="dv">621</span> <span class="kw">and</span> yymm <span class="op">&lt;</span> <span class="dv">921</span>)</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>  fall <span class="op">=</span> <span class="bu">int</span>(yymm <span class="op">&gt;=</span> <span class="dv">921</span> <span class="kw">and</span> yymm <span class="op">&lt;</span> <span class="dv">1221</span>)</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>  winter <span class="op">=</span> <span class="bu">int</span>( spring<span class="op">==</span><span class="dv">0</span> <span class="kw">and</span> summer<span class="op">==</span><span class="dv">0</span> <span class="kw">and</span> fall<span class="op">==</span><span class="dv">0</span> )</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>  warm_season <span class="op">=</span> <span class="bu">float</span>(tpl.tm_mon <span class="op">&gt;=</span> <span class="dv">4</span> <span class="kw">and</span> tpl.tm_mon <span class="op">&lt;=</span> <span class="dv">9</span>)</span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>  work_hours <span class="op">=</span> <span class="bu">float</span>(tpl.tm_hour <span class="op">&gt;</span> <span class="dv">9</span> <span class="kw">and</span> tpl.tm_hour <span class="op">&lt;</span> <span class="dv">17</span>)</span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>  morning <span class="op">=</span> <span class="bu">float</span>(tpl.tm_hour <span class="op">&gt;=</span> <span class="dv">7</span> <span class="kw">and</span> tpl.tm_hour <span class="op">&lt;=</span> <span class="dv">11</span>)</span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>  noon <span class="op">=</span> <span class="bu">float</span>(tpl.tm_hour <span class="op">&gt;=</span> <span class="dv">12</span> <span class="kw">and</span> tpl.tm_hour <span class="op">&lt;=</span> <span class="dv">14</span>)</span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>  afternoon <span class="op">=</span> <span class="bu">float</span>(tpl.tm_hour <span class="op">&gt;=</span> <span class="dv">15</span> <span class="kw">and</span> tpl.tm_hour <span class="op">&lt;=</span> <span class="dv">19</span>)</span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>  night <span class="op">=</span> <span class="bu">int</span> (morning<span class="op">==</span><span class="dv">0</span> <span class="kw">and</span> noon<span class="op">==</span><span class="dv">0</span> <span class="kw">and</span> afternoon<span class="op">==</span><span class="dv">0</span>)</span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> pd.Series([tpl.tm_hour, tpl.tm_mon,</span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a>                    tpl.tm_wday, warm_season,</span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a>                    work_hours, morning, noon, afternoon, night,</span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a>                    spring, summer, fall, winter])</span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a>cols <span class="op">=</span> [<span class="st">&#39;ts_hour&#39;</span>,<span class="st">&#39;ts_mon&#39;</span>,<span class="st">&#39;ts_wday&#39;</span>,<span class="st">&#39;ts_warm_season&#39;</span>,<span class="op">\</span></span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a>  <span class="st">&#39;ts_work_hours&#39;</span>,<span class="st">&#39;ts_morning&#39;</span>,<span class="st">&#39;ts_noon&#39;</span>,<span class="st">&#39;ts_afternoon&#39;</span>,<span class="op">\</span></span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a>  <span class="st">&#39;ts_night&#39;</span>, <span class="st">&#39;ts_spring&#39;</span>, <span class="st">&#39;ts_summer&#39;</span>, <span class="st">&#39;ts_fall&#39;</span>, <span class="st">&#39;ts_winter&#39;</span>]</span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a>df[cols] <span class="op">=</span> df.<span class="bu">apply</span>(f, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (df[cols])</span></code></pre></div>
<pre class="text"><code>   ts_hour  ts_mon  ts_wday  ts_warm_season  ts_work_hours  ts_morning  \
0     19.0     7.0      4.0             1.0            0.0         0.0   
1     21.0     2.0      4.0             0.0            0.0         0.0   
2     22.0     2.0      0.0             0.0            0.0         0.0   
3     23.0     2.0      0.0             0.0            0.0         0.0   
4      9.0     5.0      0.0             1.0            0.0         1.0   
5     11.0     2.0      1.0             0.0            1.0         1.0   
6     13.0     2.0      1.0             0.0            1.0         0.0   
7     14.0     8.0      1.0             1.0            1.0         0.0   
8     10.0     2.0      3.0             0.0            1.0         1.0   

   ts_noon  ts_afternoon  ts_night  ts_spring  ts_summer  ts_fall  ts_winter  
0      0.0           1.0       0.0        0.0        1.0      0.0        0.0  
1      0.0           0.0       1.0        0.0        0.0      0.0        1.0  
2      0.0           0.0       1.0        0.0        0.0      0.0        1.0  
3      0.0           0.0       1.0        0.0        0.0      0.0        1.0  
4      0.0           0.0       0.0        1.0        0.0      0.0        0.0  
5      0.0           0.0       0.0        0.0        0.0      0.0        1.0  
6      1.0           0.0       0.0        0.0        0.0      0.0        1.0  
7      1.0           0.0       0.0        0.0        1.0      0.0        0.0  
8      0.0           0.0       0.0        0.0        0.0      0.0        1.0  </code></pre>
<p>Sıcak mevsim (warm season) Mart-Eylül aylarını kapsar, bu ikisel bir
değişken hale getirildi. Belki siparişin, ya da diğer başka bir verinin
bununla bir alakası vardır. Genel 4 sezon tek başına yeterli değil
midir? Olabilir, fakat bazı kalıplar / örüntüler (patterns) belki sıcak
/ soğuk mevsim bilgisiyle daha çok bağlantılıdır.</p>
<p>Aynı şekilde saat 1-24 arasında bir sayı olarak var, fakat “iş
saatini” ayrı bir ikisel değişken olarak kodlamak yine bir “kalıp
yakalama” şansımızı arttırabilir. Bu kolonun ayrı bir şekilde kodlanmış
olması veri tasarımı açısından ona önem verildiğini gösterir, ve
madencilik algoritmaları bu kolonu, eğer ona bağlı bir kalıp var ise,
yakalayabilirler.</p>
<p>Not: Burada ufak bir pürüz sabah, öğlen, akşamüstü gibi zamanları
kodlarken çıktı. Gece 19’dan sonra ve 7’den önce bir sayı olacaktı,
fakat bu durumda <span class="math inline">\(x&gt;19\)</span> ve <span
class="math inline">\(x&lt;7\)</span> hiçbir sonuç getirmeyecekti.
Burada saatlerin 24 sonrası başa dönmesi durumu problem çıkartıyordu,
tabii ki karşılaştırma ifadelerini çetrefilleştirerek bu iş çözülebilir,
ama o zaman kod temiz olmaz (mesela (<span
class="math inline">\(x&gt;19\)</span> ve <span
class="math inline">\(x&lt;24\)</span>) ya da (<span
class="math inline">\(x&gt;0\)</span> ve <span
class="math inline">\(x&lt;7\)</span>) yapabilirdik). Temiz kod için
gece haricinde diğer tüm seçenekleri kontrol ediyoruz, ve gece “sabah,
öğlen, akşamüstü olmayan şey” haline geliyor. Aynı durum mevsimler için
de geçerli. Onun için</p>
<pre><code>night = int (morning==0 and noon==0 and afternoon==0)</code></pre>
<p>kullanıldı.</p>
<p>Kategorileri İkileştirme</p>
<p>Yapay öğrenim algoritmalarının çoğu zaman hem kategorik hem sayısal
değerleri aynı anda bulunduran verilerle iş yapması gerekebiliyor.
Ayrıca literatüre bakılınca görülür ki çoğunlukla bir algoritma ya biri,
ya diğeri ile çalışır, ikisi ile aynı anda çalışmaz (çalışanlar var
tabii, mesela karar ağaçları -decision tree-). Bu gibi durumlarda iki
seçenek var, ya numerik veri kategoriselleştirilir (ayrıksallaştırılır),
ya da kategorik veri numerik hale getirilir.</p>
<p>Bu durumda, kategorik bir kolon eyalet için, eyaletin Ohio olup
olmaması başlı başına ayrı bir kolon olarak gösteriliyor. Aynı şekilde
Nevada. Bu kodlamaya literatürde 1-hot kodlaması adı veriliyor. KMeans,
lojistik regresyon gibi metotlara girdi vermek için bu transformasyon
kullanılabilir.</p>
<div class="sourceCode" id="cb4"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd, os</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> scipy.sparse <span class="im">as</span> sps</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.feature_extraction <span class="im">import</span> DictVectorizer</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> one_hot_dataframe(data, cols, replace<span class="op">=</span><span class="va">False</span>):</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>    vec <span class="op">=</span> DictVectorizer()</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>    mkdict <span class="op">=</span> <span class="kw">lambda</span> row: <span class="bu">dict</span>((col, row[col]) <span class="cf">for</span> col <span class="kw">in</span> cols)</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>    vecData <span class="op">=</span> pd.DataFrame(vec.fit_transform(data[cols].<span class="bu">apply</span>(mkdict, axis<span class="op">=</span><span class="dv">1</span>)).toarray())</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>    vecData.columns <span class="op">=</span> vec.get_feature_names_out()</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>    vecData.index <span class="op">=</span> data.index</span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> replace <span class="kw">is</span> <span class="va">True</span>:</span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>        data <span class="op">=</span> data.drop(cols, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>        data <span class="op">=</span> data.join(vecData)</span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> (data, vecData, vec)</span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> {<span class="st">&#39;state&#39;</span>: [<span class="st">&#39;Ohio&#39;</span>, <span class="st">&#39;Ohio&#39;</span>, <span class="st">&#39;Ohio&#39;</span>, <span class="st">&#39;Nevada&#39;</span>, <span class="st">&#39;Nevada&#39;</span>],</span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>        <span class="st">&#39;year&#39;</span>: [<span class="dv">2000</span>, <span class="dv">2001</span>, <span class="dv">2002</span>, <span class="dv">2001</span>, <span class="dv">2002</span>],</span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>        <span class="st">&#39;pop&#39;</span>: [<span class="fl">1.5</span>, <span class="fl">1.7</span>, <span class="fl">3.6</span>, <span class="fl">2.4</span>, <span class="fl">2.9</span>]}</span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.DataFrame(data)</span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a>df2, _, _ <span class="op">=</span> one_hot_dataframe(df, [<span class="st">&#39;state&#39;</span>], replace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (df2)</span></code></pre></div>
<pre class="text"><code>   year  pop  state=Nevada  state=Ohio
0  2000  1.5           0.0         1.0
1  2001  1.7           0.0         1.0
2  2002  3.6           0.0         1.0
3  2001  2.4           1.0         0.0
4  2002  2.9           1.0         0.0</code></pre>
<p>Unutmayalım, kategorik değerler bazen binleri bulabilir (hatta sayfa
tıklama tahmini durumunda mesela milyonlar, hatta milyarlar), bu da
binlerce yeni kolon demektir. Yani 1/0 kodlaması, yani 1-hot işleminden
ele geçen yeni blok içinde aslında oldukca çok sayıda sıfır değeri
olacak (sonuçta her satırda binlerce ‘şey’ içinde sadece bir tanesi 1
oluyor), yani bu bloğun bir seyrek matris olması iyi olurdu. O zaman
matrisin tamamını <code>sps.csr_matrix</code> ya da
<code>sps.lil_matrix</code> ile gerçekten seyrek formata çevirebiliriz,
ve mesela scikit-learn paketi, numpy, scipy işlemleri seyrek matrisler
ile hesap yapabilme yeteneğine sahip. Seyrekselleştirince ne elde
ediyoruz? Sıfırları depolamadığımız için sadece sıfır olmayan değerler
ile işlem yapıyoruz, o ölçüde kod hızlanıyor, daha az yer tutuyor.</p>
<p>Dikkat etmek gerekir ki yeni kolonları üretince değerlerin yerleri
sabitlenmiş olur. Her satır bazında bazen state=Ohio, state=Nevada,
bazen sadece state=Ohio üretiyor olamayız. Üstteki örnekte her zaman 4
tane kolon elde edilmelidir.</p>
<p>Not: 1-hot yerine bir diğer seçenek kategoriyi bir indise çevirmek
(tüm kategorileri sıralayıp kaçıncı olduğuna bakarak mesela) sonra bu
sayıyı ikisel sistemde belirtmek, eğer ‘a’ sayısı 30 indisine tekabül
ediyorsa, 30 ikisel sistemde 11110, bu değer kullanılır (aslında bu son
tarif edilen sistemin 1-hot sistemden daha iyi işlediği rapor
ediliyor).</p>
<p>Anahtarlama Numarası (1-Hot Encoding, Hashing Trick)</p>
<p>Fakat bir problem var, dokümanı temsil eden ve içinde 1 ya da 0
hücreli özellik vektörünü (feature vector) oluşturmak için tüm
kelimelerin ne olduğunu bilmeliyiz. Yani veriyi bir kere baştan sonra
tarayarak bir sözlük oluşturmalıyız (ki öyle yapmaya mecbur kaldık) ve
ancak ondan sonra her doküman için hangi kelimenin olup olmadığını
saptamaya ve onu kodlamaya başlayabiliriz. Halbuki belgelere bakar
bakmaz, teker teker giderken bile hemen bir özellik vektörü
oluşturabilseydik daha iyi olmaz mıydı?</p>
<p>Bunu başarmak için anahtarlama numarasını kullanmamız lazım.
Bilindiği gibi temel yazılım bilime göre bir kelimeyi temsil eden bir
anahtar (hash) üretebiliriz, ki bu hash değeri bir sayıdır. Bu sayının
en fazla kaç olabileceğinden hareketle (hatta bu sayıya bir limit
koyarak) özellik vektörümüzün boyutunu önceden saptamış oluruz. Sonra
kelimeye bakarız, hash üretiriz, sonuç mesela 230 geldi, o zaman özellik
vektöründeki 230’uncu kolonun değerini 1 yaparız.</p>
<div class="sourceCode" id="cb6"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>d_input <span class="op">=</span> <span class="bu">dict</span>()</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> add_word(word):</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>  hashed_token <span class="op">=</span> <span class="bu">hash</span>(word) <span class="op">%</span> <span class="dv">127</span></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>  d_input[hashed_token] <span class="op">=</span> d_input.setdefault(hashed_token, <span class="dv">0</span>) <span class="op">+</span> <span class="dv">1</span></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>add_word(<span class="st">&quot;obama&quot;</span>)</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (d_input)</span></code></pre></div>
<pre class="text"><code>{50: 1}</code></pre>
<div class="sourceCode" id="cb8"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>add_word(<span class="st">&quot;politics&quot;</span>)</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (d_input)</span></code></pre></div>
<pre class="text"><code>{50: 1, 78: 1}</code></pre>
<p>Üstteki kodda bunun örneğini görüyoruz. Hash sonrası mod uyguladık
(yüzde işareti ile) ve hash sonucunu en fazla 127 olacak şekilde
sınırladık. Potansiyel problemler ne olabilir? Hashing mükemmel
değildir, çarpışma (collision) olması mümkündür yani nadiren farklı
kelimelerin aynı numaraya eşlenebilmesi durumu. Bu problemleri iyi bir
anahtarlama algoritması kullanarak, mod edilen sayıyı büyük tutarak
çözmek mümkündür, ya da bu tür nadir çarpışmalar “kabul edilir hata”
olarak addedilebilir.</p>
<p>Pandas kullanarak bir Dataframe’i otomatik olarak anahtarlamak
istersek,</p>
<div class="sourceCode" id="cb10"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> {<span class="st">&#39;state&#39;</span>: [<span class="st">&#39;Ohio&#39;</span>, <span class="st">&#39;Ohio&#39;</span>, <span class="st">&#39;Ohio&#39;</span>, <span class="st">&#39;Nevada&#39;</span>, <span class="st">&#39;Nevada&#39;</span>],</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>  <span class="st">&#39;year&#39;</span>: [<span class="dv">2000</span>, <span class="dv">2001</span>, <span class="dv">2002</span>, <span class="dv">2001</span>, <span class="dv">2002</span>],</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>  <span class="st">&#39;pop&#39;</span>: [<span class="fl">1.5</span>, <span class="fl">1.7</span>, <span class="fl">3.6</span>, <span class="fl">2.4</span>, <span class="fl">2.9</span>]}</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> pd.DataFrame(data)</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (data)</span></code></pre></div>
<pre class="text"><code>    state  year  pop
0    Ohio  2000  1.5
1    Ohio  2001  1.7
2    Ohio  2002  3.6
3  Nevada  2001  2.4
4  Nevada  2002  2.9</code></pre>
<p>Şimdi bu veri üzerinde sadece eyalet (state) için bir anahtarlama
numarası yapalım</p>
<div class="sourceCode" id="cb12"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> hash_col(df,col,N):</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(N):</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>    df[col <span class="op">+</span> <span class="st">&#39;_&#39;</span> <span class="op">+</span> <span class="bu">str</span>(i)] <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>  df[col <span class="op">+</span> <span class="st">&#39;_hash&#39;</span>] <span class="op">=</span> df.<span class="bu">apply</span>(<span class="kw">lambda</span> x: <span class="bu">hash</span>(x[col]) <span class="op">%</span> N,axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(N):</span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>      df.loc[df[col <span class="op">+</span> <span class="st">&#39;_hash&#39;</span>] <span class="op">==</span> i, <span class="st">&#39;</span><span class="sc">%s</span><span class="st">_</span><span class="sc">%d</span><span class="st">&#39;</span> <span class="op">%</span> (col,i)] <span class="op">=</span> <span class="fl">1.0</span> <span class="co"># Changed .iloc to .loc and direct boolean indexing</span></span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>  df <span class="op">=</span> df.drop([col, col <span class="op">+</span> <span class="st">&#39;_hash&#39;</span>], axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> df</span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (hash_col(data,<span class="st">&#39;state&#39;</span>,<span class="dv">4</span>))</span></code></pre></div>
<pre class="text"><code>   year  pop  state_0  state_1  state_2  state_3
0  2000  1.5      1.0      0.0      0.0      0.0
1  2001  1.7      1.0      0.0      0.0      0.0
2  2002  3.6      1.0      0.0      0.0      0.0
3  2001  2.4      0.0      0.0      0.0      1.0
4  2002  2.9      0.0      0.0      0.0      1.0</code></pre>
<p>Baştan Seyrek Matris ile Çalışmak</p>
<p>Büyük Veri ortamında, eğer kategorik değerler milyonları buluyorsa, o
zaman üstteki gibi normal Numpy matrisinden seyreğe geçiş yapmak bile
külfetli olabilir. Bu durumlarda daha en baştan seyrek matris üretiyor
olmalıyız. Mevcut tüm değerleri önceden bildiğimizi farz edersek,</p>
<div class="sourceCode" id="cb14"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd, os</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> scipy.sparse <span class="im">as</span> sps</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> itertools</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> one_hot_column(df, cols, vocabs):</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>    mats <span class="op">=</span> []<span class="op">;</span> df2 <span class="op">=</span> df.drop(cols,axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>    mats.append(sps.lil_matrix(np.array(df2)))</span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i,col <span class="kw">in</span> <span class="bu">enumerate</span>(cols):</span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>        mat <span class="op">=</span> sps.lil_matrix((<span class="bu">len</span>(df), <span class="bu">len</span>(vocabs[i])))</span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> j,val <span class="kw">in</span> <span class="bu">enumerate</span>(np.array(df[col])):</span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a>            mat[j,vocabs[i][val]] <span class="op">=</span> <span class="fl">1.</span></span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a>        mats.append(mat)</span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a>    res <span class="op">=</span> sps.hstack(mats)    </span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> res</span>
<span id="cb14-17"><a href="#cb14-17" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb14-18"><a href="#cb14-18" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> {<span class="st">&#39;state&#39;</span>: [<span class="st">&#39;Ohio&#39;</span>, <span class="st">&#39;Ohio&#39;</span>, <span class="st">&#39;Ohio&#39;</span>, <span class="st">&#39;Nevada&#39;</span>, <span class="st">&#39;Nevada&#39;</span>],</span>
<span id="cb14-19"><a href="#cb14-19" aria-hidden="true" tabindex="-1"></a>        <span class="st">&#39;year&#39;</span>: [<span class="st">&#39;2000&#39;</span>, <span class="st">&#39;2001&#39;</span>, <span class="st">&#39;2002&#39;</span>, <span class="st">&#39;2001&#39;</span>, <span class="st">&#39;2002&#39;</span>],</span>
<span id="cb14-20"><a href="#cb14-20" aria-hidden="true" tabindex="-1"></a>        <span class="st">&#39;pop&#39;</span>: [<span class="fl">1.5</span>, <span class="fl">1.7</span>, <span class="fl">3.6</span>, <span class="fl">2.4</span>, <span class="fl">2.9</span>]}</span>
<span id="cb14-21"><a href="#cb14-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-22"><a href="#cb14-22" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.DataFrame(data)</span>
<span id="cb14-23"><a href="#cb14-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (df)</span>
<span id="cb14-24"><a href="#cb14-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-25"><a href="#cb14-25" aria-hidden="true" tabindex="-1"></a>vocabs <span class="op">=</span> []</span>
<span id="cb14-26"><a href="#cb14-26" aria-hidden="true" tabindex="-1"></a>vals <span class="op">=</span> [<span class="st">&#39;Ohio&#39;</span>,<span class="st">&#39;Nevada&#39;</span>]</span>
<span id="cb14-27"><a href="#cb14-27" aria-hidden="true" tabindex="-1"></a>vocabs.append(<span class="bu">dict</span>(<span class="bu">zip</span>(vals,<span class="bu">range</span>(<span class="bu">len</span>(vals)))))</span>
<span id="cb14-28"><a href="#cb14-28" aria-hidden="true" tabindex="-1"></a>vals <span class="op">=</span> [<span class="st">&#39;2000&#39;</span>,<span class="st">&#39;2001&#39;</span>,<span class="st">&#39;2002&#39;</span>]</span>
<span id="cb14-29"><a href="#cb14-29" aria-hidden="true" tabindex="-1"></a>vocabs.append(<span class="bu">dict</span>(<span class="bu">zip</span>(vals,<span class="bu">range</span>(<span class="bu">len</span>(vals)))))</span>
<span id="cb14-30"><a href="#cb14-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-31"><a href="#cb14-31" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (vocabs)</span>
<span id="cb14-32"><a href="#cb14-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-33"><a href="#cb14-33" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (one_hot_column(df, [<span class="st">&#39;state&#39;</span>,<span class="st">&#39;year&#39;</span>], vocabs).todense())</span></code></pre></div>
<pre class="text"><code>    state  year  pop
0    Ohio  2000  1.5
1    Ohio  2001  1.7
2    Ohio  2002  3.6
3  Nevada  2001  2.4
4  Nevada  2002  2.9
[{&#39;Ohio&#39;: 0, &#39;Nevada&#39;: 1}, {&#39;2000&#39;: 0, &#39;2001&#39;: 1, &#39;2002&#39;: 2}]
[[1.5 1.  0.  1.  0.  0. ]
 [1.7 1.  0.  0.  1.  0. ]
 [3.6 1.  0.  0.  0.  1. ]
 [2.4 0.  1.  0.  1.  0. ]
 [2.9 0.  1.  0.  0.  1. ]]</code></pre>
<p><code>one_hot_column</code> çağrısına bir “sözlükler listesi” verdik,
sözlük her kolon için o kolonlardaki mümkün tüm değerleri bir sıra
sayısı ile eşliyor. Sözlük listesinin sırası kolon sırasına uyuyor
olmalı.</p>
<p>Niye sözlük verdik? Bunun sebebi eğer azar azar (incremental) ortamda
iş yapıyorsak, ki Büyük Veri (Big Data) ortamında her zaman azar azar
yapay öğrenim yapmaya mecburuz, o zaman bir kategorik kolonun mevcut tüm
değerlerine azar azar ulaşamazdık (verinin başında isek, en sonundaki
bir kategorik değeri nasıl görelim ki?). Fakat önceden bu listeyi başka
yollarla elde etmişsek, o zaman her öne-hot işlemine onu parametre
olarak geçiyoruz.</p>
<p>Sözlük niye <code>one_hot_dataframe</code> çağrısı dışında yaratıldı?
Bu çağrı düz bir liste alıp oradaki değerleri sırayla bir sayıyla
eşleyerek her seferinde bir sözlük yaratabilirdi. Bunu yapmadık, çünkü
sözlük yaratımının sadece bir kere, <code>one_hot_dataframe</code>
dışında olmasını istiyoruz. Yine Büyük Veri ortamını düşünenelim, eşleme
(map) için mesela bir script yazdık, bu script içinde (basında) hemen
sözlükler yaratılırdı. Daha sonra verinin tamamı için, azar azar sürekli
<code>one_hot_dataframe</code> çağrısı yapılacaktır. O zaman arka arkaya
sürekli aynı veriyi (sözlükleri) sıfırdan tekrar yaratmamız gerekirdi.
Bu gereksiz performans kaybı demek olacaktı. Unutmayalım, Büyük Veri
ortamında tek bir kategorik kolonun milyonlarca değişik değeri
olabilir!</p>
<p>Azar Azar İşlemek (Incremental, Minibatch Processing)</p>
<p>Çoğu zaman onlarca kategori, birkaç milyonluk satır içeren bir veriye
bakmamız gerekiyor; biliyoruz ki bu kadar veri için Büyük Veri
teknolojilerine (mesela Spark, Hadoop gibi) geçmek gereğinden fazla
külfet getirecek, elimizdeki dizüstü, masaüstü bilgisayarı bu işlemler
için yeterli olmalı, fakat çoğu kütüphane tek makinada azar azar işlem
yapmak için yazılmamış. Mesela üstte görülen anahtarlama yöntemi
anahtarlama başlamadan önce tüm verinin hafızaya alınmasını
gerektiriyor.</p>
<p>Bu durumda kendimiz çok basit Python kavramlarını, iyi bir
anahtarlama kodunu, ve lineer cebir hesaplarında seyreklik (sparsity)
tekniklerini kullanarak ufak veri parçaları işleyen bir ortamı
yaratabiliriz.</p>
<p>Örnek veri olarak [4] yazısında görülen oy kalıpları verisini biraz
değiştirerek yeni bir analiz için kullanalım. Veri oy verenlerin ırk,
cinsiyet, meslek, hangi partiye oy verdikleri ve kazançlarını kaydetmiş,
biz analizimizde bahsedilen kategorilerin bu kişilerin kazancıyla
bağlantılı olup olmadığına bakacağız. Veriyi oluşturalım,</p>
<div class="sourceCode" id="cb16"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(<span class="st">&#39;../stat_075_logit/nes.dat&#39;</span>,sep<span class="op">=</span><span class="vs">r&#39;\s+&#39;</span>)</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> df[[<span class="st">&#39;presvote&#39;</span>,<span class="st">&#39;year&#39;</span>,<span class="st">&#39;gender&#39;</span>,<span class="st">&#39;income&#39;</span>,<span class="st">&#39;race&#39;</span>,<span class="st">&#39;occup1&#39;</span>]]</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> df.dropna()</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>df.to_csv(<span class="st">&#39;nes2.csv&#39;</span>,index<span class="op">=</span><span class="va">None</span>)</span></code></pre></div>
<p>Önce kategorilerden ne kadar var, sayalım. Basit toplam yani,</p>
<div class="sourceCode" id="cb17"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(<span class="st">&#39;nes2.csv&#39;</span>)</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (<span class="st">u&#39;tüm veri&#39;</span>, <span class="bu">len</span>(df))</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (<span class="st">&#39;cinsiyet&#39;</span>, np.array(df[<span class="st">&#39;gender&#39;</span>].value_counts()))</span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (<span class="st">u&#39;ırk&#39;</span>, np.array(df[<span class="st">&#39;race&#39;</span>].value_counts()))</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (<span class="st">&#39;parti&#39;</span>, np.array(df[<span class="st">&#39;presvote&#39;</span>].value_counts()))</span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (<span class="st">u&#39;kazanç&#39;</span>, df[<span class="st">&#39;income&#39;</span>].mean())</span></code></pre></div>
<pre class="text"><code>tüm veri 13804
cinsiyet [7461 6343]
ırk [12075  1148   299   180    85    17]
parti [6998 6535  271]
kazanç 3.076499565343379</code></pre>
<p>Mesela son sonuçtaki her hücre belli bir partiye verilen oyların
sayısı; veriye göre üç farklı kategori varmış demek ki, veri ABD için
olduğuna göre bunlardan ilk ikisi bilinen iki büyük parti, üçüncü hücre
de herhalde bağımsız adaylar.</p>
<p>Kazanç 1 ile 5 arasında tam sayılar (1 az, 5 çok) bu sayıları
kategorik olarak kabul edip aslında çok çıktılı bir sınıflayıcı eğitmeyi
de seçebilirdik, fakat bu örnek için bu sayıları reel hedef olarak
aldık: test verisinde tahminleri bakılırsa 2.5’lük kazanç tahminleri
görülebilir, bu yüzden.</p>
<p>Kategorik verileri ikileştirmeye gelelim. Burada üç nokta önemli,
veriyi azar azar işleyeceğiz demiştik, ve veriyi seyrek matris olarak
almak istiyoruz, ve hangi kategorik değerin hangi kolona eşleneceğini
elle tanımlamak istemiyoruz (eşleme otomatik olmalı). Seyreklik önemli
çünkü eğer 1000 farklı kategorik değere sahip olan 10 tane kolon varsa,
bu 10000 tane yeni kolon yaratılması demektir - her farklı kategori için
o değere tekabül eden kolon 1 olacak gerisi 0 olacak. Bu rakamlar orta
ölçekte bile rahatlıkla milyonlara ulaşabilir. Eğer ikileştirme için
seyrek matris kullanırsak çoğu sıfır olan değerler hafızada bile
tutulmaz. Eşleme otomatik olmalı, zaten onun için anahtarlama
yapacağız.</p>
<p>Anahtarlama icin
<code>sklearn.feature_extraction.text.HashingVectorizer</code> var,</p>
<div class="sourceCode" id="cb19"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.feature_extraction.text <span class="im">import</span> HashingVectorizer</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>vect <span class="op">=</span> HashingVectorizer(n_features<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> [<span class="st">&#39;aa&#39;</span>,<span class="st">&#39;bb&#39;</span>,<span class="st">&#39;cc&#39;</span>]</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>res <span class="op">=</span> vect.transform(a)</span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (res)</span></code></pre></div>
<pre class="text"><code>&lt;Compressed Sparse Row sparse matrix of dtype &#39;float64&#39;
    with 3 stored elements and shape (3, 20)&gt;
  Coords    Values
  (0, 5)    1.0
  (1, 19)   1.0
  (2, 18)   -1.0</code></pre>
<p>Sonuçlar seyrek matris olarak, ve üç değer için üç ayrı satır olarak
geldi. Anahtarlama niye bazen -1 bazen +1 veriyor? Aslında bu bizim için
çok faydalı, çünkü birazdan PCA işleteceğiz, ve PCA her veri kolonunun
sıfırda ortalanmış olmasını ister. Üstteki teknikte anahtar üreten
fonksiyon -1,+1 arasında rasgele seçim yapıyor gibi duruyor, bize göre
bu üretilen anahtar kolonlarında -1, +1 değerlerinin doğal olarak
dengelenmesi için yapılmış, böylece otomatik olarak ortalamaları sıfıra
inecektir. Akıllıca bir teknik.</p>
<p>Devam edelim, sonucu tek satır olacak şekilde kendimiz tekrar
düzenleyebiliriz. O zaman Python <code>yield</code> kavramını [3]
kullanarak (azar azar satır okumak için), anahtarlama, ve seyrek
matrisler ile şu şekilde bir kod olabilir,</p>
<div class="sourceCode" id="cb21"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.feature_extraction.text <span class="im">import</span> HashingVectorizer</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd, csv</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> scipy.sparse <span class="im">as</span> sps</span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a>HASH <span class="op">=</span> <span class="dv">30</span></span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a>vect <span class="op">=</span> HashingVectorizer(decode_error<span class="op">=</span><span class="st">&#39;ignore&#39;</span>,n_features<span class="op">=</span>HASH)</span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_row(cols):</span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> <span class="bu">open</span>(<span class="st">&quot;nes2.csv&quot;</span>, <span class="st">&#39;r&#39;</span>) <span class="im">as</span> csvfile:</span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a>        rd <span class="op">=</span> csv.reader(csvfile)</span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a>        headers <span class="op">=</span> {k: v <span class="cf">for</span> v, k <span class="kw">in</span> <span class="bu">enumerate</span>(<span class="bu">next</span>(rd))}</span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> row <span class="kw">in</span> rd:</span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a>            label <span class="op">=</span> <span class="bu">float</span>(row[headers[<span class="st">&#39;income&#39;</span>]])</span>
<span id="cb21-15"><a href="#cb21-15" aria-hidden="true" tabindex="-1"></a>            rrow <span class="op">=</span> [x <span class="op">+</span> <span class="bu">str</span>(row[headers[x]]) <span class="cf">for</span> x <span class="kw">in</span> headers <span class="cf">if</span> x <span class="kw">in</span> cols]</span>
<span id="cb21-16"><a href="#cb21-16" aria-hidden="true" tabindex="-1"></a>            X_train <span class="op">=</span> vect.transform(rrow)</span>
<span id="cb21-17"><a href="#cb21-17" aria-hidden="true" tabindex="-1"></a>            <span class="cf">yield</span> X_train.tocoo(), label            </span>
<span id="cb21-18"><a href="#cb21-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-19"><a href="#cb21-19" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_minibatch(row_getter,size<span class="op">=</span><span class="dv">10</span>):</span>
<span id="cb21-20"><a href="#cb21-20" aria-hidden="true" tabindex="-1"></a>    X_train <span class="op">=</span> sps.lil_matrix((size,HASH))</span>
<span id="cb21-21"><a href="#cb21-21" aria-hidden="true" tabindex="-1"></a>    y_train <span class="op">=</span> []</span>
<span id="cb21-22"><a href="#cb21-22" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(size):</span>
<span id="cb21-23"><a href="#cb21-23" aria-hidden="true" tabindex="-1"></a>        cx,y <span class="op">=</span> <span class="bu">next</span>(row_getter)</span>
<span id="cb21-24"><a href="#cb21-24" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> dummy,j,val <span class="kw">in</span> <span class="bu">zip</span>(cx.row, cx.col, cx.data): X_train[i,j] <span class="op">=</span> val</span>
<span id="cb21-25"><a href="#cb21-25" aria-hidden="true" tabindex="-1"></a>        y_train.append(y)</span>
<span id="cb21-26"><a href="#cb21-26" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> X_train, y_train</span>
<span id="cb21-27"><a href="#cb21-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-28"><a href="#cb21-28" aria-hidden="true" tabindex="-1"></a><span class="co"># tek bir satir goster    </span></span>
<span id="cb21-29"><a href="#cb21-29" aria-hidden="true" tabindex="-1"></a>cols <span class="op">=</span> [<span class="st">&#39;gender&#39;</span>,<span class="st">&#39;income&#39;</span>,<span class="st">&#39;race&#39;</span>,<span class="st">&#39;occup1&#39;</span>]</span>
<span id="cb21-30"><a href="#cb21-30" aria-hidden="true" tabindex="-1"></a>row_getter <span class="op">=</span> get_row(cols)</span>
<span id="cb21-31"><a href="#cb21-31" aria-hidden="true" tabindex="-1"></a>X,y <span class="op">=</span> get_minibatch(row_getter,size<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb21-32"><a href="#cb21-32" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (y, X.todense())</span></code></pre></div>
<pre class="text"><code>[4.0] [[ 0.  0.  0. -1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.
   0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.]]</code></pre>
<p>İlgilendiğimiz kolon listesini <code>get_row</code>’a verip bir
gezici fonksiyon yarattık. Bu geziciyi <code>get_minibatch</code>’e
verdik, kaç tane satır istediğimizi ona söylüyoruz, o bize istenen kadar
satırı arka planda geziciye sorarak seyrek matris olarak veriyor. 10
tane daha isteyelim,</p>
<div class="sourceCode" id="cb23"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>X,y <span class="op">=</span> get_minibatch(row_getter,size<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (<span class="bu">len</span>(y), X.shape, <span class="bu">type</span>(X))</span></code></pre></div>
<pre class="text"><code>10 (10, 30) &lt;class &#39;scipy.sparse._lil.lil_matrix&#39;&gt;</code></pre>
<p>PCA</p>
<p>Lineer Cebir’in temel bileşen analizi (PCA) tekniğini kullanarak
boyut azaltması yapabiliriz. Veriyi yine satır satır işleyerek PCA
hesabı yapan teknikler var, kod veriyi seyrek formatta da alabiliyor. Bu
kod lineer cebir PCA yazısında işlendi.</p>
<div class="sourceCode" id="cb25"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> sys<span class="op">;</span> sys.path.append(<span class="st">&#39;../stat_170_pca&#39;</span>)</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> ccipca</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>cols <span class="op">=</span> [<span class="st">&#39;gender&#39;</span>,<span class="st">&#39;income&#39;</span>,<span class="st">&#39;race&#39;</span>,<span class="st">&#39;occup1&#39;</span>]</span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>row_getter <span class="op">=</span> get_row(cols)</span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>pca <span class="op">=</span> ccipca.CCIPCA(n_components<span class="op">=</span><span class="dv">10</span>,n_features<span class="op">=</span><span class="dv">30</span>)</span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">10000</span>): </span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a>    X,y <span class="op">=</span> get_minibatch(row_getter,size<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a>    pca.partial_fit(X)</span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a>pca.post_process()</span>
<span id="cb25-10"><a href="#cb25-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-11"><a href="#cb25-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (<span class="st">&#39;varyans orani&#39;</span>)</span>
<span id="cb25-12"><a href="#cb25-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (pca.explained_variance_ratio_)</span></code></pre></div>
<pre class="text"><code>varyans orani
[0.36085857 0.16186335 0.13378078 0.0944093  0.07027158 0.05112654
 0.04767845 0.03433509 0.02341634 0.02225999]</code></pre>
<p>Her bileşenin verideki varyansın ne kadarını açıkladığı
görülüyor.</p>
<p>Peki 30 kolonu 10 kolona indirdik, acaba veri temsilinde, tahmin
etmek amacında ilerleme elde ettik mi? Veriyi PCA’nın bulduğu uzaya
yansıtıp bu boyutu azaltılmış veriyi regresyonda kullansak ne olur
acaba? Yansıtma ve regresyon,</p>
<div class="sourceCode" id="cb27"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> SGDRegressor</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> SGDRegressor(random_state<span class="op">=</span><span class="dv">1</span>, max_iter<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>row_getter <span class="op">=</span> get_row(cols)</span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a>P <span class="op">=</span> pca.components_.T</span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">10000</span>):</span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a>    X_train, y_train <span class="op">=</span> get_minibatch(row_getter,<span class="dv">1</span>)</span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a>    Xp <span class="op">=</span> np.dot((X_train<span class="op">-</span>pca.mean_),P)</span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a>    clf.partial_fit(np.asarray(Xp), y_train)</span></code></pre></div>
<p>Şimdi sonraki 1000 satırı test için kullanalım,</p>
<div class="sourceCode" id="cb28"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>y_predict <span class="op">=</span> []</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>y_real <span class="op">=</span> []</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1000</span>):</span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a>    X_test,y_test <span class="op">=</span> get_minibatch(row_getter,<span class="dv">1</span>)</span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a>    Xp <span class="op">=</span> np.dot((X_test<span class="op">-</span>pca.mean_),P)</span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a>    y_predict.append(clf.predict(np.asarray(Xp))[<span class="dv">0</span>])</span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a>    y_real.append(y_test[<span class="dv">0</span>])</span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a>y_predict <span class="op">=</span> np.array(y_predict)</span>
<span id="cb28-9"><a href="#cb28-9" aria-hidden="true" tabindex="-1"></a>y_real <span class="op">=</span> np.array(y_real)</span>
<span id="cb28-10"><a href="#cb28-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-11"><a href="#cb28-11" aria-hidden="true" tabindex="-1"></a>err <span class="op">=</span> np.sqrt(((y_predict<span class="op">-</span>y_real)<span class="op">**</span><span class="dv">2</span>).<span class="bu">sum</span>()) <span class="op">/</span> <span class="bu">len</span>(y_predict)</span>
<span id="cb28-12"><a href="#cb28-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (<span class="st">&#39;ortalama tahmin hatasi&#39;</span>, err)</span>
<span id="cb28-13"><a href="#cb28-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (<span class="st">&#39;maksimum deger&#39;</span>, np.<span class="bu">max</span>(y_real))</span></code></pre></div>
<pre class="text"><code>ortalama tahmin hatasi 0.010598462941579465
maksimum deger 5.0</code></pre>
<p>1 ile 5 arasında gidip gelen değerlerin tahmininde 0.01 civarı
ortalama hata var. Fena değil. Peki verinin kendisini olduğu gibi alıp
regresyonda kullansaydık? Hedef verisi kazanç, kaynak kolonları geri
kalan kategoriler. Üstte olduğu gibi veri parçaları 1000’er satır, 10
parça olarak alacağız, yani 10,000 satır modeli eğitmek için
kullanılacak. Geri kalanlar test verisi olacak.</p>
<p><code>sklearn.linear_model.SGDRegressor</code> ufak seyrek matris
parçaları ile eğitilebiliyor,</p>
<div class="sourceCode" id="cb30"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> SGDRegressor</span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> SGDRegressor(random_state<span class="op">=</span><span class="dv">1</span>, max_iter<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a>row_getter <span class="op">=</span> get_row(cols)</span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a>y_predict <span class="op">=</span> []<span class="op">;</span> y_real <span class="op">=</span> []</span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-7"><a href="#cb30-7" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">10</span>):</span>
<span id="cb30-8"><a href="#cb30-8" aria-hidden="true" tabindex="-1"></a>    X_train, y_train <span class="op">=</span> get_minibatch(row_getter,<span class="dv">1000</span>)</span>
<span id="cb30-9"><a href="#cb30-9" aria-hidden="true" tabindex="-1"></a>    clf.partial_fit(X_train, y_train)</span></code></pre></div>
<div class="sourceCode" id="cb31"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a>X_test,y_test <span class="op">=</span> get_minibatch(row_getter,<span class="dv">1000</span>)</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>y_predict <span class="op">=</span> clf.predict(X_test) </span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a>err <span class="op">=</span> np.sqrt(((y_predict<span class="op">-</span>y_test)<span class="op">**</span><span class="dv">2</span>).<span class="bu">sum</span>()) <span class="op">/</span> <span class="bu">len</span>(y_predict)</span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (<span class="st">&#39;ortalama tahmin hatasi&#39;</span>, err)</span></code></pre></div>
<pre class="text"><code>ortalama tahmin hatasi 0.021197482640542296</code></pre>
<p>Bu sonuç ta hiç fena değil. Sonuç olarak veri içinde bazı kalıplar
olduğunu gördük, tahmin yapabiliyoruz. Hangi kolonların daha önemli
olduğunu bulmak için her kolonu teker teker atıp hatanın yukarı mı aşağı
mı indiğine bakabilirdik.</p>
<p>Tekrar vurgulamak gerekirse: üstteki analizde aslında çok fazla
kategorik veri yok, yani <code>statsmodels.formula.api</code> üzerinden
güzel formüllerle, regresyon çıktısında her kategorik değerin güzelce
listelendiği türden bir kullanıma da gidebilirdik. Bu yazıda göstermeye
çalıştığımız çok fazla veri, çok fazla kolon / kategori olduğunda ve tek
makina ortamında takip edilebilecek çözümler.</p>
<p>Zaman Karşılaştırmak</p>
<p>Eğer 23:50 ile sabah 00:10 zamanını karşılaştırmak istersek ne
yaparız? Eğer saat ve dakika farkını direk hesaplasak bu iki zamanın çok
uzak olduğunu düşünebilirdik. Fakat aslında aralarında 20 dakika var,
zaman dönüp başa gelen bir kavram.</p>
<p><img src="stat_feat_01.png" /></p>
<p>Bu hesabı yapmak için bir yöntem çember, açılar kullanmak. Gün
içindeki zamanı 0 ile 1 arasında kodlarız, sonra bu büyüklüğü <span
class="math inline">\(2\pi\)</span> ile çarparız, bu bize çember
üzerindeki bir noktayı verir, yani zamanı açıya çevirmiş oluruz. Sonra
açının <span class="math inline">\(\sin\)</span>, <span
class="math inline">\(\cos\)</span> değerini hesaplayıp iki rakam elde
ederiz, bu iki sayı bize gün içindeki zamanı temsil eden bir büyüklük
verir.</p>
<p>Bu büyüklükleri birbirleri ile karşılaştırmak daha kolay, üstteki
şekilde <span class="math inline">\(\theta_2\)</span> ve <span
class="math inline">\(\theta_3\)</span> birbirine yakın, karşılaştırma
yaparken <span class="math inline">\(\sin\)</span> bize dikey eksendeki
izdüşümü, <span class="math inline">\(\cos\)</span> yatay eksendeki
izdüşümünü verir, <span class="math inline">\(\theta_2,\theta_3\)</span>
için y eksenindeki yansıma birbirine çok yakın. Eksen x üzerindeki
yansıma farklı biri eksi biri artı yönde fakat yine de mutlak değer
bağlamında birbirlerine çok yakınlar. İstediğimiz de bu zaten.</p>
<div class="sourceCode" id="cb33"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> scipy.linalg <span class="im">as</span> lin</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a>t1 <span class="op">=</span> <span class="fl">0.12</span> <span class="op">*</span> <span class="dv">2</span><span class="op">*</span>np.pi</span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a>t2 <span class="op">=</span> <span class="fl">0.97</span> <span class="op">*</span> <span class="dv">2</span><span class="op">*</span>np.pi</span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a>t3 <span class="op">=</span> <span class="fl">0.03</span> <span class="op">*</span> <span class="dv">2</span><span class="op">*</span>np.pi</span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true" tabindex="-1"></a>d1 <span class="op">=</span> (np.cos(t1), np.sin(t1))</span>
<span id="cb33-8"><a href="#cb33-8" aria-hidden="true" tabindex="-1"></a>d2 <span class="op">=</span> (np.cos(t2), np.sin(t2))</span>
<span id="cb33-9"><a href="#cb33-9" aria-hidden="true" tabindex="-1"></a>d3 <span class="op">=</span> (np.cos(t3), np.sin(t3))</span>
<span id="cb33-10"><a href="#cb33-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-11"><a href="#cb33-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (<span class="st">&quot;</span><span class="sc">%f</span><span class="st"> </span><span class="sc">%f</span><span class="st">&quot;</span> <span class="op">%</span> d1)</span>
<span id="cb33-12"><a href="#cb33-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (<span class="st">&quot;</span><span class="sc">%f</span><span class="st"> </span><span class="sc">%f</span><span class="st">&quot;</span> <span class="op">%</span> d2)</span>
<span id="cb33-13"><a href="#cb33-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (<span class="st">&quot;</span><span class="sc">%f</span><span class="st"> </span><span class="sc">%f</span><span class="st">&quot;</span> <span class="op">%</span> d3)</span>
<span id="cb33-14"><a href="#cb33-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-15"><a href="#cb33-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (<span class="st">u&#39;uzaklık 1-2 =&#39;</span>, lin.norm(np.array(d1)<span class="op">-</span>np.array(d2)))</span>
<span id="cb33-16"><a href="#cb33-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (<span class="st">u&#39;uzaklık 2-3 =&#39;</span>, lin.norm(np.array(d2)<span class="op">-</span>np.array(d3)))</span></code></pre></div>
<pre class="text"><code>0.728969 0.684547
0.982287 -0.187381
0.982287 0.187381
uzaklık 1-2 = 0.9079809994790936
uzaklık 2-3 = 0.3747626291714493</code></pre>
<p>Kaynaklar</p>
<p>[1] Teetor, <em>R Cookbook</em></p>
<p>[2] Scikit-Learn Documentation, <em>4.2. Feature extraction</em>, <a
href="http://scikit-learn.org/dev/modules/feature_extraction.html">http://scikit-learn.org/dev/modules/feature_extraction.html</a></p>
<p>[3] Bayramlı, <em>Fonksiyon Gezmek ve Yield</em>, <a
href="https://burakbayramli.github.io/dersblog/sk/2011/02/fonksiyon-gezmek-ve-yield.html">https://burakbayramli.github.io/dersblog/sk/2011/02/fonksiyon-gezmek-ve-yield.html</a></p>
<p>[4] Bayramlı, Istatistik, <em>Lineer Regresyon</em></p>
<p>
  <a href="..">Yukarı</a>
</p>
</body>
</html>
