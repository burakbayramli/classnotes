<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
    <script type="text/x-mathjax-config">
    MathJax.Hub.Register.StartupHook("TeX Jax Ready",function () {
      MathJax.Hub.Insert(MathJax.InputJax.TeX.Definitions.macros,{
        cancel: ["Extension","cancel"], cancelto: ["Extension","cancel"]
      });
    });
    </script>  
   
  <title>Bayes Usulü İstatistiki Analiz</title>
  <style type="text/css">code{white-space: pre;}</style>
  <style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
  </style>
  <script
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS_HTML-full"
  type="text/javascript"></script>
</head>
<body>
<div id="header">
</div>
<h1 id="bayes-usulü-istatistiki-analiz">Bayes Usulü İstatistiki
Analiz</h1>
<p>Veri analizinde Bayes teorisi kullanımı sayesinde veri olasılığı,
bilmediğimiz parametreler hakkındaki bazı bilgilerimizi formülasyona
dahil edebiliyoruz. Bunun bir örneğini MAP hesaplarını işlerken gördük.
Bu bölümde Bayes formüllerinin sonuçlarını bulmak için bazı hesapsal
teknikleri işleyeceğiz, ve niye faydalı olduklarını anlamaya
uğraşacağız. Temel olasılık teorisinden biliyoruz ki Bayes teorisi</p>
<p><span class="math display">\[
P(A | B) = \frac{P(B|A) P(A)}{P(B)}
\]</span></p>
<p>diye gider. Üstteki formülü veri analizine uyarlayabiliriz.
İstatistiki modelin parametreleri <span
class="math inline">\(\theta\)</span>’yi <span class="math inline">\(A =
\theta\)</span> yaparız, <span class="math inline">\(B =
\textrm{veri}\)</span> diyelim, o zaman Bayes teorisi eldeki verinin
parametre hesabı <span class="math inline">\(\theta\)</span> için nasıl
kullanılacağının formülünü gösterir [3, Chapter 1],</p>
<p><span class="math display">\[
P(\theta | \textrm{veri}) =
\frac{P(\textrm{veri} | \theta) \times
P(\theta)}{P(\textrm{veri})}
\]</span></p>
<p>Formül öğelerinin açıklamasını [4] yazısında bulabiliriz. Tekrarlamak
gerekirse, sol tarafta, veriyi gördükten sonra ne bildiğinizi temsil
eden, sonsal dağılım olan <span class="math inline">\(P(\theta \mid
\text{veri})\)</span> bulunur. Bu, çıkarımın temelini oluşturur ve
açıkça aradığınız şeydir; eğer birden fazla parametreniz varsa,
muhtemelen çok değişkenli bir dağılım. Sağ tarafta, olurluk olan <span
class="math inline">\(P(\text{veri} \mid \theta)\)</span> bulunur. Bu
miktar, En Yüksek Olurluk Tahmini (MLE) yaklaşımındaki ile aynıdır.
Evet, Bayeşçi ve frekansçı yaklaşımların çekirdeğinde aynı olurluk
bulunur, bu da sonuçların genellikle neden çok farklı olmadığını büyük
ölçüde açıklar. Olurluk, <span class="math inline">\(\theta\)</span> ile
parametrelendirilmiş bir model verildiğinde, verinizdeki bilginin
olasılığını gösterir. Dikkat, <span
class="math inline">\(P(\textrm{veri})\)</span> ve <span
class="math inline">\(P(\theta)\)</span> tanımları ile bu iki öğeyi
birer rasgele değişken olarak formülasyona dahil etmiş oluyoruz. Bunun
ne anlama geldiğini [4]’te işledik.</p>
<p>Ardından, önsel dağılım olan <span
class="math inline">\(P(\theta)\)</span> gelir. Bu miktar, veriyi
görmeden önce ne bildiğinizi temsil eder. Eğer <span
class="math inline">\(\theta\)</span> hakkında hiçbir şey bilmiyorsanız,
belirsiz olabilir. Ancak genellikle sıfırdan başlamazsınız ve
önselinizin sahip olduğunuz bilgiyi yansıtmasını istersiniz, mesela bir
zar atımında zarların 1 ve 3 arası gelmesi daha muhtemel ise bu bilgiyi
bir onsel olasılık olarak modele dahil etmek mümkündür.</p>
<p>Son olarak, bazen ortalama olurluk olarak adlandırılan <span
class="math inline">\(P(\text{veri})\)</span> bulunur, çünkü sonsalın
standartlaştırılması, yani bir dağılım olması için bire entegre olması
amacıyla, olurluk önsele göre entegre edilerek elde edilir: <span
class="math inline">\(P(\text{veri}) = \int P(\text{veri} \mid \theta)
P(\theta)d\theta\)</span>. Ortalama olurluk, tahmin etmeniz gereken
<span class="math inline">\(\theta\)</span> parametrelerinin sayısı
boyutunda bir integraldir. Bu, genel olarak hesaplanması imkansız olmasa
da zordur. Bayesçi yöntemin yakın zamana kadar kullanılmamasının
nedenlerinden biri de budur.</p>
<p>Örneğin, ekolojide kullanilan bir yakalama-tekrar yakalama modelini,
tespit olasılığı <span class="math inline">\(p\)</span> ve hayatta kalma
olasılığı ile bir kovaryat arasındaki ilişkinin kesişim ve eğimi için
regresyon parametreleri <span class="math inline">\(\alpha\)</span> ve
<span class="math inline">\(\beta\)</span> ile uyarlamak istediğinizi
düşünün. Bu durumda Bayes teoremi, her üç parametrenin birlikteki sonsal
dağılımını size verir:</p>
<p><span class="math display">\[P(\alpha, \beta, p \mid \text{veri}) =
\frac{P(\text{veri} \mid
\alpha, \beta, p) \times P(\alpha, \beta, p)}{\iiint P(\text{veri}
\mid \alpha, \beta, p) P(\alpha, \beta, p)d\alpha d\beta
dp}\]</span></p>
<p>Bu formülde bir hesaplama zorluğu var. Bölende üç boyutlu bir
integrali görüyoruz, bu entegral çok çetrefilli bir çözümdür, analitik
çözüm çoğunlukla mümkün değildir, hesapsal yaklaşımlar gerekir. Bu
entegralin her durumda hesaplanması gerekmeyebiliyor, mesela [4]’te
gördük ki aranılan bir parametre maksimize edilmeye çalışılan büyüklükte
bölen değerine ihtiyaç duymuyordu, bu sebeple onu yok sayabildik. Fakat
bazen bölendeki entegral kesinlikle gerekir, mesela iki farklı Bayes
modelini karşılaştırıyorsak, bölendeki değer iptal edilemez, ve
hesaplanması gerekir.</p>
<p>Fakat bölümdeki entegral lazım olmasa bile, yani normalize edici
katsayıyı bilmeden yine de sonsal dağılıma “orantılı” bir sonuç elde
edebilsek bile, orada da analitik sonuç alamayacağımız ortaya
çıkabiliyor, ve orada için yine yaklaşık yöntemlere başvurmamız
gerekiyor.</p>
<p>Bir deneyde tepki süresi ölçümlerinden oluşan tek değişkenli verilere
sahip olduğumuzu varsayalım. Bu veriyi modellemek için, Weibull
dağılımının faydalı bir tanımlayıcı model olacağını varsayalım [6, sf.
42].</p>
<p>Weibull için olasılık yoğunluk fonksiyonu şudur:</p>
<p><span
class="math display">\[p(y|a,b)=ba^{-b}y^{b-1}e^{-(\frac{y}{a})^{b}}I_{(0,inf)}(y)\]</span></p>
<p>Bu dağılımın iki parametresi vardır: a dağılımın ölçeğini ve b ise
dağılımın şeklini kontrol eder. Verilerimizin <span
class="math inline">\(y_{i}\)</span> ile temsil edildiğini, <span
class="math inline">\(i\in1..N\)</span> olduğunu ve <span
class="math inline">\(N\)</span>’nin gözlem sayısını gösterdiğini
varsayalım. Modelimizde, her gözlemin bir Weibull dağılımından bağımsız
bir çekiliş olduğunu varsayalım.</p>
<p>Bu varsayımlar göz önüne alındığında, verilerimiz için artık bir
olurluk fonksiyonuna (likelihood function) sahibiz. Her gözlemin <span
class="math inline">\(a\)</span> ve <span
class="math inline">\(b\)</span> parametrelerine sahip bir Weibull’dan
bağımsız bir çekiliş olduğu varsayılırsa, tüm gözlemlerin olasılığı şu
şekilde verilir:</p>
<p><span
class="math display">\[p(y_{1},...,y_{N}|a,b)=p(y_{1}|a,b)p(y_{2}|a,b)...p(y_{N}|a,b)\]</span>
<span class="math display">\[=\prod_{i}p(y_{i}|a,b)\]</span> <span
class="math display">\[=\prod_{i}ba^{-b}y_{i}^{b-1}e^{-{(\frac{y_{i}}{a})}^{b}}I_{(0,inf)}(y_{i})\]</span></p>
<p>Ancak model tanımımızla henüz tamamen işimiz bitmedi. Her Bayesci
analizde, parametreler üzerinde önsel dağılımları (prior distributions)
da belirtmemiz gerekir. <span class="math inline">\(a\)</span> ve <span
class="math inline">\(b\)</span> parametrelerinin sırasıyla <span
class="math inline">\(\lambda_{a}\)</span> ve <span
class="math inline">\(\lambda_{b}\)</span> parametrelerine sahip bir
üstel dağılıma (exponential distribution) göre bağımsız olarak
dağıldığını varsayalım.</p>
<p>Bu önsel dağılımların yogunluklari şunlardır</p>
<p><span
class="math display">\[p(a|\lambda_{a})=\frac{1}{\lambda_{a}}e^{-\frac{a}{\lambda_{a}}}\]</span>
<span
class="math display">\[p(a|\lambda_{b})=\frac{1}{\lambda_{b}}e^{-\frac{b}{\lambda_{b}}}\]</span></p>
<p>Yukarıda ifade edilen modelin, örnekleme notasyonu (sampling
notation) kullanılarak çok daha basit terimlerle açıklanabileceğini
belirtmeliyiz:</p>
<p><span class="math display">\[\begin{array}{l}y_{i}|a,b\sim
Weibull(a,b)\\a\sim
Exp(\lambda_{a})\\b\sim Exp(\lambda_{b})\end{array}\]</span></p>
<p>Artık hem bir olurluk hem de tüm parametreler üzerinde bir önsel
içeren, tamamen belirlenmiş bir modele sahibiz. Amaç, sonsal çıkarım
(posterior inference) yapmak ve verilere koşullu olarak parametreler
üzerindeki sonsal dağılımı bulmaktır.</p>
<p>Daha önce şunu belirtmiştik:</p>
<p><span class="math display">\[p(\theta|D)\propto
p(D|\theta)p(\theta)\]</span></p>
<p>Bizim durumumuzda, <span class="math inline">\(\theta=(a,b)\)</span>
ve <span class="math inline">\(D=(y_{1},...,y_{N})\)</span>’dir. Bu
nedenle, şunu yazabiliriz:</p>
<p><span class="math display">\[p(a,b|y_{1},...,y_{N})\propto
p(y_{1},...,y_{N}|a,b)p(a,b)\]</span></p>
<p><span class="math inline">\(a\)</span> ve <span
class="math inline">\(b\)</span> parametreleri üzerinde bağımsız önsel
kullanmaya karar verdiğimize dikkat edin. Bu bize şunu yazma olanağı
verir:</p>
<p><span class="math display">\[
p(a,b|y_{1},...,y_{N}) \propto p(y_{1},...,y_{N}|a,b)
\]</span></p>
<p>Bu sonsal dağılımın fonksiyonel biçiminin neye benzediğini görmek
için açılımı yapalım,</p>
<p><span class="math display">\[p(a,b|y_{1},...,y_{N}) \propto
\left(
   \prod_{i}ba^{-b}y_{i}^{b-1}e^{-(\frac{y_{i}}{a})^{b}}I_{(0,inf)}(y_{i})
\right)
\frac{1}{\lambda_{a}}e^{-\frac{a}{\lambda_{a}}}
\frac{1}{\lambda_{b}}e^{-\frac{b}{\lambda_{b}}}
\]</span></p>
<p>Bu ifade analitik tekniklere uygun değildir.</p>
<p>Hangi durumlarda çetrefil entegral hesapları muhakkak şart oluyor?
Mesela farklı modellerin olurluk oranı (likelihood ratio)
karşılaştırılması gerektiğinde ekstra hesap şart. “Ama hem bölen hem
bölünende aynı büyüklük / normalize edici sabit var ise birbirlerini
iptal etmezler mi?”. Farklı Bayes modellerinin farklı sabit edicileri
var ise, iptal mümkün olmaz. Örnek olarak <span
class="math inline">\(M1\)</span> ve <span
class="math inline">\(M2\)</span> modelleri var ise, bir entegral <span
class="math inline">\(\int P_{a}(\text{veri} \mid \theta)
P_b(\theta)d\theta\)</span> digeri <span class="math inline">\(\int
P_{c}(\text{veri} \mid \theta) P_d(\theta)d\theta\)</span> olabilir, bu
hesaplar farklı sonuçlar verecektir çünkü farklı yoğunluk fonksiyonları
ve parametreleri kullanıyor olurlar.</p>
<h3 id="pymc">PyMC</h3>
<p>Programcıları üstte tarif edilen hesapsal yükten kurtarmaya uğraşan
ve hesapların daha rahat programlanmasını sağlayan paketler var. Bu
paketler önsel / sonsal rasgele değişkenlerin tanımlanmasını neredeyse
tanımsal (declarative) hale getirerek alt seviye kodlama detaylarını
perde arkasına itebiliyorlar, ve bu şekilde Bayeşçi hesapların çabuk
gerçekleştirilmesini sağlıyorlar. Bu paketler sayesinde istenildiği
kadar rasgele değişken bağlantısı yaratalım, çözücü kodlar sonsal
dağılımdan örneklem alabiliyor. Bu tür paketler getirdikleri rahatlık
sayesinde neredeyse bir dil yaratmış oluyorlar, ve bazıları
terminolojiye yeni bir terim ekliyor: olasılıksal programlama
(probabilistic programming).</p>
<p>Bir örnek üzerinde görelim [7, sf. 8]. Standart istatistik
örneklerinden bilindiği gibi arda atılan madeni paranın yazı mı tura mı
geleceği Binom dağılımı ile temsil edilebilir. Eğer madeni paranın
yanlılığı yok ise (her iki seçenek eşit ihtimalde) bunu <span
class="math inline">\(X \sim Bin(N,p)\)</span> ile gösterebiliriz, ki
<span class="math inline">\(X\)</span> rasgele değişken yoğunluğu</p>
<p><span class="math display">\[
P(X = k) = {N \choose k} p^k (1-p)^{N-k}
\]</span></p>
<p>Burada <span class="math inline">\(N\)</span> tane deney içinde <span
class="math inline">\(k\)</span> tane başarı elde etmeninin olasılık
yoğunluk fonksiyonunu görüyoruz. Eğer yanlılık yok ise <span
class="math inline">\(p=0.5\)</span>, var ise mesela <span
class="math inline">\(p = 0.7\)</span>. Eğer yoğunluğu verilen ve
bilinen <span class="math inline">\(p\)</span> yoğunluğundan rasgele
örneklem toplamak istesek bunu yapabilirdik, yaygın kullanılan
kütüphanelerde bile böyle kodlar mevcuttur.</p>
<p>Eğer <span class="math inline">\(p\)</span> bilinmiyor olsaydı ve
elde deney verisi olsaydı, bilinmeyen <span
class="math inline">\(p\)</span>’yi bu veriden kestirmenin de yöntemleri
mevcuttur.</p>
<p>Modeli daha çetrefilleştirebilirdik. <span
class="math inline">\(p\)</span>’nin bilinip bilinmedigi bir yana, onu
tek bir sayı ile değil, <em>bir rasgele değişken</em>, mesela <span
class="math inline">\(\theta\)</span> üzerinden tanımlıyor olabilirdik.
Bu durumda,</p>
<p><span class="math display">\[
\theta \sim Beta(\alpha, \beta)
\]</span></p>
<p><span class="math display">\[
Y \sim Bin(n = 1, p = \theta)
\]</span></p>
<p>Şimdi rasgele örneklem üretmek iki aşamalı oldu, önce bir Beta
dağılımından örneklem alınacak, sonra bu alınan değer Bin dağılımından
örneklem için kullanılacak.</p>
<p>PyMC kodları burada devreye giriyor, Bayes yaklaşımı ile iki katmanlı
bir yapı oluşturduk, bir rasgele değişken diğerine bağlı, ve biz mevcut
veriyi de hesaba katan bir sonral dağılım <span
class="math inline">\(\theta\)</span>’dan örneklem alabiliriz.</p>
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pymc <span class="im">as</span> pm, scipy.stats <span class="im">as</span> stats</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span></code></pre></div>
<div class="sourceCode" id="cb2"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>Y <span class="op">=</span> stats.bernoulli(<span class="fl">0.7</span>).rvs(<span class="dv">20</span>)</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> pm.Model() <span class="im">as</span> model:</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>     theta <span class="op">=</span> pm.Beta(<span class="st">&quot;theta&quot;</span>, alpha<span class="op">=</span><span class="dv">1</span>, beta<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>     y_obs <span class="op">=</span> pm.Binomial(<span class="st">&quot;eta_obs&quot;</span>, n<span class="op">=</span><span class="dv">1</span>, p<span class="op">=</span>theta, observed<span class="op">=</span>Y)</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>     idata <span class="op">=</span> pm.sample(<span class="dv">1000</span>, return_inferencedata<span class="op">=</span><span class="va">True</span>)</span></code></pre></div>
<div class="sourceCode" id="cb3"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>theta_post <span class="op">=</span> np.array(idata.posterior[<span class="st">&#39;theta&#39;</span>])</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (np.mean(theta_post))</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>plt.hist(theta_post[<span class="dv">0</span>],bins<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>plt.savefig(<span class="st">&#39;tser_023_bsts_03.jpg&#39;</span>)</span></code></pre></div>
<pre class="text"><code>0.7246428574887125</code></pre>
<p><img width='300' src='tser_023_bsts_03.jpg'/></p>
<p>Görüldüğü gibi 0.7 odaklı yanlı veriyi modele verince kodlar bunun
sonsal <span class="math inline">\(\theta\)</span> dağılımına
yansımasını saptadı, ortalama 0.72 çıktı. Ayrıca tek bir sayı değil,
bütün bir dağılımı sonuç olarak aldığımız için çok daha çetrefil
analizleri bu sonuçtan alabiliriz.</p>
<p>Katmanlar alttaki gibi,</p>
<div class="sourceCode" id="cb5"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>graphviz <span class="op">=</span> pm.model_to_graphviz(model)</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>graphviz.graph_attr.update(dpi<span class="op">=</span><span class="st">&quot;300&quot;</span>)</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>graphviz.render(<span class="st">&quot;tser_023_bsts_02&quot;</span>, <span class="bu">format</span><span class="op">=</span><span class="st">&quot;jpg&quot;</span>)</span></code></pre></div>
<pre class="text"><code>Out[1]: &#39;tser_023_bsts_02.jpg&#39;</code></pre>
<p><img width="200px" src="tser_023_bsts_02.jpg"></p>
<h3 id="t-testi">T-Testi</h3>
<p>Bayeşçi yaklaşımın farkını üstteki örnekte görmeye başladık.
Parametreler hatta veri bile bir anlamda bir rasgele değişken haline
gelebiliyordu. Bu yaklaşım istatistiki analizin tüm yelpazesini etkiler,
mesela hipotez testi kavramı da Bayeşçi bağlamda yenilenebilir. Standart
müfredatta iyi bilinen t-testini örnek alalım mesela. Bu test örneklem
ortalamasının önceden tanımlı bir değerden sapma durumunu kontrol eder.
Bu testin Bayeşçi versiyonu Krusçke tarafından bulunmuştur, ona BEST
(Bayesian Estimation Süpersedes the t-test) adını vermiştir [1].</p>
<p>Mesela iki grubu birbiriyle karşılaştırıyoruz, pazarlamacıların iyi
bildiği bir A/B testi yapmamız gerekiyor. Test edilen iki Web sayfası
olabilir, ve kullanıcıların her sayfada ne kadar kaldığı verisi iki ayrı
grupta. Merak ettiğimiz kullanıcıların hangi sayfada daha fazla kaldığı,
A sayfasında mı, B sayfasında mı?</p>
<p>Suni veri yaratalım, veri Gaussian bazlı olsun,</p>
<div class="sourceCode" id="cb7"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>N <span class="op">=</span> <span class="dv">250</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>mu_A, std_A <span class="op">=</span> <span class="dv">30</span>, <span class="dv">4</span></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>mu_B, std_B <span class="op">=</span> <span class="dv">26</span>, <span class="dv">7</span></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>durations_A <span class="op">=</span> np.random.normal(mu_A, std_A, size<span class="op">=</span>N)</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>durations_B <span class="op">=</span> np.random.normal(mu_B, std_B, size<span class="op">=</span>N)</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (durations_A[:<span class="dv">8</span>])</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (durations_B[:<span class="dv">8</span>])</span></code></pre></div>
<pre class="text"><code>[30.09406244 36.43862561 38.55121675 22.88904474 25.18860278 25.58463466
 26.26095514 29.65196647]
[24.03905003 21.69379493 29.05057681 31.08319069 32.84439179 26.36658114
 23.38477673 27.86670832]</code></pre>
<p>İki farklı grubun farklı ortalaması, ve standart sapması var
(<code>mean</code>, <code>std</code> bunu hemen gösterirdi), veriyi ona
göre ürettik. Şimdi acaba birazdan göreceğimiz t-testi bu farkı
yakalayabilecek mi?</p>
<div class="sourceCode" id="cb9"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Pool the data for priors</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>pooled_mean <span class="op">=</span> np.r_[durations_A, durations_B].mean()</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>pooled_std <span class="op">=</span> np.r_[durations_A, durations_B].std()</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Build the model in modern PyMC</span></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> pm.Model() <span class="im">as</span> model:</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Priors</span></span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>    mu_A <span class="op">=</span> pm.Normal(<span class="st">&quot;mu_A&quot;</span>, mu<span class="op">=</span>pooled_mean, sigma<span class="op">=</span><span class="dv">1000</span><span class="op">*</span>pooled_std)</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>    mu_B <span class="op">=</span> pm.Normal(<span class="st">&quot;mu_B&quot;</span>, mu<span class="op">=</span>pooled_mean, sigma<span class="op">=</span><span class="dv">1000</span><span class="op">*</span>pooled_std)</span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>    std_A <span class="op">=</span> pm.Uniform(<span class="st">&quot;std_A&quot;</span>, lower<span class="op">=</span>pooled_std<span class="op">/</span><span class="fl">1000.</span>, upper<span class="op">=</span><span class="fl">1000.</span><span class="op">*</span>pooled_std)</span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a>    std_B <span class="op">=</span> pm.Uniform(<span class="st">&quot;std_B&quot;</span>, lower<span class="op">=</span>pooled_std<span class="op">/</span><span class="fl">1000.</span>, upper<span class="op">=</span><span class="fl">1000.</span><span class="op">*</span>pooled_std)</span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a>    nu_minus_1 <span class="op">=</span> pm.Exponential(<span class="st">&quot;nu_minus_1&quot;</span>, lam<span class="op">=</span><span class="fl">1.</span><span class="op">/</span><span class="dv">29</span>)</span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a>    nu <span class="op">=</span> pm.Deterministic(<span class="st">&quot;nu&quot;</span>, nu_minus_1 <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Likelihood - using StudentT instead of NoncentralT</span></span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a>    obs_A <span class="op">=</span> pm.StudentT(<span class="st">&quot;obs_A&quot;</span>, nu<span class="op">=</span>nu, mu<span class="op">=</span>mu_A, sigma<span class="op">=</span>std_A, observed<span class="op">=</span>durations_A)</span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a>    obs_B <span class="op">=</span> pm.StudentT(<span class="st">&quot;obs_B&quot;</span>, nu<span class="op">=</span>nu, mu<span class="op">=</span>mu_B, sigma<span class="op">=</span>std_B, observed<span class="op">=</span>durations_B)</span>
<span id="cb9-20"><a href="#cb9-20" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb9-21"><a href="#cb9-21" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Derived quantities (deterministic nodes)</span></span>
<span id="cb9-22"><a href="#cb9-22" aria-hidden="true" tabindex="-1"></a>    diff_of_means <span class="op">=</span> pm.Deterministic(<span class="st">&quot;diff_of_means&quot;</span>, mu_A <span class="op">-</span> mu_B)</span>
<span id="cb9-23"><a href="#cb9-23" aria-hidden="true" tabindex="-1"></a>    diff_of_stds <span class="op">=</span> pm.Deterministic(<span class="st">&quot;diff_of_stds&quot;</span>, std_A <span class="op">-</span> std_B)</span>
<span id="cb9-24"><a href="#cb9-24" aria-hidden="true" tabindex="-1"></a>    effect_size <span class="op">=</span> pm.Deterministic(<span class="st">&quot;effect_size&quot;</span>, </span>
<span id="cb9-25"><a href="#cb9-25" aria-hidden="true" tabindex="-1"></a>                                    (mu_A <span class="op">-</span> mu_B) <span class="op">/</span> pm.math.sqrt((std_A<span class="op">**</span><span class="dv">2</span> <span class="op">+</span> std_B<span class="op">**</span><span class="dv">2</span>) <span class="op">/</span> <span class="dv">2</span>))</span>
<span id="cb9-26"><a href="#cb9-26" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb9-27"><a href="#cb9-27" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Sample</span></span>
<span id="cb9-28"><a href="#cb9-28" aria-hidden="true" tabindex="-1"></a>    trace <span class="op">=</span> pm.sample(<span class="dv">2000</span>, tune<span class="op">=</span><span class="dv">1000</span>, return_inferencedata<span class="op">=</span><span class="va">False</span>, cores<span class="op">=</span><span class="dv">1</span>)</span></code></pre></div>
<pre class="text"><code>                                                                                
                              Step      Grad      Sampli…                       
  Progre…   Draws   Diverg…   size      evals     Speed     Elapsed   Remaini…  
 
            3000    0         0.901     7         1955.03   0:00:01   0:00:00   
                                                  draws/s                       
            3000    0         0.982     7         962.38    0:00:03   0:00:00   
                                                  draws/s                       
                                                                                </code></pre>
<div class="sourceCode" id="cb11"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>graphviz <span class="op">=</span> pm.model_to_graphviz(model)</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>graphviz.graph_attr.update(dpi<span class="op">=</span><span class="st">&quot;300&quot;</span>)</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>graphviz.render(<span class="st">&quot;stat_047_bayes_02&quot;</span>, <span class="bu">format</span><span class="op">=</span><span class="st">&quot;jpg&quot;</span>)</span></code></pre></div>
<pre class="text"><code>Out[1]: &#39;stat_047_bayes_02.jpg&#39;</code></pre>
<p><img width="500" src="stat_047_bayes_02.jpg"/></p>
<div class="sourceCode" id="cb13"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>diff_means_trace <span class="op">=</span> trace[<span class="st">&#39;diff_of_means&#39;</span>]</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>diff_stds_trace <span class="op">=</span> trace[<span class="st">&#39;diff_of_stds&#39;</span>]</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>effect_size_trace <span class="op">=</span> trace[<span class="st">&#39;effect_size&#39;</span>]</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">4</span>))</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>plt.hist(diff_means_trace, bins<span class="op">=</span><span class="dv">50</span>, histtype<span class="op">=</span><span class="st">&#39;stepfilled&#39;</span>, alpha<span class="op">=</span><span class="fl">0.85</span>, density<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>plt.axvline(<span class="dv">0</span>, color<span class="op">=</span><span class="st">&#39;red&#39;</span>, linestyle<span class="op">=</span><span class="st">&#39;--&#39;</span>, label<span class="op">=</span><span class="st">&#39;Sifir (Null) Hipotezi&#39;</span>)</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&#39;μ_A - μ_B&#39;</span>)</span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Yogunluk (Density)&#39;</span>)</span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&#39;Ortalama Farki Sonsal Dagilimi&#39;</span>)</span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Sifirdan buyuk olma yuzdesi</span></span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a>pct_greater <span class="op">=</span> (diff_means_trace <span class="op">&gt;</span> <span class="dv">0</span>).<span class="bu">sum</span>() <span class="op">/</span> <span class="bu">len</span>(diff_means_trace) <span class="op">*</span> <span class="dv">100</span></span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a>pct_less <span class="op">=</span> (diff_means_trace <span class="op">&lt;</span> <span class="dv">0</span>).<span class="bu">sum</span>() <span class="op">/</span> <span class="bu">len</span>(diff_means_trace) <span class="op">*</span> <span class="dv">100</span></span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a>plt.text(<span class="fl">0.7</span>, <span class="fl">0.9</span>, <span class="ss">f&#39;</span><span class="sc">{</span>pct_less<span class="sc">:.1f}</span><span class="ss">% &lt; 0 &lt; </span><span class="sc">{</span>pct_greater<span class="sc">:.1f}</span><span class="ss">%&#39;</span>, </span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a>         transform<span class="op">=</span>plt.gca().transAxes, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb13-20"><a href="#cb13-20" aria-hidden="true" tabindex="-1"></a>plt.savefig(<span class="st">&#39;stat_047_bayes_01.jpg&#39;</span>)</span></code></pre></div>
<p><img src="stat_047_bayes_01.jpg" /></p>
<p>[devam edecek]</p>
<p>Kaynaklar</p>
<p>[1] Kruschke, <em>Bayesian Estimation Supersedes the t Test</em></p>
<p>[2] Pillon, <em>Bayesian Method for Hackers</em></p>
<p>[3] Gimenez,
<a href="https://oliviergimenez.github.io/banana-book/crashcourse.html">
Bayesian analysis of capture-recapture data with hidden Markov models
</a></p>
<p>[4] Bayramli, Istatistik, <em>Tahmin Edici Hesaplar
(Estimators)</em></p>
<p>[5] Bayramli, Istatistik, <em>Değişim Noktası Analizi (Changepoint
Analysis)</em></p>
<p>[6] Stevyers, <em>Computational Statistics with Matlab</em></p>
<p>[7] Kumar, Bayesian Modeling and Computation in Python</p>
<p>
  <a href="..">Yukarı</a>
</p>
</body>
</html>
