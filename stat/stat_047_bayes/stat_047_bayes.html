<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
    <script type="text/x-mathjax-config">
    MathJax.Hub.Register.StartupHook("TeX Jax Ready",function () {
      MathJax.Hub.Insert(MathJax.InputJax.TeX.Definitions.macros,{
        cancel: ["Extension","cancel"], cancelto: ["Extension","cancel"]
      });
    });
    </script>  
   
  <title>Bayes Usulü İstatistiki Analiz</title>
  <style type="text/css">code{white-space: pre;}</style>
  <style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
  </style>
  <script
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS_HTML-full"
  type="text/javascript"></script>
</head>
<body>
<div id="header">
</div>
<h1 id="bayes-usulü-istatistiki-analiz">Bayes Usulü İstatistiki
Analiz</h1>
<p>Veri analizinde Bayes teorisi kullanımı sayesinde veri olasılığı,
bilmediğimiz parametreler hakkındaki bazı bilgilerimizi formülasyona
dahil edebiliyoruz. Bunun bir örneğini MAP hesaplarını işlerken gördük.
Bu bölümde Bayes formüllerinin sonuçlarını bulmak için bazı hesapsal
teknikleri işleyeceğiz, ve niye faydalı olduklarını anlamaya
uğraşacağız.</p>
<p>Temel olasılık teorisinden biliyoruz ki Bayes teorisi</p>
<p><span class="math display">\[
P(A | B) = \frac{P(B|A) P(A)}{P(B)}
\]</span></p>
<p>diye gider. Üstteki formülü veri analizine uyarlayabiliriz.
İstatistiki modelin parametreleri <span
class="math inline">\(\theta\)</span>’yi <span class="math inline">\(A =
\theta\)</span> yaparız, <span class="math inline">\(B =
\textrm{veri}\)</span> deriz, o zaman Bayes teorisi elde edilen verinin
parametre hesabı <span class="math inline">\(\theta\)</span> için nasıl
kullanılacağının formülünü gösterir,</p>
<p><span class="math display">\[
P(\theta | \textrm{veri}) =
\frac{P(\textrm{veri} | \theta) \times
P(\theta)}{P(\textrm{veri})}
\]</span></p>
<p>Formül öğelerinin açıklamasını [4] yazısında bulabiliriz. Tekrarlamak
gerekirse, sol tarafta, veriyi gördükten sonra ne bildiğinizi temsil
eden, sonsal dağılım olan <span class="math inline">\(P(\theta \mid
\text{veri})\)</span> bulunur. Bu, çıkarımın temelini oluşturur ve
açıkça aradığınız şeydir; eğer birden fazla parametreniz varsa,
muhtemelen çok değişkenli bir dağılım. Sağ tarafta, olurluk olan <span
class="math inline">\(P(\text{veri} \mid \theta)\)</span> bulunur. Bu
miktar, En Yüksek Olurluk Tahmini (MLE) yaklaşımındaki ile aynıdır.
Evet, Bayeşçi ve frekansçı yaklaşımların çekirdeğinde aynı olurluk
bulunur, bu da sonuçların genellikle neden çok farklı olmadığını büyük
ölçüde açıklar. Olurluk, <span class="math inline">\(\theta\)</span> ile
parametrelendirilmiş bir model verildiğinde, verinizdeki bilginin
olasılığını gösterir.</p>
<p>Ardından, önsel dağılım olan <span
class="math inline">\(P(\theta)\)</span> gelir. Bu miktar, veriyi
görmeden önce ne bildiğinizi temsil eder. Eğer <span
class="math inline">\(\theta\)</span> hakkında hiçbir şey bilmiyorsanız,
belirsiz olabilir. Ancak genellikle sıfırdan başlamazsınız ve
önselinizin sahip olduğunuz bilgiyi yansıtmasını istersiniz.</p>
<p>Son olarak, bazen ortalama olurluk olarak adlandırılan <span
class="math inline">\(P(\text{veri})\)</span> bulunur, çünkü sonsalın
standartlaştırılması, yani bir dağılım olması için bire entegre olması
amacıyla, olurluk önsele göre entegre edilerek elde edilir: <span
class="math inline">\(P(\text{veri}) = \int P(\text{veri} \mid \theta)
P(\theta)d\theta\)</span>. Ortalama olurluk, tahmin etmeniz gereken
<span class="math inline">\(\theta\)</span> parametrelerinin sayısı
boyutunda bir integraldir. Bu, genel olarak hesaplanması imkansız olmasa
da zordur. Bayesçi yöntemin yakın zamana kadar kullanılmamasının
nedenlerinden biri de budur.</p>
<p>Örneğin, ekolojide kullanilan bir yakalama-tekrar yakalama modelini,
tespit olasılığı <span class="math inline">\(p\)</span> ve hayatta kalma
olasılığı ile bir kovaryat arasındaki ilişkinin kesişim ve eğimi için
regresyon parametreleri <span class="math inline">\(\alpha\)</span> ve
<span class="math inline">\(\beta\)</span> ile uyarlamak istediğinizi
düşünün. Bu durumda Bayes teoremi, her üç parametrenin birlikteki sonsal
dağılımını size verir:</p>
<p><span class="math display">\[P(\alpha, \beta, p \mid \text{veri}) =
\frac{P(\text{veri} \mid
\alpha, \beta, p) \times P(\alpha, \beta, p)}{\iiint P(\text{veri}
\mid \alpha, \beta, p) P(\alpha, \beta, p)d\alpha d\beta
dp}\]</span></p>
<p>Bu formülde bir hesaplama zorluğu var. Bölende üç boyutlu bir
integrali görüyoruz, bu entegral çok çetrefilli bir çözümdür, analitik
çözüm çoğunlukla mümkün değildir, hesapsal yaklaşımlar gerekir. Bu
entegralin her durumda hesaplanması gerekmeyebiliyor, mesela [4]’te
gördük ki aranılan bir parametre maksimize edilmeye çalışılan büyüklükte
bölen değerine ihtiyaç duymuyordu, bu sebeple onu yok sayabildik. Fakat
bazen bölendeki entegral kesinlikle gerekir, mesela iki farklı Bayes
modelini karşılaştırıyorsak, bölendeki değer iptal edilemez, ve
hesaplanması gerekir.</p>
<p>Fakat bölümdeki entegral lazım olmasa bile, yani normalize edici
katsayıyı bilmeden yine de sonsal dağılıma “orantılı” bir sonuç elde
edebilsek bile, orada da analitik sonuç alamayacağımız ortaya
çıkabiliyor, ve orada için yine yaklaşık yöntemlere başvurmamız
gerekiyor.</p>
<p>Bir deneyde tepki süresi ölçümlerinden oluşan tek değişkenli verilere
sahip olduğumuzu varsayalım. Bu veriyi modellemek için, Weibull
dağılımının faydalı bir tanımlayıcı model olacağını varsayalım.</p>
<p>Weibull için olasılık yoğunluk fonksiyonu şudur:</p>
<p><span
class="math display">\[p(y|a,b)=ba^{-b}y^{b-1}e^{-(\frac{y}{a})^{b}}I_{(0,inf)}(y)\]</span></p>
<p>Bu dağılımın iki parametresi vardır: a dağılımın ölçeğini ve b ise
dağılımın şeklini kontrol eder. Verilerimizin <span
class="math inline">\(y_{i}\)</span> ile temsil edildiğini, <span
class="math inline">\(i\in1..N\)</span> olduğunu ve <span
class="math inline">\(N\)</span>’nin gözlem sayısını gösterdiğini
varsayalım. Modelimizde, her gözlemin bir Weibull dağılımından bağımsız
bir çekiliş olduğunu varsayalım.</p>
<p>Bu varsayımlar göz önüne alındığında, verilerimiz için artık bir
olurluk fonksiyonuna (likelihood function) sahibiz. Her gözlemin <span
class="math inline">\(a\)</span> ve <span
class="math inline">\(b\)</span> parametrelerine sahip bir Weibull’dan
bağımsız bir çekiliş olduğu varsayılırsa, tüm gözlemlerin olasılığı şu
şekilde verilir:</p>
<p><span
class="math display">\[p(y_{1},...,y_{N}|a,b)=p(y_{1}|a,b)p(y_{2}|a,b)...p(y_{N}|a,b)\]</span>
<span class="math display">\[=\prod_{i}p(y_{i}|a,b)\]</span> <span
class="math display">\[=\prod_{i}ba^{-b}y_{i}^{b-1}e^{-{(\frac{y_{i}}{a})}^{b}}I_{(0,inf)}(y_{i})\]</span></p>
<p>Ancak model tanımımızla henüz tamamen işimiz bitmedi. Her Bayesci
analizde, parametreler üzerinde önsel dağılımları (prior distributions)
da belirtmemiz gerekir. <span class="math inline">\(a\)</span> ve <span
class="math inline">\(b\)</span> parametrelerinin sırasıyla <span
class="math inline">\(\lambda_{a}\)</span> ve <span
class="math inline">\(\lambda_{b}\)</span> parametrelerine sahip bir
üstel dağılıma (exponential distribution) göre bağımsız olarak
dağıldığını varsayalım.</p>
<p>Bu önsel dağılımların yogunluklari şunlardır</p>
<p><span
class="math display">\[p(a|\lambda_{a})=\frac{1}{\lambda_{a}}e^{-\frac{a}{\lambda_{a}}}\]</span>
<span
class="math display">\[p(a|\lambda_{b})=\frac{1}{\lambda_{b}}e^{-\frac{b}{\lambda_{b}}}\]</span></p>
<p>Yukarıda ifade edilen modelin, örnekleme notasyonu (sampling
notation) kullanılarak çok daha basit terimlerle açıklanabileceğini
belirtmeliyiz:</p>
<p><span class="math display">\[\begin{array}{l}y_{i}|a,b\sim
Weibull(a,b)\\a\sim
Exp(\lambda_{a})\\b\sim Exp(\lambda_{b})\end{array}\]</span></p>
<p>Artık hem bir olurluk hem de tüm parametreler üzerinde bir önsel
içeren, tamamen belirlenmiş bir modele sahibiz. Amaç, sonsal çıkarım
(posterior inference) yapmak ve verilere koşullu olarak parametreler
üzerindeki sonsal dağılımı bulmaktır.</p>
<p>Daha önce şunu belirtmiştik:</p>
<p><span class="math display">\[p(\theta|D)\propto
p(D|\theta)p(\theta)\]</span></p>
<p>Bizim durumumuzda, <span class="math inline">\(\theta=(a,b)\)</span>
ve <span class="math inline">\(D=(y_{1},...,y_{N})\)</span>’dir. Bu
nedenle, şunu yazabiliriz:</p>
<p><span class="math display">\[p(a,b|y_{1},...,y_{N})\propto
p(y_{1},...,y_{N}|a,b)p(a,b)\]</span></p>
<p><span class="math inline">\(a\)</span> ve <span
class="math inline">\(b\)</span> parametreleri üzerinde bağımsız önsel
kullanmaya karar verdiğimize dikkat edin. Bu bize şunu yazma olanağı
verir:</p>
<p><span class="math display">\[
p(a,b|y_{1},...,y_{N}) \propto p(y_{1},...,y_{N}|a,b)
\]</span></p>
<p>Bu sonsal dağılımın fonksiyonel biçiminin neye benzediğini görmek
için açılımı yapalım,</p>
<p><span class="math display">\[p(a,b|y_{1},...,y_{N}) \propto
(\prod_{i}ba^{-b}y_{i}^{b-1}e^{-(\frac{y_{i}}{a})^{b}}I_{(0,inf)}(y_{i}))\frac{1}{\lambda_{a}}e^{-\frac{a}{\lambda_{a}}}
\frac{1}{\lambda_{b}}e^{-\frac{b}{\lambda_{b}}}
\]</span></p>
<p>Bu ifade analitik tekniklere uygun değildir.</p>
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pymc <span class="im">as</span> pm, scipy.stats <span class="im">as</span> stats</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span></code></pre></div>
<div class="sourceCode" id="cb2"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>Y <span class="op">=</span> stats.bernoulli(<span class="fl">0.7</span>).rvs(<span class="dv">20</span>)</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>theta <span class="op">=</span> <span class="fl">0.5</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> pm.Model() <span class="im">as</span> model:</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>     theta <span class="op">=</span> pm.Beta(<span class="st">&quot;theta&quot;</span>, alpha<span class="op">=</span><span class="dv">1</span>, beta<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>     y_obs <span class="op">=</span> pm.Binomial(<span class="st">&quot;eta_obs&quot;</span>, n<span class="op">=</span><span class="dv">1</span>, p<span class="op">=</span>theta, observed<span class="op">=</span>Y)</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>     idata <span class="op">=</span> pm.sample(<span class="dv">1000</span>, return_inferencedata<span class="op">=</span><span class="va">True</span>)</span></code></pre></div>
<div class="sourceCode" id="cb3"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>theta_post <span class="op">=</span> np.array(idata.posterior[<span class="st">&#39;theta&#39;</span>])</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (np.mean(theta_post))</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>plt.hist(theta_post[<span class="dv">0</span>],bins<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>plt.savefig(<span class="st">&#39;tser_023_bsts_03.jpg&#39;</span>)</span></code></pre></div>
<pre class="text"><code>0.5952869333604922</code></pre>
<p><img src="tser_023_bsts_03.jpg" /></p>
<div class="sourceCode" id="cb5"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>graphviz <span class="op">=</span> pm.model_to_graphviz(model)</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>graphviz.graph_attr.update(dpi<span class="op">=</span><span class="st">&quot;300&quot;</span>)</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>graphviz.render(<span class="st">&quot;tser_023_bsts_02&quot;</span>, <span class="bu">format</span><span class="op">=</span><span class="st">&quot;jpg&quot;</span>)</span></code></pre></div>
<pre class="text"><code>Out[1]: &#39;tser_023_bsts_02.jpg&#39;</code></pre>
<p><img width="200px" src="tser_023_bsts_02.jpg"></p>
<h3 id="t-testi">T-Testi</h3>
<div class="sourceCode" id="cb7"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>N <span class="op">=</span> <span class="dv">250</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>mu_A, std_A <span class="op">=</span> <span class="dv">30</span>, <span class="dv">4</span></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>mu_B, std_B <span class="op">=</span> <span class="dv">26</span>, <span class="dv">7</span></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>durations_A <span class="op">=</span> np.random.normal(mu_A, std_A, size<span class="op">=</span>N)</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>durations_B <span class="op">=</span> np.random.normal(mu_B, std_B, size<span class="op">=</span>N)</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (durations_A[:<span class="dv">8</span>])</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (durations_B[:<span class="dv">8</span>])</span></code></pre></div>
<pre class="text"><code>[24.16407223 26.33809627 26.02574579 33.21505722 28.50448144 26.99996422
 30.76649221 30.59385573]
[35.63522369 24.06562288 30.18425953 22.17136243 32.47047614 32.74779037
 33.07401654 34.0171137 ]</code></pre>
<div class="sourceCode" id="cb9"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Pool the data for priors</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>pooled_mean <span class="op">=</span> np.r_[durations_A, durations_B].mean()</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>pooled_std <span class="op">=</span> np.r_[durations_A, durations_B].std()</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Build the model in modern PyMC</span></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> pm.Model() <span class="im">as</span> model:</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Priors</span></span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>    mu_A <span class="op">=</span> pm.Normal(<span class="st">&quot;mu_A&quot;</span>, mu<span class="op">=</span>pooled_mean, sigma<span class="op">=</span><span class="dv">1000</span><span class="op">*</span>pooled_std)</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>    mu_B <span class="op">=</span> pm.Normal(<span class="st">&quot;mu_B&quot;</span>, mu<span class="op">=</span>pooled_mean, sigma<span class="op">=</span><span class="dv">1000</span><span class="op">*</span>pooled_std)</span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>    std_A <span class="op">=</span> pm.Uniform(<span class="st">&quot;std_A&quot;</span>, lower<span class="op">=</span>pooled_std<span class="op">/</span><span class="fl">1000.</span>, upper<span class="op">=</span><span class="fl">1000.</span><span class="op">*</span>pooled_std)</span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a>    std_B <span class="op">=</span> pm.Uniform(<span class="st">&quot;std_B&quot;</span>, lower<span class="op">=</span>pooled_std<span class="op">/</span><span class="fl">1000.</span>, upper<span class="op">=</span><span class="fl">1000.</span><span class="op">*</span>pooled_std)</span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a>    nu_minus_1 <span class="op">=</span> pm.Exponential(<span class="st">&quot;nu_minus_1&quot;</span>, lam<span class="op">=</span><span class="fl">1.</span><span class="op">/</span><span class="dv">29</span>)</span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a>    nu <span class="op">=</span> pm.Deterministic(<span class="st">&quot;nu&quot;</span>, nu_minus_1 <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Likelihood - using StudentT instead of NoncentralT</span></span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a>    obs_A <span class="op">=</span> pm.StudentT(<span class="st">&quot;obs_A&quot;</span>, nu<span class="op">=</span>nu, mu<span class="op">=</span>mu_A, sigma<span class="op">=</span>std_A, observed<span class="op">=</span>durations_A)</span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a>    obs_B <span class="op">=</span> pm.StudentT(<span class="st">&quot;obs_B&quot;</span>, nu<span class="op">=</span>nu, mu<span class="op">=</span>mu_B, sigma<span class="op">=</span>std_B, observed<span class="op">=</span>durations_B)</span>
<span id="cb9-20"><a href="#cb9-20" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb9-21"><a href="#cb9-21" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Derived quantities (deterministic nodes)</span></span>
<span id="cb9-22"><a href="#cb9-22" aria-hidden="true" tabindex="-1"></a>    diff_of_means <span class="op">=</span> pm.Deterministic(<span class="st">&quot;diff_of_means&quot;</span>, mu_A <span class="op">-</span> mu_B)</span>
<span id="cb9-23"><a href="#cb9-23" aria-hidden="true" tabindex="-1"></a>    diff_of_stds <span class="op">=</span> pm.Deterministic(<span class="st">&quot;diff_of_stds&quot;</span>, std_A <span class="op">-</span> std_B)</span>
<span id="cb9-24"><a href="#cb9-24" aria-hidden="true" tabindex="-1"></a>    effect_size <span class="op">=</span> pm.Deterministic(<span class="st">&quot;effect_size&quot;</span>, </span>
<span id="cb9-25"><a href="#cb9-25" aria-hidden="true" tabindex="-1"></a>                                    (mu_A <span class="op">-</span> mu_B) <span class="op">/</span> pm.math.sqrt((std_A<span class="op">**</span><span class="dv">2</span> <span class="op">+</span> std_B<span class="op">**</span><span class="dv">2</span>) <span class="op">/</span> <span class="dv">2</span>))</span>
<span id="cb9-26"><a href="#cb9-26" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb9-27"><a href="#cb9-27" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Sample</span></span>
<span id="cb9-28"><a href="#cb9-28" aria-hidden="true" tabindex="-1"></a>    trace <span class="op">=</span> pm.sample(<span class="dv">2000</span>, tune<span class="op">=</span><span class="dv">1000</span>, return_inferencedata<span class="op">=</span><span class="va">False</span>, cores<span class="op">=</span><span class="dv">1</span>)</span></code></pre></div>
<pre class="text"><code>                                                                                
                              Step      Grad      Sampli…                       
  Progre…   Draws   Diverg…   size      evals     Speed     Elapsed   Remaini…  
 
            3000    0         0.901     7         1955.03   0:00:01   0:00:00   
                                                  draws/s                       
            3000    0         0.982     7         962.38    0:00:03   0:00:00   
                                                  draws/s                       
                                                                                </code></pre>
<div class="sourceCode" id="cb11"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>graphviz <span class="op">=</span> pm.model_to_graphviz(model)</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>graphviz.graph_attr.update(dpi<span class="op">=</span><span class="st">&quot;300&quot;</span>)</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>graphviz.render(<span class="st">&quot;stat_047_bayes_02&quot;</span>, <span class="bu">format</span><span class="op">=</span><span class="st">&quot;jpg&quot;</span>)</span></code></pre></div>
<pre class="text"><code>Out[1]: &#39;stat_047_bayes_02.jpg&#39;</code></pre>
<p><img width="500" src="stat_047_bayes_02.jpg"/></p>
<div class="sourceCode" id="cb13"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>diff_means_trace <span class="op">=</span> trace[<span class="st">&#39;diff_of_means&#39;</span>]</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>diff_stds_trace <span class="op">=</span> trace[<span class="st">&#39;diff_of_stds&#39;</span>]</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>effect_size_trace <span class="op">=</span> trace[<span class="st">&#39;effect_size&#39;</span>]</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">4</span>))</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>plt.hist(diff_means_trace, bins<span class="op">=</span><span class="dv">50</span>, histtype<span class="op">=</span><span class="st">&#39;stepfilled&#39;</span>, alpha<span class="op">=</span><span class="fl">0.85</span>, density<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>plt.axvline(<span class="dv">0</span>, color<span class="op">=</span><span class="st">&#39;red&#39;</span>, linestyle<span class="op">=</span><span class="st">&#39;--&#39;</span>, label<span class="op">=</span><span class="st">&#39;Sifir (Null) Hipotezi&#39;</span>)</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&#39;μ_A - μ_B&#39;</span>)</span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Yogunluk (Density)&#39;</span>)</span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&#39;Ortalama Farki Sonsal Dagilimi&#39;</span>)</span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Sifirdan buyuk olma yuzdesi</span></span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a>pct_greater <span class="op">=</span> (diff_means_trace <span class="op">&gt;</span> <span class="dv">0</span>).<span class="bu">sum</span>() <span class="op">/</span> <span class="bu">len</span>(diff_means_trace) <span class="op">*</span> <span class="dv">100</span></span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a>pct_less <span class="op">=</span> (diff_means_trace <span class="op">&lt;</span> <span class="dv">0</span>).<span class="bu">sum</span>() <span class="op">/</span> <span class="bu">len</span>(diff_means_trace) <span class="op">*</span> <span class="dv">100</span></span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a>plt.text(<span class="fl">0.7</span>, <span class="fl">0.9</span>, <span class="ss">f&#39;</span><span class="sc">{</span>pct_less<span class="sc">:.1f}</span><span class="ss">% &lt; 0 &lt; </span><span class="sc">{</span>pct_greater<span class="sc">:.1f}</span><span class="ss">%&#39;</span>, </span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a>         transform<span class="op">=</span>plt.gca().transAxes, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb13-20"><a href="#cb13-20" aria-hidden="true" tabindex="-1"></a>plt.savefig(<span class="st">&#39;stat_047_bayes_01.jpg&#39;</span>)</span></code></pre></div>
<p><img src="stat_047_bayes_01.jpg" /></p>
<p>[devam edecek]</p>
<p>Kaynaklar</p>
<p>[1] Kruschke, <em>Bayesian Estimation Supersedes the t Test</em></p>
<p>[2] Pillon, <em>Bayesian Method for Hackers</em></p>
<p>[3] Gimenez,
<a href="https://oliviergimenez.github.io/banana-book/crashcourse.html">
Bayesian analysis of capture-recapture data with hidden Markov models
</a></p>
<p>[4] Bayramli, Istatistik, <em>Tahmin Edici Hesaplar
(Estimators)</em></p>
<p>[5] Bayramli, Istatistik, <em>Değişim Noktası Analizi (Changepoint
Analysis)</em></p>
<p>
  <a href="..">Yukarı</a>
</p>
</body>
</html>
