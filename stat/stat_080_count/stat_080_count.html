<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
    <script type="text/x-mathjax-config">
    MathJax.Hub.Register.StartupHook("TeX Jax Ready",function () {
      MathJax.Hub.Insert(MathJax.InputJax.TeX.Definitions.macros,{
        cancel: ["Extension","cancel"], cancelto: ["Extension","cancel"]
      });
    });
    </script>  
   
  <title>Sayım, Poisson ve Negatif Binom Bazlı Genel Lineer Modelleri (GLM)</title>
  <style type="text/css">code{white-space: pre;}</style>
  <style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
  </style>
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>
</head>
<body>
<div id="header">
</div>
<h1 id="sayım-poisson-ve-negatif-binom-bazlı-genel-lineer-modelleri-glm">Sayım, Poisson ve Negatif Binom Bazlı Genel Lineer Modelleri (GLM)</h1>
<p>Sayım (count) verisini modellemek için genellikle Poisson dağılımına başvurulur. Ayrıca ortada bir regresyon problemi var ise, yani belli katsayılar üzerinden çarpılan değişkenlerin sonucu ile bir sayım arasında ilişki kurulmak istenirse -ki bu Logit örneğinde görülmüştü, link fonksiyonu sigmoid yerine Poisson olur- o zaman Poisson GLM kullanılır.</p>
<p>Poisson dağılımını hatırlarsak,</p>
<p><span class="math display">\[ f(x;\lambda) = e^{-\lambda}\frac{\lambda^{x}}{x!} \]</span></p>
<p>Eğer bir <span class="math inline">\(y_i\)</span> rasgele değişkenini dağılımı <span class="math inline">\(\lambda=\theta_i\)</span> olan Poisson rasgele değişkeni diye tanımlamak istersek, ki bu dağılım alttaki tanıma göre her <span class="math inline">\(i\)</span> için değişik olur,</p>
<p><span class="math display">\[ y_i \sim Poisson(\theta_i) \]</span></p>
<p>Yoğunluk</p>
<p><span class="math display">\[ f(y_i;\theta_i) = Poisson(y_i;\theta_i) \]</span></p>
<p>olarak ta gösterilebilir. Şimdi GLM, yani regresyon yapmak için <span class="math inline">\(\theta_i\)</span>'yi biraz daha detaylandıralım / içini dolduralım,</p>
<p><span class="math display">\[ \theta_i = \exp(X_i \beta)\]</span></p>
<p>Poisson dağılımı regresyon kaynağı olacak değişkenlerin lineer kombinasyonu ile parametrize edilecek, <span class="math inline">\(\beta\)</span> regresyonun tahmin edeceği katsayılar olacak. <span class="math inline">\(\theta_i\)</span> ile parametrizasyon sonucu her veri noktası için farklı olabilecek bir <span class="math inline">\(\theta_i\)</span> ortaya çıkabileceğinden bahsettik, fakat bu parametrizasyonların arkasında hep aynı <span class="math inline">\(\beta\)</span> vektörü olacak, bu durumda Poisson GLM'i veriye uydurmak demek veriyi en iyi açıklayan bu aynı <span class="math inline">\(\beta\)</span>'yi ortaya çıkartmaktır.</p>
<p><span class="math inline">\(\exp\)</span> alınmış olmasının sebebi ise sadece artı sayılar ile çalışmak istememiz, çünkü <span class="math inline">\(\exp\)</span> alınınca eksi sayılar bile sıfırdan büyük olur,</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="bu">print</span> np.exp(<span class="op">-</span><span class="dv">2</span>)
<span class="bu">print</span> np.exp(<span class="fl">1.</span><span class="op">/</span><span class="dv">6</span>)</code></pre></div>
<pre><code>0.135335283237
1.18136041287</code></pre>
<p>Merak edenler için maksimum olurluk</p>
<p><span class="math display">\[ f(y;\beta,X) = \prod_{i=1}^n Poisson(y_i;e^{X_i\beta} ) \]</span></p>
<p>Veri</p>
<p>Devam etmeden önce veriye bakıp Poisson varsayımını kontrol etmek iyi olur. Mesela örnek verimiz bir bölgede oturan insanların medyan kazanç (median income) ile bu kazanca sahip olan şahısların evlerine ne kadar hırsız girdiği arasındaki ilişki. Medyan kazanç için kaç eve hırsız girdiği bir sayım verisi, ilk akla gelen Poisson ile modellenmesi, bakalım,</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="im">import</span> pandas <span class="im">as</span> pd
burg <span class="op">=</span> pd.read_csv(<span class="st">&#39;burglary.txt&#39;</span>,sep<span class="op">=</span><span class="st">&#39; &#39;</span>)
burg.plot(y<span class="op">=</span><span class="st">&#39;burglaries&#39;</span>,x<span class="op">=</span><span class="st">&#39;median_income&#39;</span>,kind<span class="op">=</span><span class="st">&#39;scatter&#39;</span>)
plt.savefig(<span class="st">&#39;stat_count_01.png&#39;</span>)</code></pre></div>
<div class="figure">
<img src="stat_count_01.png" />

</div>
<p>Grafik Poisson'a benziyor.. Diğer yandan aslında negatif binom dağılımına da benziyor. Şimdilik Poisson varsayımı ile devam edelim. Bu dağılımın önemli bir varsayımı ortalamasının varyansı ile aynı olmasıdır. Veride durum böyle midir?</p>
<p>Medyan kazancı 59 ile 61 arasında olan kişilere bakalım,</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">burg_59_61 <span class="op">=</span> burg[(burg[<span class="st">&#39;median_income&#39;</span>] <span class="op">&gt;</span> <span class="dv">59</span>) <span class="op">&amp;</span> (burg[<span class="st">&#39;median_income&#39;</span>] <span class="op">&lt;</span> <span class="dv">61</span>)]
m <span class="op">=</span> burg_59_61[<span class="st">&#39;burglaries&#39;</span>].mean()
v <span class="op">=</span> burg_59_61[<span class="st">&#39;burglaries&#39;</span>].std()<span class="op">**</span><span class="dv">2</span>
<span class="bu">print</span> m, v, v<span class="op">/</span>m</code></pre></div>
<pre><code>7.33333333333 22.5384615385 3.07342657343</code></pre>
<p>Veriden örneklem ortalaması ve örneklem varyansını hesapladık. Ne yazık ki varyans ortalamanın üç katı! Demek ki bu verinin dağılımının Poisson olma olasılığı düşük. Verinin başka bir bölgesine bakarsak,</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">burg_59_61 <span class="op">=</span> burg[(burg[<span class="st">&#39;median_income&#39;</span>] <span class="op">&gt;</span> <span class="dv">39</span>) <span class="op">&amp;</span> (burg[<span class="st">&#39;median_income&#39;</span>] <span class="op">&lt;</span> <span class="dv">41</span>)]
m <span class="op">=</span> burg_59_61[<span class="st">&#39;burglaries&#39;</span>].mean()
v <span class="op">=</span> burg_59_61[<span class="st">&#39;burglaries&#39;</span>].std()<span class="op">**</span><span class="dv">2</span>
<span class="bu">print</span> m, v, v<span class="op">/</span>m</code></pre></div>
<pre><code>21.8571428571 97.1428571429 4.44444444444</code></pre>
<p>Aradaki fark bu sefer daha da büyük. Eğer bu veriye Poisson bazlı bir GLM uydurmaya kalksaydık, ortaya aşırı saçılmış (overdispersed) bir durum ortaya çıkardı. Ya da terminoloji olarak ve Poisson bazlı düşünürsek bu verinin aşırı saçılmış olduğu söylenecekti. Her iki yöntemi de deneyebiliriz, önce Poisson bazlı sonra Negatif Binomial bazlı bir GLM. İkincisinin daha iyi sonuç verdiğini daha düşük kalıntı sapma (residual deviance) değerinden anlayabiliriz.</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="im">import</span> pandas <span class="im">as</span> pd
<span class="im">import</span> statsmodels.formula.api <span class="im">as</span> smf
<span class="im">import</span> statsmodels.api <span class="im">as</span> sm
model<span class="op">=</span>smf.glm(<span class="st">&quot;burglaries ~ median_income&quot;</span>, data<span class="op">=</span>burg,
             family<span class="op">=</span>sm.families.Poisson()).fit()
<span class="bu">print</span>(model.summary())
model<span class="op">=</span>smf.glm(<span class="st">&quot;burglaries ~ median_income&quot;</span>, data<span class="op">=</span>burg,
             family<span class="op">=</span>sm.families.NegativeBinomial()).fit()
<span class="bu">print</span>(model.summary())</code></pre></div>
<pre><code>                 Generalized Linear Model Regression Results                  
==============================================================================
Dep. Variable:             burglaries   No. Observations:                  500
Model:                            GLM   Df Residuals:                      498
Model Family:                 Poisson   Df Model:                            1
Link Function:                    log   Scale:                             1.0
Method:                          IRLS   Log-Likelihood:                -1596.2
Date:                Mon, 09 Mar 2015   Deviance:                       1452.6
Time:                        16:10:11   Pearson chi2:                 1.47e+03
No. Iterations:                     8                                         
=================================================================================
                    coef    std err          z      P&gt;|z|      [95.0% Conf. Int.]
---------------------------------------------------------------------------------
Intercept         5.6124      0.056    100.228      0.000         5.503     5.722
median_income    -0.0613      0.001    -56.191      0.000        -0.063    -0.059
=================================================================================
                 Generalized Linear Model Regression Results                  
==============================================================================
Dep. Variable:             burglaries   No. Observations:                  500
Model:                            GLM   Df Residuals:                      498
Model Family:        NegativeBinomial   Df Model:                            1
Link Function:                    log   Scale:                  0.354315963879
Method:                          IRLS   Log-Likelihood:                -1482.4
Date:                Mon, 09 Mar 2015   Deviance:                       208.25
Time:                        16:10:12   Pearson chi2:                     176.
No. Iterations:                     7                                         
=================================================================================
                    coef    std err          z      P&gt;|z|      [95.0% Conf. Int.]
---------------------------------------------------------------------------------
Intercept         5.5857      0.133     42.103      0.000         5.326     5.846
median_income    -0.0608      0.002    -27.925      0.000        -0.065    -0.057
=================================================================================</code></pre>
<p>Titanik Verisi</p>
<p>Daha ilginç bir veri batan Titanik gemisinin kayıtları. Bu kayıtlarda yolcuların sağ kurtulup kurtulmadığı onlar hakkında baz bilgi ile beraber kişi seviyesinde kaydedilmiş. Hangi sınıfta (whichclass) seyahat etmiş, yetişkin mi (adult) çocuk mu, cinsiyeti erkek mi kadın mı (man / woman), hayatta kaldı mı (survived) gibi bilgiler bu kayıtlarda. Bu veriye bakıp istatistiki olarak mesela yolcunun seyahat ettiği sınıfın hayatta kalmaya etki edip etmediği görülebilir. Ham verinin birkaç satırına bakalım,</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="im">import</span> pandas <span class="im">as</span> pd
tmp <span class="op">=</span> pd.read_csv(<span class="st">&quot;titanic.csv&quot;</span>,sep<span class="op">=</span><span class="st">&#39;,&#39;</span>,index_col<span class="op">=</span><span class="dv">0</span>)
<span class="bu">print</span> tmp.head(<span class="dv">5</span>)</code></pre></div>
<pre><code>       class     age  sex survived
1  1st class  adults  man      yes
2  1st class  adults  man      yes
3  1st class  adults  man      yes
4  1st class  adults  man      yes
5  1st class  adults  man      yes</code></pre>
<p>Tahmin bağlamında verinin 1/0 etiketlerine sahip olmasından hareketle ilk akla gelen ona bir lojistik regresyon ya da Logit modeli uydurmak olabilir. Fakat bu verinin her satırı üzerinden Logit yapmak yerine grup toplamları üzerinden Poisson ya da Negatif Binom yapmak daha uygun olur. Toplamlara bakalım (ayrı bir dosyada),</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="im">import</span> pandas <span class="im">as</span> pd
df <span class="op">=</span> pd.read_csv(<span class="st">&quot;titanicgrp.csv&quot;</span>,sep<span class="op">=</span><span class="st">&#39;,&#39;</span>,index_col<span class="op">=</span><span class="dv">0</span>)
<span class="bu">print</span> df</code></pre></div>
<pre><code>    survive  cases  age  sex  whichclass
1         1      1    0    0           1
2        13     13    0    0           2
3        14     31    0    0           3
4         5      5    0    1           1
5        11     11    0    1           2
6        13     48    0    1           3
7       140    144    1    0           1
8        80     93    1    0           2
9        76    165    1    0           3
10       57    175    1    1           1
11       14    168    1    1           2
12       75    462    1    1           3</code></pre>
<p>Poisson ile ilerlemeden önce, bir soru soralım: niye 1. sınıfta kurtulan çocuk sayısı 2. ve 3. sınıftakinden daha az?</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="bu">print</span> df[(df[<span class="st">&#39;age&#39;</span>]<span class="op">==</span><span class="dv">0</span>) <span class="op">&amp;</span> (df[<span class="st">&#39;whichclass&#39;</span>]<span class="op">==</span><span class="dv">1</span>) ].<span class="bu">sum</span>()[<span class="st">&#39;survive&#39;</span>]
<span class="bu">print</span> df[(df[<span class="st">&#39;age&#39;</span>]<span class="op">==</span><span class="dv">0</span>) <span class="op">&amp;</span> (df[<span class="st">&#39;whichclass&#39;</span>]<span class="op">==</span><span class="dv">2</span>) ].<span class="bu">sum</span>()[<span class="st">&#39;survive&#39;</span>]
<span class="bu">print</span> df[(df[<span class="st">&#39;age&#39;</span>]<span class="op">==</span><span class="dv">0</span>) <span class="op">&amp;</span> (df[<span class="st">&#39;whichclass&#39;</span>]<span class="op">==</span><span class="dv">3</span>) ].<span class="bu">sum</span>()[<span class="st">&#39;survive&#39;</span>]</code></pre></div>
<pre><code>6
24
27</code></pre>
<p>Bu bizi şaşırtıyor, çünkü o sınıftan daha fazla kişinin kurtulmasını bekleriz. Fakat sebep başka, sebep 1. sınıfta seyahat eden toplam çocuk sayısının zaten az olması. Toplamlara bakarsak,</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="bu">print</span> <span class="st">&#39;1. sinif cocuk sayisi,&#39;</span>, 
df[(df[<span class="st">&#39;age&#39;</span>]<span class="op">==</span><span class="dv">0</span>) <span class="op">&amp;</span> (df[<span class="st">&#39;whichclass&#39;</span>]<span class="op">==</span><span class="dv">1</span>) ].<span class="bu">sum</span>()[<span class="st">&#39;cases&#39;</span>]
<span class="bu">print</span> <span class="st">&#39;2. sinif cocuk sayisi,&#39;</span>, 
df[(df[<span class="st">&#39;age&#39;</span>]<span class="op">==</span><span class="dv">0</span>) <span class="op">&amp;</span> (df[<span class="st">&#39;whichclass&#39;</span>]<span class="op">==</span><span class="dv">2</span>) ].<span class="bu">sum</span>()[<span class="st">&#39;cases&#39;</span>]
<span class="bu">print</span> <span class="st">&#39;3. sinif cocuk sayisi,&#39;</span>, 
df[(df[<span class="st">&#39;age&#39;</span>]<span class="op">==</span><span class="dv">0</span>) <span class="op">&amp;</span> (df[<span class="st">&#39;whichclass&#39;</span>]<span class="op">==</span><span class="dv">3</span>) ].<span class="bu">sum</span>()[<span class="st">&#39;cases&#39;</span>]</code></pre></div>
<pre><code>1. sinif cocuk sayisi, 6
2. sinif cocuk sayisi, 24
3. sinif cocuk sayisi, 79</code></pre>
<p>0 zaman direk sayımı modellemek yerine, bir şekilde 6 içinden 6 kurtulmasının, 79 içinden 27 kurtulmaktan daha iyi olduğunu gösterebilecek bir model eki bize gerekiyor. Yoksa şu anki haliyle 6 ve 27 ana regresyon hedefleri olarak alınacaktır, ki bu doğru olmaz.</p>
<p>Kaydırma (offset) numarası burada ise yarar. Ondan önce, oran kavramını bir şekilde modele dahil etmeyi görelim; Diyelim ki <span class="math inline">\(\theta_i\)</span> sayısının (ki bu mesela hayatta kalma sayısı) hangi toplam içinden çıktığını belirtmek için bir <span class="math inline">\(u_i\)</span> değişkeni tasarlayalım, ve oranı şöyle modele dahil edelim,</p>
<p><span class="math display">\[ \frac{\theta_i}{u_i} = \exp (X_i\beta) \]</span></p>
<p>Eğer 79'dan 27 kişi kurtulduysa <span class="math inline">\(u_i=79\)</span> ve <span class="math inline">\(\theta_i=27\)</span> olacak. Şimdi bir numara daha yapacağız, çünkü 100 içinden 10 gelmesi ile 200 içinden 20 gelmesi arasındaki farkı da modellemek istiyoruz, normal şartlarda bu iki oran aynıdır (1/10). Fakat bir fark olmalı. İki tarafın <span class="math inline">\(\log\)</span>'unu alırsak,</p>
<p><span class="math display">\[ \log \bigg(\frac{\theta_i}{u_i} \bigg) = X_i\beta \]</span></p>
<p><span class="math display">\[ \log \theta_i -  \log u_i = X_i\beta \]</span></p>
<p><span class="math display">\[ \log \theta_i = \log u_i + X_i\beta \]</span></p>
<p>Böylece <span class="math inline">\(u_i\)</span> değişkeni bir kaydırma operasyonu ile olduğu haliyle modele eklenmiş oldu! Modelde bu değişkenin bir katsayısı olacak, maksimum olurluk onu öğrenmeye çalışacak, vs. Tek bir ek işlem lazım, regresyona veriyi vermeden önce kaydırılan değişkenin (toplam sayımın) <span class="math inline">\(\log\)</span>'u alınır (Poisson modelleri kendi içinde hedef değişkenini zaten <span class="math inline">\(\log\)</span>'lar, ona dokunmaya gerek yok).</p>
<p>Şimdi Titanik verisini modelleyelim.</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="im">import</span> pandas <span class="im">as</span> pd
<span class="im">import</span> statsmodels.formula.api <span class="im">as</span> smf
<span class="im">import</span> statsmodels.api <span class="im">as</span> sm

df <span class="op">=</span> pd.read_csv(<span class="st">&quot;titanicgrp.csv&quot;</span>,sep<span class="op">=</span><span class="st">&#39;,&#39;</span>,index_col<span class="op">=</span><span class="dv">0</span>)
df[<span class="st">&#39;lncases&#39;</span>] <span class="op">=</span> df[<span class="st">&#39;cases&#39;</span>].<span class="bu">map</span>(<span class="kw">lambda</span> x:np.log(x))

model<span class="op">=</span>smf.glm(<span class="st">&quot;survive ~ age + sex + C(whichclass)&quot;</span>, data<span class="op">=</span>df, offset<span class="op">=</span>df[<span class="st">&#39;lncases&#39;</span>],
             family<span class="op">=</span>sm.families.Poisson()).fit()
<span class="bu">print</span>(model.summary())</code></pre></div>
<pre><code>                 Generalized Linear Model Regression Results                  
==============================================================================
Dep. Variable:                survive   No. Observations:                   12
Model:                            GLM   Df Residuals:                        7
Model Family:                 Poisson   Df Model:                            4
Link Function:                    log   Scale:                             1.0
Method:                          IRLS   Log-Likelihood:                -48.530
Date:                Thu, 19 Mar 2015   Deviance:                       38.304
Time:                        14:15:55   Pearson chi2:                     39.1
No. Iterations:                     9                                         
======================================================================================
                         coef    std err          z      P&gt;|z|      [95.0% Conf. Int.]
--------------------------------------------------------------------------------------
Intercept              0.4845      0.160      3.035      0.002         0.172     0.797
C(whichclass)[T.2]    -0.3783      0.118     -3.217      0.001        -0.609    -0.148
C(whichclass)[T.3]    -0.7691      0.107     -7.185      0.000        -0.979    -0.559
age                   -0.4830      0.146     -3.317      0.001        -0.768    -0.198
sex                   -1.1657      0.095    -12.267      0.000        -1.352    -0.979
======================================================================================</code></pre>
<p>Negatif Binom Modelleri</p>
<p>Üstteki sonuçlar hiç fena değil. Fakat verinin kurtulan kişi sayısının dağılımının Poisson olduğu varsayımı her zaman doğru olmayabilir. Bu durumlarda Negatif Binom kullanımı daha doğru olabilir. NB regresyonu için üstte gördüğümüz tüm kavramlar hala geçerli, sadece perde arkasında</p>
<p><span class="math display">\[ y_i \sim NegativeBinomial(\theta_i) \]</span></p>
<p>kullanımı olacaktır, ve tabii ki farklı bir kütüphane çağrısı yapılır, ama geri kalan her şey aynı.</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">modelnb<span class="op">=</span>smf.glm(<span class="st">&quot;survive ~ age + sex + C(whichclass)&quot;</span>, data<span class="op">=</span>df, offset<span class="op">=</span>df[<span class="st">&#39;lncases&#39;</span>],
             family<span class="op">=</span>sm.families.NegativeBinomial()).fit()
<span class="bu">print</span>(modelnb.summary())</code></pre></div>
<pre><code>                 Generalized Linear Model Regression Results                  
==============================================================================
Dep. Variable:                survive   No. Observations:                   12
Model:                            GLM   Df Residuals:                        7
Model Family:        NegativeBinomial   Df Model:                            4
Link Function:                    log   Scale:                  0.222676200695
Method:                          IRLS   Log-Likelihood:                -50.130
Date:                Thu, 19 Mar 2015   Deviance:                       1.9976
Time:                        14:16:24   Pearson chi2:                     1.56
No. Iterations:                    13                                         
======================================================================================
                         coef    std err          z      P&gt;|z|      [95.0% Conf. Int.]
--------------------------------------------------------------------------------------
Intercept              0.5197      0.340      1.527      0.127        -0.147     1.187
C(whichclass)[T.2]    -0.2573      0.354     -0.728      0.467        -0.950     0.436
C(whichclass)[T.3]    -0.9164      0.352     -2.605      0.009        -1.606    -0.227
age                   -0.6795      0.286     -2.380      0.017        -1.239    -0.120
sex                   -0.8033      0.284     -2.825      0.005        -1.361    -0.246
======================================================================================</code></pre>
<p>Görüldüğü gibi kalıntı sapmada (residual deviance) seviyesinde büyük bir düşüş oldu, yani hata azaldı. Bu regresyon çıktısında bazı katsayılar Poisson GLM'dekiyle aynı olsa da bazıları değişti. Daha doğru olan değerler bunlar.</p>
<p>Katsayıları Yorumlamak</p>
<p>Elde edilen sonuçları pek çok şekilde yorumlamak mümkün, fakat en faydalı olanı kategorik değişkenler için hesaplanabilen bir Oluş Oran Hızıdır (İncidence Rate Ratio -IRR-). İsim biraz garip, evet, İngilizcesi de öyle. Bu gayet basit bir operasyon, sadece katsayının <span class="math inline">\(\exp\)</span>'sini almak yeterli. İRR ne sağlar? Aynı büyüklükteki bir oluş sayısının içinden iki grubu (ve onu gösteren değişken üzerinden) karşılaştırmayı. Mesela her ikisi de <span class="math inline">\(t\)</span> büyüklüğünde (yani aynı büyüklükte) olan yetişkin ve çocuk gruplarının birbirinle oranla hayatta kalma şansı nedir? Modele dönersek, yetişkinler için oran,</p>
<p><span class="math display">\[ \theta_{adults} / t = \exp ( \beta_0 + \beta_1(1) + \beta_2(sex) + \beta_2(whichclass=2) + \beta_2(whichclass=3)  \]</span></p>
<p>Çocuklar için oran (sadece üstteki <span class="math inline">\(\beta_1(1)\)</span> yerine <span class="math inline">\(\beta_1(0)\)</span> olacak), <span class="math display">\[ \theta_{children} / t = \exp ( \beta_0 + \beta_1(0) + \beta_2(sex) + \beta_2(whichclass=2) + \beta_2(whichclass=3)  \]</span></p>
<p>Bu iki oranı bölersek İRR ortaya çıkar,</p>
<p><span class="math display">\[ 
\frac{\theta_{adults} / t}{\theta_{children} / t} = 
\frac
{\exp ( \beta_0 + \beta_1(1) + \beta_2(sex) + \beta_2(whichclass=2) + \beta_2(whichclass=3))}
{\exp ( \beta_0 + \beta_1(0) + \beta_2(sex) + \beta_2(whichclass=2) + \beta_2(whichclass=3))}
\]</span></p>
<p>Toplamların <span class="math inline">\(\exp\)</span>'sı her terimin <span class="math inline">\(\exp\)</span>'sinin çarpımıdır. Bu çarpımların çoğu iptal olur, geriye sadece,</p>
<p><span class="math display">\[ =
\frac{\exp ( \beta_1(1))} {\exp ( \beta_1(0) ) } = 
e^{\beta_1}
\]</span></p>
<p>kalır. Yani İRR'i hesaplamak bir katsayının <span class="math inline">\(\exp\)</span>'sini almaktan ibarettir. Biz altta tüm katsayıların <span class="math inline">\(\exp\)</span>'sini aldık,</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="bu">print</span> <span class="st">&#39;exp katsayilar&#39;</span>
<span class="bu">print</span> np.exp(modelnb.params)</code></pre></div>
<pre><code>exp katsayilar
Intercept             1.681497
C(whichclass)[T.2]    0.773108
C(whichclass)[T.3]    0.399941
age                   0.506850
sex                   0.447870
dtype: float64</code></pre>
<p>Bizim aradığımız sonuç <span class="math inline">\(e^{\beta_1} = e^{-0.678} = 0.50\)</span>, üstte görülen soldan 2. değer. İRR'de bölen çocuk ve değer 1'den küçük olduğuna göre, demek ki yetişkenlerin çocuklara göre hayatta kalma oranı yarı yarıya! Çocuklar daha şanslı.</p>
<p>Not: Bir sürü işlem yaptık, insanın aklına gelebilir, acaba bu cevabı ana veri üzerinde sadece basit bölme operasyonları ile yapamaz mıydık?</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">adults <span class="op">=</span> np.array(df[(df[<span class="st">&#39;age&#39;</span>]<span class="op">==</span><span class="dv">1</span>)].<span class="bu">sum</span>()[[<span class="st">&#39;survive&#39;</span>,<span class="st">&#39;cases&#39;</span>]])
ratea <span class="op">=</span> adults[<span class="dv">0</span>] <span class="op">/</span> <span class="bu">float</span>(adults[<span class="dv">1</span>])
children <span class="op">=</span>  np.array(df[(df[<span class="st">&#39;age&#39;</span>]<span class="op">==</span><span class="dv">0</span>)].<span class="bu">sum</span>()[[<span class="st">&#39;survive&#39;</span>,<span class="st">&#39;cases&#39;</span>]])
ratec <span class="op">=</span> children[<span class="dv">0</span>] <span class="op">/</span> <span class="bu">float</span>(children[<span class="dv">1</span>])
<span class="bu">print</span> ratea, ratec, <span class="st">&#39;nihai sonuc&#39;</span>, ratea<span class="op">/</span>ratec</code></pre></div>
<pre><code>0.366197183099 0.522935779817 nihai sonuc 0.700271806276</code></pre>
<p>0.70 sonucu üstteki 0.50'den oldukça farklı. Daha doğru olan GLM değeri.</p>
<p>Tahmin Üretmek</p>
<p>Katsayıları kullanarak tahmin nasıl üretiriz? Yeni veri noktasına tekabül eden katsayıları alıp çarpıp, toplarız, ve sonuç üzerine <span class="math inline">\(\exp\)</span> uygularız. Bu bize <span class="math inline">\(\theta_i/u_i\)</span> oranını verecektir.</p>
<p>Örnek, acaba 3. sınıftaki erkek çocukların hayatta kalma oranı nedir?</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">p <span class="op">=</span> model.params
arr <span class="op">=</span> np.array(df[ (df[<span class="st">&#39;whichclass&#39;</span>]<span class="op">==</span><span class="dv">3</span>) <span class="op">&amp;</span> (df[<span class="st">&#39;sex&#39;</span>]<span class="op">==</span><span class="dv">1</span>) <span class="op">&amp;</span> (df[<span class="st">&#39;age&#39;</span>]<span class="op">==</span><span class="dv">0</span>) ])
<span class="bu">print</span> <span class="st">&#39;veri&#39;</span>, arr[<span class="dv">0</span>][<span class="dv">0</span>] <span class="op">/</span> arr[<span class="dv">0</span>][<span class="dv">1</span>]
<span class="bu">print</span> <span class="st">&#39;tahmin&#39;</span>, np.exp(p[<span class="dv">0</span>] <span class="op">+</span> p[<span class="dv">2</span>] <span class="op">+</span> p[<span class="dv">4</span>])</code></pre></div>
<pre><code>veri 0.270833333333
tahmin 0.234504990187</code></pre>
<p>Acaba 2. sınıftaki yetişkin erkeklerin hayatta kalma oranı nedir?</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">p <span class="op">=</span> model.params
arr <span class="op">=</span> np.array(df[ (df[<span class="st">&#39;whichclass&#39;</span>]<span class="op">==</span><span class="dv">2</span>) <span class="op">&amp;</span> (df[<span class="st">&#39;sex&#39;</span>]<span class="op">==</span><span class="dv">1</span>) <span class="op">&amp;</span> (df[<span class="st">&#39;age&#39;</span>]<span class="op">==</span><span class="dv">1</span>) ])
<span class="bu">print</span> <span class="st">&#39;veri&#39;</span>, arr[<span class="dv">0</span>][<span class="dv">0</span>] <span class="op">/</span> arr[<span class="dv">0</span>][<span class="dv">1</span>]
<span class="bu">print</span> <span class="st">&#39;tahmin&#39;</span>, np.exp(p[<span class="dv">0</span>] <span class="op">+</span> p[<span class="dv">1</span>] <span class="op">+</span> p[<span class="dv">4</span>] <span class="op">+</span> p[<span class="dv">4</span>])</code></pre></div>
<pre><code>veri 0.0833333333333
tahmin 0.108052057562</code></pre>
<p>Eğer üretilen tahminler için bir güven aralığı tanımlamak istiyorsak, <code>conf_int()</code> ile tüm katsayılar için %95 güven aralığını alabiliriz,</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="bu">print</span> model.conf_int()</code></pre></div>
<pre><code>                           0         1
Intercept           0.171628  0.797290
C(whichclass)[T.2] -0.608738 -0.147836
C(whichclass)[T.3] -0.978885 -0.559276
age                -0.768391 -0.197547
sex                -1.351899 -0.979415</code></pre>
<p>Bu sonuç bir Pandas DataFrame'i, rahatlıkla istediğimiz satırı, kolonuna erişebiliriz. Kolon <code>0</code> alt değeri, kolon <code>1</code> üst değeri taşıyor. Bu güven aralıkları üzerinde de <span class="math inline">\(\exp\)</span> hesabı yapmak mümkündür.</p>
<p>Kaynaklar</p>
<p>[1] Zwilling, <em>Negative Binomial Regression</em>, <a href="http://www.mathematica-journal.com/2013/06/negative-binomial-regression" class="uri">http://www.mathematica-journal.com/2013/06/negative-binomial-regression</a></p>
<p>[2] SAS, {}, <a href="http://support.sas.com/kb/24/188.html" class="uri">http://support.sas.com/kb/24/188.html</a></p>
<p>[3] Gelman, Hill, <em>Data Analysis Using Regression and Multilevel/Hierarchical Models</em></p>
<p>
  <a href="..">Yukarı</a>
</p>
</body>
</html>
