\documentclass[12pt,fleqn]{article}\usepackage{../../common}
\begin{document}
Sayým, Poisson ve Negatif Binom Bazlý Genel Lineer Modelleri (GLM)

Sayým (count) verisini modellemek için genellikle Poisson daðýlýmýna
baþvurulur. Ayrýca ortada bir regresyon problemi var ise, yani belli
katsayýlar üzerinden çarpýlan deðiþkenlerin sonucu ile bir sayým arasýnda
iliþki kurulmak istenirse -ki bu Logit örneðinde görülmüþtü, link
fonksiyonu sigmoid yerine Poisson olur- o zaman Poisson GLM kullanýlýr.

Poisson daðýlýmýný hatýrlarsak, 

$$ f(x;\lambda) = e^{-\lambda}\frac{\lambda^{x}}{x!} $$

Eðer bir $y_i$ rasgele deðiþkenini daðýlýmý $\lambda=\theta_i$ olan Poisson
rasgele deðiþkeni diye tanýmlamak istersek, ki bu daðýlým alttaki tanýma
göre her $i$ için deðiþik olur,

$$ y_i \sim Poisson(\theta_i) $$

Yoðunluk 

$$ f(y_i;\theta_i) = Poisson(y_i;\theta_i) $$

olarak ta gösterilebilir.  Þimdi GLM, yani regresyon yapmak için
$\theta_i$'yi biraz daha detaylandýralým / içini dolduralým,

$$ \theta_i = \exp(X_i \beta)$$

Poisson daðýlýmý regresyon kaynaðý olacak deðiþkenlerin lineer kombinasyonu
ile parametrize edilecek, $\beta$ regresyonun tahmin edeceði katsayýlar
olacak.  $\theta_i$ ile parametrizasyon sonucu her veri noktasý için farklý
olabilecek bir $\theta_i$ ortaya çýkabileceðinden bahsettik, fakat bu
parametrizasyonlarýn arkasýnda hep ayný $\beta$ vektörü olacak, bu durumda
Poisson GLM'i veriye uydurmak demek veriyi en iyi açýklayan bu ayný
$\beta$'yi ortaya çýkartmaktýr.

$\exp$ alýnmýþ olmasýnýn sebebi ise sadece artý sayýlar ile çalýþmak
istememiz, çünkü $\exp$ alýnýnca eksi sayýlar bile sýfýrdan büyük olur,

\begin{minted}[fontsize=\footnotesize]{python}
print np.exp(-2)
print np.exp(1./6)
\end{minted}

\begin{verbatim}
0.135335283237
1.18136041287
\end{verbatim}

Merak edenler için maksimum olurluk

$$ f(y;\beta,X) = \prod_{i=1}^n Poisson(y_i;e^{X_i\beta} ) $$

Veri

Devam etmeden önce veriye bakýp Poisson varsayýmýný kontrol etmek iyi
olur. Mesela örnek verimiz bir bölgede oturan insanlarýn medyan kazanç
(median income) ile bu kazanca sahip olan þahýslarýn evlerine ne kadar
hýrsýz girdiði arasýndaki iliþki. Medyan kazanç için kaç eve hýrsýz girdiði
bir sayým verisi, ilk akla gelen Poisson ile modellenmesi, bakalým,

\begin{minted}[fontsize=\footnotesize]{python}
import pandas as pd
burg = pd.read_csv('burglary.txt',sep=' ')
burg.plot(y='burglaries',x='median_income',kind='scatter')
plt.savefig('stat_count_01.png')
\end{minted}

\includegraphics[height=6cm]{stat_count_01.png}

Grafik Poisson'a benziyor.. Diðer yandan aslýnda negatif binom daðýlýmýna
da benziyor. Þimdilik Poisson varsayýmý ile devam edelim. Bu daðýlýmýn
önemli bir varsayýmý ortalamasýnýn varyansý ile ayný olmasýdýr. Veride
durum böyle midir?

Medyan kazancý 59 ile 61 arasýnda olan kiþilere bakalým,

\begin{minted}[fontsize=\footnotesize]{python}
burg_59_61 = burg[(burg['median_income'] > 59) & (burg['median_income'] < 61)]
m = burg_59_61['burglaries'].mean()
v = burg_59_61['burglaries'].std()**2
print m, v, v/m
\end{minted}

\begin{verbatim}
7.33333333333 22.5384615385 3.07342657343
\end{verbatim}

Veriden örneklem ortalamasý ve örneklem varyansýný hesapladýk. Ne yazýk ki
varyans ortalamanýn üç katý! Demek ki bu verinin daðýlýmýnýn Poisson olma
olasýlýðý düþük. Verinin baþka bir bölgesine bakarsak,

\begin{minted}[fontsize=\footnotesize]{python}
burg_59_61 = burg[(burg['median_income'] > 39) & (burg['median_income'] < 41)]
m = burg_59_61['burglaries'].mean()
v = burg_59_61['burglaries'].std()**2
print m, v, v/m
\end{minted}

\begin{verbatim}
21.8571428571 97.1428571429 4.44444444444
\end{verbatim}

Aradaki fark bu sefer daha da büyük. Eðer bu veriye Poisson bazlý bir GLM
uydurmaya kalksaydýk, ortaya aþýrý saçýlmýþ (överdispersed) bir durum
ortaya çýkardý. Ya da terminoloji olarak ve Poisson bazlý düþünürsek bu
verinin aþýrý saçýlmýþ olduðu söylenecekti. Her iki yöntemi de
deneyebiliriz, önce Poisson bazlý sonra Negatif Binomial bazlý bir
GLM. Ýkincisinin daha iyi sonuç verdiðini daha düþük kalýntý sapma
(residual deviance) deðerinden anlayabiliriz.

\begin{minted}[fontsize=\footnotesize]{python}
import pandas as pd
import statsmodels.formula.api as smf
import statsmodels.api as sm
model=smf.glm("burglaries ~ median_income", data=burg,
             family=sm.families.Poisson()).fit()
print(model.summary())
model=smf.glm("burglaries ~ median_income", data=burg,
             family=sm.families.NegativeBinomial()).fit()
print(model.summary())
\end{minted}

\begin{verbatim}
                 Generalized Linear Model Regression Results                  
==============================================================================
Dep. Variable:             burglaries   No. Observations:                  500
Model:                            GLM   Df Residuals:                      498
Model Family:                 Poisson   Df Model:                            1
Link Function:                    log   Scale:                             1.0
Method:                          IRLS   Log-Likelihood:                -1596.2
Date:                Mon, 09 Mar 2015   Deviance:                       1452.6
Time:                        16:10:11   Pearson chi2:                 1.47e+03
No. Iterations:                     8                                         
=================================================================================
                    coef    std err          z      P>|z|      [95.0% Conf. Int.]
---------------------------------------------------------------------------------
Intercept         5.6124      0.056    100.228      0.000         5.503     5.722
median_income    -0.0613      0.001    -56.191      0.000        -0.063    -0.059
=================================================================================
                 Generalized Linear Model Regression Results                  
==============================================================================
Dep. Variable:             burglaries   No. Observations:                  500
Model:                            GLM   Df Residuals:                      498
Model Family:        NegativeBinomial   Df Model:                            1
Link Function:                    log   Scale:                  0.354315963879
Method:                          IRLS   Log-Likelihood:                -1482.4
Date:                Mon, 09 Mar 2015   Deviance:                       208.25
Time:                        16:10:12   Pearson chi2:                     176.
No. Iterations:                     7                                         
=================================================================================
                    coef    std err          z      P>|z|      [95.0% Conf. Int.]
---------------------------------------------------------------------------------
Intercept         5.5857      0.133     42.103      0.000         5.326     5.846
median_income    -0.0608      0.002    -27.925      0.000        -0.065    -0.057
=================================================================================
\end{verbatim}

Titanik Verisi 

Daha ilginç bir veri batan Titanik gemisinin kayýtlarý. Bu kayýtlarda
yolcularýn sað kurtulup kurtulmadýðý onlar hakkýnda baz bilgi ile beraber
kiþi seviyesinde kaydedilmiþ. Hangi sýnýfta (whichclass) seyahat etmiþ,
yetiþkin mi (adult) çocuk mu, cinsiyeti erkek mi kadýn mý (man / woman),
hayatta kaldý mý (survived) gibi bilgiler bu kayýtlarda. Bu veriye bakýp
istatistiki olarak mesela yolcunun seyahat ettiði sýnýfýn hayatta kalmaya
etki edip etmediði görülebilir. Ham verinin birkaç satýrýna bakalým,

\begin{minted}[fontsize=\footnotesize]{python}
import pandas as pd
tmp = pd.read_csv("titanic.csv",sep=',',index_col=0)
print tmp.head(5)
\end{minted}

\begin{verbatim}
       class     age  sex survived
1  1st class  adults  man      yes
2  1st class  adults  man      yes
3  1st class  adults  man      yes
4  1st class  adults  man      yes
5  1st class  adults  man      yes
\end{verbatim}

Tahmin baðlamýnda verinin 1/0 etiketlerine sahip olmasýndan hareketle ilk
akla gelen ona bir lojistik regresyon ya da Logit modeli uydurmak
olabilir. Fakat bu verinin her satýrý üzerinden Logit yapmak yerine grup
toplamlarý üzerinden Poisson ya da Negatif Binom yapmak daha uygun
olur. Toplamlara bakalým (ayrý bir dosyada),

\begin{minted}[fontsize=\footnotesize]{python}
import pandas as pd
df = pd.read_csv("titanicgrp.csv",sep=',',index_col=0)
print df
\end{minted}

\begin{verbatim}
    survive  cases  age  sex  whichclass
1         1      1    0    0           1
2        13     13    0    0           2
3        14     31    0    0           3
4         5      5    0    1           1
5        11     11    0    1           2
6        13     48    0    1           3
7       140    144    1    0           1
8        80     93    1    0           2
9        76    165    1    0           3
10       57    175    1    1           1
11       14    168    1    1           2
12       75    462    1    1           3
\end{verbatim}

Poisson ile ilerlemeden önce, bir soru soralým: niye 1. sýnýfta kurtulan
çocuk sayýsý 2. ve 3. sýnýftakinden daha az?

\begin{minted}[fontsize=\footnotesize]{python}
print df[(df['age']==0) & (df['whichclass']==1) ].sum()['survive']
print df[(df['age']==0) & (df['whichclass']==2) ].sum()['survive']
print df[(df['age']==0) & (df['whichclass']==3) ].sum()['survive']
\end{minted}

\begin{verbatim}
6
24
27
\end{verbatim}

Bu bizi þaþýrtýyor, çünkü o sýnýftan daha fazla kiþinin kurtulmasýný
bekleriz. Fakat sebep baþka, sebep 1. sýnýfta seyahat eden toplam çocuk
sayýsýnýn zaten az olmasý. Toplamlara bakarsak,

\begin{minted}[fontsize=\footnotesize]{python}
print '1. sinif cocuk sayisi,', 
df[(df['age']==0) & (df['whichclass']==1) ].sum()['cases']
print '2. sinif cocuk sayisi,', 
df[(df['age']==0) & (df['whichclass']==2) ].sum()['cases']
print '3. sinif cocuk sayisi,', 
df[(df['age']==0) & (df['whichclass']==3) ].sum()['cases']
\end{minted}

\begin{verbatim}
1. sinif cocuk sayisi, 6
2. sinif cocuk sayisi, 24
3. sinif cocuk sayisi, 79
\end{verbatim}

0 zaman direk sayýmý modellemek yerine, bir þekilde 6 içinden 6
kurtulmasýnýn, 79 içinden 27 kurtulmaktan daha iyi olduðunu gösterebilecek
bir model eki bize gerekiyor. Yoksa þu anki haliyle 6 ve 27 ana regresyon
hedefleri olarak alýnacaktýr, ki bu doðru olmaz. 

Kaydýrma (offset) numarasý burada ise yarar. Ondan önce, oran kavramýný bir
þekilde modele dahil etmeyi görelim; Diyelim ki $\theta_i$ sayýsýnýn (ki bu
mesela hayatta kalma sayýsý) hangi toplam içinden çýktýðýný belirtmek için
bir $u_i$ deðiþkeni tasarlayalým, ve oraný þöyle modele dahil edelim,

$$ \frac{\theta_i}{u_i} = \exp (X_i\beta) $$

Eðer 79'dan 27 kiþi kurtulduysa $u_i=79$ ve $\theta_i=27$ olacak. Þimdi bir
numara daha yapacaðýz, çünkü 100 içinden 10 gelmesi ile 200 içinden 20
gelmesi arasýndaki farký da modellemek istiyoruz, normal þartlarda bu iki
oran aynýdýr (1/10). Fakat bir fark olmalý. Ýki tarafýn $\log$'unu alýrsak,

$$ \log \bigg(\frac{\theta_i}{u_i} \bigg) = X_i\beta $$

$$ \log \theta_i -  \log u_i = X_i\beta $$

$$ \log \theta_i = \log u_i + X_i\beta $$

Böylece $u_i$ deðiþkeni bir kaydýrma operasyonu ile olduðu haliyle modele
eklenmiþ oldu! Modelde bu deðiþkenin bir katsayýsý olacak, maksimum olurluk
onu öðrenmeye çalýþacak, vs. Tek bir ek iþlem lazým, regresyona veriyi
vermeden önce kaydýrýlan deðiþkenin (toplam sayýmýn) $\log$'u alýnýr
(Poisson modelleri kendi içinde hedef deðiþkenini zaten $\log$'lar, ona
dokunmaya gerek yok).

Þimdi Titanik verisini modelleyelim. 

\begin{minted}[fontsize=\footnotesize]{python}
import pandas as pd
import statsmodels.formula.api as smf
import statsmodels.api as sm

df = pd.read_csv("titanicgrp.csv",sep=',',index_col=0)
df['lncases'] = df['cases'].map(lambda x:np.log(x))

model=smf.glm("survive ~ age + sex + C(whichclass)", data=df, offset=df['lncases'],
             family=sm.families.Poisson()).fit()
print(model.summary())
\end{minted}

\begin{verbatim}
                 Generalized Linear Model Regression Results                  
==============================================================================
Dep. Variable:                survive   No. Observations:                   12
Model:                            GLM   Df Residuals:                        7
Model Family:                 Poisson   Df Model:                            4
Link Function:                    log   Scale:                             1.0
Method:                          IRLS   Log-Likelihood:                -48.530
Date:                Thu, 19 Mar 2015   Deviance:                       38.304
Time:                        14:15:55   Pearson chi2:                     39.1
No. Iterations:                     9                                         
======================================================================================
                         coef    std err          z      P>|z|      [95.0% Conf. Int.]
--------------------------------------------------------------------------------------
Intercept              0.4845      0.160      3.035      0.002         0.172     0.797
C(whichclass)[T.2]    -0.3783      0.118     -3.217      0.001        -0.609    -0.148
C(whichclass)[T.3]    -0.7691      0.107     -7.185      0.000        -0.979    -0.559
age                   -0.4830      0.146     -3.317      0.001        -0.768    -0.198
sex                   -1.1657      0.095    -12.267      0.000        -1.352    -0.979
======================================================================================
\end{verbatim}

Negatif Binom Modelleri 

Üstteki sonuçlar hiç fena deðil. Fakat verinin kurtulan kiþi sayýsýnýn
daðýlýmýnýn Poisson olduðu varsayýmý her zaman doðru olmayabilir. Bu
durumlarda Negatif Binom kullanýmý daha doðru olabilir. NB regresyonu için
üstte gördüðümüz tüm kavramlar hala geçerli, sadece perde arkasýnda

$$ y_i \sim NegativeBinomial(\theta_i) $$

kullanýmý olacaktýr, ve tabii ki farklý bir kütüphane çaðrýsý yapýlýr,
ama geri kalan her þey ayný. 

\begin{minted}[fontsize=\footnotesize]{python}
modelnb=smf.glm("survive ~ age + sex + C(whichclass)", data=df, offset=df['lncases'],
             family=sm.families.NegativeBinomial()).fit()
print(modelnb.summary())
\end{minted}

\begin{verbatim}
                 Generalized Linear Model Regression Results                  
==============================================================================
Dep. Variable:                survive   No. Observations:                   12
Model:                            GLM   Df Residuals:                        7
Model Family:        NegativeBinomial   Df Model:                            4
Link Function:                    log   Scale:                  0.222676200695
Method:                          IRLS   Log-Likelihood:                -50.130
Date:                Thu, 19 Mar 2015   Deviance:                       1.9976
Time:                        14:16:24   Pearson chi2:                     1.56
No. Iterations:                    13                                         
======================================================================================
                         coef    std err          z      P>|z|      [95.0% Conf. Int.]
--------------------------------------------------------------------------------------
Intercept              0.5197      0.340      1.527      0.127        -0.147     1.187
C(whichclass)[T.2]    -0.2573      0.354     -0.728      0.467        -0.950     0.436
C(whichclass)[T.3]    -0.9164      0.352     -2.605      0.009        -1.606    -0.227
age                   -0.6795      0.286     -2.380      0.017        -1.239    -0.120
sex                   -0.8033      0.284     -2.825      0.005        -1.361    -0.246
======================================================================================
\end{verbatim}

Görüldüðü gibi kalýntý sapmada (residual deviance) seviyesinde büyük bir
düþüþ oldu, yani hata azaldý. Bu regresyon çýktýsýnda bazý katsayýlar
Poisson GLM'dekiyle ayný olsa da bazýlarý deðiþti. Daha doðru olan deðerler
bunlar.

Katsayýlarý Yorumlamak

Elde edilen sonuçlarý pek çok þekilde yorumlamak mümkün, fakat en faydalý
olaný kategorik deðiþkenler için hesaplanabilen bir Oluþ Oran Hýzýdýr
(Ýncidence Rate Ratio -IRR-). Ýsim biraz garip, evet, Ýngilizcesi de öyle.
Bu gayet basit bir operasyon, sadece katsayýnýn $\exp$'sini almak
yeterli. ÝRR ne saðlar? Ayný büyüklükteki bir oluþ sayýsýnýn içinden iki
grubu (ve onu gösteren deðiþken üzerinden) karþýlaþtýrmayý. Mesela her
ikisi de $t$ büyüklüðünde (yani ayný büyüklükte) olan yetiþkin ve çocuk
gruplarýnýn birbirinle oranla hayatta kalma þansý nedir? Modele dönersek,
yetiþkinler için oran,

$$ \theta_{adults} / t = \exp ( \beta_0 + \beta_1(1) + \beta_2(sex) + \beta_2(whichclass=2) + \beta_2(whichclass=3)  $$

Çocuklar için oran (sadece üstteki $\beta_1(1)$ yerine $\beta_1(0)$ olacak),
$$ \theta_{children} / t = \exp ( \beta_0 + \beta_1(0) + \beta_2(sex) + \beta_2(whichclass=2) + \beta_2(whichclass=3)  $$

Bu iki oraný bölersek ÝRR ortaya çýkar, 

$$ 
\frac{\theta_{adults} / t}{\theta_{children} / t} = 
\frac
{\exp ( \beta_0 + \beta_1(1) + \beta_2(sex) + \beta_2(whichclass=2) + \beta_2(whichclass=3))}
{\exp ( \beta_0 + \beta_1(0) + \beta_2(sex) + \beta_2(whichclass=2) + \beta_2(whichclass=3))}
$$

Toplamlarýn $\exp$'sý her terimin $\exp$'sinin çarpýmýdýr. Bu çarpýmlarýn
çoðu iptal olur, geriye sadece,

$$ =
\frac{\exp ( \beta_1(1))} {\exp ( \beta_1(0) ) } = 
e^{\beta_1}
$$

kalýr. Yani ÝRR'i hesaplamak bir katsayýnýn $\exp$'sini almaktan
ibarettir. Biz altta tüm katsayýlarýn $\exp$'sini aldýk,

\begin{minted}[fontsize=\footnotesize]{python}
print 'exp katsayilar'
print np.exp(modelnb.params)
\end{minted}

\begin{verbatim}
exp katsayilar
Intercept             1.681497
C(whichclass)[T.2]    0.773108
C(whichclass)[T.3]    0.399941
age                   0.506850
sex                   0.447870
dtype: float64
\end{verbatim}

Bizim aradýðýmýz sonuç $e^{\beta_1} = e^{-0.678} = 0.50$, üstte görülen
soldan 2. deðer. ÝRR'de bölen çocuk ve deðer 1'den küçük olduðuna göre,
demek ki yetiþkenlerin çocuklara göre hayatta kalma oraný yarý yarýya!
Çocuklar daha þanslý.

Not: Bir sürü iþlem yaptýk, insanýn aklýna gelebilir, acaba bu cevabý ana
veri üzerinde sadece basit bölme operasyonlarý ile yapamaz mýydýk?

\begin{minted}[fontsize=\footnotesize]{python}
adults = np.array(df[(df['age']==1)].sum()[['survive','cases']])
ratea = adults[0] / float(adults[1])
children =  np.array(df[(df['age']==0)].sum()[['survive','cases']])
ratec = children[0] / float(children[1])
print ratea, ratec, 'nihai sonuc', ratea/ratec
\end{minted}

\begin{verbatim}
0.366197183099 0.522935779817 nihai sonuc 0.700271806276
\end{verbatim}

0.70 sonucu üstteki 0.50'den oldukça farklý. Daha doðru olan GLM deðeri.

Tahmin Üretmek 

Katsayýlarý kullanarak tahmin nasýl üretiriz? Yeni veri noktasýna tekabül
eden katsayýlarý alýp çarpýp, toplarýz, ve sonuç üzerine $\exp$
uygularýz. Bu bize $\theta_i/u_i$ oranýný verecektir. 

Örnek, acaba 3. sýnýftaki erkek çocuklarýn hayatta kalma oraný nedir?

\begin{minted}[fontsize=\footnotesize]{python}
p = model.params
arr = np.array(df[ (df['whichclass']==3) & (df['sex']==1) & (df['age']==0) ])
print 'veri', arr[0][0] / arr[0][1]
print 'tahmin', np.exp(p[0] + p[2] + p[4])
\end{minted}

\begin{verbatim}
veri 0.270833333333
tahmin 0.234504990187
\end{verbatim}

Acaba 2. sýnýftaki yetiþkin erkeklerin hayatta kalma oraný nedir? 

\begin{minted}[fontsize=\footnotesize]{python}
p = model.params
arr = np.array(df[ (df['whichclass']==2) & (df['sex']==1) & (df['age']==1) ])
print 'veri', arr[0][0] / arr[0][1]
print 'tahmin', np.exp(p[0] + p[1] + p[4] + p[4])
\end{minted}

\begin{verbatim}
veri 0.0833333333333
tahmin 0.108052057562
\end{verbatim}

Eðer üretilen tahminler için bir güven aralýðý tanýmlamak istiyorsak,
\verb!conf_ýnt()! ile tüm katsayýlar için \%95 güven aralýðýný alabiliriz,

\begin{minted}[fontsize=\footnotesize]{python}
print model.conf_int()
\end{minted}

\begin{verbatim}
                           0         1
Intercept           0.171628  0.797290
C(whichclass)[T.2] -0.608738 -0.147836
C(whichclass)[T.3] -0.978885 -0.559276
age                -0.768391 -0.197547
sex                -1.351899 -0.979415
\end{verbatim}

Bu sonuç bir Pandas DataFrame'i, rahatlýkla istediðimiz satýrý, kolonuna
eriþebiliriz. Kolon \verb!0! alt deðeri, kolon \verb!1! üst deðeri
taþýyor. Bu güven aralýklarý üzerinde de $\exp$ hesabý yapmak mümkündür. 

Kaynaklar

[1] Zwilling, {\em Negative Binomial Regression}, \url{http://www.mathematica-journal.com/2013/06/negative-binomial-regression}

[2] SAS, {\em Usage Note 24188: Modeling rates and estimating rates and rate
  ratios (with confidence intervals)}, \url{http://support.sas.com/kb/24/188.html}

[3] Gelman, Hill, {\em Data Analysis Using Regression and Multilevel/Hierarchical Models}



\end{document}
