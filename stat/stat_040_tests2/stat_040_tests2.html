<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title></title>
  <style type="text/css">code{white-space: pre;}</style>
  <style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
  </style>
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>
  
  
  
  
</head>
<body>
<h1 id="testlere-devam">Testlere Devam</h1>
<p>İstatistiki test yaratmak için takip edilen teknik basit; bir istatistiki ölçüt hesaplıyoruz, ya da hesabımızın başka noktasından çıkanı alıyoruz, ki bu ölçüt mesela bir ortalama olabilir bu durumda bilinen bir dağılımı vardır, ya da lineer regresyondan bize verilen bir katsayıdır, onun t değeri vardır, bu durumda da dağılımın ne olduğunu biliyoruz. Yani hangi ölçüte bakarsak bakalım, ya da biz yeni bir tanesini uyduralım, önce elde ettiğimiz rasgele değişkeninin ideal koşullarda dağılımının ne olduğuna bakarız, ki test ettiğimiz bir anlamda bu ideal koşullar olacaktır. Ardından bir kriter ortaya koyarak testi ortaya çıkartırız.</p>
<p>Ama ondan önce biraz regresyon.</p>
<p>Örnek veri olarak Big Andy's Burger Barn adında hamburger satan bir restoran zincirinin verisini kullanalım [1, sf. 168]. Veride her nokta ayrı bir şehirdeki belli bir aydaki dükkan için kaydedilmiş reklam gideri <span class="math inline">\(ADVERT\)</span>, burger fiyatı <span class="math inline">\(PRICE\)</span>, ve satış getirisi <span class="math inline">\(SALES\)</span> (<span class="math inline">\(SALES\)</span> ve <span class="math inline">\(ADVERT\)</span> bin dolarlık birimde kaydedilmiş). Şirket yönetimi diyelim ki reklam harcamalarının satışları nasıl etkilediğini merak ediyor. Ayrıca yönetim bir fiyatlama stratejisi belirlemek istiyor, fiyatın geliri nasıl etkilmektedir? Fiyatta düşüş çok az satış artışı yaratıyorsa bu durum kazancı düşürür, demek ki talep fiyatsal-elastik değildir (price inelastic). Tam tersi de olabilir, fiyat değişimi satışı arttırır, o zaman talep fiyatsal-elastiktir.</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="im">import</span> pandas <span class="im">as</span> pd
df <span class="op">=</span> pd.read_csv(<span class="st">&#39;andy.dat&#39;</span>,sep<span class="op">=</span><span class="st">&#39;\s*&#39;</span>,names<span class="op">=</span>[<span class="st">&#39;sales&#39;</span>,<span class="st">&#39;price&#39;</span>,<span class="st">&#39;advert&#39;</span>])
<span class="bu">print</span> df.head(<span class="dv">3</span>)</code></pre></div>
<pre><code>   sales  price  advert
0   73.2   5.69     1.3
1   71.8   6.49     2.9
2   62.4   5.63     0.8</code></pre>
<p>Regresyon modelini kuralım,</p>
<p><span class="math display">\[ SALES = \beta_1 + \beta_2 PRICE + \beta_3 ADVERT \]</span></p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="im">import</span> statsmodels.formula.api <span class="im">as</span> smf
results <span class="op">=</span> smf.ols(<span class="st">&#39;sales ~ price + advert&#39;</span>, data<span class="op">=</span>df).fit()
<span class="bu">print</span> results.summary()</code></pre></div>
<pre><code>                            OLS Regression Results                            
==============================================================================
Dep. Variable:                  sales   R-squared:                       0.448
Model:                            OLS   Adj. R-squared:                  0.433
Method:                 Least Squares   F-statistic:                     29.25
Date:                Mon, 24 Aug 2015   Prob (F-statistic):           5.04e-10
Time:                        08:59:52   Log-Likelihood:                -223.87
No. Observations:                  75   AIC:                             453.7
Df Residuals:                      72   BIC:                             460.7
Df Model:                           2                                         
Covariance Type:            nonrobust                                         
==============================================================================
                 coef    std err          t      P&gt;|t|      [95.0% Conf. Int.]
------------------------------------------------------------------------------
Intercept    118.9136      6.352     18.722      0.000       106.252   131.575
price         -7.9079      1.096     -7.215      0.000       -10.093    -5.723
advert         1.8626      0.683      2.726      0.008         0.501     3.225
==============================================================================
Omnibus:                        0.535   Durbin-Watson:                   2.183
Prob(Omnibus):                  0.765   Jarque-Bera (JB):                0.159
Skew:                          -0.072   Prob(JB):                        0.924
Kurtosis:                       3.174   Cond. No.                         69.5
==============================================================================</code></pre>
<p>Fiyatsal elastikliği kontrol etmek için <span class="math inline">\(\beta_2\)</span>'nin t değerine bakabiliriz çünkü bu değer <span class="math inline">\(\beta_2=0\)</span> hipotezini reddedip reddedemeyeceğimiz hakkında bize bir şeyler söylüyor. Eğer t değer ve <code>P&gt;|t|</code> değeri 0.05'ten küçük ise hipotezi reddedebiliriz. Çıktıya bakıyoruz, 0 değerini görüyoruz. Demek ki fiyatsal elastiklik vardır.</p>
<p>Gayrı Lineerlik: Fakat acaba reklam harcaması ile satış arasında tam lineer bir ilişki mi var? Belli bir noktadan sonra ne kadar harcarsak harcayalım daha fazla kazanamayacağımız bir durum da olamaz mı? Bunu test edelim, <span class="math inline">\(ADVERT^2\)</span> değişkenini ekleyip yeni bir regresyon yaratalım. <span class="math inline">\(ADVERT\)</span>'in karesini aldık çünkü karesi alınmış <span class="math inline">\(ADVERT\)</span> normal olana göre daha hızlı büyür, yani büyük değerlerde karesinin sonucu çok daha büyüktür, ve eğer bu uç noktalarda bir kalıp var ise, onu &quot;yakalamak'' bu karesi alınmış yeni değişken sayesinde mümkün olur.</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="im">import</span> statsmodels.formula.api <span class="im">as</span> smf
df[<span class="st">&#39;advert2&#39;</span>] <span class="op">=</span> df.advert<span class="op">**</span><span class="dv">2</span> <span class="co"># kare aldik</span>
results2 <span class="op">=</span> smf.ols(<span class="st">&#39;sales ~ price + advert + advert2&#39;</span>, data<span class="op">=</span>df).fit()
<span class="bu">print</span> results2.summary()</code></pre></div>
<pre><code>                            OLS Regression Results                            
==============================================================================
Dep. Variable:                  sales   R-squared:                       0.508
Model:                            OLS   Adj. R-squared:                  0.487
Method:                 Least Squares   F-statistic:                     24.46
Date:                Mon, 24 Aug 2015   Prob (F-statistic):           5.60e-11
Time:                        15:54:13   Log-Likelihood:                -219.55
No. Observations:                  75   AIC:                             447.1
Df Residuals:                      71   BIC:                             456.4
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
==============================================================================
                 coef    std err          t      P&gt;|t|      [95.0% Conf. Int.]
------------------------------------------------------------------------------
Intercept    109.7190      6.799     16.137      0.000        96.162   123.276
price         -7.6400      1.046     -7.304      0.000        -9.726    -5.554
advert        12.1512      3.556      3.417      0.001         5.060    19.242
advert2       -2.7680      0.941     -2.943      0.004        -4.644    -0.892
==============================================================================
Omnibus:                        1.004   Durbin-Watson:                   2.043
Prob(Omnibus):                  0.605   Jarque-Bera (JB):                0.455
Skew:                          -0.088   Prob(JB):                        0.797
Kurtosis:                       3.339   Cond. No.                         101.
==============================================================================
</code></pre>
<p>Yeni regresyon için <span class="math inline">\(R^2=0.50\)</span>! Bu yeni model verideki varyansın yüzde 50'sini açıklıyor! Eskisinden daha iyi bir model ve AIC'i de daha düşük zaten, ve <span class="math inline">\(ADVERT^2\)</span> için hesaplanan katsayı -2.768 eksi değeri taşıyor. Demek ki reklam harcamalarının belli bir noktadan sonra etkisinin aynı olmayacağı varsayımımız doğru.</p>
<p>Birleşik Hipotez Testleri</p>
<p>Ne yazık ki t testi ile ortak (joint) hipotez testleri yapamıyoruz. Mesela sadece bir değil, <em>birkaç değişkenin</em> model için ne kadar önemli olduğunu bilmek istiyoruz. Tabii bu değişkenleri regresyondan atabiliriz, sonra çıplak gözle AIC'e bakarız, vs. Fakat bu testi daha İstatistiksel bir hipotez testi olarak yapmak daha iyi olmaz mıydı? Alttaki test bu durumlar için kullanılır,</p>
<p>F Testi</p>
<p>Diyelim ki reklam harcamasının satışı etkileyip etkilemediğini merak ediyoruz. Fakat artık bir değil iki tane reklam ile alakalı değişkenimiz var! Biri <span class="math inline">\(ADVERT\)</span> diğeri onun karesi <span class="math inline">\(ADVERT^2\)</span>. Sıfır hipotezimiz şu olacak, &quot;reklam harcaması satışları belirlemede etkili değildir''. Yani</p>
<p><span class="math display">\[ H_0: \beta_3=0, \beta_4=0 \]</span></p>
<p><span class="math display">\[ H_1: \beta_3 \ne 0, \textrm{ ya da } \beta_4 \ne 0 \textrm{ ya da ikisi
  de sıfır değil} \]</span></p>
<p>Hipotez bu şekilde tanımlanınca onu reddetmek demek reklamın satışları etkilediği hakkında güçlü bir kanıt ortaya koyar. Bu nokta önemli, aşırı fantastik bir şekilde zaten umduğumuz şeyi desteklemek için kanıt aramak yerine, onun tam tersini reddetmek için kanıt arıyoruz.</p>
<p>Peki bu testi nasıl yaratacağız? Bir regresyona değişken eklemek onun hatasını azaltır, çıkartmak ise çoğaltır. Eğer ana regresyondan değişken çıkartırsak onun hatası <span class="math inline">\(SSE_u\)</span> diyelim, çoğalarak <span class="math inline">\(SSE_r\)</span> olur. Notasyonel açıdan değişik bir şekilde de duruma bakabiliriz, <span class="math inline">\(\beta_3=0, \beta_4=0\)</span> şartını koşmak aslında bir modeli kısıtlamak ta (restrict) anlamına gelir, üzerinde şart belirlenmemiş olan model de kısıtlanmamış (unrestricted) olur. Neyse, F testi ile yapmaya çalışacağımız bu çoğalmanın istatistiki olarak önemli (significant) olup olmadığını anlamaktır. <span class="math inline">\(SSE\)</span> notasyonu bu arada hata karelerinin toplamı (sum of squared errors) kelimelerinden geliyor.</p>
<p>Şimdi, daha önce belirttiğimiz gibi, ideal şartlarda doğru olacak bir ölçüt yaratmak, ve bu ideal şartlarda bu ölçütün dağılımını bulmak, ve veriyi kullanıp bu ölçütü hesaplayıp sonucu bu dağılıma &quot;sormak'' gerekiyor. Eğer sıfır hipotezi doğru ise,</p>
<p><span class="math display">\[ F = \frac{(SSE_r - SSE_u)/j}{SSE_u/(n-k)} \]</span></p>
<p>hesabı bir <span class="math inline">\(F_{j,n-k}\)</span> dağılımıdır. F dağılımının tanımını hatırlayalım, iki chi kare dağılımının birbiriyle bölünmüş hali idi,</p>
<p><span class="math display">\[ F_{j,n-k} = \frac{\chi^2 / j}{\chi^2 / n-k} \]</span></p>
<p>SSE hesapları karelerin toplamı olduğu için ve hataların normal dağıldığı varsayımından hareketle bölüm ve bölendeki rasgele değişkenler Chi kare dağılımına sahiptir.</p>
<p>Peki neden üstteki F dağılımının <span class="math inline">\(j,n-k\)</span> derece serbestliği vardır? İki chi kare dağılımını toplayınca onların dereceleri toplanır. Aynı şekilde çıkartma derece eksiltir. Şimdi, <span class="math inline">\(SSE_r\)</span>'nin derecesi <span class="math inline">\(n-k\)</span>'dir, <span class="math inline">\(k\)</span> tane katsayı dereceyi / serbestliği azaltmıştır. Eğer <span class="math inline">\(SSE_r\)</span> elde etmek için <span class="math inline">\(j\)</span> tane katsayıyı çıkartırsak, bu durum dereceyi fazlalaştırır, yani <span class="math inline">\(SSE_r\)</span> için <span class="math inline">\(n-k+j\)</span> elde ederiz. O zaman bölümdeki çıkartmanın derecesi</p>
<p><span class="math display">\[ (n-r+j) - (n-r) = j\]</span></p>
<p>olacaktır. Şimdi nihai hesabı yapalım, regresyonu reklamla alakalı iki değişkeni çıkartılmış şekilde bir daha işletiriz, sonra SSE hesabı için her iki regresyondan gelen artıklar <code>resid</code>'leri kullanırız, onların karelerinin toplamı bize gerekli <span class="math inline">\(SSE\)</span> hesabını verecektir,</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="im">import</span> statsmodels.formula.api <span class="im">as</span> smf
results3 <span class="op">=</span> smf.ols(<span class="st">&#39;sales ~ price &#39;</span>, data<span class="op">=</span>df).fit()
SSE_u <span class="op">=</span> np.<span class="bu">sum</span>(results2.resid<span class="op">**</span><span class="dv">2</span>)
SSE_r <span class="op">=</span> np.<span class="bu">sum</span>(results3.resid<span class="op">**</span><span class="dv">2</span>)
<span class="bu">print</span> <span class="st">&#39;SSE_u&#39;</span>, SSE_u
<span class="bu">print</span> <span class="st">&#39;SSE_r&#39;</span>, SSE_r
J <span class="op">=</span> <span class="dv">2</span><span class="op">;</span> N<span class="op">=</span><span class="bu">len</span>(df)<span class="op">;</span> K <span class="op">=</span> <span class="bu">len</span>(results2.params)
F <span class="op">=</span> (SSE_r <span class="op">-</span> SSE_u)<span class="op">/</span>J <span class="op">/</span> SSE_u<span class="op">*</span>(N<span class="op">-</span>K)
<span class="bu">print</span> <span class="st">&#39;j,n-k&#39;</span>,J,N<span class="op">-</span>K
<span class="bu">print</span> <span class="st">&#39;F =&#39;</span>, F</code></pre></div>
<pre><code>SSE_u 1532.0844587
SSE_r 1896.39083709
j,n-k 2 71
F = 8.44135997807</code></pre>
<p>p değeri <span class="math inline">\(P(F_{j,n-k}&gt;8.44)\)</span>. Kumulatif yoğunluk fonksiyonu (CDF) kullanabilmek için formülü şu şekilde tekrar yazalım, <span class="math inline">\(1-P(F_{j,n-k}&lt;8.44)\)</span>,</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="im">import</span> scipy.stats <span class="im">as</span> st
f <span class="op">=</span> st.f(J,N<span class="op">-</span>K)
<span class="bu">print</span> <span class="dv">1</span><span class="op">-</span>f.cdf(F)</code></pre></div>
<pre><code>0.000514159058424</code></pre>
<p>Üstteki değer 0.05 kritik değerinden daha ufak olduğu için hipotez reddedilmiştir. Direk p değeri hesabı yerine yüzde 95 güven için bir eşik değeri de hesaplayabilirdik,</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="bu">print</span> f.ppf(<span class="fl">0.95</span>)</code></pre></div>
<pre><code>3.12576423681</code></pre>
<p>Ve eğer F değeri bu değerden büyük ise hipotez reddedilmiştir diyebilirdik, ki hesapladığımız F değeri eşik değerinden büyük idi. Vardığımız sonuç reklam harcamalarının satış için önemli olduğudur.</p>
<p>Daha Basit bir F-Test Örneği</p>
<p>F-Test'in ana fonksiyonu ve ilk kullanımı varyans karşılaştırmak aslında, iki ölçüm grubunu standard sapma karesinin oranı alınır, ve sonuç bir F rasgele değişkenidir, belli serbestlik dereceleri vardır,</p>
<p><span class="math display">\[ F = \frac{S_x^2}{S_y^2} \]</span></p>
<p>ki <span class="math inline">\(S_x,S_y\)</span> 1. ve 2. grubun örneklem standart sapmasıdır. Bu şekilde bir örnek te görelim [2, sf. 42]. Diyelim ki elimizde göz hareketlerini ölçen iki metod var, gözümüzü 20 derece hareket ettirince metotlar şu rakamları veriyor,</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">method_1 <span class="op">=</span> [<span class="fl">20.7</span>, <span class="fl">20.3</span>,<span class="fl">20.3</span>, <span class="fl">20.3</span>, <span class="fl">20.7</span>, <span class="fl">19.9</span>, <span class="fl">19.9</span>, <span class="fl">19.9</span>, <span class="op">\</span>
            <span class="fl">20.3</span>, <span class="fl">20.3</span>, <span class="fl">19.7</span>, <span class="fl">20.3</span>]
method_2 <span class="op">=</span> [<span class="fl">19.7</span>, <span class="fl">19.4</span>, <span class="fl">20.1</span>, <span class="fl">18.6</span>, <span class="fl">18.8</span>, <span class="fl">20.2</span>, <span class="fl">18.7</span>, <span class="fl">19.</span>]</code></pre></div>
<p>F-testini kullanarak bu metotların, ölçümlerin doğruluğunun (accuracy) aynı mı, yoksa birinin diğerinden daha doğru mu olduğunu bulacağız.</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="im">import</span> pandas <span class="im">as</span> pd
m1 <span class="op">=</span> np.array(method_1)<span class="op">;</span> m2 <span class="op">=</span> np.array(method_2)
df <span class="op">=</span> pd.DataFrame([m1,m2]).T
ss <span class="op">=</span> df.std()
F <span class="op">=</span> ss.ix[<span class="dv">0</span>]<span class="op">**</span><span class="dv">2</span><span class="op">/</span>ss.ix[<span class="dv">1</span>]<span class="op">**</span><span class="dv">2</span>
<span class="bu">print</span> F</code></pre></div>
<pre><code>0.243934673841</code></pre>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="im">import</span> scipy.stats <span class="im">as</span> st
f <span class="op">=</span> st.f(<span class="bu">len</span>(m1)<span class="op">-</span><span class="dv">1</span>,<span class="bu">len</span>(m2)<span class="op">-</span><span class="dv">1</span>)
<span class="bu">print</span> <span class="dv">1</span><span class="op">-</span>f.cdf(F)</code></pre></div>
<pre><code>0.981334830069</code></pre>
<p>F dağılımı <span class="math inline">\(n-1\)</span> ve <span class="math inline">\(m-1\)</span> serbestlik derecesine sahip. Üstteki <span class="math inline">\(p\)</span> değeri 0.05'ten küçük değildir, demek ki iki metotun ölçüm doğruluğunun aynı olduğu hipotezini reddedemiyoruz. Not: Örneklem standart sapma hesabı için <span class="math inline">\(n-1\)</span>'e bölünme durumu var, bu bölüm kullanılan <span class="math inline">\(F\)</span>'in derecesine yansıyor tabii.</p>
<p>Testin özünde şu var, ki varyansın eşitsizliği oranın 1'den ne kadar uzak olduğuna bağlı. Ama ne kadar uzak istatistiki olarak önemli bir uzaklık? İşte bunun cevabını F-dağılımı veriyor.</p>
<p>Örneklem Korelasyonu</p>
<p>Korelasyon <span class="math inline">\(\rho\)</span>'yu daha önce gördük, tahmin edicisi <span class="math inline">\(r\)</span>'dir,</p>
<p><span class="math display">\[ 
\hat{\rho} = r = \frac{S_{xy}}{\sqrt{S_{xx}S_{yy}}} 
\qquad (1) 
\]</span></p>
<p>ki örneklem hesapları <span class="math inline">\(S_{xx},S_{xy},S_{yy}\)</span></p>
<p><span class="math display">\[ S_{xx} = \sum_{i=1}^{n} (x_i-\bar{x})^2 \]</span></p>
<p><span class="math display">\[ S_{xy} = \sum_{i=1}^{n} (x_i-\bar{x})(y_i-\bar{y}) \]</span></p>
<p><span class="math display">\[ S_{yy} = \sum_{i=1}^{n} (y_i-\bar{y})^2 \]</span></p>
<p>olsun; bu hesapların teorik varyans ile olan bağlantısı görülebilir. Eğer <span class="math inline">\(X,Y\)</span> iki değişkenli (bivariate) bir normal dağılımından geliyorsa, o zaman ortada bir regresyon varmış gibi gösterebiliriz</p>
<p><span class="math display">\[ E(Y|X=x) = \beta_0 + \beta_1 x + \epsilon \]</span></p>
<p>ki <span class="math inline">\(\beta_1 = \sigma_Y / \sigma_X \cdot \rho\)</span> olur. Detaylar için [4]. Soru şu, <span class="math inline">\(r\)</span> için bir istatistiksel önemlilik (significance) hesabı nasıl yapardık? Yani, eğer <span class="math inline">\(-1 \le r \le 1\)</span> işe, ve <span class="math inline">\(r=0\)</span> hiç korelasyon olmama durumu ise, acaba bu &quot;sıfır olmama'' durumunu test edebilir miydim? Evet. Yukarıdaki normallik faraziyesi doğru ise <span class="math inline">\(\beta_1 = 0\)</span> olmama durumunu test etmek <span class="math inline">\(\rho = 0\)</span> olmama testi ile aynı, bu durumda</p>
<p><span class="math display">\[ t_0 = \frac{\hat{\beta_1}}{\sqrt{ Var(\hat{\beta_1} ) }} \]</span></p>
<p>gibi bir test istatistiği yaratırız, ki bu istatistik Öğrenci t dağılımına sahip olurdu çünkü sıfır hipotezi <span class="math inline">\(\hat{\beta_1} = 0\)</span>, ve üstteki istatistik sıfır hipotezi altında ile Öğrenci t dağılımına sahip olmak zorundadır, çünkü bölünen normal dağılmış, bölen chi karenin karekökü olarak dağılmış. Eğer <span class="math inline">\(t_o\)</span> hesabı veriye uygulandıktan sonra hipotezin öngördüğü dağılıma uymaz ise, sıfır hipotezini reddederiz.</p>
<p>Bu noktada lineer regresyon ile alakalı bilgiler devreye sokulabilir, [4]'den biliyoruz ki</p>
<p><span class="math display">\[ Var(\hat{\beta_1}) = \frac{\sigma^2}{S_{xx}} \]</span></p>
<p><span class="math inline">\(\sigma\)</span> yerine örneklemden gelen <span class="math inline">\(S\)</span> kullanırsak ve üstteki formüle koyarsak,</p>
<p><span class="math display">\[ t_0 = \frac{\hat{\beta_1}}{\sqrt{S / S_{xx}}} \]</span></p>
<p>Bu ifadeyi <span class="math inline">\(r\)</span> bazında ifade edebilir miyiz? Deneyelim, <span class="math inline">\(\hat{\beta_1} = S_{xy} / S_{xx}\)</span> ve <span class="math inline">\(r = \hat{\beta_1}\sqrt{\frac{S_{xx}}{S_{yy}}}\)</span> olduğunu biliyoruz [4], ayrıca</p>
<p><span class="math display">\[ S = \frac{SSE}{n-2}, \qquad SSE = S_{yy} - \hat{\beta_1} S_{xy} \]</span></p>
<p>ki <span class="math inline">\(SSE\)</span> hata karelerinin toplamıdır (sum of squared errors),</p>
<p><span class="math display">\[ t_0 = \frac{  \sqrt{S_{xx}} \hat{\beta_1} \sqrt{n-2} }{\sqrt{SSE}} \]</span></p>
<p><span class="math display">\[ = \frac{  \sqrt{S_{xx}} \hat{\beta_1} \sqrt{n-2} }{\sqrt{S_{yy} - \hat{\beta_1} S_{xy}}} \]</span></p>
<p>Bölümün iki kısmını <span class="math inline">\(\sqrt{S_y}\)</span> ile bölelim,</p>
<p><span class="math display">\[ = 
\frac{ \sqrt{S_{xx}/S_{yy}} \hat{\beta_1} \sqrt{n-2} }
{\sqrt{1 - \hat{\beta_1} S_{xy}/S_{yy}}} 
\]</span></p>
<p>Bölünen kısmında bir <span class="math inline">\(r\)</span> ortaya çıktı,</p>
<p><span class="math display">\[ = 
\frac{ r\sqrt{n-2} }
{\sqrt{1 - \hat{\beta_1} S_{xy}/S_{yy}}} 
\]</span></p>
<p>Bölen kısmındaki <span class="math inline">\(\hat{\beta_1}\)</span> yerine <span class="math inline">\(\hat{\beta_1} = S_{xy} / S_{xx}\)</span> koyarsak yine (1)'deki <span class="math inline">\(r\)</span> tanımına geliriz, ve alttaki basitleştirilmiş ifade ortaya çıkar,</p>
<p><span class="math display">\[ t_o = \sqrt{\frac{(n-2)r^2}{(1-r^2)}} \]</span></p>
<p>Bu istatistik <span class="math inline">\(n-2\)</span> derece serbestliğe sahip bir Öğrenci t dağılımıdır.</p>
<p>Örnek</p>
<p>Possum adı verilen bir tür hayvanın dişilerinin tüm uzunluğu ve kafa ölçümü <code>totlngth,hdlngth</code> değişkenleri arasında korelasyon olup olmadığı merak edilmektedir.</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="im">import</span> pandas <span class="im">as</span> pd
<span class="im">import</span> scipy.stats

<span class="kw">def</span> p_corr(df1, df2):
    corr <span class="op">=</span> df1.corr(df2)
    N <span class="op">=</span> np.<span class="bu">sum</span>(df1.notnull())
    t <span class="op">=</span> corr<span class="op">*</span>np.sqrt((N<span class="dv">-2</span>)<span class="op">/</span>(<span class="dv">1</span><span class="op">-</span>corr<span class="op">**</span><span class="dv">2</span>))
    p <span class="op">=</span> <span class="dv">1</span><span class="op">-</span>scipy.stats.t.cdf(<span class="bu">abs</span>(t),N<span class="dv">-2</span>)  <span class="co"># one-tailed</span>
    <span class="cf">return</span> corr, t, p

df <span class="op">=</span> pd.read_csv(<span class="st">&#39;fossum.csv&#39;</span>)
c,tval, pval <span class="op">=</span> p_corr(df.totlngth,df.hdlngth)
<span class="bu">print</span> c, pval</code></pre></div>
<pre><code>0.779239322172 3.75045772216e-10</code></pre>
<p>p-değeri çok küçük, demek ki korelason olmadığı tezi reddedildi. Korelasyon var.</p>
<p>Pearson Chi Kare Uyum Derecesi (Goodness-of-Fit) Testi</p>
<p>Her sene günde kaç saat çalıştığımızı bir yere yazdık diyelim, elde 365 veri noktası var. Ertesi sene yine aynı veriyi topladık, şu soruyu soruyoruz, iki veri birbirinden istatistiki olarak farklı mıdır? Ya da; elimizdeki belli bir veri var, ve o verinin normal mi, ya da üstel (exponential) dağılımdan mı geldiğini merak ediyoruz. Acaba veri istatistiki olarak hangi <em>tip</em> dağılım fonksiyona (yani teorik yoğunluk fonksiyonuna) daha yakındır? Ya da; eldeki bir verinin <span class="math inline">\(\mu = 0\)</span> merkezli normal dağılımdan mı, yoksa <span class="math inline">\(\mu = 30\)</span> merkezli normal dağılımdan mı geldiğini merak ediyoruz.</p>
<p>Her üç sorunun ve benzerlerinin cevabı Pearson'un chi kare (chi square) uyum derece testi ile verilebilir.</p>
<p>İki veriyi karşılaştırdığımız durumda bu iki veri kümesini dağılım olarak kabul edip, birini diğerine uyum açısından test edebiliriz. Bu karşılaştırma her iki tarafta histogram alınıp histogram kutucuklarının (bins) içine her iki tarafta düşen miktarların bir test istatistiği üzerinden karşılaştırılması ile olabilir. Veri ile yoğunluk karşılaştırdığımızda ise veriyi histogram kutucukları, yoğunluğu ise aynı aralıklara düşen olasılıkların fonksiyonel hesaplarıyla karşılaştırılması ile yaparız.</p>
<p>Test istatistiği</p>
<p>Diyelim ki her kutucukta görülen miktar <span class="math inline">\(N_i\)</span>, ki <span class="math inline">\(N_1 + N_2 + .. + N_k = n\)</span>, ve karşılaştırmak istediğimiz, bu miktara tekabül eden &quot;ideal'' olasılık <span class="math inline">\(p_i\)</span>, o zaman ideal miktar <span class="math inline">\(n p_i\)</span>. Kutucuktaki sayıları bir binom dağılımından geliyormuş gibi modelleyebiliriz, 1. kutucuk için mesela <span class="math inline">\(N_1 \sim Bin(n,p_1)\)</span>, ve <span class="math inline">\(N_1\)</span> rasgele değişkeni <span class="math inline">\(N\)</span> tane deneyde &quot;başarılı'' olan sayı - tipik binom kullanımı. Bu durumda Pearson uyum derecesi istatistiği</p>
<p><span class="math display">\[
\chi^2 = \sum_{j=1}^{k} \frac{(N_j - np_j)^2}{np_j}
\]</span></p>
<p>ile belirtilir, üstteki toplamın yaklaşıksal olarak <span class="math inline">\(\chi^2_{k-1}\)</span> dağılımına yaklaştığı ispatlanmıştır. Detaylar için [5, sf 318, 6]. Nihai ispat oldukça çetrefil, biz burada alternatif bazı yaklaşıksal ispatlardan bahsetmek istiyoruz (okkalı ispat için yukarıdaki referanslar geçerli tabii).</p>
<p>Eğer her <span class="math inline">\(N_j\)</span> binom dağılımını Gaussian ile yaklaşıkladığımızı düşünürsek, ki bu yeterince büyük <span class="math inline">\(n\)</span>, ve <span class="math inline">\(np_i&gt;5\)</span> için mümkün, bu dağılım <span class="math inline">\(\mu=np_j\)</span> ve varyans <span class="math inline">\(np_j(1-p_j)\)</span>'ye sahip olur, o zaman Gaussian'ı standardize etmek için</p>
<p><span class="math display">\[ \frac{N_j-np_j}{\sqrt{np_j(1-p_j)}} \approx N(0,1) \]</span></p>
<p><span class="math inline">\(Z=N(0,1)\)</span> diyelim,</p>
<p><span class="math display">\[
\frac{(N_j - np_j)}{\sqrt{np_j} } \approx  \sqrt{(1-p_j)}Z
\]</span></p>
<p>İki tarafın karesini alalım, ve her <span class="math inline">\(j\)</span> üzerinden toplam alalım,</p>
<p><span class="math display">\[
\sum_j \frac{(N_j - np_j)^2}{np_j} \approx \sum_j (1-p_j)Z^2
\]</span></p>
<p>Üstteki eşitliğin sol tarafı Pearson istatistiğiyle aynı. Sağ tarafı neye eşit?</p>
<p><span class="math display">\[
\sum_j (1-p_j)Z^2 =  (1-p_1)Z^2 + (1-p_2)Z^2 + ... + (1-p_k)Z^2 
\]</span></p>
<p><span class="math display">\[
 =  Z^2 [(1-p_1) + (1-p_2) + ... + (1-p_k)]
\]</span></p>
<p><span class="math display">\[
 =  Z^2 [k - (p_1+p_2+..+p_k))] = (k-1)Z^2 = \sum_{k-1} Z^2 
\]</span></p>
<p>Şimdi, bu eriştiğimiz toplamın <span class="math inline">\(\chi^2_{k-1}\)</span> dağılımı, yani <span class="math inline">\(k-1\)</span> derece serbestliği olan bir chi kare dağılımı olduğunu iddia edebilir miyiz? Eğer <span class="math inline">\(Z_j\)</span>'ler birbirinden bağımsız ise kesinlikle evet, çünkü standart normal rasgele değişkenlerin toplamı chi kare dağılımını verir. Üstteki kolay ispatın önündeki tek engel budur, bizim burada yapacağımız yaklaşıksal argüman <span class="math inline">\(i,j\)</span> ikilisi için <span class="math inline">\(Z\)</span>'lerin bağlantısının, kovaryansının küçük olduğudur, ki bu küçüklük sebebiyle <span class="math inline">\(Z_j\)</span>'ler çoğu durumda bağımsız kabul edilebilir.</p>
<p>Diyelim ki <span class="math inline">\(X_1,X_2,..\)</span> değişkenleri bağımsız ve <span class="math inline">\(Mult(1,p)\)</span>, yani multinom dağılımdan geliyorlar [7, sf. 180], ve <span class="math inline">\(p = \left[\begin{array}{ccc} p_1 &amp; p_2 &amp;  \dots \end{array}\right]\)</span>, ve <span class="math inline">\(\sum_j p_j = 1\)</span>. Yani her <span class="math inline">\(X_i\)</span> zar attığında <span class="math inline">\(1 \times k\)</span> boyutlu bir vektör ortaya çıkıyor, bu vektörün sadece bir hücresi 1 diğerleri 0. Multinom dağılımların tanımından biliyoruz ki <span class="math inline">\(Cov(X_i,X_j) = -n p_ip_j = -p_ip_j\)</span> (çünkü <span class="math inline">\(n=1\)</span>).</p>
<p>Bu demektir ki 1'den küçük iki değer çarpılıyor bu daha da küçük bir değer verecektir. Eğer <span class="math inline">\(k\)</span> yeterince büyük ise, bu, mesela sürekli yoğunlukları ayrıksal olarak gösterdiğimiz durumda ve yeterince çok kutucuk var ise bu kutucuklara &quot;düşen'' olasılıkların ufalması demektir, ve ufak değerlerin çarpımı iyice ufalır, ki bu kovaryansı sıfıra yaklaştırır. Yani yeterince büyük <span class="math inline">\(k\)</span> için <span class="math inline">\(i,j\)</span> bağlantısını sezgisel bağlamda etkisiz olduğunu görebiliriz. Tabii, toplamın <em>kesinlikle</em> chi kare olduğunun ispatı için dediğimiz gibi verdiğimiz referanslara bakılabilir.</p>
<p>İstatistiki testlerin mantığını hatırlarsak, tarif edilen Pearson istatistiği sıfır hipotezi. Bize reddetmeye uğraşacağımız bir dağılım / hesap ikilisi üretiyor. Eğer hesap beklenen, normal (sıfır hipotez durumu) uymuyorsa, hipotezi reddediyoruz. Ret durumu özellikle seçiliyor çünkü kabul edilmezlik daha kesin bir cevap.</p>
<p>Örnek</p>
<p>Bir paralı otoyolunda geçiş noktasında durulmuş ve her dakika gelen araç sayılmış, ve dakika başına bu araç sayısı yazılmış. Bu deney 106 dakika süresince yapılmış (elde 106 satırlı bir veri var yani). Bu veri için Poisson dağılımının uygun olup olmadığını yüzde 5 önemlilik seviyesinde ispatlamamız isteniyor.</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="im">import</span> pandas <span class="im">as</span> pd
vehicle <span class="op">=</span> [<span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">3</span>, <span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">4</span>, <span class="dv">4</span>, <span class="dv">4</span>, <span class="dv">4</span>, <span class="dv">5</span>, <span class="dv">5</span>, <span class="dv">5</span>, <span class="dv">5</span>, <span class="dv">5</span>, <span class="dv">5</span>, <span class="dv">5</span>, <span class="dv">6</span>,<span class="op">\</span>
<span class="dv">6</span>, <span class="dv">6</span>, <span class="dv">6</span>, <span class="dv">6</span>, <span class="dv">6</span>, <span class="dv">6</span>, <span class="dv">6</span>, <span class="dv">6</span>, <span class="dv">6</span>, <span class="dv">6</span>, <span class="dv">6</span>, <span class="dv">6</span>, <span class="dv">7</span>, <span class="dv">7</span>, <span class="dv">7</span>, <span class="dv">7</span>, <span class="dv">7</span>, <span class="dv">7</span>, <span class="dv">7</span>,<span class="op">\</span>
<span class="dv">7</span>, <span class="dv">7</span>, <span class="dv">7</span>, <span class="dv">7</span>, <span class="dv">7</span>, <span class="dv">8</span>, <span class="dv">8</span>, <span class="dv">8</span>, <span class="dv">8</span>, <span class="dv">8</span>, <span class="dv">8</span>, <span class="dv">8</span>, <span class="dv">8</span>, <span class="dv">9</span>, <span class="dv">9</span>, <span class="dv">9</span>, <span class="dv">9</span>, <span class="dv">9</span>, <span class="dv">9</span>, <span class="dv">9</span>,
<span class="dv">9</span>, <span class="dv">9</span>, <span class="dv">10</span>, <span class="dv">10</span>, <span class="dv">10</span>, <span class="dv">10</span>, <span class="dv">10</span>, <span class="dv">10</span>, <span class="dv">10</span>, <span class="dv">10</span>, <span class="dv">10</span>, <span class="dv">10</span>, <span class="dv">10</span>, <span class="dv">10</span>, <span class="dv">10</span>, <span class="op">\</span>
<span class="dv">11</span>, <span class="dv">11</span>, <span class="dv">11</span>, <span class="dv">11</span>, <span class="dv">11</span>, <span class="dv">11</span>, <span class="dv">11</span>, <span class="dv">11</span>, <span class="dv">11</span>, <span class="dv">11</span>, <span class="dv">12</span>, <span class="dv">12</span>, <span class="dv">12</span>, <span class="dv">12</span>, <span class="op">\</span>
<span class="dv">12</span>, <span class="dv">13</span>, <span class="dv">13</span>, <span class="dv">13</span>, <span class="dv">13</span>, <span class="dv">13</span>, <span class="dv">13</span>, <span class="dv">14</span>, <span class="dv">14</span>, <span class="dv">14</span>, <span class="dv">14</span>, <span class="dv">15</span>, <span class="dv">15</span>, <span class="dv">15</span>, <span class="dv">15</span>,<span class="op">\</span>
<span class="dv">15</span>, <span class="dv">16</span>, <span class="dv">16</span>, <span class="dv">16</span>, <span class="dv">16</span>, <span class="dv">18</span>]
df <span class="op">=</span> pd.DataFrame(vehicle)</code></pre></div>
<p>Verinin histogramına bakalım,</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">f <span class="op">=</span> plt.figure()<span class="op">;</span> df.hist(bins<span class="op">=</span><span class="dv">13</span>)
plt.savefig(<span class="st">&#39;stat_tests2_01.png&#39;</span>)</code></pre></div>
<div class="figure">
<img src="stat_tests2_01.png" />

</div>
<p>Poisson dağılımı muhtemel gözüküyor. Ama şimdi bunu uyum derece testi ile daha kararlı şekilde göstermeye uğraşacağız. Verideki sayımları o sayım rakamı bazında gruplayalıp gösterelim,</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">kt <span class="op">=</span> plt.hist(np.array(df),bins<span class="op">=</span><span class="bu">range</span>(<span class="dv">20</span>))
kt <span class="op">=</span> pd.DataFrame([kt[<span class="dv">1</span>],kt[<span class="dv">0</span>]]).T
kt <span class="op">=</span> kt[:<span class="op">-</span><span class="dv">1</span>] <span class="co"># sonuncu satiri at</span>
kt.columns <span class="op">=</span> [<span class="st">&#39;kac araba&#39;</span>,<span class="st">&#39;kac kere&#39;</span>]
<span class="bu">print</span> (kt)</code></pre></div>
<pre><code>    kac araba  kac kere
0         0.0       0.0
1         1.0       0.0
2         2.0       1.0
3         3.0       3.0
4         4.0       5.0
5         5.0       7.0
6         6.0      13.0
7         7.0      12.0
8         8.0       8.0
9         9.0       9.0
10       10.0      13.0
11       11.0      10.0
12       12.0       5.0
13       13.0       6.0
14       14.0       4.0
15       15.0       5.0
16       16.0       4.0
17       17.0       0.0
18       18.0       1.0</code></pre>
<p>Yani bir dakikada 6 araba sayımı 13 kere yapılmış (13 değişik dakikada). Not: Üstte bir kütüphane çağrısı <code>hist</code> kullandık (grafikleme kısmını kullanmadan), ama Poisson frekans hesabı elle çok kolay yapılabilir.</p>
<p>Eğer üstteki verinin bir Poisson dağılımdan geldiğini kabul ediyorsak, Poisson'un parametresi <span class="math inline">\(\lambda\)</span>'yi veriden hesaplamak için ortalama almak yeterlidir,</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">lam <span class="op">=</span> np.mean(kt[<span class="st">&#39;kac kere&#39;</span>])
<span class="bu">print</span> (<span class="st">&#39;lambda </span><span class="sc">%0.2f</span><span class="st">&#39;</span> <span class="op">%</span> lam)</code></pre></div>
<pre><code>lambda 5.58</code></pre>
<p>Bu Poisson'u kullanarak bazı olasılık hesapları hemen yapabilirdik, mesela 3'ten fazla, 9'dan fazla araba sayılma ihtimali nedir?</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="im">from</span> scipy.stats <span class="im">import</span> poisson
<span class="bu">print</span> (<span class="dv">1</span><span class="op">-</span>poisson.cdf(<span class="dv">3</span>, lam))
<span class="bu">print</span> (<span class="dv">1</span><span class="op">-</span>poisson.cdf(<span class="dv">9</span>, lam))</code></pre></div>
<pre><code>0.807087823822676
0.057975438622207665</code></pre>
<p>Devam edelim. Veride bazı kutucukların boş olduğunu görüyoruz, bu durum özellikle tek tepeli (unimodel) dağılımlı verilerde etekleri temsil eden uçlardaki kutucukların boş olması sonucunu verebilir. Bu durumda o kutucukların verisi daha dolu olanlara aktarabilmek için kutucuk noktalarını tekrar tanımlıyoruz,</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">bins <span class="op">=</span> [<span class="dv">0</span>] <span class="op">+</span> <span class="bu">range</span>(<span class="dv">5</span>,<span class="dv">15</span>) <span class="op">+</span> [<span class="dv">100</span>]
kt2 <span class="op">=</span> plt.hist(np.array(df),bins<span class="op">=</span>bins)
kt2 <span class="op">=</span> pd.DataFrame([kt2[<span class="dv">1</span>],kt2[<span class="dv">0</span>]]).T
kt2.columns <span class="op">=</span> [<span class="st">&#39;int_low&#39;</span>,<span class="st">&#39;n_i&#39;</span>]
<span class="bu">print</span> kt2</code></pre></div>
<pre><code>    int_low  n_i
0         0    9
1         5    7
2         6   13
3         7   12
4         8    8
5         9    9
6        10   13
7        11   10
8        12    5
9        13    6
10       14   14
11      100  NaN</code></pre>
<p>Şimdi bu değerler üzerinden Pearson <span class="math inline">\(\chi^2\)</span> hesabını yapalım. Ama ondan önce, hatırlayalım, bu verinin <em>herhangi bir</em> Poisson'dan gelip gelmediğini kontrol ediyoruz, ama testimiz için parametresi belli olan, özel bir Poisson lazım, bunun için bize bir <span class="math inline">\(\lambda\)</span> gerekiyor. Önemli değil, <span class="math inline">\(\lambda\)</span>'nin tahmin edicisi <span class="math inline">\(\hat{\lambda}\)</span>'yi biliyoruz,</p>
<p><span class="math display">\[ \hat{\lambda} = \frac{1}{n} \sum_{j=1}^{n}x_j \]</span></p>
<p>Bu <span class="math inline">\(\hat{\lambda}\)</span>'yi kullanarak Poisson hesaplarını yapabiliriz artık. Bir kutucuğa düşen Poisson olasılığının hesabı <span class="math inline">\(P(a \le X &lt; b)\)</span>, ki bu basit bir <span class="math inline">\(F(b)-F(a)\)</span>, yani <span class="math inline">\(a,b\)</span> noktalarındaki kümülatif yoğunluk fonksiyonun farkı üzerinden hesaplanabilir, altta kullanılan çağrı <code>poisson.cdf</code>.</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="im">from</span> scipy.stats <span class="im">import</span> poisson
kt2[<span class="st">&#39;int_high&#39;</span>] <span class="op">=</span> kt2.shift(<span class="op">-</span><span class="dv">1</span>).int_low
lam <span class="op">=</span> df.mean() <span class="co"># tahmin edici</span>
<span class="kw">def</span> f(x): 
   high <span class="op">=</span> poisson.cdf(x.int_high<span class="dv">-1</span>,lam)
   low <span class="op">=</span> poisson.cdf(x.int_low<span class="dv">-1</span>,lam)
   <span class="cf">return</span> pd.Series(high<span class="op">-</span>low)
kt2[<span class="st">&#39;p_i&#39;</span>] <span class="op">=</span> kt2.<span class="bu">apply</span>(f,axis<span class="op">=</span><span class="dv">1</span>)
kt2[<span class="st">&#39;np_i&#39;</span>] <span class="op">=</span> <span class="bu">len</span>(df) <span class="op">*</span> kt2[<span class="st">&#39;p_i&#39;</span>]
kt2[<span class="st">&#39;chi&#39;</span>] <span class="op">=</span> (kt2[<span class="st">&#39;n_i&#39;</span>]<span class="op">-</span>kt2[<span class="st">&#39;np_i&#39;</span>])<span class="op">**</span><span class="dv">2</span> <span class="op">/</span> kt2[<span class="st">&#39;np_i&#39;</span>]
kt2 <span class="op">=</span> kt2[:<span class="op">-</span><span class="dv">1</span>]
<span class="bu">print</span> kt2
<span class="bu">print</span> <span class="st">&#39;</span><span class="ch">\n</span><span class="st">chi kare istatistigi&#39;</span>, kt2.chi.<span class="bu">sum</span>()</code></pre></div>
<pre><code>    int_low  n_i  int_high       p_i       np_i       chi
0         0    9         5  0.051863   5.497487  2.231492
1         5    7         6  0.058217   6.171048  0.111352
2         6   13         7  0.088242   9.353602  1.421508
3         7   12         8  0.114643  12.152118  0.001904
4         8    8         9  0.130325  13.814437  2.447271
5         9    9        10  0.131691  13.959242  1.761849
6        10   13        11  0.119764  12.695009  0.007327
7        11   10        12  0.099016  10.495702  0.023412
8        12    5        13  0.075040   7.954290  1.097248
9        13    6        14  0.052496   5.564539  0.034078
10       14   14       100  0.078703   8.342527  3.836608

chi kare istatistigi 12.9740502104</code></pre>
<p>Şimdi üstteki değerin istatistiki önem taşıyıp taşımadığını anlamaya geldi sıra. Eşik değerimiz <span class="math inline">\(\chi^2_{9,0.05}\)</span> olacak. Peki niye serbestlik derecesi 9 alındı? Elde kaç tane kutucuk var?</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="bu">print</span> <span class="bu">len</span>(kt2), <span class="st">&#39;kutucuk&#39;</span></code></pre></div>
<pre><code>11 kutucuk</code></pre>
<p>11-1=0 niye olmadı, -1 ile serbestlik derecesi hesaplamıyor muyduk? Evet. Fakat bir kavis daha var, tahmin edici ile <span class="math inline">\(\lambda\)</span>'yi hesaplayınca 1 serbestlik derecesi daha kaybettik! <span class="math inline">\(\chi_2\)</span> ile çalışırken hatırlanması gereken bilgilerden biri bu. Pearson bu testi keşfettiğinde aslında bu eksiltmeye gerek görmüyordu, daha sonraları Fisher adlı istatistikçi bunun gerekli olduğunu ispatladı.</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="im">from</span> scipy.stats <span class="im">import</span> chi2
dof <span class="op">=</span> <span class="bu">len</span>(kt2)<span class="op">-</span><span class="dv">1-1</span> <span class="co"># lambda tahmini 1 derece kaybettirdi</span>
<span class="bu">print</span> <span class="st">&#39;serbestlik derecesi&#39;</span>, dof
<span class="bu">print</span> <span class="st">&#39;chi kare&#39;</span>, chi2.ppf(<span class="fl">0.95</span>,dof)</code></pre></div>
<pre><code>serbestlik derecesi 9
chi kare 16.9189776046</code></pre>
<p>Hesaplanan değer üstteki değerden küçük olduğu için Poisson hipotezi kabul edilmiştir (ya da olmadığı reddedilememiştir, eğer p-değeri hesaplasaydık, 0.05'den az sonuca bakacaktık, aynı şey).</p>
<p>Örnek</p>
<p>Gördüğümüz gibi bir dağılım varlığlığını test için o dağılımın analitik yoğunluk fonksiyonunu veriden gelen tahmin ediciler üzerinden tanımlayıp, veriyi bu fonksiyon ile üretmeyi deneyebiliriz, ve bu sonuç ile veri arasında uyumluluğa bakabiliriz.</p>
<p>Mesela olayların coğrafi olarak dağılımına bakalım.. Bu tür olayları nasıl modelleriz? Olaylar depremler, yangınlar, ya da bir savaşta bir alana atılan bombalar olabilir, ve bu tür sayılar Poisson dağılımı ile modellenir. Bu dağılım ilk bölümde gördüğümüz gibi,</p>
<p><span class="math display">\[ f(x) = P(X=x) = e^{-\lambda}\frac{\lambda^{x}}{x!} \]</span></p>
<p>olay sayısı <span class="math inline">\(x=1\)</span>, <span class="math inline">\(x=2\)</span>, vs.. olacak şekilde, ki önceden tanımlı belli bir zaman aralığında <span class="math inline">\(x\)</span> tane olayın olma olasılığını bu yoğunluk veriyor. Coğrafi olay sayılarını ölçmek için biraz farklı düşünmek gerekiyor, mesela 2'inci Dünya Savaşı sırasında Almanların Londra'ya attıkları bombaları düşünelim, analizi [13]'te var; Merak edilen şuydu, acaba bombalar belli bir yerde kümeleniyor muydu (clustering)? Cevap önemli olabilirdi, belki özel bir yer vurulmak isteniyordu? Analizde olayların doğal oluş sayısını modelleyen Poisson varlığı ispatlanırsa, kümelenme hipotezi reddedilmiş olacaktı. İstatistikçi Clarke Londra'yı 536 tane ızgaraya böldü, ve her öğe içine düşen bombaları saydı. Bu bittikten sonra 1 tane bomba, 2 tane bomba, vs.. şeklinde olan hücrelerin sayısını aldı, ki yoğunluğa <span class="math inline">\(x\)</span> ile geçilecek olan bu sayıydı.</p>
<p>Sonra Clarke yoğunluğu <span class="math inline">\(\lambda\)</span> tahmin edici hücre sayısı bölü bomba sayısı üzerinden tanımladı, ve bu yoğunluktan tüm sayılar için bir tahmini bomba sayısı ürettirdi, sonuçları gerçek bomba sayıları ile karşılaştırdı.</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">N <span class="op">=</span> <span class="fl">576.</span>
lam <span class="op">=</span> <span class="dv">537</span><span class="op">/</span>N
d <span class="op">=</span> N<span class="op">*</span>np.exp(<span class="op">-</span>lam)
probs <span class="op">=</span> [d<span class="op">*</span><span class="dv">1</span>, d<span class="op">*</span>lam, d<span class="op">*</span>lam<span class="op">**</span><span class="dv">2</span><span class="op">/</span><span class="dv">2</span>, d<span class="op">*</span>(lam<span class="op">**</span><span class="dv">3</span>)<span class="op">/</span>(<span class="dv">3</span><span class="op">*</span><span class="dv">2</span>), d<span class="op">*</span>(lam<span class="op">**</span><span class="dv">4</span>)<span class="op">/</span>(<span class="dv">4</span><span class="op">*</span><span class="dv">3</span><span class="op">*</span><span class="dv">2</span>)]
<span class="bu">list</span>(<span class="bu">map</span>(<span class="kw">lambda</span> x: np.<span class="bu">round</span>(x,<span class="dv">2</span>), probs))</code></pre></div>
<pre><code>Out[1]: [226.74, 211.39, 98.54, 30.62, 7.14]</code></pre>
<p>Gerçek sayılar 229, 211, 93, 35, 7, .. idi, görüldüğü gibi oldukca yakın sayılar. Bir adım daha atılıp bunun üzerinde bir istatistik testi uygulanınca Poisson varlığı, ve dolaylı olarak kümelemenin olmadığı ispatlanmış oldu.</p>
<p>Kaynaklar</p>
<p>[1] Hill, <em>Principles of Econometrics</em></p>
<p>[2] Uriel, <em>Introduction to Econometrics, Lecture</em></p>
<p>[3] Haslwanter, <em>Introduction to Statistics Using Python</em></p>
<p>[4] Wackerly, <em>Mathematical Statistics, 7th Edition</em></p>
<p>[5] Soong, <em>Fundamentals of Probability and Statistics for Engineers</em></p>
<p>[6] OCW MIT, <em>Statistics for Applications, 18.443</em></p>
<p>[7] Hunter, <em>Asymptotics for Statisticians</em></p>
<p>[8] Steiger, <em>Correlation and Regresion, Lecture Notes</em></p>
<p>[9] Sheppard, <em>Introduction to Python for Econometrics</em></p>
<p>[10] Greene, <em>Econometric Analysis</em></p>
<p>[11] Uriel, <em>Introduction to Econometrics</em></p>
<p>[12] Bayramlı, <em>İstatistik, Gayri Lineer Regresyon, Petrol Tepe Noktası</em></p>
<p>[13] Clarke, <em>An application of the Poisson distribution</em>, <a href="https://www.actuaries.org.uk/system/files/documents/pdf/0481.pdf" class="uri">https://www.actuaries.org.uk/system/files/documents/pdf/0481.pdf</a></p>
</body>
</html>
