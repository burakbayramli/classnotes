<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
    <script type="text/x-mathjax-config">
    MathJax.Hub.Register.StartupHook("TeX Jax Ready",function () {
      MathJax.Hub.Insert(MathJax.InputJax.TeX.Definitions.macros,{
        cancel: ["Extension","cancel"], cancelto: ["Extension","cancel"]
      });
    });
    </script>  
   
  <title>Testlere Devam</title>
  <style type="text/css">code{white-space: pre;}</style>
  <style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
  </style>
  <script
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS_HTML-full"
  type="text/javascript"></script>
</head>
<body>
<div id="header">
</div>
<h1 id="testlere-devam">Testlere Devam</h1>
<p>İstatistiki test yaratmak için takip edilen teknik basit; bir
istatistiki ölçüt hesaplıyoruz, ya da hesabımızın başka noktasından
çıkanı alıyoruz, ki bu ölçüt mesela bir ortalama olabilir bu durumda
bilinen bir dağılımı vardır, ya da lineer regresyondan bize verilen bir
katsayıdır, onun t değeri vardır, bu durumda da dağılımın ne olduğunu
biliyoruz. Yani hangi ölçüte bakarsak bakalım, ya da biz yeni bir
tanesini uyduralım, önce elde ettiğimiz rasgele değişkeninin ideal
koşullarda dağılımının ne olduğuna bakarız, ki test ettiğimiz bir
anlamda bu ideal koşullar olacaktır. Ardından bir kriter ortaya koyarak
testi ortaya çıkartırız.</p>
<p>Ama ondan önce biraz regresyon.</p>
<p>Örnek veri olarak Big Andy’s Burger Barn adında hamburger satan bir
restoran zincirinin verisini kullanalım [1, sf. 168]. Veride her nokta
ayrı bir şehirdeki belli bir aydaki dükkan için kaydedilmiş reklam
gideri <span class="math inline">\(ADVERT\)</span>, burger fiyatı <span
class="math inline">\(PRICE\)</span>, ve satış getirisi <span
class="math inline">\(SALES\)</span> (<span
class="math inline">\(SALES\)</span> ve <span
class="math inline">\(ADVERT\)</span> bin dolarlık birimde kaydedilmiş).
Şirket yönetimi diyelim ki reklam harcamalarının satışları nasıl
etkilediğini merak ediyor. Ayrıca yönetim bir fiyatlama stratejisi
belirlemek istiyor, fiyatın geliri nasıl etkilmektedir? Fiyatta düşüş
çok az satış artışı yaratıyorsa bu durum kazancı düşürür, demek ki talep
fiyatsal-elastik değildir (price inelastic). Tam tersi de olabilir,
fiyat değişimi satışı arttırır, o zaman talep fiyatsal-elastiktir.</p>
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(<span class="st">&#39;andy.dat&#39;</span>,sep<span class="op">=</span><span class="st">&#39;</span><span class="ch">\\</span><span class="st">s+&#39;</span>,names<span class="op">=</span>[<span class="st">&#39;sales&#39;</span>,<span class="st">&#39;price&#39;</span>,<span class="st">&#39;advert&#39;</span>],engine<span class="op">=</span><span class="st">&#39;python&#39;</span>)</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (df.head(<span class="dv">3</span>))</span></code></pre></div>
<pre><code>   sales  price  advert
0   73.2   5.69     1.3
1   71.8   6.49     2.9
2   62.4   5.63     0.8</code></pre>
<p>Regresyon modelini kuralım,</p>
<p><span class="math display">\[ SALES = \beta_1 + \beta_2 PRICE +
\beta_3 ADVERT \]</span></p>
<div class="sourceCode" id="cb3"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> statsmodels.formula.api <span class="im">as</span> smf</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> smf.ols(<span class="st">&#39;sales ~ price + advert&#39;</span>, data<span class="op">=</span>df).fit()</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (results.summary())</span></code></pre></div>
<pre><code>                            OLS Regression Results                            
==============================================================================
Dep. Variable:                  sales   R-squared:                       0.448
Model:                            OLS   Adj. R-squared:                  0.433
Method:                 Least Squares   F-statistic:                     29.25
Date:                Mon, 24 Aug 2015   Prob (F-statistic):           5.04e-10
Time:                        08:59:52   Log-Likelihood:                -223.87
No. Observations:                  75   AIC:                             453.7
Df Residuals:                      72   BIC:                             460.7
Df Model:                           2                                         
Covariance Type:            nonrobust                                         
==============================================================================
                 coef    std err          t      P&gt;|t|      [95.0% Conf. Int.]
------------------------------------------------------------------------------
Intercept    118.9136      6.352     18.722      0.000       106.252   131.575
price         -7.9079      1.096     -7.215      0.000       -10.093    -5.723
advert         1.8626      0.683      2.726      0.008         0.501     3.225
==============================================================================
Omnibus:                        0.535   Durbin-Watson:                   2.183
Prob(Omnibus):                  0.765   Jarque-Bera (JB):                0.159
Skew:                          -0.072   Prob(JB):                        0.924
Kurtosis:                       3.174   Cond. No.                         69.5
==============================================================================</code></pre>
<p>Fiyatsal elastikliği kontrol etmek için <span
class="math inline">\(\beta_2\)</span>’nin t değerine bakabiliriz çünkü
bu değer <span class="math inline">\(\beta_2=0\)</span> hipotezini
reddedip reddedemeyeceğimiz hakkında bize bir şeyler söylüyor. Eğer t
değer ve <code>P&gt;|t|</code> değeri 0.05’ten küçük ise hipotezi
reddedebiliriz. Çıktıya bakıyoruz, 0 değerini görüyoruz. Demek ki
fiyatsal elastiklik vardır.</p>
<p>Gayrı Lineerlik: Fakat acaba reklam harcaması ile satış arasında tam
lineer bir ilişki mi var? Belli bir noktadan sonra ne kadar harcarsak
harcayalım daha fazla kazanamayacağımız bir durum da olamaz mı? Bunu
test edelim, <span class="math inline">\(ADVERT^2\)</span> değişkenini
ekleyip yeni bir regresyon yaratalım. <span
class="math inline">\(ADVERT\)</span>’in karesini aldık çünkü karesi
alınmış <span class="math inline">\(ADVERT\)</span> normal olana göre
daha hızlı büyür, yani büyük değerlerde karesinin sonucu çok daha
büyüktür, ve eğer bu uç noktalarda bir kalıp var ise, onu “yakalamak’’
bu karesi alınmış yeni değişken sayesinde mümkün olur.</p>
<div class="sourceCode" id="cb5"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> statsmodels.formula.api <span class="im">as</span> smf</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>df[<span class="st">&#39;advert2&#39;</span>] <span class="op">=</span> df.advert<span class="op">**</span><span class="dv">2</span> <span class="co"># kare aldik</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>results2 <span class="op">=</span> smf.ols(<span class="st">&#39;sales ~ price + advert + advert2&#39;</span>, data<span class="op">=</span>df).fit()</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (results2.summary())</span></code></pre></div>
<pre><code>                            OLS Regression Results                            
==============================================================================
Dep. Variable:                  sales   R-squared:                       0.508
Model:                            OLS   Adj. R-squared:                  0.487
Method:                 Least Squares   F-statistic:                     24.46
Date:                Mon, 24 Aug 2015   Prob (F-statistic):           5.60e-11
Time:                        15:54:13   Log-Likelihood:                -219.55
No. Observations:                  75   AIC:                             447.1
Df Residuals:                      71   BIC:                             456.4
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
==============================================================================
                 coef    std err          t      P&gt;|t|      [95.0% Conf. Int.]
------------------------------------------------------------------------------
Intercept    109.7190      6.799     16.137      0.000        96.162   123.276
price         -7.6400      1.046     -7.304      0.000        -9.726    -5.554
advert        12.1512      3.556      3.417      0.001         5.060    19.242
advert2       -2.7680      0.941     -2.943      0.004        -4.644    -0.892
==============================================================================
Omnibus:                        1.004   Durbin-Watson:                   2.043
Prob(Omnibus):                  0.605   Jarque-Bera (JB):                0.455
Skew:                          -0.088   Prob(JB):                        0.797
Kurtosis:                       3.339   Cond. No.                         101.
==============================================================================
</code></pre>
<p>Yeni regresyon için <span class="math inline">\(R^2=0.50\)</span>! Bu
yeni model verideki varyansın yüzde 50’sini açıklıyor! Eskisinden daha
iyi bir model ve AIC’i de daha düşük zaten, ve <span
class="math inline">\(ADVERT^2\)</span> için hesaplanan katsayı -2.768
eksi değeri taşıyor. Demek ki reklam harcamalarının belli bir noktadan
sonra etkisinin aynı olmayacağı varsayımımız doğru.</p>
<p>Birleşik Hipotez Testleri</p>
<p>Ne yazık ki t testi ile ortak (joint) hipotez testleri yapamıyoruz.
Mesela sadece bir değil, <em>birkaç değişkenin</em> model için ne kadar
önemli olduğunu bilmek istiyoruz. Tabii bu değişkenleri regresyondan
atabiliriz, sonra çıplak gözle AIC’e bakarız, vs. Fakat bu testi daha
İstatistiksel bir hipotez testi olarak yapmak daha iyi olmaz mıydı?
Alttaki test bu durumlar için kullanılır,</p>
<p>F Testi</p>
<p>Diyelim ki reklam harcamasının satışı etkileyip etkilemediğini merak
ediyoruz. Fakat artık bir değil iki tane reklam ile alakalı değişkenimiz
var! Biri <span class="math inline">\(ADVERT\)</span> diğeri onun karesi
<span class="math inline">\(ADVERT^2\)</span>. Sıfır hipotezimiz şu
olacak, “reklam harcaması satışları belirlemede etkili değildir’’.
Yani</p>
<p><span class="math display">\[ H_0: \beta_3=0, \beta_4=0 \]</span></p>
<p><span class="math display">\[ H_1: \beta_3 \ne 0, \textrm{ ya da }
\beta_4 \ne 0 \textrm{ ya da ikisi
  de sıfır değil} \]</span></p>
<p>Hipotez bu şekilde tanımlanınca onu reddetmek demek reklamın
satışları etkilediği hakkında güçlü bir kanıt ortaya koyar. Bu nokta
önemli, aşırı fantastik bir şekilde zaten umduğumuz şeyi desteklemek
için kanıt aramak yerine, onun tam tersini reddetmek için kanıt
arıyoruz.</p>
<p>Peki bu testi nasıl yaratacağız? Bir regresyona değişken eklemek onun
hatasını azaltır, çıkartmak ise çoğaltır. Eğer ana regresyondan değişken
çıkartırsak onun hatası <span class="math inline">\(SSE_u\)</span>
diyelim, çoğalarak <span class="math inline">\(SSE_r\)</span> olur.
Notasyonel açıdan değişik bir şekilde de duruma bakabiliriz, <span
class="math inline">\(\beta_3=0, \beta_4=0\)</span> şartını koşmak
aslında bir modeli kısıtlamak ta (restrict) anlamına gelir, üzerinde
şart belirlenmemiş olan model de kısıtlanmamış (unrestricted) olur.
Neyse, F testi ile yapmaya çalışacağımız bu çoğalmanın istatistiki
olarak önemli (significant) olup olmadığını anlamaktır. <span
class="math inline">\(SSE\)</span> notasyonu bu arada hata karelerinin
toplamı (sum of squared errors) kelimelerinden geliyor.</p>
<p>Şimdi, daha önce belirttiğimiz gibi, ideal şartlarda doğru olacak bir
ölçüt yaratmak, ve bu ideal şartlarda bu ölçütün dağılımını bulmak, ve
veriyi kullanıp bu ölçütü hesaplayıp sonucu bu dağılıma “sormak’’
gerekiyor. Eğer sıfır hipotezi doğru ise,</p>
<p><span class="math display">\[ F = \frac{(SSE_r -
SSE_u)/j}{SSE_u/(n-k)} \]</span></p>
<p>hesabı bir <span class="math inline">\(F_{j,n-k}\)</span>
dağılımıdır. F dağılımının tanımını hatırlayalım, iki chi kare
dağılımının birbiriyle bölünmüş hali idi,</p>
<p><span class="math display">\[ F_{j,n-k} = \frac{\chi^2 / j}{\chi^2 /
n-k} \]</span></p>
<p>SSE hesapları karelerin toplamı olduğu için ve hataların normal
dağıldığı varsayımından hareketle bölüm ve bölendeki rasgele değişkenler
Chi kare dağılımına sahiptir.</p>
<p>Peki neden üstteki F dağılımının <span
class="math inline">\(j,n-k\)</span> derece serbestliği vardır? İki chi
kare dağılımını toplayınca onların dereceleri toplanır. Aynı şekilde
çıkartma derece eksiltir. Şimdi, <span
class="math inline">\(SSE_r\)</span>’nin derecesi <span
class="math inline">\(n-k\)</span>’dir, <span
class="math inline">\(k\)</span> tane katsayı dereceyi / serbestliği
azaltmıştır. Eğer <span class="math inline">\(SSE_r\)</span> elde etmek
için <span class="math inline">\(j\)</span> tane katsayıyı çıkartırsak,
bu durum dereceyi fazlalaştırır, yani <span
class="math inline">\(SSE_r\)</span> için <span
class="math inline">\(n-k+j\)</span> elde ederiz. O zaman bölümdeki
çıkartmanın derecesi</p>
<p><span class="math display">\[ (n-r+j) - (n-r) = j\]</span></p>
<p>olacaktır. Şimdi nihai hesabı yapalım, regresyonu reklamla alakalı
iki değişkeni çıkartılmış şekilde bir daha işletiriz, sonra SSE hesabı
için her iki regresyondan gelen artıklar <code>resid</code>’leri
kullanırız, onların karelerinin toplamı bize gerekli <span
class="math inline">\(SSE\)</span> hesabını verecektir,</p>
<div class="sourceCode" id="cb7"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> statsmodels.formula.api <span class="im">as</span> smf</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>results3 <span class="op">=</span> smf.ols(<span class="st">&#39;sales ~ price &#39;</span>, data<span class="op">=</span>df).fit()</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>SSE_u <span class="op">=</span> np.<span class="bu">sum</span>(results2.resid<span class="op">**</span><span class="dv">2</span>)</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>SSE_r <span class="op">=</span> np.<span class="bu">sum</span>(results3.resid<span class="op">**</span><span class="dv">2</span>)</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (<span class="st">&#39;SSE_u&#39;</span>, SSE_u)</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (<span class="st">&#39;SSE_r&#39;</span>, SSE_r)</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>J <span class="op">=</span> <span class="dv">2</span><span class="op">;</span> N<span class="op">=</span><span class="bu">len</span>(df)<span class="op">;</span> K <span class="op">=</span> <span class="bu">len</span>(results2.params)</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>F <span class="op">=</span> (SSE_r <span class="op">-</span> SSE_u)<span class="op">/</span>J <span class="op">/</span> SSE_u<span class="op">*</span>(N<span class="op">-</span>K)</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (<span class="st">&#39;j,n-k&#39;</span>,J,N<span class="op">-</span>K)</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (<span class="st">&#39;F =&#39;</span>, F)</span></code></pre></div>
<pre><code>SSE_u 1532.0844587
SSE_r 1896.39083709
j,n-k 2 71
F = 8.44135997807</code></pre>
<p>p değeri <span class="math inline">\(P(F_{j,n-k}&gt;8.44)\)</span>.
Kumulatif yoğunluk fonksiyonu (CDF) kullanabilmek için formülü şu
şekilde tekrar yazalım, <span
class="math inline">\(1-P(F_{j,n-k}&lt;8.44)\)</span>,</p>
<div class="sourceCode" id="cb9"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> scipy.stats <span class="im">as</span> st</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>f <span class="op">=</span> st.f(J,N<span class="op">-</span>K)</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (<span class="dv">1</span><span class="op">-</span>f.cdf(F))</span></code></pre></div>
<pre><code>0.000514159058424</code></pre>
<p>Üstteki değer 0.05 kritik değerinden daha ufak olduğu için hipotez
reddedilmiştir. Direk p değeri hesabı yerine yüzde 95 güven için bir
eşik değeri de hesaplayabilirdik,</p>
<div class="sourceCode" id="cb11"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (f.ppf(<span class="fl">0.95</span>))</span></code></pre></div>
<pre><code>3.12576423681</code></pre>
<p>Ve eğer F değeri bu değerden büyük ise hipotez reddedilmiştir
diyebilirdik, ki hesapladığımız F değeri eşik değerinden büyük idi.
Vardığımız sonuç reklam harcamalarının satış için önemli olduğudur.</p>
<p>Daha Basit bir F-Test Örneği</p>
<p>F-Test’in ana fonksiyonu ve ilk kullanımı varyans karşılaştırmak
aslında, iki ölçüm grubunu standard sapma karesinin oranı alınır, ve
sonuç bir F rasgele değişkenidir, belli serbestlik dereceleri
vardır,</p>
<p><span class="math display">\[ F = \frac{S_x^2}{S_y^2} \]</span></p>
<p>ki <span class="math inline">\(S_x,S_y\)</span> 1. ve 2. grubun
örneklem standart sapmasıdır. Bu şekilde bir örnek te görelim [2, sf.
42]. Diyelim ki elimizde göz hareketlerini ölçen iki metod var, gözümüzü
20 derece hareket ettirince metotlar şu rakamları veriyor,</p>
<div class="sourceCode" id="cb13"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>method_1 <span class="op">=</span> [<span class="fl">20.7</span>, <span class="fl">20.3</span>,<span class="fl">20.3</span>, <span class="fl">20.3</span>, <span class="fl">20.7</span>, <span class="fl">19.9</span>, <span class="fl">19.9</span>, <span class="fl">19.9</span>, <span class="op">\</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>            <span class="fl">20.3</span>, <span class="fl">20.3</span>, <span class="fl">19.7</span>, <span class="fl">20.3</span>]</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>method_2 <span class="op">=</span> [<span class="fl">19.7</span>, <span class="fl">19.4</span>, <span class="fl">20.1</span>, <span class="fl">18.6</span>, <span class="fl">18.8</span>, <span class="fl">20.2</span>, <span class="fl">18.7</span>, <span class="fl">19.</span>]</span></code></pre></div>
<p>F-testini kullanarak bu metotların, ölçümlerin doğruluğunun
(accuracy) aynı mı, yoksa birinin diğerinden daha doğru mu olduğunu
bulacağız.</p>
<div class="sourceCode" id="cb14"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>m1 <span class="op">=</span> np.array(method_1)<span class="op">;</span> m2 <span class="op">=</span> np.array(method_2)</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.DataFrame([m1,m2]).T</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>ss <span class="op">=</span> df.std()</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>F <span class="op">=</span> ss.iloc[<span class="dv">0</span>]<span class="op">**</span><span class="dv">2</span><span class="op">/</span>ss.iloc[<span class="dv">1</span>]<span class="op">**</span><span class="dv">2</span></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (F)</span></code></pre></div>
<pre><code>0.243934673841</code></pre>
<div class="sourceCode" id="cb16"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> scipy.stats <span class="im">as</span> st</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>f <span class="op">=</span> st.f(<span class="bu">len</span>(m1)<span class="op">-</span><span class="dv">1</span>,<span class="bu">len</span>(m2)<span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (<span class="dv">1</span><span class="op">-</span>f.cdf(F))</span></code></pre></div>
<pre><code>0.981334830069</code></pre>
<p>F dağılımı <span class="math inline">\(n-1\)</span> ve <span
class="math inline">\(m-1\)</span> serbestlik derecesine sahip. Üstteki
<span class="math inline">\(p\)</span> değeri 0.05’ten küçük değildir,
demek ki iki metotun ölçüm doğruluğunun aynı olduğu hipotezini
reddedemiyoruz. Not: Örneklem standart sapma hesabı için <span
class="math inline">\(n-1\)</span>’e bölünme durumu var, bu bölüm
kullanılan <span class="math inline">\(F\)</span>’in derecesine yansıyor
tabii.</p>
<p>Testin özünde şu var, ki varyansın eşitsizliği oranın 1’den ne kadar
uzak olduğuna bağlı. Ama ne kadar uzak istatistiki olarak önemli bir
uzaklık? İşte bunun cevabını F-dağılımı veriyor.</p>
<p>Örneklem Korelasyonu</p>
<p>Korelasyon <span class="math inline">\(\rho\)</span>’yu daha önce
gördük, tahmin edicisi <span class="math inline">\(r\)</span>’dir,</p>
<p><span class="math display">\[
\hat{\rho} = r = \frac{S_{xy}}{\sqrt{S_{xx}S_{yy}}}
\qquad (1)
\]</span></p>
<p>ki örneklem hesapları <span
class="math inline">\(S_{xx},S_{xy},S_{yy}\)</span></p>
<p><span class="math display">\[ S_{xx} = \sum_{i=1}^{n} (x_i-\bar{x})^2
\]</span></p>
<p><span class="math display">\[ S_{xy} = \sum_{i=1}^{n}
(x_i-\bar{x})(y_i-\bar{y}) \]</span></p>
<p><span class="math display">\[ S_{yy} = \sum_{i=1}^{n} (y_i-\bar{y})^2
\]</span></p>
<p>olsun; bu hesapların teorik varyans ile olan bağlantısı görülebilir.
Eğer <span class="math inline">\(X,Y\)</span> iki değişkenli (bivariate)
bir normal dağılımından geliyorsa, o zaman ortada bir regresyon varmış
gibi gösterebiliriz</p>
<p><span class="math display">\[ E(Y|X=x) = \beta_0 + \beta_1 x +
\epsilon \]</span></p>
<p>ki <span class="math inline">\(\beta_1 = \sigma_Y / \sigma_X \cdot
\rho\)</span> olur. Detaylar için [4]. Soru şu, <span
class="math inline">\(r\)</span> için bir istatistiksel önemlilik
(significance) hesabı nasıl yapardık? Yani, eğer <span
class="math inline">\(-1 \le r \le 1\)</span> işe, ve <span
class="math inline">\(r=0\)</span> hiç korelasyon olmama durumu ise,
acaba bu “sıfır olmama’’ durumunu test edebilir miydim? Evet. Yukarıdaki
normallik faraziyesi doğru ise <span class="math inline">\(\beta_1 =
0\)</span> olmama durumunu test etmek <span class="math inline">\(\rho =
0\)</span> olmama testi ile aynı, bu durumda</p>
<p><span class="math display">\[ t_0 = \frac{\hat{\beta_1}}{\sqrt{
Var(\hat{\beta_1} ) }} \]</span></p>
<p>gibi bir test istatistiği yaratırız, ki bu istatistik Öğrenci t
dağılımına sahip olurdu çünkü sıfır hipotezi <span
class="math inline">\(\hat{\beta_1} = 0\)</span>, ve üstteki istatistik
sıfır hipotezi altında ile Öğrenci t dağılımına sahip olmak zorundadır,
çünkü bölünen normal dağılmış, bölen chi karenin karekökü olarak
dağılmış. Eğer <span class="math inline">\(t_o\)</span> hesabı veriye
uygulandıktan sonra hipotezin öngördüğü dağılıma uymaz ise, sıfır
hipotezini reddederiz.</p>
<p>Bu noktada lineer regresyon ile alakalı bilgiler devreye sokulabilir,
[4]’den biliyoruz ki</p>
<p><span class="math display">\[ Var(\hat{\beta_1}) =
\frac{\sigma^2}{S_{xx}} \]</span></p>
<p><span class="math inline">\(\sigma\)</span> yerine örneklemden gelen
<span class="math inline">\(S\)</span> kullanırsak ve üstteki formüle
koyarsak,</p>
<p><span class="math display">\[ t_0 = \frac{\hat{\beta_1}}{\sqrt{S /
S_{xx}}} \]</span></p>
<p>Bu ifadeyi <span class="math inline">\(r\)</span> bazında ifade
edebilir miyiz? Deneyelim, <span class="math inline">\(\hat{\beta_1} =
S_{xy} / S_{xx}\)</span> ve <span class="math inline">\(r =
\hat{\beta_1}\sqrt{\frac{S_{xx}}{S_{yy}}}\)</span> olduğunu biliyoruz
[4], ayrıca</p>
<p><span class="math display">\[ S = \frac{SSE}{n-2}, \qquad SSE =
S_{yy} - \hat{\beta_1} S_{xy} \]</span></p>
<p>ki <span class="math inline">\(SSE\)</span> hata karelerinin
toplamıdır (sum of squared errors),</p>
<p><span class="math display">\[ t_0 = \frac{  \sqrt{S_{xx}}
\hat{\beta_1} \sqrt{n-2} }{\sqrt{SSE}} \]</span></p>
<p><span class="math display">\[ = \frac{  \sqrt{S_{xx}} \hat{\beta_1}
\sqrt{n-2} }{\sqrt{S_{yy} - \hat{\beta_1} S_{xy}}} \]</span></p>
<p>Bölümün iki kısmını <span class="math inline">\(\sqrt{S_y}\)</span>
ile bölelim,</p>
<p><span class="math display">\[ =
\frac{ \sqrt{S_{xx}/S_{yy}} \hat{\beta_1} \sqrt{n-2} }
{\sqrt{1 - \hat{\beta_1} S_{xy}/S_{yy}}}
\]</span></p>
<p>Bölünen kısmında bir <span class="math inline">\(r\)</span> ortaya
çıktı,</p>
<p><span class="math display">\[ =
\frac{ r\sqrt{n-2} }
{\sqrt{1 - \hat{\beta_1} S_{xy}/S_{yy}}}
\]</span></p>
<p>Bölen kısmındaki <span class="math inline">\(\hat{\beta_1}\)</span>
yerine <span class="math inline">\(\hat{\beta_1} = S_{xy} /
S_{xx}\)</span> koyarsak yine (1)’deki <span
class="math inline">\(r\)</span> tanımına geliriz, ve alttaki
basitleştirilmiş ifade ortaya çıkar,</p>
<p><span class="math display">\[ t_o = \sqrt{\frac{(n-2)r^2}{(1-r^2)}}
\]</span></p>
<p>Bu istatistik <span class="math inline">\(n-2\)</span> derece
serbestliğe sahip bir Öğrenci t dağılımıdır.</p>
<p>Örnek</p>
<p>Possum adı verilen bir tür hayvanın dişilerinin tüm uzunluğu ve kafa
ölçümü <code>totlngth,hdlngth</code> değişkenleri arasında korelasyon
olup olmadığı merak edilmektedir.</p>
<div class="sourceCode" id="cb18"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> scipy.stats</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> p_corr(df1, df2):</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>    corr <span class="op">=</span> df1.corr(df2)</span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>    N <span class="op">=</span> np.<span class="bu">sum</span>(df1.notnull())</span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a>    t <span class="op">=</span> corr<span class="op">*</span>np.sqrt((N<span class="op">-</span><span class="dv">2</span>)<span class="op">/</span>(<span class="dv">1</span><span class="op">-</span>corr<span class="op">**</span><span class="dv">2</span>))</span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a>    p <span class="op">=</span> <span class="dv">1</span><span class="op">-</span>scipy.stats.t.cdf(<span class="bu">abs</span>(t),N<span class="op">-</span><span class="dv">2</span>)  <span class="co"># one-tailed</span></span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> corr, t, p</span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(<span class="st">&#39;fossum.csv&#39;</span>)</span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a>c,tval, pval <span class="op">=</span> p_corr(df.totlngth,df.hdlngth)</span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (c, pval)</span></code></pre></div>
<pre><code>0.779239322172 3.75045772216e-10</code></pre>
<p>p-değeri çok küçük, demek ki korelason olmadığı tezi reddedildi.
Korelasyon var.</p>
<p>Pearson Chi Kare Uyum Derecesi (Goodness-of-Fit) Testi</p>
<p>Her sene günde kaç saat çalıştığımızı bir yere yazdık diyelim, elde
365 veri noktası var. Ertesi sene yine aynı veriyi topladık, şu soruyu
soruyoruz, iki veri birbirinden istatistiki olarak farklı mıdır? Ya da;
elimizdeki belli bir veri var, ve o verinin normal mi, ya da üstel
(exponential) dağılımdan mı geldiğini merak ediyoruz. Acaba veri
istatistiki olarak hangi <em>tip</em> dağılım fonksiyona (yani teorik
yoğunluk fonksiyonuna) daha yakındır? Ya da; eldeki bir verinin <span
class="math inline">\(\mu = 0\)</span> merkezli normal dağılımdan mı,
yoksa <span class="math inline">\(\mu = 30\)</span> merkezli normal
dağılımdan mı geldiğini merak ediyoruz.</p>
<p>Her üç sorunun ve benzerlerinin cevabı Pearson’un chi kare (chi
square) uyum derece testi ile verilebilir.</p>
<p>İki veriyi karşılaştırdığımız durumda bu iki veri kümesini dağılım
olarak kabul edip, birini diğerine uyum açısından test edebiliriz. Bu
karşılaştırma her iki tarafta histogram alınıp histogram kutucuklarının
(bins) içine her iki tarafta düşen miktarların bir test istatistiği
üzerinden karşılaştırılması ile olabilir. Veri ile yoğunluk
karşılaştırdığımızda ise veriyi histogram kutucukları, yoğunluğu ise
aynı aralıklara düşen olasılıkların fonksiyonel hesaplarıyla
karşılaştırılması ile yaparız.</p>
<p>Test istatistiği</p>
<p>Diyelim ki her kutucukta görülen miktar <span
class="math inline">\(N_i\)</span>, ki <span class="math inline">\(N_1 +
N_2 + .. + N_k = n\)</span>, ve karşılaştırmak istediğimiz, bu miktara
tekabül eden “ideal’’ olasılık <span class="math inline">\(p_i\)</span>,
o zaman ideal miktar <span class="math inline">\(n p_i\)</span>.
Kutucuktaki sayıları bir binom dağılımından geliyormuş gibi
modelleyebiliriz, 1. kutucuk için mesela <span class="math inline">\(N_1
\sim Bin(n,p_1)\)</span>, ve <span class="math inline">\(N_1\)</span>
rasgele değişkeni <span class="math inline">\(N\)</span> tane
deneyde”başarılı’’ olan sayı - tipik binom kullanımı. Bu durumda Pearson
uyum derecesi istatistiği</p>
<p><span class="math display">\[
\chi^2 = \sum_{j=1}^{k} \frac{(N_j - np_j)^2}{np_j}
\]</span></p>
<p>ile belirtilir, üstteki toplamın yaklaşıksal olarak <span
class="math inline">\(\chi^2_{k-1}\)</span> dağılımına yaklaştığı
ispatlanmıştır. Detaylar için [5, sf 318, 6]. Nihai ispat oldukça
çetrefil, biz burada alternatif bazı yaklaşıksal ispatlardan bahsetmek
istiyoruz (okkalı ispat için yukarıdaki referanslar geçerli tabii).</p>
<p>Eğer her <span class="math inline">\(N_j\)</span> binom dağılımını
Gaussian ile yaklaşıkladığımızı düşünürsek, ki bu yeterince büyük <span
class="math inline">\(n\)</span>, ve <span
class="math inline">\(np_i&gt;5\)</span> için mümkün, bu dağılım <span
class="math inline">\(\mu=np_j\)</span> ve varyans <span
class="math inline">\(np_j(1-p_j)\)</span>’ye sahip olur, o zaman
Gaussian’ı standardize etmek için</p>
<p><span class="math display">\[ \frac{N_j-np_j}{\sqrt{np_j(1-p_j)}}
\approx N(0,1) \]</span></p>
<p><span class="math inline">\(Z=N(0,1)\)</span> diyelim,</p>
<p><span class="math display">\[
\frac{(N_j - np_j)}{\sqrt{np_j} } \approx  \sqrt{(1-p_j)}Z
\]</span></p>
<p>İki tarafın karesini alalım, ve her <span
class="math inline">\(j\)</span> üzerinden toplam alalım,</p>
<p><span class="math display">\[
\sum_j \frac{(N_j - np_j)^2}{np_j} \approx \sum_j (1-p_j)Z^2
\]</span></p>
<p>Üstteki eşitliğin sol tarafı Pearson istatistiğiyle aynı. Sağ tarafı
neye eşit?</p>
<p><span class="math display">\[
\sum_j (1-p_j)Z^2 =  (1-p_1)Z^2 + (1-p_2)Z^2 + ... + (1-p_k)Z^2
\]</span></p>
<p><span class="math display">\[
=  Z^2 [(1-p_1) + (1-p_2) + ... + (1-p_k)]
\]</span></p>
<p><span class="math display">\[
=  Z^2 [k - (p_1+p_2+..+p_k))] = (k-1)Z^2 = \sum_{k-1} Z^2
\]</span></p>
<p>Şimdi, bu eriştiğimiz toplamın <span
class="math inline">\(\chi^2_{k-1}\)</span> dağılımı, yani <span
class="math inline">\(k-1\)</span> derece serbestliği olan bir chi kare
dağılımı olduğunu iddia edebilir miyiz? Eğer <span
class="math inline">\(Z_j\)</span>’ler birbirinden bağımsız ise
kesinlikle evet, çünkü standart normal rasgele değişkenlerin toplamı chi
kare dağılımını verir. Üstteki kolay ispatın önündeki tek engel budur,
bizim burada yapacağımız yaklaşıksal argüman <span
class="math inline">\(i,j\)</span> ikilisi için <span
class="math inline">\(Z\)</span>’lerin bağlantısının, kovaryansının
küçük olduğudur, ki bu küçüklük sebebiyle <span
class="math inline">\(Z_j\)</span>’ler çoğu durumda bağımsız kabul
edilebilir.</p>
<p>Diyelim ki <span class="math inline">\(X_1,X_2,..\)</span>
değişkenleri bağımsız ve <span class="math inline">\(Mult(1,p)\)</span>,
yani multinom dağılımdan geliyorlar [7, sf. 180], ve <span
class="math inline">\(p = \left[\begin{array}{ccc} p_1 &amp; p_2
&amp;  \dots \end{array}\right]\)</span>, ve <span
class="math inline">\(\sum_j p_j = 1\)</span>. Yani her <span
class="math inline">\(X_i\)</span> zar attığında <span
class="math inline">\(1 \times k\)</span> boyutlu bir vektör ortaya
çıkıyor, bu vektörün sadece bir hücresi 1 diğerleri 0. Multinom
dağılımların tanımından biliyoruz ki <span
class="math inline">\(Cov(X_i,X_j) = -n p_ip_j = -p_ip_j\)</span> (çünkü
<span class="math inline">\(n=1\)</span>).</p>
<p>Bu demektir ki 1’den küçük iki değer çarpılıyor bu daha da küçük bir
değer verecektir. Eğer <span class="math inline">\(k\)</span> yeterince
büyük ise, bu, mesela sürekli yoğunlukları ayrıksal olarak gösterdiğimiz
durumda ve yeterince çok kutucuk var ise bu kutucuklara “düşen’’
olasılıkların ufalması demektir, ve ufak değerlerin çarpımı iyice
ufalır, ki bu kovaryansı sıfıra yaklaştırır. Yani yeterince büyük <span
class="math inline">\(k\)</span> için <span
class="math inline">\(i,j\)</span> bağlantısını sezgisel bağlamda
etkisiz olduğunu görebiliriz. Tabii, toplamın <em>kesinlikle</em> chi
kare olduğunun ispatı için dediğimiz gibi verdiğimiz referanslara
bakılabilir.</p>
<p>İstatistiki testlerin mantığını hatırlarsak, tarif edilen Pearson
istatistiği sıfır hipotezi. Bize reddetmeye uğraşacağımız bir dağılım /
hesap ikilisi üretiyor. Eğer hesap beklenen, normal (sıfır hipotez
durumu) uymuyorsa, hipotezi reddediyoruz. Ret durumu özellikle seçiliyor
çünkü kabul edilmezlik daha kesin bir cevap.</p>
<p>Örnek</p>
<p>Bir paralı otoyolunda geçiş noktasında durulmuş ve her dakika gelen
araç sayılmış, ve dakika başına bu araç sayısı yazılmış. Bu deney 106
dakika süresince yapılmış (elde 106 satırlı bir veri var yani). Bu veri
için Poisson dağılımının uygun olup olmadığını yüzde 5 önemlilik
seviyesinde ispatlamamız isteniyor.</p>
<div class="sourceCode" id="cb20"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>vehicle <span class="op">=</span> [<span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">3</span>, <span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">4</span>, <span class="dv">4</span>, <span class="dv">4</span>, <span class="dv">4</span>, <span class="dv">5</span>, <span class="dv">5</span>, <span class="dv">5</span>, <span class="dv">5</span>, <span class="dv">5</span>, <span class="dv">5</span>, <span class="dv">5</span>, <span class="dv">6</span>,<span class="op">\</span></span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a><span class="dv">6</span>, <span class="dv">6</span>, <span class="dv">6</span>, <span class="dv">6</span>, <span class="dv">6</span>, <span class="dv">6</span>, <span class="dv">6</span>, <span class="dv">6</span>, <span class="dv">6</span>, <span class="dv">6</span>, <span class="dv">6</span>, <span class="dv">6</span>, <span class="dv">7</span>, <span class="dv">7</span>, <span class="dv">7</span>, <span class="dv">7</span>, <span class="dv">7</span>, <span class="dv">7</span>, <span class="dv">7</span>,<span class="op">\</span></span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a><span class="dv">7</span>, <span class="dv">7</span>, <span class="dv">7</span>, <span class="dv">7</span>, <span class="dv">7</span>, <span class="dv">8</span>, <span class="dv">8</span>, <span class="dv">8</span>, <span class="dv">8</span>, <span class="dv">8</span>, <span class="dv">8</span>, <span class="dv">8</span>, <span class="dv">8</span>, <span class="dv">9</span>, <span class="dv">9</span>, <span class="dv">9</span>, <span class="dv">9</span>, <span class="dv">9</span>, <span class="dv">9</span>, <span class="dv">9</span>,</span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a><span class="dv">9</span>, <span class="dv">9</span>, <span class="dv">10</span>, <span class="dv">10</span>, <span class="dv">10</span>, <span class="dv">10</span>, <span class="dv">10</span>, <span class="dv">10</span>, <span class="dv">10</span>, <span class="dv">10</span>, <span class="dv">10</span>, <span class="dv">10</span>, <span class="dv">10</span>, <span class="dv">10</span>, <span class="dv">10</span>, <span class="op">\</span></span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a><span class="dv">11</span>, <span class="dv">11</span>, <span class="dv">11</span>, <span class="dv">11</span>, <span class="dv">11</span>, <span class="dv">11</span>, <span class="dv">11</span>, <span class="dv">11</span>, <span class="dv">11</span>, <span class="dv">11</span>, <span class="dv">12</span>, <span class="dv">12</span>, <span class="dv">12</span>, <span class="dv">12</span>, <span class="op">\</span></span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a><span class="dv">12</span>, <span class="dv">13</span>, <span class="dv">13</span>, <span class="dv">13</span>, <span class="dv">13</span>, <span class="dv">13</span>, <span class="dv">13</span>, <span class="dv">14</span>, <span class="dv">14</span>, <span class="dv">14</span>, <span class="dv">14</span>, <span class="dv">15</span>, <span class="dv">15</span>, <span class="dv">15</span>, <span class="dv">15</span>,<span class="op">\</span></span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a><span class="dv">15</span>, <span class="dv">16</span>, <span class="dv">16</span>, <span class="dv">16</span>, <span class="dv">16</span>, <span class="dv">18</span>]</span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.DataFrame(vehicle)</span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a>df.to_csv(<span class="st">&#39;vehicles.csv&#39;</span>,index<span class="op">=</span><span class="va">None</span>,header<span class="op">=</span><span class="va">None</span>)</span></code></pre></div>
<p>Verinin histogramına bakalım,</p>
<div class="sourceCode" id="cb21"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>f <span class="op">=</span> plt.figure()<span class="op">;</span> df.hist(bins<span class="op">=</span><span class="dv">13</span>)</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>plt.savefig(<span class="st">&#39;stat_tests2_01.png&#39;</span>)</span></code></pre></div>
<p><img src="stat_tests2_01.png" /></p>
<p>Poisson dağılımı muhtemel gözüküyor. Ama şimdi bunu uyum derece testi
ile daha kararlı şekilde göstermeye uğraşacağız. Verideki sayımları o
sayım rakamı bazında gruplayalıp gösterelim,</p>
<div class="sourceCode" id="cb22"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>kt <span class="op">=</span> plt.hist(np.array(df),bins<span class="op">=</span><span class="bu">range</span>(<span class="dv">20</span>))</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>kt <span class="op">=</span> pd.DataFrame([kt[<span class="dv">1</span>],kt[<span class="dv">0</span>]]).T</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>kt <span class="op">=</span> kt[:<span class="op">-</span><span class="dv">1</span>] <span class="co"># sonuncu satiri at</span></span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>kt.columns <span class="op">=</span> [<span class="st">&#39;kac araba&#39;</span>,<span class="st">&#39;kac kere&#39;</span>]</span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (kt)</span></code></pre></div>
<pre><code>    kac araba  kac kere
0         0.0       0.0
1         1.0       0.0
2         2.0       1.0
3         3.0       3.0
4         4.0       5.0
5         5.0       7.0
6         6.0      13.0
7         7.0      12.0
8         8.0       8.0
9         9.0       9.0
10       10.0      13.0
11       11.0      10.0
12       12.0       5.0
13       13.0       6.0
14       14.0       4.0
15       15.0       5.0
16       16.0       4.0
17       17.0       0.0
18       18.0       1.0</code></pre>
<p>Yani bir dakikada 6 araba sayımı 13 kere yapılmış (13 değişik
dakikada). Not: Üstte bir kütüphane çağrısı <code>hist</code> kullandık
(grafikleme kısmını kullanmadan), ama Poisson frekans hesabı elle çok
kolay yapılabilir.</p>
<p>Eğer üstteki verinin bir Poisson dağılımdan geldiğini kabul
ediyorsak, Poisson’un parametresi <span
class="math inline">\(\lambda\)</span>’yi veriden hesaplamak için
ortalama almak yeterlidir,</p>
<div class="sourceCode" id="cb24"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>lam <span class="op">=</span> np.mean(kt[<span class="st">&#39;kac kere&#39;</span>])</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (<span class="st">&#39;lambda </span><span class="sc">%0.2f</span><span class="st">&#39;</span> <span class="op">%</span> lam)</span></code></pre></div>
<pre><code>lambda 5.58</code></pre>
<p>Bu Poisson’u kullanarak bazı olasılık hesapları hemen yapabilirdik,
mesela 3’ten fazla, 9’dan fazla araba sayılma ihtimali nedir?</p>
<div class="sourceCode" id="cb26"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> poisson</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (<span class="dv">1</span><span class="op">-</span>poisson.cdf(<span class="dv">3</span>, lam))</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (<span class="dv">1</span><span class="op">-</span>poisson.cdf(<span class="dv">9</span>, lam))</span></code></pre></div>
<pre><code>0.807087823822676
0.057975438622207665</code></pre>
<p>Devam edelim. Veride bazı kutucukların boş olduğunu görüyoruz, bu
durum özellikle tek tepeli (unimodel) dağılımlı verilerde etekleri
temsil eden uçlardaki kutucukların boş olması sonucunu verebilir. Bu
durumda o kutucukların verisi daha dolu olanlara aktarabilmek için
kutucuk noktalarını tekrar tanımlıyoruz,</p>
<div class="sourceCode" id="cb28"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>bins <span class="op">=</span> [<span class="dv">0</span>] <span class="op">+</span> <span class="bu">list</span>(<span class="bu">range</span>(<span class="dv">5</span>,<span class="dv">15</span>)) <span class="op">+</span> [<span class="dv">100</span>]</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>kt2 <span class="op">=</span> plt.hist(np.array(df),bins<span class="op">=</span>bins)</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>kt2 <span class="op">=</span> pd.DataFrame([kt2[<span class="dv">1</span>],kt2[<span class="dv">0</span>]]).T</span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a>kt2.columns <span class="op">=</span> [<span class="st">&#39;int_low&#39;</span>,<span class="st">&#39;n_i&#39;</span>]</span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (kt2)</span></code></pre></div>
<pre><code>    int_low  n_i
0         0    9
1         5    7
2         6   13
3         7   12
4         8    8
5         9    9
6        10   13
7        11   10
8        12    5
9        13    6
10       14   14
11      100  NaN</code></pre>
<p>Şimdi bu değerler üzerinden Pearson <span
class="math inline">\(\chi^2\)</span> hesabını yapalım. Ama ondan önce,
hatırlayalım, bu verinin <em>herhangi bir</em> Poisson’dan gelip
gelmediğini kontrol ediyoruz, ama testimiz için parametresi belli olan,
özel bir Poisson lazım, bunun için bize bir <span
class="math inline">\(\lambda\)</span> gerekiyor. Önemli değil, <span
class="math inline">\(\lambda\)</span>’nin tahmin edicisi <span
class="math inline">\(\hat{\lambda}\)</span>’yi biliyoruz,</p>
<p><span class="math display">\[ \hat{\lambda} = \frac{1}{n}
\sum_{j=1}^{n}x_j \]</span></p>
<p>Bu <span class="math inline">\(\hat{\lambda}\)</span>’yi kullanarak
Poisson hesaplarını yapabiliriz artık. Bir kutucuğa düşen Poisson
olasılığının hesabı <span class="math inline">\(P(a \le X &lt;
b)\)</span>, ki bu basit bir <span
class="math inline">\(F(b)-F(a)\)</span>, yani <span
class="math inline">\(a,b\)</span> noktalarındaki kümülatif yoğunluk
fonksiyonun farkı üzerinden hesaplanabilir, altta kullanılan çağrı
<code>poisson.cdf</code>.</p>
<div class="sourceCode" id="cb30"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> poisson</span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>kt2[<span class="st">&#39;int_high&#39;</span>] <span class="op">=</span> kt2.shift(<span class="op">-</span><span class="dv">1</span>).int_low</span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a>lam <span class="op">=</span> df.mean() <span class="co"># tahmin edici</span></span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> f(x): </span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a>   high <span class="op">=</span> poisson.cdf(x.int_high<span class="op">-</span><span class="dv">1</span>,lam)</span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a>   low <span class="op">=</span> poisson.cdf(x.int_low<span class="op">-</span><span class="dv">1</span>,lam)</span>
<span id="cb30-7"><a href="#cb30-7" aria-hidden="true" tabindex="-1"></a>   <span class="cf">return</span> pd.Series(high<span class="op">-</span>low)</span>
<span id="cb30-8"><a href="#cb30-8" aria-hidden="true" tabindex="-1"></a>kt2[<span class="st">&#39;p_i&#39;</span>] <span class="op">=</span> kt2.<span class="bu">apply</span>(f,axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb30-9"><a href="#cb30-9" aria-hidden="true" tabindex="-1"></a>kt2[<span class="st">&#39;np_i&#39;</span>] <span class="op">=</span> <span class="bu">len</span>(df) <span class="op">*</span> kt2[<span class="st">&#39;p_i&#39;</span>]</span>
<span id="cb30-10"><a href="#cb30-10" aria-hidden="true" tabindex="-1"></a>kt2[<span class="st">&#39;chi&#39;</span>] <span class="op">=</span> (kt2[<span class="st">&#39;n_i&#39;</span>]<span class="op">-</span>kt2[<span class="st">&#39;np_i&#39;</span>])<span class="op">**</span><span class="dv">2</span> <span class="op">/</span> kt2[<span class="st">&#39;np_i&#39;</span>]</span>
<span id="cb30-11"><a href="#cb30-11" aria-hidden="true" tabindex="-1"></a>kt2 <span class="op">=</span> kt2[:<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb30-12"><a href="#cb30-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (kt2)</span>
<span id="cb30-13"><a href="#cb30-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (<span class="st">&#39;</span><span class="ch">\n</span><span class="st">chi kare istatistigi&#39;</span>, kt2.chi.<span class="bu">sum</span>())</span></code></pre></div>
<pre><code>    int_low  n_i  int_high       p_i       np_i       chi
0         0    9         5  0.051863   5.497487  2.231492
1         5    7         6  0.058217   6.171048  0.111352
2         6   13         7  0.088242   9.353602  1.421508
3         7   12         8  0.114643  12.152118  0.001904
4         8    8         9  0.130325  13.814437  2.447271
5         9    9        10  0.131691  13.959242  1.761849
6        10   13        11  0.119764  12.695009  0.007327
7        11   10        12  0.099016  10.495702  0.023412
8        12    5        13  0.075040   7.954290  1.097248
9        13    6        14  0.052496   5.564539  0.034078
10       14   14       100  0.078703   8.342527  3.836608

chi kare istatistigi 12.9740502104</code></pre>
<p>Şimdi üstteki değerin istatistiki önem taşıyıp taşımadığını anlamaya
geldi sıra. Eşik değerimiz <span
class="math inline">\(\chi^2_{9,0.05}\)</span> olacak. Peki niye
serbestlik derecesi 9 alındı? Elde kaç tane kutucuk var?</p>
<div class="sourceCode" id="cb32"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (<span class="bu">len</span>(kt2), <span class="st">&#39;kutucuk&#39;</span>)</span></code></pre></div>
<pre><code>11 kutucuk</code></pre>
<p>11-1=0 niye olmadı, -1 ile serbestlik derecesi hesaplamıyor muyduk?
Evet. Fakat bir kavis daha var, tahmin edici ile <span
class="math inline">\(\lambda\)</span>’yi hesaplayınca 1 serbestlik
derecesi daha kaybettik! <span class="math inline">\(\chi_2\)</span> ile
çalışırken hatırlanması gereken bilgilerden biri bu. Pearson bu testi
keşfettiğinde aslında bu eksiltmeye gerek görmüyordu, daha sonraları
Fisher adlı istatistikçi bunun gerekli olduğunu ispatladı.</p>
<div class="sourceCode" id="cb34"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> chi2</span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>dof <span class="op">=</span> <span class="bu">len</span>(kt2)<span class="op">-</span><span class="dv">1</span><span class="op">-</span><span class="dv">1</span> <span class="co"># lambda tahmini 1 derece kaybettirdi</span></span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (<span class="st">&#39;serbestlik derecesi&#39;</span>, dof)</span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (<span class="st">&#39;chi kare&#39;</span>, chi2.ppf(<span class="fl">0.95</span>,dof))</span></code></pre></div>
<pre><code>serbestlik derecesi 9
chi kare 16.9189776046</code></pre>
<p>Hesaplanan değer üstteki değerden küçük olduğu için Poisson hipotezi
kabul edilmiştir (ya da olmadığı reddedilememiştir, eğer p-değeri
hesaplasaydık, 0.05’den az sonuca bakacaktık, aynı şey).</p>
<p>Kaynaklar</p>
<p>[1] Hill, <em>Principles of Econometrics</em></p>
<p>[2] Uriel, <em>Introduction to Econometrics, Lecture</em></p>
<p>[3] Haslwanter, <em>Introduction to Statistics Using Python</em></p>
<p>[4] Wackerly, <em>Mathematical Statistics, 7th Edition</em></p>
<p>[5] Soong, <em>Fundamentals of Probability and Statistics for
Engineers</em></p>
<p>[6] OCW MIT, <em>Statistics for Applications, 18.443</em></p>
<p>[7] Hunter, <em>Asymptotics for Statisticians</em></p>
<p>[8] Steiger, <em>Correlation and Regresion, Lecture Notes</em></p>
<p>[9] Sheppard, <em>Introduction to Python for Econometrics</em></p>
<p>[10] Greene, <em>Econometric Analysis</em></p>
<p>[11] Uriel, <em>Introduction to Econometrics</em></p>
<p>[12] Bayramlı, <em>İstatistik, Gayri Lineer Regresyon, Petrol Tepe
Noktası</em></p>
<p>
  <a href="..">Yukarı</a>
</p>
</body>
</html>
