<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
    <script type="text/x-mathjax-config">
    MathJax.Hub.Register.StartupHook("TeX Jax Ready",function () {
      MathJax.Hub.Insert(MathJax.InputJax.TeX.Definitions.macros,{
        cancel: ["Extension","cancel"], cancelto: ["Extension","cancel"]
      });
    });
    </script>  
   
  <title>Olasılıksal Matris Ayrıştırması (Probabilistic Matrix Factorization) ve Film Tavsiyeleri</title>
  <style type="text/css">code{white-space: pre;}</style>
  <script
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS_HTML-full"
  type="text/javascript"></script>
</head>
<body>
<div id="header">
</div>
<h1
id="olasılıksal-matris-ayrıştırması-probabilistic-matrix-factorization-ve-film-tavsiyeleri">Olasılıksal
Matris Ayrıştırması (Probabilistic Matrix Factorization) ve Film
Tavsiyeleri</h1>
<p>Tavsiye sistemleri film, şarkı gibi ürünler üzerinde yapılan beğeni
notları üzerinden o kullanıcının not vermediği filmler, şarkılar
üzerinde bir tahmin üretmeye uğraşır. Diyelim ki <span
class="math inline">\(N\)</span> tane kullanıcı ve <span
class="math inline">\(M\)</span> tane film var, ve <span
class="math inline">\(i\)</span> kullanıcısının <span
class="math inline">\(j\)</span> filmine verdiği not <span
class="math inline">\(R_{ij}\)</span> üzerinde. Eğer kullanıcı ve film
özelliklerini azaltılmış, sıkıştırılmış, “gizil” bir uzay üzerinden
temsil etmek istersek, ki bu <span class="math inline">\(N,M\)</span>’ye
kıyasla boyutu daha küçük bir uzay olacaktır, şu şekilde olasılıksal bir
tanım yapabilirdik [1],</p>
<ul>
<li><span class="math inline">\(N\)</span>: kullanıcı sayısı</li>
<li><span class="math inline">\(M\)</span>: film sayısı</li>
<li><span class="math inline">\(K\)</span>: gizil (latent) boyut, yani
sıkıştırılmış, <span class="math inline">\(U,V\)</span>’nin daraltılmış
uzayı</li>
<li><span class="math inline">\(U_i \in \mathbb{R}^K\)</span>, <span
class="math inline">\(i = 1, \dots, N\)</span> için</li>
<li><span class="math inline">\(V_j \in \mathbb{R}^K\)</span>, <span
class="math inline">\(j = 1, \dots, M\)</span> için</li>
<li><span class="math inline">\(\mu \in \mathbb{R}\)</span> (global
ortalama)</li>
<li><span class="math inline">\(R_{ij} \in \mathbb{R}\)</span> (<span
class="math inline">\(I_{ij}=1\)</span> ise bu kullanıcı o filme not
vermiştir)</li>
</ul>
<p><span class="math display">\[
R_{ij}
=
\mu + U_i^\top V_j + \epsilon_{ij},
\quad
\epsilon_{ij} \sim \mathcal{N}(0, \sigma^2)
\qquad (3)
\]</span></p>
<p>Bir tavsiye sisteminin eğitmek demek üstteki daha az boyutlu <span
class="math inline">\(U,V\)</span> matrislerinin optimal değerlerini
bulmak demektir. Bu değerleri bulunca bir tür özet temsil elde etmiş
olacağız, bu temsil bize kullanıcının seyretmediği filmlere verebileceği
notu tahmin etmemizi sağlayacak.</p>
<h3 id="hesap-yöntemi">Hesap Yöntemi</h3>
<p>Hesapsal baglamda amacımız alttaki dağılıma erişmek, yani bu “sonsal
(posterior)” dağılımdan örneklem alabilmek istiyoruz:</p>
<p><span class="math display">\[
p(U, V \mid R)
\]</span></p>
<p>Bu dağılımdan örneklem alabilmek için Gibbs tekniği kullanarak, yani
koşullu dağılımlardan tekrarlı örnekleme yaparak oraya erisebiliriz.
Mesela bir adımda <span class="math inline">\(p(U_i \mid V, R)\)</span>
örneklemesi alırız, o değerleri kullanarak sonrakinde <span
class="math inline">\(p(V_i \mid U, R)\)</span> alırız, bunu ardı ardına
yapınca üstteki nihai dağılıma erisebileceğimizi biliyoruz. Tabii <span
class="math inline">\(R\)</span> verisine uyan <span
class="math inline">\(U,V\)</span> değerlerine erişmek demek, kavramsal
olarak bir dağılım elde etmektir, uygulama bağlamında mesela bir
kullanıcının daha not vermediği filme not vermek için (1) formülünü
direk kullanmak mümkündür, <span class="math inline">\(U,V\)</span> ile
düz matris çarpımı yaparak bir tahmin hesaplayabiliriz.</p>
<p>Yani bize, kullanıcılar için, <span class="math inline">\(p(U_i \mid
V, R)\)</span> formülasyonu lazım, bunu cebirsel olarak elde etmek için
tam genişletilmiş birleşik dağılımdan başlamalıyız.</p>
<p><span class="math display">\[
p(U)
=
\prod_{i=1}^{N}
\mathcal{N}(U_i \mid 0, \lambda_U^{-1} I)
\]</span></p>
<p>Film gizil vektörleri</p>
<p><span class="math display">\[
p(V)
=
\prod_{j=1}^{M}
\mathcal{N}(V_j \mid 0, \lambda_V^{-1} I)
\]</span></p>
<p>Olurluk</p>
<p>Gösterge <span class="math inline">\(I_{ij} = 1\)</span> eğer <span
class="math inline">\(R_{ij}\)</span> gözlemlenmis ise, yani not mevcut
ise, aksi halde 0 olarak tanımlanır.</p>
<p><span class="math display">\[
p(R \mid U, V)
=
\prod_{i=1}^{N}
\prod_{j=1}^{M}
\mathcal{N}
\left(
R_{ij}
\mid
\mu + U_i^\top V_j,
\sigma^2
\right)^{I_{ij}}
\]</span></p>
<p>Tam birleşik dağılım</p>
<p><span class="math display">\[
\begin{aligned}
p(U, V, R)
=
p(R \mid U, V) \cdot p(U) \cdot p(V)
=
\left[
\prod_{i=1}^{N}
\prod_{j=1}^{M}
\mathcal{N}
\left(
R_{ij}
\mid
\mu + U_i^\top V_j,
\sigma^2
\right)^{I_{ij}}
\right] \\
\quad \times
\left[
\prod_{i=1}^{N}
\mathcal{N}(U_i \mid 0, \lambda_U^{-1} I)
\right] \\
\quad \times
\left[
\prod_{j=1}^{M}
\mathcal{N}(V_j \mid 0, \lambda_V^{-1} I)
\right]
\end{aligned}
\]</span></p>
<p>Amaç: <span class="math inline">\(p(U_i \mid V, R)\)</span>
türetmek</p>
<p>Bayes kuralına göre (koşullu olasılığın tanımı):</p>
<p><span class="math display">\[
p(U_i \mid V, R)
=
\frac{p(U_i, V, R)}{p(V, R)}
\]</span></p>
<p>Not: Tek bir kullanıcı vektörü <span
class="math inline">\(U_i\)</span> üzerine koşullandırdığımızı
vurgulamak için <span class="math inline">\(p(U, V, R)\)</span> yerine
<span class="math inline">\(p(U_i, V, R)\)</span> yazıyoruz. Daha kesin
olarak:</p>
<p><span class="math display">\[
p(U_i \mid U_{-i}, V, R)
=
\frac{p(U_i, U_{-i}, V, R)}{p(U_{-i}, V, R)}
\]</span></p>
<p>burada <span class="math inline">\(U_{-i} = \{U_1, \dots, U_{i-1},
U_{i+1}, \dots, U_N\}\)</span>, <span class="math inline">\(U_i\)</span>
hariç tüm kullanıcı vektörlerini gösterir.</p>
<p>Payda <span class="math inline">\(U_i\)</span>’ye bağlı değildir, bu
nedenle onu bir normalizasyon sabiti olarak ele alabiliriz.</p>
<p><span class="math inline">\(U_i\)</span> içeren tüm terimleri izole
et</p>
<p>Adım 1: Birleşik dağılımı genişlet</p>
<p>Tam birleşik dağılımdan başlayarak:</p>
<p><span class="math display">\[
p(U_i, U_{-i}, V, R)
=
p(R \mid U_i, U_{-i}, V) \cdot p(U_i) \cdot p(U_{-i}) \cdot p(V)
\]</span></p>
<p><span class="math inline">\(U_i\)</span> üzerindeki önseli geri
kalanından ayır:</p>
<p><span class="math display">\[
p(U_i, U_{-i}, V, R)
=
\mathcal{N}(U_i \mid 0, \lambda_U^{-1} I)
\times
\left[
\prod_{k \neq i} \mathcal{N}(U_k \mid 0, \lambda_U^{-1} I)
\right]
\times
p(V)
\times
p(R \mid U_i, U_{-i}, V)
\qquad (1)
\]</span></p>
<p>Adım 2: Şimdi (1) içindeki <span class="math inline">\(p(R \mid U_i,
U_{-i}, V)\)</span> terimine dikkat et. Bunu nasıl genişletebiliriz?
İşte nasıl.</p>
<p><span class="math inline">\(U_i\)</span> içeren olabilirlik
terimlerini izole et</p>
<p>Olabilirlik tüm gözlemlenen derecelendirmeler üzerinden çarpanlara
ayrılır:</p>
<p><span class="math display">\[
p(R \mid U_i, U_{-i}, V)
=
\prod_{i=1}^{N}
\prod_{j=1}^{M}
\mathcal{N}
\left(
R_{ij}
\mid
\mu + U_i^\top V_j,
\sigma^2
\right)^{I_{ij}}
\]</span></p>
<p>Sadece kullanıcı <span class="math inline">\(i\)</span>’den gelen
derecelendirmeler <span class="math inline">\(U_i\)</span>’ye
bağlıdır.</p>
<p>Tanım: <span class="math display">\[
\Omega_i = \{ j \mid I_{ij} = 1 \}
\]</span> (kullanıcı <span class="math inline">\(i\)</span> tarafından
derecelendirilen filmlerin kümesi)</p>
<p>O zaman ayırabiliriz:</p>
<p><span class="math display">\[
p(R \mid U_i, U_{-i}, V)
=
\left[
\prod_{j \in \Omega_i}
\mathcal{N}
\left(
R_{ij}
\mid
\mu + U_i^\top V_j,
\sigma^2
\right)
\right]
\times
\left[
\prod_{k \neq i} \prod_{j=1}^M
\mathcal{N}
\left(
R_{kj}
\mid
\mu + U_k^\top V_j,
\sigma^2
\right)^{I_{kj}}
\right]
\qquad{(2)}
\]</span></p>
<p>İkinci çarpım <span class="math inline">\(U_i\)</span>’ye bağlı
değildir.</p>
<p>Bayes’i tekrar uygulayalım</p>
<p><span class="math display">\[
p(U_i \mid U_{-i}, V, R) = \frac{p(U_i, U_{-i}, V, R)}{p(U_{-i}, V, R)}
\]</span></p>
<p>Payda <span class="math inline">\(U_i\)</span>’ye bağlı olmadığından,
sadece bir normalizasyon sabitidir, dolayısıyla:</p>
<p><span class="math display">\[
p(U_i \mid U_{-i}, V, R) \propto p(U_i, U_{-i}, V, R)
\]</span></p>
<p>Sağ taraf (1)’dir,</p>
<p><span class="math display">\[
p(U_i, U_{-i}, V, R)
=
\mathcal{N}(U_i \mid 0, \lambda_U^{-1} I)
\times
\left[
\prod_{k \neq i} \mathcal{N}(U_k \mid 0, \lambda_U^{-1} I)
\right]
\times
p(V)
\times
p(R \mid U_i, U_{-i}, V)
\]</span></p>
<p>Ve onu (2) ile genişletiyoruz</p>
<p><span class="math display">\[
= \mathcal{N}(U_i \mid 0, \lambda_U^{-1} I)
\times
\left[
\prod_{k \neq i} \mathcal{N}(U_k \mid 0, \lambda_U^{-1} I)
\right]
\times
p(V)
\times
\left[
\prod_{j \in \Omega_i}
\mathcal{N}(R_{ij} \mid \mu + U_i^\top V_j, \sigma^2)
\right]
\times
\left[
\prod_{k \neq i} \prod_{j=1}^M
\mathcal{N}(R_{kj} \mid \mu + U_k^\top V_j, \sigma^2)^{I_{kj}}
\right]
\]</span></p>
<p>Ve şimdi bundan sadece <span class="math inline">\(U_i\)</span>’ye
bağlı terimleri topluyoruz,</p>
<p><span class="math display">\[
\begin{aligned}
p(U_i \mid U_{-i}, V, R)
&amp;\propto
\mathcal{N}(U_i \mid 0, \lambda_U^{-1} I)
\times
\prod_{j \in \Omega_i}
\mathcal{N}
\left(
R_{ij}
\mid
\mu + U_i^\top V_j,
\sigma^2
\right)
\end{aligned}
\]</span></p>
<p>Bu doğru olur, değil mi? Çünkü (1)’de <span
class="math inline">\(U_i\)</span>’ye bağlı olmayan terimler</p>
<ul>
<li><span class="math inline">\(\prod_{k \neq i} \mathcal{N}(U_k \mid 0,
\lambda_U^{-1} I)\)</span> — sadece diğer kullanıcılara bağlı</li>
<li><span class="math inline">\(p(V)\)</span> — sadece filmlere
bağlı</li>
<li><span class="math inline">\(p(R \mid U_i, U_{-i}, V, R)\)</span>’nin
çoğu — sadece kullanıcı <span class="math inline">\(i\)</span>’den gelen
derecelendirmeler <span class="math inline">\(U_i\)</span>’ye bağlı</li>
</ul>
<p><span class="math inline">\(U_i\)</span>’ye bağlı olan terimler</p>
<ul>
<li><span class="math inline">\(\mathcal{N}(U_i \mid 0, \lambda_U^{-1}
I)\)</span> — <span class="math inline">\(U_i\)</span> üzerindeki
önsel</li>
<li><span class="math inline">\(\prod_{j \in \Omega_i}
\mathcal{N}(R_{ij} \mid \mu + U_i^\top V_j, \sigma^2)\)</span> —
kullanıcı <span class="math inline">\(i\)</span>’nin
derecelendirmelerinin olabilirliği</li>
</ul>
<p><span class="math inline">\(p(V)\)</span> gibi terimler <span
class="math inline">\(U_i\)</span>’ye bağlı değildir, <span
class="math inline">\(U_i\)</span> ne olursa olsun aynıdırlar, bu
nedenle sadece normalizasyon sabitine katkıda bulunabilirler (eşitlikten
<span class="math inline">\(\propto\)</span>’ya geçişe dikkat edin),
dolayısıyla atılırlar.</p>
<p>Devam edelim. <span class="math inline">\(U_{-i}\)</span> üzerine
koşullandırdığımız için, şunu yazabiliriz:</p>
<p><span class="math display">\[
p(U_i \mid V, R)
\propto
\mathcal{N}(U_i \mid 0, \lambda_U^{-1} I)
\prod_{j \in \Omega_i}
\mathcal{N}
\left(
R_{ij}
\mid
\mu + U_i^\top V_j,
\sigma^2
\right)
\]</span></p>
<p>Not: Gibbs örneklemesinde, <span
class="math inline">\(U_i\)</span>’yi örneklediğimizde, diğer tüm
değişkenler (<span class="math inline">\(U_{-i}, V\)</span>) sabit
tutulur, bu nedenle gösterim basitliği için <span
class="math inline">\(U_{-i}\)</span> üzerine koşullandırmayı
atıyoruz.</p>
<p>Log-yoğunluğa dönüştür</p>
<p>Normalize edilmemiş yoğunluğun logaritmasını alarak:</p>
<p><span class="math display">\[
\begin{aligned}
\log p(U_i \mid V, R)
&amp;=
\log \mathcal{N}(U_i \mid 0, \lambda_U^{-1} I)
+
\sum_{j \in \Omega_i}
\log \mathcal{N}
\left(
R_{ij}
\mid
\mu + U_i^\top V_j,
\sigma^2
\right)
+ \text{const}
\end{aligned}
\]</span></p>
<p>Gauss log-yoğunluklarını genişlet:</p>
<p><span class="math display">\[
\log \mathcal{N}(U_i \mid 0, \lambda_U^{-1} I)
=
-\frac{1}{2} U_i^\top (\lambda_U I) U_i + \text{const}
=
-\frac{\lambda_U}{2} U_i^\top U_i + \text{const}
\]</span></p>
<p><span class="math display">\[
\log \mathcal{N}
\left(
R_{ij}
\mid
\mu + U_i^\top V_j,
\sigma^2
\right)
=
-\frac{1}{2\sigma^2}
\left(
R_{ij} - \mu - U_i^\top V_j
\right)^2
+ \text{const}
\]</span></p>
<p>Birleştir:</p>
<p><span class="math display">\[
\begin{aligned}
\log p(U_i \mid \cdot)
&amp;=
-\frac{\lambda_U}{2} U_i^\top U_i
\\
&amp;\quad
-\frac{1}{2\sigma^2}
\sum_{j \in \Omega_i}
\left(
R_{ij} - \mu - U_i^\top V_j
\right)^2
+ \text{const}
\end{aligned}
\]</span></p>
<p>Karesel terimi genişlet</p>
<p>Artığı tanımla:</p>
<p><span class="math display">\[
\tilde{R}_{ij} = R_{ij} - \mu
\]</span></p>
<p>O zaman:</p>
<p><span class="math display">\[
\left(\tilde{R}_{ij} - U_i^\top V_j\right)^2
=
\tilde{R}_{ij}^2
- 2 \tilde{R}_{ij} U_i^\top V_j
+ (U_i^\top V_j)^2
\]</span></p>
<p>Not: <span class="math inline">\((U_i^\top V_j)^2 = (U_i^\top
V_j)(V_j^\top U_i) = U_i^\top V_j V_j^\top U_i\)</span></p>
<p>Yani:</p>
<p><span class="math display">\[
\left(\tilde{R}_{ij} - U_i^\top V_j\right)^2
=
\tilde{R}_{ij}^2
- 2 \tilde{R}_{ij} U_i^\top V_j
+ U_i^\top V_j V_j^\top U_i
\]</span></p>
<p><span class="math inline">\(j \in \Omega_i\)</span> üzerinden
toplayarak:</p>
<p><span class="math display">\[
\sum_{j \in \Omega_i}
\left(\tilde{R}_{ij} - U_i^\top V_j\right)^2
=
\sum_{j \in \Omega_i} \tilde{R}_{ij}^2
- 2 U_i^\top \sum_{j \in \Omega_i} V_j \tilde{R}_{ij}
+ U_i^\top \left(\sum_{j \in \Omega_i} V_j V_j^\top\right) U_i
\]</span></p>
<p><span class="math inline">\(U_i\)</span> içindeki kuadratik ve lineer
terimleri topla</p>
<p>Log-yoğunluğa geri koyarak:</p>
<p><span class="math display">\[
\begin{aligned}
\log p(U_i \mid \cdot)
&amp;=
-\frac{\lambda_U}{2} U_i^\top U_i
-\frac{1}{2\sigma^2}
\left[
U_i^\top \left(\sum_{j \in \Omega_i} V_j V_j^\top\right) U_i
- 2 U_i^\top \sum_{j \in \Omega_i} V_j \tilde{R}_{ij}
+ \sum_{j \in \Omega_i} \tilde{R}_{ij}^2
\right]
+ \text{const}
\end{aligned}
\]</span></p>
<p>Kuadratik terimleri grupla:</p>
<p><span class="math display">\[
-\frac{\lambda_U}{2} U_i^\top U_i
-\frac{1}{2\sigma^2} U_i^\top \left(\sum_{j \in \Omega_i} V_j
V_j^\top\right) U_i
=
-\frac{1}{2} U_i^\top
\left(
\lambda_U I + \frac{1}{\sigma^2} \sum_{j \in \Omega_i} V_j V_j^\top
\right)
U_i
\]</span></p>
<p>Lineer terimleri grupla:</p>
<p><span class="math display">\[
\frac{1}{\sigma^2} U_i^\top \sum_{j \in \Omega_i} V_j \tilde{R}_{ij}
\]</span></p>
<p>Sabit terim <span class="math inline">\(\sum_{j \in \Omega_i}
\tilde{R}_{ij}^2\)</span>, <span class="math inline">\(U_i\)</span>’ye
bağlı değildir.</p>
<p>Gauss sonsalı tanımlayalım. Şimdi elimizde:</p>
<p><span class="math display">\[
\log p(U_i \mid \cdot)
=
-\frac{1}{2} U_i^\top \Sigma_i^{-1} U_i
+
U_i^\top \Sigma_i^{-1} \mu_i
+ \text{const}
\]</span></p>
<p>Bu, çok değişkenli bir Gauss’un kanonik formudur:</p>
<p><span class="math display">\[
\log \mathcal{N}(x \mid \mu, \Sigma)
=
-\frac{1}{2}(x - \mu)^\top \Sigma^{-1} (x - \mu) + \text{const}
=
-\frac{1}{2} x^\top \Sigma^{-1} x + x^\top \Sigma^{-1} \mu +
\text{const}
\]</span></p>
<p>Kesinliği (kovaryansın tersini) tanımla:</p>
<p><span class="math display">\[
\Sigma_i^{-1}
=
\lambda_U I + \frac{1}{\sigma^2} \sum_{j \in \Omega_i} V_j V_j^\top
\]</span></p>
<p>Ortalamayı tanımla (lineer terimden), <span
class="math inline">\(U_i^\top \Sigma_i^{-1} \mu_i = \frac{1}{\sigma^2}
U_i^\top \sum_{j \in \Omega_i} V_j \tilde{R}_{ij}\)</span>’den:</p>
<p><span class="math display">\[
\Sigma_i^{-1} \mu_i
=
\frac{1}{\sigma^2} \sum_{j \in \Omega_i} V_j \tilde{R}_{ij}
\]</span></p>
<p>Dolayısıyla:</p>
<p><span class="math display">\[
\mu_i
=
\Sigma_i
\left(
\frac{1}{\sigma^2}
\sum_{j \in \Omega_i}
V_j
\left(
R_{ij} - \mu
\right)
\right)
\]</span></p>
<p>Nihai sonuç:</p>
<p><span class="math display">\[
p(U_i \mid V, R)
=
\mathcal{N}(U_i \mid \mu_i, \Sigma_i)
\]</span></p>
<p>Özet: <span class="math inline">\(U_i\)</span> için koşullu
sonsal</p>
<p><span class="math display">\[
\begin{aligned}
\Sigma_i^{-1}
&amp;=
\lambda_U I + \frac{1}{\sigma^2} \sum_{j \in \Omega_i} V_j V_j^\top
\\[1em]
\mu_i
&amp;=
\Sigma_i
\left(
\frac{1}{\sigma^2}
\sum_{j \in \Omega_i}
V_j
(R_{ij} - \mu )
\right)
\end{aligned}
\]</span></p>
<p>burada <span class="math inline">\(\Omega_i = \{j : I_{ij} =
1\}\)</span>, kullanıcı <span class="math inline">\(i\)</span>
tarafından derecelendirilen filmlerin kümesidir.</p>
<p>Simetri: <span class="math inline">\(V_j\)</span> için koşullu
sonsal</p>
<p>Simetri ile (kullanıcı/film indekslerini değiştirerek):</p>
<p><span class="math display">\[
p(V_j \mid U, R) = \mathcal{N}(V_j \mid \hat{\mu}_j, \hat{\Sigma}_j)
\]</span></p>
<p>burada:</p>
<p><span class="math display">\[
\begin{aligned}
\hat{\Sigma}_j^{-1}
&amp;=
\lambda_V I + \frac{1}{\sigma^2} \sum_{i \in \Omega_j} U_i U_i^\top
\\[1em]
\hat{\mu}_j
&amp;=
\hat{\Sigma}_j
\left(
\frac{1}{\sigma^2}
\sum_{i \in \Omega_j}
U_i
(R_{ij} - \mu )
\right)
\end{aligned}
\]</span></p>
<p>burada <span class="math inline">\(\Omega_j = \{i : I_{ij} =
1\}\)</span>, film <span class="math inline">\(j\)</span>’yi
derecelendiren kullanıcıların kümesidir.</p>
<p>Gibbs örneklemesi neden işe yarar</p>
<ul>
<li>Tüm koşullu sonsallar Gauss’tur (kapalı form)</li>
<li>Örnekleme, normalizasyon sabitlerini hesaplamayı gerektirmez</li>
<li>Her güncelleme sadece yerel veriyi kullanır (o kullanıcı/filmi
içeren derecelendirmeler)</li>
<li>Tekrarlı taramalar bilgiyi gizil uzayda global olarak yayar</li>
<li>Hafif koşullar altında gerçek sonsala yakınsama garantilidir</li>
</ul>
<p>Gibbs Örnekleme Algoritması</p>
<p>Başlat: <span class="math inline">\(U^{(0)}, V^{(0)}\)</span>’ı
rastgele değerlere</p>
<p><span class="math inline">\(t = 1, 2, \dots, T\)</span> için:</p>
<ol type="1">
<li>Her kullanıcı <span class="math inline">\(i = 1, \dots, N\)</span>
için:
<ul>
<li><span class="math inline">\(U_i^{(t)} \sim p(U_i \mid V^{(t-1)},
R)\)</span> örnekle</li>
</ul></li>
<li>Her film <span class="math inline">\(j = 1, \dots, M\)</span> için:
<ul>
<li><span class="math inline">\(V_j^{(t)} \sim p(V_j \mid U^{(t)},
R)\)</span> örnekle</li>
</ul></li>
</ol>
<p>Isınma (burn-in) sonrasında, tahmin için örnekleri kullan.</p>
<p><span class="math inline">\(R_{ij}\)</span> hem <span
class="math inline">\(\epsilon_{ij}\)</span> nedeniyle hem de <span
class="math inline">\(U_i, V_j\)</span>’nin kendilerinin önsel
dağılımlara sahip rastgele değişkenler olması nedeniyle bir rastgele
değişkendir.</p>
<h3 id="genel-sorular">Genel Sorular</h3>
<p>Sistemdeki rasgelelik nereden geliyor? <span
class="math inline">\(U,V\)</span> rasgele değişken midirler? Burada
aslında iki seviye rastgelelik var:</p>
<p>1] Gözlem seviyesi rastgelelik (<span
class="math inline">\(\epsilon_{ij}\)</span>’den)</p>
<p><span class="math inline">\(U_i, V_j\)</span>’nin sabit değerleri
verildiğinde, derecelendirme <span class="math inline">\(R_{ij}\)</span>
hala rastgeledir çünkü:</p>
<p><span class="math display">\[
R_{ij} \mid U_i, V_j \sim \mathcal{N}(\mu + U_i^\top V_j, \sigma^2)
\]</span></p>
<p>Bu, ölçüm gürültüsünü veya derecelendirme sürecindeki doğal
stokastikliği temsil eder. Gerçek gizil özellikleri bilsek bile, bir
kullanıcı aynı filmi farklı günlerde farklı derecelendirebilir.</p>
<p>2] Parametre seviyesi rastgelelik (<span class="math inline">\(U,
V\)</span> üzerindeki önsellerden)</p>
<p>Bayesçi çerçevede, <span class="math inline">\(U_i, V_j\)</span>
sabit parametreler değil, önsel dağılımlara sahip rastgele
değişkenlerdir:</p>
<p><span class="math display">\[
\begin{aligned}
U_i &amp;\sim \mathcal{N}(0, \lambda_U^{-1} I) \\
V_j &amp;\sim \mathcal{N}(0, \lambda_V^{-1} I)
\end{aligned}
\]</span></p>
<p>Dolayısıyla herhangi bir veri gözlemlemeden önce, <span
class="math inline">\(R_{ij}\)</span> rastgeledir çünkü parametrelerin
kendileri rastgeledir.</p>
<p>Bayesçi perspektiften, <span
class="math inline">\(R_{ij}\)</span>’nin koşulsuz dağılımı (hiçbir şey
gözlemlemeden önce):</p>
<p><span class="math display">\[
p(R_{ij}) = \int p(R_{ij} \mid U_i, V_j) \cdot p(U_i, V_j) \, dU_i \,
dV_j
\]</span></p>
<p>Bu, her iki rastgelelik kaynağı üzerinden integral alır: -
Olabilirlik <span class="math inline">\(p(R_{ij} \mid U_i,
V_j)\)</span>, <span class="math inline">\(\epsilon_{ij}\)</span>
gürültüsünü yakalar - Önsel <span class="math inline">\(p(U_i,
V_j)\)</span>, parametreler hakkındaki belirsizliğimizi yakalar</p>
<p>Pratikte:</p>
<p>Gibbs örneklemesi yaptığımızda:</p>
<ul>
<li>Bazı derecelendirmeleri <span class="math inline">\(R_{ij}\)</span>
gözlemliyoruz (onları sabit veri olarak ele alıyoruz)</li>
<li>Bu gözlemler verildiğinde <span class="math inline">\(U,
V\)</span>’nin sonsal dağılımını çıkarıyoruz</li>
<li><span class="math inline">\(\epsilon_{ij}\)</span> terimleri
olabilirlik yoluyla örtük olarak “integral alınarak çıkarılır”</li>
</ul>
<p>Yani model şunu söyler:</p>
<ul>
<li>Veri görmeden önce: Her şey (<span class="math inline">\(U, V,
R\)</span>) rastgeledir</li>
<li>Veri gördükten sonra: Gözlemlenen <span
class="math inline">\(R_{ij}\)</span> üzerine koşullandırır ve <span
class="math inline">\(U, V\)</span> için dağılımları çıkarırız</li>
<li>Tahmin için: Yeni <span class="math inline">\(R_{ij}^*\)</span>’yi
tahmin etmek için sonsal örneklerini kullanırız, bu hem parametre
belirsizliğini hem de <span class="math inline">\(\epsilon\)</span>
gürültüsünü içerir</li>
</ul>
<h3 id="yeni-kullanıcı">Yeni Kullanıcı</h3>
<p>Sistemi eğitip <span class="math inline">\(U,V\)</span> elde ettikten
sonra mesela mevcut 100’uncu kullanıcı için tavsiye üretmek basit
olurdu. <span class="math inline">\(U\)</span> matrisinin 100’uncu
satırına gideriz, bu satır <span class="math inline">\(1 \times
K\)</span> boyutundadır, sonra o satır ile <span
class="math inline">\(V\)</span> matrisini çarparız, <span
class="math inline">\(1 \times K\)</span> çarpı <span
class="math inline">\(K \times M\)</span> bize <span
class="math inline">\(1 \times M\)</span> boyutunda bir vektör veriyor,
<span class="math inline">\(\mu\)</span> ile toplayınca tüm filmlere
verilmiş tahmini notlar böylece hesaplanmış olur.</p>
<p>Fakat ya eğer tavsiye üretmek istediğimiz kullanıcı yeni bir
kullanıcı ise, yani verisi eğitim fazına dahil edilmemiş bir kişi ise?
Bu durumda bu kişinin <span class="math inline">\(U\)</span> matrisinde
satırı yoktur. O zaman bu kişi <span class="math inline">\(U\)</span>
matrisinde olsaydı nasıl bir satır verisi, diyelim <span
class="math inline">\(u_{ben}\)</span>’e, sahip olurdu sorusunu
cevaplamak gerekir, yani bu amaç için bir hesap yöntemi bulmak
gerekir.</p>
<p>Şöyle bir yaklaşım olabilir, öyle bir <span
class="math inline">\(u_{\textrm{ben}}\)</span> bul ki onun <span
class="math inline">\(V\)</span> ile çarpımı artı global ortalama
kullanıcının oylamış olduğu filmler için verilen nota yakın bir değer
versin. Bu bir tür regresyon hesabı olabilir aslında. Herhangi bir <span
class="math inline">\(j\)</span> filmi için</p>
<p><span class="math display">\[
\hat{r}_j = \mu + u_{ben}^T v_j
\]</span></p>
<p>diyebiliriz. En iyi <span class="math inline">\(u_{ben}\)</span>
vektörünü bulmak için karesi alınmış hataların toplamını minimize
edebiliriz, bu hatalar benim gerçekten verdiğim notlar <span
class="math inline">\(r_j\)</span> ile tahmin edilen notlar <span
class="math inline">\(\hat{r}_j\)</span> arasında olur, bir de
regülarize edici terim ekleriz ki aşırı öğrenme (overfitting)
engellenmiş olsun. Yani amac <span
class="math inline">\(J(u_{ben})\)</span>’nin minizasyonu.</p>
<p><span class="math display">\[
J(u_{self}) = \sum_{j \in \Omega_j} (r_j - (\mu + u_{self}^T
v_j))^2 + \lambda_U \|u_{self}\|^2
\]</span></p>
<p>Basitleştirmek için global ortalamayı notlardan çıkartabiliriz, <span
class="math inline">\(y_j = r_j - \mu\)</span>. Formül şöyle olur,</p>
<p><span class="math display">\[
J(u_{self}) = \sum_{j \in \text{Rated}} (y_j - u_{self}^T v_j)^2 +
\lambda_U \|u_{self}\|^2
\]</span></p>
<p>Formülü matrisler kullanacak şekilde adapte edebiliriz, diyelim ki
<span class="math inline">\(V\)</span>’nin alt kümesi olan bir <span
class="math inline">\(V_{rated}\)</span> yarattım bu matris <span
class="math inline">\(V\)</span>’nin benim oy verdiğim satırlarını
içeriyor, eğer <span class="math inline">\(B\)</span> tane film
oylamışsam, <span class="math inline">\(V_{rated}\)</span> matrisi <span
class="math inline">\(B \times K\)</span> olur.</p>
<p><span class="math display">\[
J(u_{ben}) = \|y - V_{rated}u_{self}\|^2 + \lambda_U u_{ben}^T u_{ben}
\]</span></p>
<p><span class="math display">\[
J(u_{ben}) = (y - V_{rated}u_{ben})^T (y - V_{rated}u_{ben}) + \lambda_U
u_{ben}^T u_{ben}
\]</span></p>
<p>Şu terimi açalım, <span class="math inline">\((y -
V_{rated}u_{self})^T (y - V_{rated}u_{self})\)</span>,</p>
<p><span class="math display">\[
J(u_{self}) = (y^T - u_{self}^T V_{rated}^T) (y - V_{rated}u_{self})
+ \lambda_U u_{self}^T u_{self}
\]</span></p>
<p>Çarpımı yapalım,</p>
<p><span class="math display">\[
J(u_{self}) = y^T y - y^T V_{rated} u_{self} - u_{self}^T
V_{rated}^T y + u_{self}^T V_{rated}^T V_{rated} u_{self} + \lambda_U
u_{self}^T u_{self}
\]</span></p>
<p>Üstte görülen <span class="math inline">\(y^T V_{rated}
u_{self}\)</span> bir tek sayı olduğu için kendi devriğine eşittir, o
yüzden ortadaki terimleri birleştirebiliriz,</p>
<p><span class="math display">\[
J(u_{self}) = y^T y - 2u_{self}^T V_{rated}^T y + u_{self}^T
V_{rated}^T V_{rated} u_{self} + \lambda_U u_{self}^T u_{self}
\]</span></p>
<p>Şimdi <span class="math inline">\(J(u_{ben})\)</span>’in <span
class="math inline">\(u_{self}\)</span>’a göre türevini alalım, ve
minizasyon için sıfıra eşitleyelim. Matris Calculus kurallarından
biliyoruz ki</p>
<p><span class="math inline">\(\frac{\partial}{\partial u} (u^T A u) =
2Au\)</span> (eger <span class="math inline">\(A\)</span> simetrik
ise)</p>
<p><span class="math inline">\(\frac{\partial}{\partial u} (u^T b) =
b\)</span></p>
<p>O zaman</p>
<p><span class="math display">\[
\frac{\partial J}{\partial u_{self}} =
0 - 2V_{rated}^T y + 2V_{rated}^T V_{rated} u_{self} + 2\lambda_U
u_{self} = 0
\]</span></p>
<p>2 ile bölelim ve <span class="math inline">\(u_{ben}\)</span> sol
tarafta kalacak şekilde tekrar düzenleyelim,</p>
<p><span class="math display">\[
V_{rated}^T V_{rated} u_{self} + \lambda_U u_{self} = V_{rated}^T
y\]</span></p>
<p><span class="math inline">\(u_{self}\)</span>’i dışarı çekelim,</p>
<p><span class="math display">\[
(V_{rated}^T V_{rated} + \lambda_U I) u_{self} = V_{rated}^T y
\]</span></p>
<p><span class="math display">\[
u_{self} = (V_{rated}^T V_{rated} + \lambda_U I)^{-1} V_{rated}^T
y\]</span></p>
<p><span class="math display">\[(V_{rated}^T V_{rated} + \lambda_U
I)u_{self} = V_{rated}^T y\]</span></p>
<p><span class="math inline">\(u_{ben}\)</span> için çözelim,</p>
<p><span class="math display">\[
u_{ben} = (V_{rated}^T V_{rated} + \lambda_U I)^{-1} V_{rated}^T y
\]</span></p>
<p>Üstteki bir Sırt (Ridge) Regresyon tanımıdır [5].</p>
<h3 id="kodlama">Kodlama</h3>
<p>Ekteki kodlar arasında <code>sng_bpmf.py</code> dosyası tek islemci
ile Gibbs örneklemesi yapar, <code>par_bpmf.py</code> ise aynı işlemi
paralel şekilde yapar. Detaylar için kodlara bakılabilir. Veri olarak
[2],[3] kullanmak mümkün, bu verilerin dizin olarak
<code>/opt/Downloads</code> altında olduğunu farz ediyoruz. Verinin
hazırlanması için <code>pmf/prep1.py</code>, <code>pmf/prep2.py</code>,
<code>pmf/prep3.py</code>, <code>pmf/prep4.py</code> script’leri o
sırada işletilmeli. Bu scriptler ile kullanıcı ve film kimlikleri tekrar
üretiliyor, tüm film ve kullanıcılar sıfırdan başlayıp birer birer
artacak şekilde tekrar kimlikleniyor. Bunun yapılmasının sebebi bu
kimlik değerlerinin <span class="math inline">\(U,V\)</span> üzerinde
direk satır erişimi için kullanılabilmesi.. Daha sonra
<code>user_movie.txt</code> ve <code>movie_user.txt</code> dosyaları
yaratılıyor, bu dosyalarda her satır, mesela <code>user_movie.txt</code>
için diyelim, satır başında kullanıcı kimliği ardından aynı satırda o
kullanıcının verdiği film notlarını içerir. Bu şekilde tek bir satır
okuması ile o kullanıcı hakkında tüm bilgileri alabilmiş oluyoruz
(filmler için benzer şekilde). Movielens verisine bakanlar farketmiş
olabilir, oradaki <code>ratings.csv</code> içinde bu tür bir satırsal
temsil yoktur.</p>
<p>Gibbs işlemi bitince sonuçlar, sonsal dağılımlar, bir
<code>.npz</code> dosyasına yazılır, ve <code>recom.py</code> koduyla bu
çıktılar kullanılarak taviyeler üretilebilir. Tavsiye kodu kullanıcının
beğendiği filmleri, notlar okumak için su anda
<code>~/Documents/kod/movpicks.csv</code> dosyasını kullanıyor, burada
benim kendi seçimlerim var, mesela</p>
<pre><code>movie,rating
..
Swordfish (2001),5
Dunkirk (2017),2
Tombstone (1993),5
..</code></pre>
<p>diye notlar vermişim. Bu notlar kullanılarak ve üstteki matematik
kullanılarak tavsiyeler üretiliyor.</p>
<p>Paralellik</p>
<p>Üstte görülen Gibbs örnekleme algoritmasında dikkat edersek
kullanıcılar için bir döngü var, onun içinde kullanıcı 1,2,3.. diye
giden ve o kullanıcıların <span class="math inline">\(U\)</span>
satırlarını örnekleyen (yani mevcut satırın üzerine yazan) bir yaklaşım
var. Bu yaklaşıma göre kullanıcıların satırlarının örneklenmesi
birbirinden bağımsız, yani kullanıcı 100 örneklenmesi için kullanıcı
99’un işinin bitmiş olmasını beklemiyoruz. Bu demektir ki örneklem
işlemi kullanıcı ve film bazında paralel şekilde işletilebilir.</p>
<p>Kullanıcılar için 10 tane paralel süreç başlatırız, bu süreçler
kullanıcıları ve onun verdiği notları 10 parçaya böler, her biri kendi
içinde örneklem işini yapar, kendi <span
class="math inline">\(U\)</span> parçasını üretir, tümü bitince <span
class="math inline">\(U\)</span> parçaları birleştirilip yeni <span
class="math inline">\(U\)</span> oluşturulur ve filmler için aynı işlem
yapılır, 10 parçaya bölünür, orneklenip birlestirilir vs. Bu bir dongu
(iteration) olur.</p>
<p>Bölme işlemini <code>user_movie.txt</code> ve
<code>movie_user.txt</code> üzerinden basit bir şekilde yapabiliriz,
kullanıcı ve film kimlik değerleri artık direk <span
class="math inline">\(U,V\)</span> satırlarına tekabül ettiği için
erişimde zorluk çıkmaz. Her süreç kendi verisine odaklanır, ama <span
class="math inline">\(U,V\)</span> verisinin her süreç içinde
kopyalanması problem değil, çünkü bunlar nispeten ufak matrislerdir,
bellek için yük oluşturmazlar.</p>
<p>Kodlar</p>
<p><a href="sng_bpmf.py">sng_bpmf.py</a>, <a
href="par_bpmf.py">par_bpmf.py</a>, <a href="prep1.py">prep1.py</a>, <a
href="prep2.py">prep2.py</a>, <a href="prep3.py">prep3.py</a>, <a
href="prep4.py">prep4.py</a>, <a href="recom.py">recom.py</a>, <a
href="rmse_mypicks.py">rmse_mypicks.py</a></p>
<p>Kaynaklar</p>
<p>[1] Salakhudtinov,
<a href="https://www.cs.toronto.edu/~amnih/papers/bpmf.pdf">Bayesian
Probabilistic Matrix Factorization using Markov Chain Monte
Carlo</a></p>
<p>[2] Netflix,
<a href="https://grouplens.org/datasets/movielens/latest/">MovieLens
Small (ml-latest-small)</a></p>
<p>[3] Netflix,
<a href="https://grouplens.org/datasets/movielens/32m/">MovieLens 32M,
(ml-32m)</a></p>
<p>[4] Anton Gerber Sort,
<a href="https://research-api.cbs.dk/ws/portalfiles/portal/98731723/1641765_Thesis_Anton_Sort.pdf">Probabilistic
Matrix Factorisation in Collaborative Filtering, Thesis</a></p>
<p>[5] Bayramli,
<a href="../stat_120_regular/stat_120_regular.html">Regresyon, Ridge,
Lasso, Çapraz Sağlama, Regülarize Etmek</a></p>
<p>
  <a href="..">Yukarı</a>
</p>
</body>
</html>
