<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
    <script type="text/x-mathjax-config">
    MathJax.Hub.Register.StartupHook("TeX Jax Ready",function () {
      MathJax.Hub.Insert(MathJax.InputJax.TeX.Definitions.macros,{
        cancel: ["Extension","cancel"], cancelto: ["Extension","cancel"]
      });
    });
    </script>  
   
  <title>Markov Zincirleri (Markov Chains)</title>
  <style type="text/css">code{white-space: pre;}</style>
  <style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
  </style>
  <script
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS_HTML-full"
  type="text/javascript"></script>
</head>
<body>
<div id="header">
</div>
<h1 id="markov-zincirleri-markov-chains">Markov Zincirleri (Markov
Chains)</h1>
<p>Markov Zincirlerinde (MZ) <span class="math inline">\(i\)</span>
konumundan <span class="math inline">\(j\)</span> konumuna geçiş
olasılığını, <span class="math inline">\(P_{ij}\)</span> gösterir.
Farklı şekile <span class="math inline">\(P(X_{n+1} = j | X_{n} =
i)\)</span> olarak açılabilir. Açılımdan görüleceği üzere bir MZ sonraki
adıma geçiş olasılığı için sadece bir önceki adıma bakar. Bu tür
önce/sonra yapısındaki iki boyutlu hal, çok rahat bir şekilde matrise
çevirilebilir. Önceki konum satırlar, sonraki konum kolonlar olarak
temsil edilir mesela.</p>
<p>Örnek</p>
<p>Bir sonraki günde yağmur yağmayacağını bir MZ olarak tasarlayalım [1,
sf 196]. Bir sonraki günde yağmur yağmayacağını sadece bugün etkiliyor
olsun. Eğer bugün yağmur yağıyorsa yarın yağmur yağması 0.7, eğer bugün
yağmıyor ise yarın yağması 0.4. MZ şöyle</p>
<p><span class="math display">\[
P =
\left[\begin{array}{cc}
0.7 &amp; 0.3 \\
0.4 &amp; 0.6
\end{array}\right]
\]</span></p>
<p>Geçiş olasılıklarından bahsettiğimize göre ve elimizde sınırlı /
belli sayıda konum (state) olduğu için, bir MZ’nin her satırındaki
olasılıkların toplamı tabii ki 1’e eşit olmalıdır.</p>
<p>MZ’lerin ilginç bir özelliği <span class="math inline">\(n\)</span>
adım sonra <span class="math inline">\(i,j\)</span> geçişinin <span
class="math inline">\(P_{i,j}^n\)</span> hesabıyla yapılabilmesidir.
Yani <span class="math inline">\(P\)</span>’yi <span
class="math inline">\(n\)</span> defa kendisiyle çarpıp <span
class="math inline">\(i,j\)</span> indislerindeki öğeye bakarsak <span
class="math inline">\(n\)</span> adım sonrasını görüyoruz. İspat altta
[1, sf. 195].</p>
<p>Bulmak istediğimiz <span class="math inline">\(n\)</span> adım
sonrası geçiş olasılıkları, yani <span class="math inline">\(i\)</span>
adımında olan sürecin <span class="math inline">\(n\)</span> adım sonra
<span class="math inline">\(j\)</span> adımında olma olasılığı.
Aradığımız,</p>
<p><span class="math display">\[
P_{ij}^n = P ( X_{n+k} = j | X_k = i ), \quad n \ge 0, i,j \ge 0
\]</span></p>
<p>Tabii ki <span class="math inline">\(P_{ij}^1 = P_{ij}\)</span>.
Chapman-Kolmogorov denklemleri bu n-adım geçişlerini hesaplamak için
bize bir yöntem sağlıyoar. Bu denklemler,</p>
<p><span class="math display">\[
P_{ij}^{n+m} = \sum_{k=0}^{\infty} P_{ik}^n P_{kj}^m,
\quad \forall n,m \ge 0, \quad \forall i,j
\qquad (1)
\]</span></p>
<p><span class="math inline">\(P_{ij}^{n+m}\)</span> formülü şunu
söylüyor, <span class="math inline">\(i\)</span>’de başlayan süreç <span
class="math inline">\(n+m\)</span> geçiş sonrası <span
class="math inline">\(j\)</span>’e varacak, ve geçtiği yol onu <span
class="math inline">\(n\)</span> anında <span
class="math inline">\(k\)</span>’den geçirecek. O zaman tüm bu geçiş
noktaları <span class="math inline">\(k\)</span>’ler üzerinden bir
toplam alırsak sürecin <span class="math inline">\(n+m\)</span> adım
sonrası <span class="math inline">\(j\)</span>’de olma olasılığını elde
etmiş oluyoruz.</p>
<p>Formel olarak</p>
<p><span class="math display">\[
P_{ij}^{n+m} = P(X_{n+m} = j | X_0 = i )
\]</span></p>
<p>söylenmiş oluyor. Üstteki olasılık hesabına / birleşik olasılığa
<span class="math inline">\(k\)</span>’den geçme aksiyonunu ekleyip aynı
anda tüm <span class="math inline">\(k\)</span>’ler üzerinden toplam
alırsak (entegre edip çıkartma tekniği -integrate out-) hiçbir şey
değiştirmemiş oluruz,</p>
<p><span class="math display">\[
= \sum_{k=0}^{\infty} P(X_{n+m} = j, X_n = k | X_0 = i )
\]</span></p>
<p><span class="math display">\[
= \sum_{k=0}^{\infty} P(X_{n+m} = j, X_n = k, X_0 = i )
P(X_n=k|X_0=i)
\]</span></p>
<p>Üstteki ifade diyor ki,</p>
<p><span class="math display">\[
P_{ij}^{n+m} = \sum_{k=0}^{\infty} P_{kj}^m P_{ik}^n
\]</span></p>
<p>Ayrıca dikkat edersek (1)’deki tarif</p>
<p><span class="math display">\[
P^{n+m} = P^n \cdot P^m
\]</span></p>
<p>işlemini ima ediyor. Nokta işareti çarpım işlemi, çünkü hatırlarsak
matris çarpımının tanımı şöyleydi; elimizde N x M boyutunda <span
class="math inline">\(A\)</span> matrisi var, <span
class="math inline">\(B\)</span> ise M x K boyutunda olsun, her ikisinin
<span class="math inline">\(i\)</span> satırı <span
class="math inline">\(j\)</span> kolonundaki öğesi <span
class="math inline">\(a_{ij}\)</span>, <span
class="math inline">\(b_{ij}\)</span> ise, <span class="math inline">\(A
\cdot B\)</span> çarpımı bir N x K matrisidir, bu matrisin <span
class="math inline">\(i,j\)</span> öğesi <span
class="math inline">\(\sum_{k=1}^{M} a_{ik}b_{kj}\)</span> ile verilir.
Toplamın üst sınırı sonsuz değil <span class="math inline">\(M\)</span>
fakat sonsuzluk üst sınırı genel bir formül için tanımlanmış zaten.</p>
<p>İlk örneğe dönersek, eğer bugün yağmur yağıyorsa 4 gün sonra yağmur
yağma olasılığı nedir?</p>
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy.linalg <span class="im">as</span> lin</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>P <span class="op">=</span> np.array([[<span class="fl">0.7</span>,<span class="fl">0.3</span>],[<span class="fl">0.4</span>,<span class="fl">0.6</span>]])</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>P4 <span class="op">=</span> lin.matrix_power(P,<span class="dv">4</span>)</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (P4)</span></code></pre></div>
<pre><code>[[ 0.5749  0.4251]
 [ 0.5668  0.4332]]</code></pre>
<p>Aradığımız geçiş için kordinat 0,0’a bakıyoruz ve sonuç 0.5749. Numpy
<code>matrix_power</code> bir matrisi istediğimiz kadar kendisiyle
çarpmamızı sağlıyor.</p>
<p>Durağan Dağılım (Stationary Distribution)</p>
<p>Eğer yağmur örneğindeki matrisi çarpmaya devam edersek, mesela 8 kere
kendisiyle çarpsak sonuç ne olurdu?</p>
<div class="sourceCode" id="cb3"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy.linalg <span class="im">as</span> lin</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>P <span class="op">=</span> np.array([[<span class="fl">0.7</span>,<span class="fl">0.3</span>],[<span class="fl">0.4</span>,<span class="fl">0.6</span>]])</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>P8 <span class="op">=</span> lin.matrix_power(P,<span class="dv">8</span>)</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (P8)</span></code></pre></div>
<pre><code>[[ 0.57145669  0.42854331]
 [ 0.57139108  0.42860892]]</code></pre>
<p>Dikkat edilirse, her satır bir değere yaklaşmaya başladı. Bu değer
MZ’nin durağan dağılımıdır, belli koşullara uyan her MZ’nin böyle bir
durağan dağılımı vardır. Bu koşullar MZ’nin periyodik olmayan
(aperiodic) ve tekrar eden (recurrent) olmasıdır. Bu şartlar çok “özel’’
şartlar değildir aslında, daha çok”normal’’ bir MZ’yi tarif ediyor
diyebiliriz. Tüm konumları tekrar eden yapmak kolaydır, MZ tek bağlı
(singly connected) hale getirilir, yani her konumdan her diğer konuma
bir geçiş olur, ve periyodik olmaması için ise MZ’de olmadığı zamanlarda
bir konumdan kendisine geçiş sağlanır (az bir gürültü üzerinden).</p>
<p>Neyse, matematiksel olarak durağanlık şu denklemi ortaya
çıkartır,</p>
<p><span class="math display">\[ \pi = \pi P \]</span></p>
<p>Burada durağan dağılım <span class="math inline">\(\pi\)</span>’dir.
Bu denklem tanıdık geliyor mu? Devriğini alarak şöyle gösterelim, belki
daha iyi tanınır,</p>
<p><span class="math display">\[ P^T\pi^T = \pi^T \]</span></p>
<p>Bir şey daha ekleyelim,</p>
<p><span class="math display">\[ P^T\pi^T = 1 \cdot \pi^T \]</span></p>
<p>Özdeğer/vektör formuna benzemiyor mu? Evet. Bu form,</p>
<p><span class="math display">\[ Ax = \lambda x \]</span></p>
<p>MZ denklemi şunu söylüyor, 1 değerindeki özdeğere ait özvektör bir
MZ’nin durağan dağılımıdır. Bu arada, MZ geçiş matrisi <span
class="math inline">\(P\)</span>’nin en büyük özdeğerinin her zaman 1
olduğunu biliyoruz (çünkü üstteki tarif ettiğimiz özel şartlara sahip
olan türden matrisler böyle özdeğerlere sahip olmalı). Bu durumda en
büyük özdeğere ait özvektörü hesaplamak yeterli olacaktır. Bunu yapmayı
zaten [2]’de öğrenmiştik, üst metot (power method) sayesinde bu hesap
kolayca yapılabiliyor.</p>
<p>MZ kavramının ilginç bir uygulaması için [3] yazısına
bakılabilir.</p>
<p>Çizitler ve Matrisler</p>
<p>Markov matrisleri kavramını biraz daha ilerletebiliriz. Üstteki
Markov örneği için mesela alttaki çizit gösterilebilir,</p>
<p><img src="stat_093_mc_01.png" /></p>
<p>Örnekteki durumda 1’den başlayınca hangi olasılıkla hangi diğer
düğüme atlandığı görülebiliyor. Bu geçiş olasılıklarına göre zar atılıp
geçiş yapılabilir. Markov matrisleri bu bağlamda kendi içindeki
geçişleri gösteriyor, sürekli 1,2,3,.. düğümleri arasında gidip
geliyoruz. 1’den 3’e geçiş için 1’inci satır 3’üncü kolona bakıyoruz,
bir sonraki geçiş için <span class="math inline">\(P^2\)</span>’nin
3’üncü satırına bakıyoruz.</p>
<p>Bu kavramı daha da genişletebiliriz. Bir çizitin katman katman,
farklı blokları arasındaki geçişleri de ayrı matris çarpımları olarak
gösterebiliriz.</p>
<p><img src="stat_093_mc_02.png" /></p>
<p>Mesela her X bölümündeki konumlardan Y bölümündeki konumlara
geçişleri, oradan Z konumlarına geçişleri matris olarak göstermek
mümkün, bu durumda matris çarpımı X ve Z arasındaki tüm geçişlerin bir
toplamı haline gelir, tüm mümkün gidiş yollarının ağırlığını bu çarpımda
görebiliriz. Üstteki örnekte mesela her geçiş bir olasılık hesabı
taşıyabilirdi, o zaman <span class="math inline">\(M \cdot N\)</span>
çarpımında her Z konumuna herhangi bir X konumundan varma olasılığını
taşırdı. Ya da tüm bir Z konumuna varma olasılığı en fazla olan X
başlangıcını bu matriste görebilirdik.</p>
<p>Bu tür bir yaklaşımın kullanma alanı geniştir. Mesela her katmanda
farklı karar seçenekleri, olasılıkları olabilir, ve ara katmanlar
binlerce, milyonlarca seçimi içerebilir. Fakat zincirleme bir matris
çarpımı ile o tüm ara katmanların toplamını almış oluyoruz, ve elimizde
üstteki başlangıç ve bitiş için 3 x 2 boyutunda bir matris kalıyor.</p>
<p>Kaynaklar</p>
<p>[1] Ross, <em>Introduction to Probability Models, 10th Ed</em></p>
<p>[2] Bayramlı, <em>Lineer Cebir, Ders 21</em></p>
<p>[3] Bayramlı, <em>Lineer Cebir, Google Nasıl İşler?</em></p>
<p>[4] Math3ma, <a
href="https://www.math3ma.com/blog/matrices-probability-graphs">https://www.math3ma.com/blog/matrices-probability-graphs</a></p>
<p>
  <a href="..">Yukarı</a>
</p>
</body>
</html>
