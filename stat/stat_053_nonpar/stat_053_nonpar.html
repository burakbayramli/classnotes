<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
    <script type="text/x-mathjax-config">
    MathJax.Hub.Register.StartupHook("TeX Jax Ready",function () {
      MathJax.Hub.Insert(MathJax.InputJax.TeX.Definitions.macros,{
        cancel: ["Extension","cancel"], cancelto: ["Extension","cancel"]
      });
    });
    </script>  
   
  <title>Parametresiz İstatistik (Nonparametric Statistics)</title>
  <style type="text/css">code{white-space: pre;}</style>
  <style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
  </style>
  <script
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS_HTML-full"
  type="text/javascript"></script>
</head>
<body>
<div id="header">
</div>
<h1 id="parametresiz-istatistik-nonparametric-statistics">Parametresiz
İstatistik (Nonparametric Statistics)</h1>
<p>Parametrik istatistik açıklamaya çalıştığı bir örneklemin dağılımına
ilişkin varsayımlar yapmaya uğraşır, mesela “bu veri bir Gaussian
dağılımdan geliyordur” diyebilir, bilinmeyenler bu Gaussian dağılımının
<span class="math inline">\(\mu\)</span>, ve <span
class="math inline">\(\sigma\)</span> değişkenleridir,
<em>parametreleridir</em>. Bu değişkenler başta bilinmiyor olabilir
fakat parametre olarak yaklaşımın bir parçasıdırlar. Parametrik olmayan
istatistik ise varsayımlara dayanmaz; veriler belirli bir dağılımı takip
etmeyen bir örneklemden toplanabilir, ya da dağılım varsa bile yaklaşım
varsayım yapmayarak belki daha kuvvetli bazı sonuçlar almaya
uğraşır.</p>
<p>Parametresiz İstatistik yaklaşımlarını pek çoğumuz belki de ait
olduğu kategoriyi bilmeden sürekli kullanıyoruz. Bir histogram
aldığımızda aslında parametresiz istatistik uygulamış oluyoruz, çünkü
histogram yaklaşımı bilindiği gibi hiçbir dağılım varsayımı yapmıyor ve
herhangi bir veri kümesiyle işleme kabiliyetine sahip. Verinin
histogramını hesapladığımızda diyelim ki <span
class="math inline">\(N\)</span> tane kutucuk içine düşen verileri
sayıyoruz, onların frekansını hesaplıyoruz ve bu frekans
grafiklendiğinde bize verinin gerçek dağılımının ne olduğu hakkında bir
fikir verebiliyor.</p>
<p>Bir örnek üzerinde görelim, altta iki değişkenli (bivariate) Gaussian
dağılımından kendi ürettiğimiz rasgele verileri ve onun histogram
temsilini gösteriyoruz.</p>
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy <span class="im">import</span> stats</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> make_data_binormal(data_count<span class="op">=</span><span class="dv">1000</span>, seed<span class="op">=</span><span class="dv">100</span>):</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>    np.random.seed(seed)</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>    n1 <span class="op">=</span> data_count <span class="op">//</span> <span class="dv">2</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>    n2 <span class="op">=</span> data_count <span class="op">-</span> n1</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> np.concatenate([</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>        np.random.normal(<span class="op">-</span><span class="dv">1</span>, <span class="dv">2</span>, n1),</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>        np.random.normal(<span class="dv">5</span>, <span class="dv">1</span>, n2)  </span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>    ])</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> true_pdf(z):</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="fl">0.5</span> <span class="op">*</span> norm(<span class="op">-</span><span class="dv">1</span>, <span class="dv">2</span>).pdf(z) <span class="op">+</span> <span class="fl">0.5</span> <span class="op">*</span> norm(<span class="dv">5</span>, <span class="dv">1</span>).pdf(z)</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># verileri karistir yoksa verinin ilk yarisinda sadece bir tur tepe</span></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># gelecektir, bu durum azar azar (incremental) islem yaparken problem</span></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>    <span class="co"># cikartabilir. </span></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>    np.random.shuffle(x) </span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> x, true_pdf</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>data, d <span class="op">=</span> make_data_binormal()</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>x_vals <span class="op">=</span> np.linspace(np.<span class="bu">min</span>(data), np.<span class="bu">max</span>(data), <span class="dv">1000</span>)</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>plt.hist(data, bins<span class="op">=</span><span class="dv">20</span>, density<span class="op">=</span><span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.6</span>, label<span class="op">=</span><span class="st">&#39;Histogram&#39;</span>)</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>plt.plot(x_vals, d(x_vals), color<span class="op">=</span><span class="st">&#39;green&#39;</span>, lw<span class="op">=</span><span class="dv">2</span>, linestyle<span class="op">=</span><span class="st">&#39;--&#39;</span>, label<span class="op">=</span><span class="st">&#39;True Distribution&#39;</span>)</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>plt.savefig(<span class="st">&#39;stat_053_nonpar_01.png&#39;</span>)</span></code></pre></div>
<p><img src="stat_053_nonpar_01.png" /></p>
<p>Histogram yaklaşımı gerçek dağılımın iki tepesini kabaca yakaladı,
her iki tepe de grafikte görülebiliyor.</p>
<p>Histogram hesabının gerçek dağılımı temsil kabiliyetinin teorik
ispatını [1, sf. 311]’de bulabiliriz.</p>
<p>Çekirdek Yoğunluk Tahmini (Kernel Density Estimation / KDE)</p>
<p>Histogram gibi parametresiz olan bir yaklaşım daha: KDE. Bu metotla
diyelim ki bir olasılık yoğunluk fonksiyonu (pdf) <span
class="math inline">\(f(x)\)</span> tahmin edilmeye, yaklaşık olarak bir
<span class="math inline">\(\hat{f}\)</span> ile temsil edilmeye
uğraşılıyor, bunu</p>
<p><span class="math display">\[
\hat{f}(x) = \frac{1}{n} \sum _{i=1}^{n} \frac{1}{h} K \left( \frac{x -
x_i}{h}  \right)
\qquad{(1)}
\]</span></p>
<p>hesabı ile gerçekleştirebiliriz. <span
class="math inline">\(K\)</span> ile gösterilen çekirdek
fonksiyonlarıdır, farklı <span class="math inline">\(K\)</span>
seçimleri farklı sonuçlara sonuç verebilir, fakat genel olarak Gaussian
dağılım fonksiyonları iyi sonuç verir. <span
class="math inline">\(h\)</span> değişkeni bant genişliği (bandwidth),
bunu dışarıdan biz tanımlarız, tabii formülde <span
class="math inline">\(1/h\)</span> ekinin özel bir diğer önemi <span
class="math inline">\(\hat{f}\)</span>’nin entegre edilince 1 sonucunu
vermesi [1, sf. 313].</p>
<p><span class="math inline">\(K\)</span> içeriğine gelelim, Gaussian
dağılım formülünü hatırlarsak, standart sapma <span
class="math inline">\(\sigma\)</span> ortalama <span
class="math inline">\(\mu\)</span> olan bir dağılım,</p>
<p><span class="math display">\[
f_g(x) = \frac{1}{\sigma \sqrt{2\pi} }
e^{-\frac{1}{2}\left(\frac{x-\mu}{\sigma}\right)^2}
\]</span></p>
<p>Eğer <span class="math inline">\(\sigma=1,\mu=0\)</span> dersek
<em>standart</em> normal dağılım elde ederiz,</p>
<p><span class="math display">\[
f_g(x) = \frac{1}{\sqrt{2\pi} } e^{-x^2 / 2}
\]</span></p>
<p>Bu formulu <span class="math inline">\(K\)</span> icin
kullanabiliriz,</p>
<p><span class="math display">\[
K(u) = \frac{1}{\sqrt{2\pi} } e^{-u^2 / 2}
\]</span></p>
<p>KDE formülü</p>
<p><span class="math display">\[
\hat f(x) = \frac{1}{n h} \sum_{i=1}^n K\!\left(\frac{x - x_i}{h}\right)
\]</span></p>
<p>O zaman</p>
<p><span class="math display">\[
\hat f(x) = \frac{1}{n h} \sum_{i=1}^n \frac{1}{\sqrt{2\pi}}
\exp\!\left(-\frac{1}{2}\left(\frac{x - x_i}{h}\right)^2\right)
\]</span></p>
<p>Burada ilginç bir nokta var, çok detaya girmek istemeyenler
atlayabilir, fakat biraz cebirsel değişim sonrası farkediyoruz ki toplam
içinde yeni bir Gaussan elde etmiş oluyoruz. Yani KDE tanımı itibariyle
<span class="math inline">\(h\)</span> bölümünün dikte edilmesi bizi
şöyle bir Gaussian’a getiriyor, üstte toplam içini biraz açarsak ve
dışarıdaki <span class="math inline">\(h\)</span>’yi içeri getirirsek,
toplam sembolü terimleri şu hale gelir,</p>
<p><span class="math display">\[
\frac{1}{h \sqrt{2\pi}}  \exp\!\left(-\frac{(x-x_i)^2}{2 h^2}\right)
\]</span></p>
<p>Üstteki formül sonuçta bir <span class="math inline">\(N(x_i,
h^2)\)</span> dağılımı degil midir? Ortalama <span
class="math inline">\(x_i\)</span> varyansı <span
class="math inline">\(h^2\)</span>. Yani KDE mekanizması başlangıç <span
class="math inline">\(N(0,1)\)</span> çekirdeği üzerinden bizi dolaylı
olarak her veri noktasında bir <span class="math inline">\(N(x_i,
h^2)\)</span> tepesi eklemeye götürmüş oluyor.</p>
<p>Kavramsal olarak tahmin edici <span
class="math inline">\(\hat{f}\)</span> her <span
class="math inline">\(x\)</span> noktasında <span
class="math inline">\(x_i\)</span> verisini merkez almış çekirdek
fonksiyonlarının ortalamasıdır. Yani <span
class="math inline">\(x_1\)</span>’i merkez alan bir Gaussian vardır,
tabii ki <span class="math inline">\(K(x)\)</span> hesabı için <span
class="math inline">\(x_1\)</span>’deki çekirdeğe <span
class="math inline">\(x_2,x_3,..\)</span> üzerindeki Gaussian’ların
değerleri de eklenir [2, sf. 313].</p>
<p><img src="stat_053_nonpar_03.jpg" /></p>
<p>Kod ile bu hesabı görelim,</p>
<div class="sourceCode" id="cb2"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> kernel(<span class="bu">type</span><span class="op">=</span><span class="st">&#39;gaussian&#39;</span>):</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="kw">lambda</span> u: (<span class="dv">1</span> <span class="op">/</span> np.sqrt(<span class="dv">2</span> <span class="op">*</span> np.pi)) <span class="op">*</span> np.exp(<span class="op">-</span><span class="fl">0.5</span> <span class="op">*</span> u<span class="op">**</span><span class="dv">2</span>)</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> kde(data, k<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> np.linspace(np.<span class="bu">min</span>(data), np.<span class="bu">max</span>(data), <span class="dv">1000</span>)</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>    k <span class="op">=</span> kernel(<span class="st">&#39;gaussian&#39;</span>)</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>    n <span class="op">=</span> <span class="bu">len</span>(data)</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>    h <span class="op">=</span> <span class="fl">0.5</span></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>    diffs <span class="op">=</span> (x[:, np.newaxis] <span class="op">-</span> data) <span class="op">/</span> h</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>    kernel_values <span class="op">=</span> k(diffs)</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>    kde <span class="op">=</span> np.<span class="bu">sum</span>(kernel_values, axis<span class="op">=</span><span class="dv">1</span>) <span class="op">/</span> (n <span class="op">*</span> h)</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> kde</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>fhat_kde <span class="op">=</span> kde(data)</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>plt.plot(x_vals, fhat_kde, color<span class="op">=</span><span class="st">&#39;red&#39;</span>, lw<span class="op">=</span><span class="dv">2</span>, label<span class="op">=</span><span class="st">&#39;KDE&#39;</span>)</span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>plt.plot(x_vals, d(x_vals), color<span class="op">=</span><span class="st">&#39;green&#39;</span>, lw<span class="op">=</span><span class="dv">2</span>, linestyle<span class="op">=</span><span class="st">&#39;--&#39;</span>)</span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a>plt.savefig(<span class="st">&#39;stat_053_nonpar_02.png&#39;</span>)</span></code></pre></div>
<p><img src="stat_053_nonpar_02.png" /></p>
<p>Üstteki standart KDE kodlaması. Açıklamada tahmin edicinin “her <span
class="math inline">\(x\)</span> noktasında” yaptığı hesaptan bahsettik,
bu <span class="math inline">\(x\)</span> noktası teorik muhakkak,
sayısal hesaplar için en az ve en çok <span
class="math inline">\(x\)</span> değerleri arasında belli noktaları
önceden <code>np.linspace</code> ile tanımlıyoruz, ve sadece bu noktalar
üzerinde Gaussian hesapları yapıyoruz. Bir nevi histogramsal bir
yaklaşım bu, ama kutucuklar yok, önceden seçilmiş <span
class="math inline">\(x\)</span> noktaları var.</p>
<p>Bir performans konusuna da dikkat çekelim. Formül (1)’deki <span
class="math inline">\(K((x - x_i) / h)\)</span> hesabının bir toplam
içinde olduğuna ve her <span class="math inline">\(x\)</span> hesabı
için <em>tüm</em> diğer <span class="math inline">\(x\)</span>’lerin
üzerinden geçilmesi gerektiğine dikkat çekmek gerekiyor. Bu demektir ki
üstte verilen yaklaşımın hesapsal karmaşıklığı <span
class="math inline">\(O(n^2)\)</span> olacaktır, ki bu hız anlık
(online) işlem yapan uygulamalar için tercih edilen bir performans
olmaz. KDE’yi daha hızlandırmak için bir yaklaşımı ileride
göreceğiz.</p>
<p>KDE Olasılık Dağılımıdır</p>
<p>Çekirdek üzerinden tanımlanan fonksiyon bize bir yaklaşıksal
olasılıksal yoğunluk fonksiyonu (pdf) veriyor mu? Bunun ispatı için
<span class="math inline">\(K\)</span> seçimindeki bazı şartları tam
belirleyelim. KDE matematiğine göre çekirdek pürüzsüz bir fonksiyon
olmalıdır, öyle ki <span class="math inline">\(K(x) \ge 0\)</span>,
<span class="math inline">\(\int K(x) \,dx = 1\)</span>, <span
class="math inline">\(\int x K(x) \,dx = 0\)</span>, ve <span
class="math inline">\(\int x^2 K(x) \,dx &gt; 0\)</span>.</p>
<p>Bir fonksiyonun pdf olması için iki şart var, <span
class="math inline">\(\hat{f}(x) \ge 0\)</span> olmalı, ve <span
class="math inline">\(\int \hat{f}(x) \,dx = 1\)</span> olmalı. Dikkat
edersek bu iki şart <span class="math inline">\(K\)</span> için
tanımlanan şartlarla aynı. Bunun KDE formülü üzerinden yansıması şöyle
olur,</p>
<p><span class="math display">\[
\int_{-\infty}^{\infty} \hat{f}(x) \,dx = \int_{-\infty}^{\infty}
\frac{1}{n} \sum_{i=1}^n K(x-x_i) \,dx
\]</span></p>
<p>Eşitliğin sağındaki sabit <span class="math inline">\(1/n\)</span>
entegral dışına çıkartılabilir,</p>
<p><span class="math display">\[= \frac{1}{n} \sum_{i=1}^n
\int_{-\infty}^{\infty} K(x-x_i) \,dx\]</span></p>
<p>Bir değişken değişimi yapalım, <span class="math inline">\(u =
\frac{x-x_i}{h}\)</span> olsun, o zaman <span class="math inline">\(x =
uh + x_i\)</span>, ve <span class="math inline">\(dx = h\,du\)</span>.
Entegral limitleri aynı kalıyor, demek ki</p>
<p><span class="math display">\[= \frac{1}{n} \sum_{i=1}^n
\int_{-\infty}^{\infty} \frac{1}{h}K(u) (h\,du)\]</span></p>
<p>Bölüm ve bölendeki <span class="math inline">\(h\)</span> terimleri
iptal olur,</p>
<p><span class="math display">\[= \frac{1}{n} \sum_{i=1}^n
\int_{-\infty}^{\infty} K(u) \,du\]</span></p>
<p>Çekirdek fonksiyonu tanımına göre <span
class="math inline">\(K(u)\)</span>’nun tüm tanım alanı üzerinden
entegrali 1 olmak zorundaydı, <span
class="math inline">\(\int_{-\infty}^{\infty} K(u) \,du = 1\)</span>. O
zaman,</p>
<p><span class="math display">\[= \frac{1}{n} \sum_{i=1}^n (1) =
\frac{1}{n} (n) = 1\]</span></p>
<p>Görüldüğü gibi çekirdek yoğunluk tahminsel hesap hem negatif olmama
hem de normalizasyon (entegralin 1 olması) şartlarını yerine getiriyor,
o zaman tanım itibariyle o bir pdf’tır.</p>
<p>KDE Ana Yoğunluğa Ne Kadar Yakındır?</p>
<p>KDE ile elde edilen fonksiyonun bir pdf olması yeterli değil, önemli
olan tahmin edilmeye uğraşılan ana pdf’e ne kadar yaklaştığı.</p>
<p>Her <span class="math inline">\(x\)</span> noktasında KDE’nin
ortalama ve varyansına bakalım. Once ortalama,</p>
<p><span class="math display">\[
E[\hat{f}(x) ] = \frac{1}{n} \sum _{i=1}^{n}
E \left[
\frac{1}{h} K \left( \frac{x - x_i}{h}  \right)
\right]
\]</span></p>
<p><span class="math display">\[
= \int K(u) \left[
f(x) - h u f&#39;(x) + \frac{h^2 u^2 }{2} f&#39;&#39;(x) + o(h^2)
\right] \,du
\]</span></p>
<p><span class="math display">\[
= f(x) \int K(u)\,du
\;-\; h f&#39;(x)\int u K(u)\,du
\;+\; \frac{h^2 f&#39;&#39;(x)}{2}\int u^2 K(u)\,du
\;+\; \int K(u)\,o(h^2)\,du.
\]</span></p>
<p><span class="math inline">\(K\)</span> tanımına göre <span
class="math inline">\(\int K(x) \,dx = 1\)</span>, <span
class="math inline">\(\int x K(x) \,dx = 0\)</span> olması gerektiğini
hatırlarsak,</p>
<p><span class="math display">\[
= f(x) + \frac{h^2 f&#39;&#39;(x)}{2} \int K(u) u^2 \,du + o(h^2)
\]</span></p>
<p>Eğer <span class="math inline">\(\int K(u) u^2 \,du =
\sigma_K^2\)</span> dersek, ve <span class="math inline">\(f(x)\)</span>
ifadesini eşitliğin soluna taşırsak,</p>
<p><span class="math display">\[
E[\hat{f}(x)] - f(x) = \frac{h^2 \sigma_K^2 f&#39;&#39;(x)}{2} + o(h^2)
\qquad{(3)}
\]</span></p>
<p>Eşitliğin solundaki terim yanlılık (bias) hesabıdır. Doğal olarak
yanlılığın azalmasını isteriz, üstteki ifade diyor ki <span
class="math inline">\(h\)</span> küçüldükçe yanlılık ta sıfıra gidecek.
Demek ki <span class="math inline">\(h\)</span> değerini küçültürsem
yanlılığı azaltırım.</p>
<p>Fakat yanlılık tek başına yeterli değil, genellikle aranan bir hata
kare ortalaması (mean square error), MSE olarak bilinen hesabın
ufalmasıdır.. MSE hesabı da yanlılık karesi artı varyanstır, burada
istatistik literatüründe bilinen yanlılık / varyans dengesi (tradeoff)
aklımıza gelebilir, yanlılığı azalttığımızda varyansta patlamaya sebep
olabiliriz, bu sebeple her iki ölçümü dengeleyen bir yaklaşım
bulunmalıdır. O zaman nihai bir optimal sonuca ulaşmak için KDE’nin
varyansını hesaplayalım.</p>
<p><span class="math display">\[
Var \left[ \hat{f}(x)  \right] =
\frac{1}{n} Var \left[
  \frac{1}{h} K \left( \frac{x - X}{h}  \right)
\right]
\]</span></p>
<p>Temel İstatistiği hatırlarsak <span class="math inline">\(Var(X) =
E(X^2) - E(X)^2\)</span>, o zaman üstteki</p>
<p><span class="math display">\[
= \frac{1}{n} \left[
E \left[ \frac{1}{h^2} K^2 \left( \frac{x - X}{h}  \right) \right]
\right] -
\left(
E \left[ \frac{1}{h} K \left( \frac{x - X}{h}  \right)  \right]
\right)^2
\]</span></p>
<p>olacaktır. İlk beklenti (expectation) hesabını standart beklenti
formülü ile açabiliriz, bu bir entegraldir, <span
class="math inline">\(X\)</span> pdf fonksiyonu <span
class="math inline">\(f_X\)</span> için bunun <span
class="math inline">\(\int x f_X \,dx\)</span> olduğunu biliyoruz, bunu
uygularız. İkinci beklenti için daha önce bulduğumuz (3)’teki formülü
kullanırız,</p>
<p><span class="math display">\[
E[\hat{f}(x)]  = \frac{h^2 \sigma_K^2 f&#39;&#39;(x)}{2} + f(x) + o(h^2)
\]</span></p>
<p>Buradaki ilk terimi <span class="math inline">\(o(h^2)\)</span>’ye
dahil edebiliriz, o zaman iki üstteki,</p>
<p><span class="math display">\[
= \frac{1}{n} \left[
\int K^2 \left( \frac{x - t}{h}  \right) \,dt - [ f(x) + O(h^2)]^2
\right]
\]</span></p>
<p>olur. Eksiden sonraki kare alma işlemini açalım,</p>
<p><span class="math display">\[
[ f(x) + O(h^2)]^2 = f(x)^2 + 2f(x) O(h^2) + (O(h^2))^2 =
\]</span></p>
<p><span class="math inline">\(f(x)\)</span>, O(h^2)’e kıyasla sabit
sayılır, etkisi yoktur, <span class="math inline">\((O(h^2))^2 =
O(h^4)\)</span>,</p>
<p><span class="math display">\[
= f(x)^2 + O(h^2) + O(h^4)
\]</span></p>
<p>elde ederiz. Büyük O notasyonu matematiğine göre iki farklı dereceyi
topladığımız zaman daha yavaş azalan / sönümlenen (decay) terim tutulur,
o zaman <span class="math inline">\(O(h^4)\)</span> atılır, geriye <span
class="math inline">\(f(x)^2 + O(h^2)\)</span> kalır.</p>
<p><span class="math display">\[
= \frac{1}{n} \left[
\int K^2 \left( \frac{x - t}{h}  \right) \,dt - f(x) + O(h^2)]
\right]
\]</span></p>
<p>Not: Büyük O notasyonunda <span class="math inline">\(-O(h^2) =
O(h^2)\)</span>, negatif işaret farketmiyor.</p>
<p>Değişken değişimi yapıyoruz</p>
<p><span class="math display">\[
\frac{1}{n} \left[
\int \frac{1}{h} K^2(u) f(x - hu) \,du - f(x)^2 + O(h^2)
\right]
\]</span></p>
<p>Taylor açılımını tekrar uyguluyoruz,</p>
<p><span class="math display">\[
\frac{1}{n} \left[
\int \frac{1}{h} K^2(u) \big( f(x) - huf&#39;(x) \big) \,du - f(x)^2 +
O(h^2)
\right]
\qquad{(2)}
\]</span></p>
<p>Şimdi entegrali açalım, sonuç şöyle olur,</p>
<p><span class="math display">\[
= \frac{f(x)}{hn} \int K^2(u) \,du - f&#39;(x) \int u K^2(u) \,du - ...
\]</span></p>
<p>Ilk terimde <span class="math inline">\(\int K^2(u) \,du\)</span>
var, bu bir sabite esittir.</p>
<p><span class="math display">\[
K(u)^2 = \left( \frac{1}{\sqrt{2\pi}} e^{-u^2/2} \right)^2
= \frac{1}{2\pi} e^{-u^2}.
\]</span></p>
<p><span class="math display">\[
\int_{-\infty}^{\infty} K(u)^2 \, du
= \frac{1}{2\pi} \int_{-\infty}^{\infty} e^{-u^2} \, du.
\]</span></p>
<p>Eşitliğin sağındaki entegralin <span
class="math inline">\(\sqrt{\pi}\)</span> olduğu biliniyor, o zaman</p>
<p><span class="math display">\[
\Rightarrow \frac{1}{2\pi} \cdot \sqrt{\pi} \Rightarrow
\int_{-\infty}^{\infty} K(u)^2 \, du = \frac{1}{2\sqrt{\pi}} = R(K)
\]</span></p>
<p>Üstteki sonuç literatürde <span class="math inline">\(R(K)\)</span>
ile anılır.</p>
<p>İkinci terimde <span class="math inline">\(\int u K^2(u) du\)</span>
var, bu sıfırdır, <span class="math inline">\(K(u)\)</span> bir çift
fonksiyon (tek fonksiyon, çift fonksiyon kavramlarını hatırlarsak, <span
class="math inline">\(K(u)=K(-u)\)</span>), ve <span
class="math inline">\(K^2(u)\)</span> yine çift, fakat <span
class="math inline">\(u K^2(u)\)</span> tek çünkü <span
class="math inline">\(u\)</span> değişkeni, bir fonksiyon olarak
düşünülürse tektir. Ve tek fonksiyonların sıfır etrafındaki simetrik
limitleri üzerinden entegrali sıfırdır.</p>
<p>Formül (2)’den geriye kalanlar</p>
<p><span class="math display">\[
= \frac{1}{n} \left[ \frac{f(x)}{h}R(K) - f(x)^2 + O(h^2)  \right]
\]</span></p>
<p>Şimdi O notasyonu bağlamında düşünürsek, ilk terimde <span
class="math inline">\(f(x)R(K) / nh\)</span> var, burada <span
class="math inline">\(R(K)\)</span> seçilen çekirdek <span
class="math inline">\(K\)</span>’ye bağlı bir sabittir, o zaman O
notasyon sonucunda <span class="math inline">\(O(1/nh)\)</span> elde
ederiz. İkinci terimde <span class="math inline">\(f(x)^2/n\)</span>
var, burası <span class="math inline">\(O(1/n)\)</span> oluyor, çünkü
<span class="math inline">\(n\)</span> ve <span
class="math inline">\(h\)</span> büyümesine göre <span
class="math inline">\(f(x)^2\)</span> sabit sayılır. Üçüncü terimde
<span class="math inline">\(O(h^2)/n\)</span> var, bu da <span
class="math inline">\(O(h^2/n)\)</span> oluyor. Hepsinin nihai toplamı
<span class="math inline">\(O(1/nh)\)</span> olurdu. Ama birinci terimi
tutalım ve şunu gösterelim,</p>
<p><span class="math display">\[
Var \left[ \hat{f}(x)  \right] = \frac{f(x)R(K)}{nh} + O(1/n)
\]</span></p>
<p><span class="math inline">\(n \to \infty\)</span> iken ve <span
class="math inline">\(nh \to \infty\)</span> ise üstteki sıfıra gider. O
zaman yanlılık ve varyans dengesi bağlamında suna dikkat edersek yöntem
işler; <span class="math inline">\(h\)</span> sıfıra gitmelidir, ama
bunu <span class="math inline">\(1/n\)</span>’den daha yavaş yapmalıdır
[1, sf. 314].</p>
<p>Alttaki formülde daha açık görebiliriz, hataların kare ortalaması
(mean square error, MSE) hesabı yanlılık karesi artı varyanstır, o
zaman</p>
<p><span class="math display">\[
MSE = \frac{h^4 \sigma_K^4 (f&#39;&#39;(x))^2}{4} + \frac{f(x)}{hn} \int
K^2 (u) \,du + \textrm{ufak degerler}
\]</span></p>
<p>Doğru seçilmiş <span class="math inline">\(h,n\)</span> değerleri
büyürken MSE’yi minimal hale getirebilir, ama tabii ki bölünende olan
<span class="math inline">\(h\)</span> değerine dikkat edersek. Bu iki
değer, <span class="math inline">\(h,n\)</span> arasındaki denge için ek
hesabı [1, sf. 315]’te bulabiliriz, optimal oran <span
class="math inline">\(h_{opt} = O(n^{-1/5})\)</span> olarak gösterilmiş,
yani en iyi bant genişliği <span class="math inline">\(h\)</span> değeri
veri noktası sayısının 1 bölü beşinci kuvvetine oranla sıfıra
gitmelidir. Not: Üstteki formül her <span
class="math inline">\(x\)</span> bazındadır, [1] kaynağında optimal
<span class="math inline">\(h\)</span> bulmak için tüm <span
class="math inline">\(x\)</span>’ler üzerinden entegral alınarak <span
class="math inline">\(h\)</span> üzerinden türev alınmıştır, bir “hata
karelerinin entegresi alınmış beklentisi” hesaplanmıştır.</p>
<p>Artımsal KDE</p>
<p>KDE formülünü kullanarak <span class="math inline">\(p_n(x)\)</span>
tanımlayalım,</p>
<p><span class="math display">\[
p_n(x) = \frac{1}{n}\sum_{i=1}^{n} K_h(x - x_i).
\]</span></p>
<p><span class="math inline">\((n+1)\)</span>’inci veri gelince <span
class="math inline">\(n+1\)</span> veri noktası içeren KDE şudur,</p>
<p><span class="math display">\[
p_{n+1}(x)
=\frac{1}{n+1}\sum_{i=1}^{n+1} K_h(x - x_i)
=\frac{1}{n+1}\Big(\sum_{i=1}^{n} K_h(x - x_i) + K_h(x - x_{n+1})\Big).
\]</span></p>
<p>Eşitliğin sağındaki ilk terimde <span
class="math inline">\(\sum_{i=1}^{n} K_h(x - x_i)\)</span> ifadesi
yerine bir önceki tanımdan <span class="math inline">\(n p_n(x)\)</span>
formüle sokulabilir, bu bize <span
class="math inline">\(p_{n+1}(x)\)</span> için özyineli bir güncelleme
formülü verir,</p>
<p><span class="math display">\[
p_{n+1}(x) = \frac{n}{n+1}\,p_n(x) + \frac{1}{n+1}\,K_h(x - x_{n+1})
\qquad{(1)}
\]</span></p>
<p>Kodları görelim,</p>
<div class="sourceCode" id="cb3"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> norm</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>num_points <span class="op">=</span> <span class="bu">len</span>(data)    </span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>total_density <span class="op">=</span> <span class="va">None</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>N <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>h <span class="op">=</span> <span class="fl">0.5</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>x_values <span class="op">=</span> np.linspace(<span class="bu">min</span>(data) <span class="op">-</span> <span class="dv">1</span>, <span class="bu">max</span>(data) <span class="op">+</span> <span class="dv">1</span>, num_points)</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>current <span class="op">=</span> data[<span class="dv">0</span>]</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>total_density <span class="op">=</span> norm.pdf(x_values, loc<span class="op">=</span>current, scale<span class="op">=</span>h)</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(data)):</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>    current <span class="op">=</span> data[i]</span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>    density <span class="op">=</span> norm.pdf(x_values, loc<span class="op">=</span>current, scale<span class="op">=</span>h)</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>    total_density <span class="op">=</span> (N<span class="op">/</span>(N<span class="op">+</span><span class="dv">1</span>)) <span class="op">*</span> total_density <span class="op">+</span>  (<span class="dv">1</span> <span class="op">/</span> (N<span class="op">+</span><span class="dv">1</span>)) <span class="op">*</span> density</span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>    N <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>x_vals <span class="op">=</span> np.linspace(np.<span class="bu">min</span>(data), np.<span class="bu">max</span>(data), <span class="dv">1000</span>)</span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>plt.plot(x_vals, d(x_vals), color<span class="op">=</span><span class="st">&#39;green&#39;</span>, lw<span class="op">=</span><span class="dv">2</span>, linestyle<span class="op">=</span><span class="st">&#39;-&#39;</span>, label<span class="op">=</span><span class="st">&#39;Gercek Dagilim&#39;</span>)</span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>plt.plot(x_values, total_density, color<span class="op">=</span><span class="st">&#39;red&#39;</span>, lw<span class="op">=</span><span class="dv">2</span>, linestyle<span class="op">=</span><span class="st">&#39;--&#39;</span>, label<span class="op">=</span><span class="st">&#39;Artimsal KDE&#39;</span>)</span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a>plt.savefig(<span class="st">&#39;stat_053_nonpar_03.png&#39;</span>)</span></code></pre></div>
<p><img src="stat_053_nonpar_03.png" /></p>
<p>EWMA Bağlantısı</p>
<p>Önce [6] yazısında gördüğümüz basit sayılar üzerinde artımsal
(incremental) ortalama hesabı formülünü hatırlayalım,</p>
<p><span class="math display">\[
\bar{x}_n = \left(1 - \tfrac{1}{n}\right)\bar{x}_{n-1} + \tfrac{1}{n}
x_n.
\]</span></p>
<p>Ya da</p>
<p><span class="math display">\[
\bar{x}_n = \frac{n-1}{n} \bar{x}_{n-1} + \tfrac{1}{n} x_n.
\]</span></p>
<p>Şimdi KDE, sayaç güncellemesinin nerede olduğuna bağlı olarak ve bir
indis kaydırması yaparak KDE özyineli formül (1) şu şekilde de
gösterilebilir,</p>
<p><span class="math display">\[
p_{n}(x) = \frac{n-1}{n}\,p_{n-1}(x) + \frac{1}{n}\,K_h(x - x_{n})
\]</span></p>
<p>Her iki form birbirinin aynısı. Tek fark güncelleme için kullanılan
“yeni veri” noktasının birinde reel sayı olması diğerinde ise <span
class="math inline">\(K_h(x - x_{n})\)</span> ile hesaplanan son
noktanın olasılık değeri.</p>
<p>Bu form benzerliğini saptamak önemli çünkü şimdi, aynen [5]’de
gösterildiği gibi, ortalama güncellemesini üstel ağırlıklı EWMA forma
geçirebildiğimiz gibi üstteki KDE güncellemesini de EWMA formatına
geçirebiliriz. Yani, en son veriye daha ağırlık veren EWMA formundaki
KDE şu şekilde yazılabilir.</p>
<p><span class="math display">\[
p_n(x) = (1-\alpha)\,p_{n-1}(x) + \alpha\,K_h(x - x_n).
\]</span></p>
<p>Bu noktada EWMA’nın bir tür “kayan pencere ortalaması” olduğunu
hatırlayabiliriz, kabaca bu pencere büyüklüğünün <span
class="math inline">\(\alpha\)</span> bazlı nasıl saptanabildiğini
[3]’te görmüştük. Yani ortalama güncellemesinden kayan pencere
ortalamasına, oradan tek parametre kullanarak hızlı şekilde pencere
ortalaması EWMA ile yapmaya doğru bir geçiş mümkündür. Bu geçiş
performans, kodlama açısından faydalı olabilir, çünkü çok uzun süreli
güncelleme alan bir sistem düşünelim, veri nokta sayısı <span
class="math inline">\(n\)</span> çok büyüyecektir, bu sayı bölüm
sırasında problem çıkartabilir. Fakat EWMA yaklaşımı sabit tek parametre
üzerinden işlediği için bu tür problemleri olmaz.</p>
<div class="sourceCode" id="cb4"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> norm</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>num_points <span class="op">=</span> <span class="bu">len</span>(data)    </span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>h <span class="op">=</span> <span class="fl">0.5</span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>alpha <span class="op">=</span> <span class="fl">0.001</span></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>x_values <span class="op">=</span> np.linspace(<span class="bu">min</span>(data) <span class="op">-</span> <span class="dv">1</span>, <span class="bu">max</span>(data) <span class="op">+</span> <span class="dv">1</span>, num_points)</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>current <span class="op">=</span> data[<span class="dv">0</span>]</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>total_density <span class="op">=</span> norm.pdf(x_values, loc<span class="op">=</span>current, scale<span class="op">=</span>h)</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(data)):</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>    current <span class="op">=</span> data[i]</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>    density <span class="op">=</span> norm.pdf(x_values, loc<span class="op">=</span>current, scale<span class="op">=</span>h)</span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>    total_density <span class="op">=</span>  (<span class="dv">1</span><span class="op">-</span>alpha)<span class="op">*</span>total_density <span class="op">+</span>  (alpha)<span class="op">*</span>density</span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>data, d <span class="op">=</span> make_data_binormal(data_count<span class="op">=</span><span class="dv">10</span><span class="op">*</span><span class="dv">1000</span>)</span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>x_vals <span class="op">=</span> np.linspace(np.<span class="bu">min</span>(data), np.<span class="bu">max</span>(data), <span class="dv">1000</span>)</span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>plt.plot(x_vals, d(x_vals), color<span class="op">=</span><span class="st">&#39;green&#39;</span>, lw<span class="op">=</span><span class="dv">2</span>, linestyle<span class="op">=</span><span class="st">&#39;-&#39;</span>, label<span class="op">=</span><span class="st">&#39;Gercek Dagilim&#39;</span>)</span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>plt.plot(x_values, total_density, color<span class="op">=</span><span class="st">&#39;red&#39;</span>, lw<span class="op">=</span><span class="dv">2</span>, linestyle<span class="op">=</span><span class="st">&#39;--&#39;</span>, label<span class="op">=</span><span class="st">&#39;EWMA KDE&#39;</span>)</span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>plt.savefig(<span class="st">&#39;stat_053_nonpar_04.png&#39;</span>)</span></code></pre></div>
<p><img src="stat_053_nonpar_04.png" /></p>
<p>Üstteki metotun ne kadar verimli çalıştığını ne kadar anlatsak az
gelir. Örnek amaçlı olarak <code>data</code> içindeki veriyi yarattık ve
onun üzerinden geçiyoruz fakat dikkatlice bakarsak kodun aslında elde
hiçbir veri tutmasına ihtiyacı yok. Onun tek hatırlaması gereken
<code>total_density</code>, <code>x_values</code> icindeki <span
class="math inline">\(x\)</span> değer listesi (bunlar bir kere
ayarlandıktan sonra bir daha değişmiyor), ve tek bir <code>alpha</code>
sabiti. Bu kadar. Yeni veri bize dış sistemden teker teker veriliyor
olabilirdi, biz yine üstteki aynı güncelleme mantığını kullanırdık, ve
bu mantık her yeni veri için <code>x_values</code> kadar nokta üzerinden
geçerdi, orada bir Gaussian hesabı yapardı ve özyineli güncellemesini
tek bir satırda gerçekleştirdi. Bu sayede, bu hızlı güncelleme ile,
verinin dağılımı ne olursa olsun, onun esas dağılımı hakkında hiçbir şey
bilmeden bu dağılımı yaklaşık şekilde temsil edebilmiş oluyoruz.</p>
<p>Kaynaklar</p>
<p>[1] Shalizi, <em>Advanced Data Analysis From An Elementary Point of
View</em></p>
<p>[2] Wasserman, <em>All of Statistics</em></p>
<p>[3] Bayramli, <em>Zaman Serileri - ARIMA, ARCH, GARCH, Periyotlar,
Yürüyen Ortalama</em></p>
<p>[4] Bayramli, <em>Istatistik, Parametresiz İstatistik (Nonparametric
Statistics)</em></p>
<p>[5] Bayramli, <em>Zaman Serileri, ARIMA, ARCH, GARCH, Periyotlar,
Yürüyen Ortalama</em></p>
<p>[6] Bayramli, <em>Azar Azar İstatistik (Incremental
Statistics)</em></p>
<p>
  <a href="..">Yukarı</a>
</p>
</body>
</html>
