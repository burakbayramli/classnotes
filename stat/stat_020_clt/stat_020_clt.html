<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
    <script type="text/x-mathjax-config">
    MathJax.Hub.Register.StartupHook("TeX Jax Ready",function () {
      MathJax.Hub.Insert(MathJax.InputJax.TeX.Definitions.macros,{
        cancel: ["Extension","cancel"], cancelto: ["Extension","cancel"]
      });
    });
    </script>  
   
  <title>Büyük Sayılar</title>
  <style type="text/css">code{white-space: pre;}</style>
  <script
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS_HTML-full"
  type="text/javascript"></script>
</head>
<body>
<div id="header">
</div>
<h1 id="büyük-sayılar">Büyük Sayılar</h1>
<p>Büyük Sayılar Kanunu (Law of Large Numbers)</p>
<p>Bu kanun, örneklem (sample) ile rasgele değişkenler, yani
matematiksel olasılık dağılımları arasında bir bağlantı görevi görür.
Kanun kabaca bildiğimiz günlük bir gerçeğin matematiksel ispatıdır.
Yazı-tura atarken yazı çıkma ihtimalinin 1/2 olduğunu biliyoruz;
herhalde çoğumuz bu yazı-tura işlemin “bir çok kere” tekrarlandığı
durumda, toplam sonucun aşağı yukarı yarısının yazı olacağını bilir.</p>
<p>Matematiksel olarak, farzedelim ki her yazı-tura atışı bir deney
olsun. Deneylerin sonucu <span class="math inline">\(X_1,
X_2...X_n\)</span> olarak rasgelen değişkenlerle olsun, bu değişkenlerin
dağılımı aynı (çünkü aynı zar), ve birbirlerinden bağımsızlar (çünkü her
deney diğerinden alakasız). Değişkenlerin sonucu 1 ya da 0 değeri
taşıyacak, Yazı=1, Tura=0.</p>
<p>Büyük Sayılar Kanunu tüm bu deney sonuçlarının, yani rasgele
değişkenlerin averajı alınırsa, yani <span class="math inline">\(\bar{X}
= X_1 + .. + X_n\)</span> ile, elde edilen sonucun <span
class="math inline">\(X_i\)</span>’lerin (aynı olan) beklentisine
yaklaşacağının söyler, yani <span class="math inline">\(n\)</span>
büyüdükçe <span class="math inline">\(\bar{X}_n\)</span>’in 1/2’ye
yaklaştığını ispatlar, yani <span class="math inline">\(E[X_i] =
1/2\)</span> değerine. Notasyonel olarak <span
class="math inline">\(E(X_i) = \mu\)</span> olarak da
gösterilebilir.</p>
<p>Özetlemek gerekirse, bir olasılık dağılımına sahip olan, görmediğimiz
bir “yerlerde’’ olan bir dağılımdan bir örneklem alıyoruz, örneklem bir
zar atma işlemi gibi (simülasyon ile bu değişkenleri de
doldurabilirdik), sonra bu değişkenlerin averajını alıyoruz, ve bu
averajın o görmediğimiz bilmediğimiz”gerçek’’ dağılımın <span
class="math inline">\(\mu\)</span> değerine yaklaştığını görüyoruz.</p>
<p>Formülsel olarak, herhangi bir <span class="math inline">\(\epsilon
&gt; 0\)</span> için,</p>
<p><span class="math display">\[ \lim_{n \to \infty} P(|\bar{X} - \mu|
\le \epsilon) = 1\]</span></p>
<p>ya da</p>
<p><span class="math display">\[ \lim_{n \to \infty} P(|\bar{X}_n-\mu|
&gt; \epsilon) = 0 \]</span></p>
<p>ya da</p>
<p><span class="math display">\[ P(|\bar{X}_n-\mu| &gt; \epsilon)
\rightarrow 0 \]</span></p>
<p>Burada ne söylendiğine dikkat edelim, <span
class="math inline">\(X_i\)</span> dağılımı <em>ne olursa olsun</em>,
yanı ister Binom, ister Gaussian olsun, <em>örneklem</em> üzerinden
hesaplanan sayısal ortalamanın (empirical mean) formülsel olasılık
beklentisine yaklaştığını söylüyoruz! <span
class="math inline">\(X_i\)</span>’ler en absürt dağılımlar olabilirler,
bu dağılımların fonksiyonu son derece çetrefil, tek tepeli (unimodal)
bile olmayabilir, o formüller üzerinden beklenti için gereken entegralin
belki analitik çözümü bile mevcut olmayabilir! Ama yine de ortalama, o
dağılımların beklentisine yaklaşacaktır. İstatistik ile olasılık teorisi
arasındaki çok önemli bir bağlantı bu.</p>
<p>Sonuç şaşırtıcı, fakat bir ek daha yapalım, sezgisel (intuitive)
olarak bakarsak aslında sonuç çok şaşırtıcı olmayabilir. Niye? Diyelim
ki genel veri <span class="math inline">\(N(\mu,\sigma^2)\)</span>
şeklinde bir Normal dağılımdan geliyor ve örneklem de bu sebeple aynı
dağılıma sahip. Bu durumda örneklemdeki veri noktalarının <span
class="math inline">\(\mu\)</span>’ya yakın değerler olmasını beklemek
mantıklı olmaz mı? Çünkü bu dağılım “zar atınca’’ ya da bir genel
nüfustan bir”örnek toplayınca’’ (ki bunu bir anlamda istatistiksel bir
zar atışı olarak görebiliriz) onu <span
class="math inline">\(\mu,\sigma^2\)</span>’e göre atacak. Örneklemi zar
atışı sonuçları olarak gördüğümüze göre elde edilen verilerin bu şekilde
olacağı şaşırtıcı olmamalı. Ve bu zar atışlarının ortalamasının, son
derece basit bir aritmetik bir işlemle hesaplanıyor olsa bile, <span
class="math inline">\(\mu\)</span>’ye yaklaşması normal olmalı.</p>
<p>Bu arada, bu argümana tersten bakarsak Monte Carlo entegralinin niye
işlediğini görebiliriz, bkz [3].</p>
<p>Özellikle örneklem ile genel nüfus (population) arasında kurulan
bağlantıya dikkat edelim. İstatiğin önemli bir bölümünün bu bağlantı
olduğu söylenebilir. Her örneklem, bilmediğimiz ama genel nüfusu temsil
eden bir dağılımla aynı dağılıma sahip olan <span
class="math inline">\(X_i\)</span>’dir dedik, ve bu aynılıktan ve
bağımsızlıktan yola çıkarak bize genel nüfus hakkında bir ipucu sağlayan
bir kanun geliştirdik (ve birazdan ispatlayacağız).</p>
<p>İspata başlayalım.</p>
<p><span class="math inline">\(X_1,X_2,..,X_n\)</span> bağımsız
değişkenler olsun.</p>
<p><span class="math display">\[ E(X_i) = \mu \]</span></p>
<p><span class="math display">\[ Var(X_i) = \sigma \]</span></p>
<p><span class="math display">\[ \bar{X}_n = \frac{1}{n} \sum_{i=1}^n
X_i  \]</span></p>
<p><span class="math inline">\(\bar{X}_n\)</span> de bir rasgele
değişkendir, çünku <span class="math inline">\(\bar{X}_n\)</span>
değişkeni her <span class="math inline">\(X_i\)</span> dağılımıyla
alakalı.</p>
<p>İspata devam etmek için <span
class="math inline">\(\bar{X}_n\)</span> dağılımının beklentisini
bulmamız gerekiyor.</p>
<p><span class="math display">\[ E(\bar{X}_n) = E(\frac{1}{n}
\sum_{i=1}^n X_i)  \]</span></p>
<p>E doğrusal bir işleç (linear operatör) olduğu için dışarıdan içeri
doğru nüfuz eder.</p>
<p><span class="math display">\[ = \frac{1}{n} \sum_{i=1}^n E(X_i) =
\frac{1}{n}n\mu = \mu \]</span></p>
<p>Dikkat edelim, bu <em>ortalamanın</em> beklentisi, ortalamanın
kendisinin hangi değere yaklaşacağını hala göstermiyor. Eğer öyle
olsaydı işimiz bitmiş olurdu :) Daha yapacak çok iş var.</p>
<p>Şimdi <span class="math inline">\(\bar{X}_n\)</span> dağılımının
standart sapmasını da bulalım. Diğer bir olasılık kuramına göre</p>
<p><span class="math display">\[ Y = a + bX \]</span></p>
<p><span class="math display">\[ Var(Y) = b^2Var(X) \]</span></p>
<p>oldugunu biliyoruz. O zaman,</p>
<p><span class="math display">\[ \bar{X}_n = \frac{1}{n} \sum_{i=1}^n
X_i  \]</span></p>
<p><span class="math display">\[ Var(\bar{X}_n) =
Var(\frac{1}{n}\sum_{i=1}^nX_i) =
\frac{1}{n^2}\sum_{i=1}^n Var(X_i)
\]</span></p>
<p><span class="math display">\[
Var(\bar{X}_n) = \frac{1}{n^2}\sum_{i=1}^n \sigma^2 =
\frac{1}{n^2}n\sigma^2 = \frac{\sigma^2}{n}
\qquad (3)
\]</span></p>
<p>Artık Çebişev kuramını kullanmaya hazırız. Ispatlamaya calistigimiz
neydi? <span class="math inline">\(n \rightarrow \infty\)</span>
iken,</p>
<p><span class="math display">\[ P(|\bar{X}_n-\mu| &gt; \epsilon)
\rightarrow 0 \]</span></p>
<p>Çebişev’den</p>
<p><span class="math display">\[ P(|\bar{X}_n-\mu| &gt; \epsilon) \le
\frac{Var(\bar{X}_n)}{\epsilon^2} \]</span></p>
<p><span class="math display">\[ P(|\bar{X}_n-\mu| &gt; \epsilon) \le
\frac{\sigma^2}{n\epsilon^2}
\rightarrow 0 \]</span></p>
<p><span class="math inline">\(\sigma^2 / n\epsilon^2\)</span>’in sıfıra
gitmesi normal çünkü <span class="math inline">\(n\)</span> sonsuza
gidiyor.</p>
<p>Peki <span class="math inline">\(P(|\bar{X}_n-\mu| &gt;
\epsilon)\)</span>’nin sıfıra gittiğini gösterdik mi?</p>
<p><span class="math inline">\(\sigma^2 / n\epsilon^2\)</span>’nin
sıfıra gittiğini gösterdik. <span class="math inline">\(\sigma^2 /
n\epsilon^2\)</span> de <span class="math inline">\(P(|\bar{X}_n-\mu|
&gt; \epsilon)\)</span>’den büyük olduğuna göre, demek ki o da sıfıra
iner.</p>
<p>Çebişev Eşitsizliğinin ispatı ek bölümde bulunabilir.</p>
<p><span class="math inline">\(\square\)</span></p>
<p>Büyük Sayılar Kanunu örneklem ortalamasının ve varyansının <span
class="math inline">\(X_i\)</span>’in beklentisi ve varyansı ile
bağlantı kurar. Merkezi Limit Teorisi bir adım daha atar, ve der ki
“<span class="math inline">\(\bar{X}\)</span>’in dağılımı Gaussian
dağılım olmalıdır yani normal eğrisi şeklinde çıkmalıdır!’’. Teorinin
detayları bu bölümde bulunabilir.</p>
<p>Merkezi Limit Teorisi (Central Limit Theorem -CLT-)</p>
<p>Büyük Sayılar Kanunu örneklem ortalamasının gerçek nüfus beklentisine
yaklaşacağını ispatladı. Örneklem herhangi bir dağılımdan gelebiliyordu.
CLT bu teoriyi bir adım ilerletiyor ve diyor ki kendisi de bir rasgele
değişken olan örneklem ortalaması <span
class="math inline">\(\bar{X}\)</span> Normal dağılıma sahiptir! Daha
detaylandırmal gerekirse,</p>
<p>Diyelim ki <span class="math inline">\(X_1,..,X_i\)</span> örneklemi
birbirinden bağımsız, aynı dağılımlı ve ortalaması <span
class="math inline">\(\mu\)</span>, standart sapması <span
class="math inline">\(\sigma\)</span> olan (ki o da aynı dağılıma sahip)
bir nüfustan geliyorlar. Örneklem ortalaması <span
class="math inline">\(\bar{X}\)</span>, ki bu rasgele değişkenin
beklentisinin <span class="math inline">\(\mu\)</span>, ve (3)’e göre
standart sapmasının <span class="math inline">\(\sigma /
\sqrt{n}\)</span> olduğunu biliyoruz. Dikkat: <span
class="math inline">\(\bar{X}\)</span>’in kendisinden değil,
<em>beklentisinden</em> bahsediyoruz, BSK’deki aynı durum, yani ortalama
dağılımının ortalaması. Teori der ki <span
class="math inline">\(n\)</span> büyüdükçe <span
class="math inline">\(\bar{X}\)</span> dağılımı (bu sefer kendisi) bir
<span class="math inline">\(N(\mu, \sigma/\sqrt{n})\)</span> dağılımına
yaklaşır.</p>
<p>Bu ifade genelde standart normal olarak gösterilir, herhangi bir
normal dağılımı standart normal’e dönüştürmeyi daha önce görmüştük
zaten, beklentiyi çıkartıp standart sapmaya bölüyoruz, o zaman örneklem
dağılımı <span class="math inline">\(\bar{X}\)</span>,</p>
<p><span class="math display">\[ Z = \frac{\bar{X} - \mu}{\sigma /
\sqrt{n}} \]</span></p>
<p>dağılımına yaklaşır diyoruz, ki <span class="math inline">\(Z =
N(0,1)\)</span> dağılımıdır, beklentisi sıfır, standart sapması 1
değerindedir.</p>
<p>Bu teorinin ispatını şimdilik vermeyeceğiz.</p>
<p>Kaynaklar</p>
<p>[1] Wolfram Mathworld, <em>Maximum Likelihood</em>, <a
href="http://mathworld.wolfram.com/MaximumLikelihood.html">http://mathworld.wolfram.com/MaximumLikelihood.html</a></p>
<p>[2] <em>Introduction to Probability and Statistics Using R</em></p>
<p>[3] Bayramlı, Istatistik, <em>Monte Carlo, Entegraller, MCMC</em></p>
<p>
  <a href="..">Yukarı</a>
</p>
</body>
</html>
