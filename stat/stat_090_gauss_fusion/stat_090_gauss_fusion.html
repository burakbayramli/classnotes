<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
    <script type="text/x-mathjax-config">
    MathJax.Hub.Register.StartupHook("TeX Jax Ready",function () {
      MathJax.Hub.Insert(MathJax.InputJax.TeX.Definitions.macros,{
        cancel: ["Extension","cancel"], cancelto: ["Extension","cancel"]
      });
    });
    </script>  
   
  <title>Algılayıcı Birleştirimi, Füzyonu (Sensor Fusion)</title>
  <style type="text/css">code{white-space: pre;}</style>
  <style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
  </style>
  <script
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS_HTML-full"
  type="text/javascript"></script>
</head>
<body>
<div id="header">
</div>
<h1 id="algılayıcı-birleştirimi-füzyonu-sensor-fusion">Algılayıcı
Birleştirimi, Füzyonu (Sensor Fusion)</h1>
<p>Tek boyutlu ortamda bir büyüklüğü mesela bir lokasyon bilgisi <span
class="math inline">\(x\)</span>’i, iki kere ölçüyoruz, ve bu ölçümü iki
değişik algılayıcıya yaptırıyoruz, ve yine diyelim ki iki değişik alet
bir cismin olduğu uzaklığını / yerini bize geri döndürüyor. Devam
edelim, bu bilgilerde belli ölçüde gürültü var; bu aletlerin hatalı
ölçümü yüzünden olabilir, çevre şartları sebebiyle olabilir, örnek
olarak iki <span class="math inline">\(z_1,z_2\)</span> ölçümü için iki
değişik belirsizlik (uncertainty) olduğunu farzedelim, bunlar <span
class="math inline">\(\sigma_1,\sigma_2\)</span>. Soru şu: bu iki ölçümü
kullanarak daha iyi bir <span class="math inline">\(x\)</span> tahmini
yapabilir miyiz?</p>
<p>Bunun için iki ölçümü bir şekilde birleştirmemiz gerekiyor. Her
ölçümü Gaussian / Normal dağılım olarak modelleyebiliriz, o zaman iki
Gaussian dağılımı bir şekilde birleştirmemiz (fusion) lazım.</p>
<p>Ölçümleri temsil etmek için Gaussian biçilmiş kaftan. Ölçümdeki
belirsizliği standart sapma (standart deviation) üzerinden rahatlıkla
temsil edebiliriz. Peki birleştirimi nasıl yapalım?</p>
<p>Bu tür problemlerde maksimum olurluk (maximum likelihood)
kullanılması gerektiğini aşağı yukarı tahmin edebiliriz, çünkü maksimum
olurluk verinin olurluğunu (olasılığını yani) maksimize ederek
bilinmeyen parametreleri tahmin etmeye uğraşır. Çoğunlukla bu tekniği
hep <em>tek</em> bir dağılım bağlamında görürüz, bazı bilinmeyen
parametreleri olan tek bir dağılıma değişik veri noktaları verilerek
olasılık sonuçları çarpılır, ve elde edilen formül maksimize edilmeye
uğraşılırken aynı anda bilinmeyen parametrelerin optimal değerleri
saptanmaya uğraşılır. Bizim bu problemimizde iki değişik dağılım olacak,
maksimum olurluk illa tek bir dağılımla kullanılabilir diye bir kural
yok.</p>
<p>Problemimizde iki ölçümü, iki Gaussian ile temsil edebiliriz, ve bu
iki Gaussian’a verilen iki ölçüm noktasını olurluğunu bu Gaussian’ların
sonuçlarını çarparak hesaplayabiliriz. Peki bilinmeyen parametre nedir?
Onu da <em>her iki Gaussian için de aynı olduğunu farzettiğimiz orta
nokta</em> (mean) olarak alabiliriz, ve <span
class="math inline">\(x\)</span> olarak belirtiriz. Yani</p>
<p><span class="math display">\[ L(x) = p(z_1|x,\sigma_1)
p(z_2|x,\sigma_2) \]</span></p>
<p><span class="math display">\[ L(x) \sim
\exp{\frac{-(z_1-x)^2}{2\sigma_1^2} }
\times \exp \frac{-(z_2-x)^2}{2\sigma_2^2} \]</span></p>
<p>1D Gaussian formülünü hatırlarsak,</p>
<p><span class="math display">\[ p(z;x,\sigma) =
\frac{1}{\sigma\sqrt{2\pi}}
\exp \bigg\{ - \frac{(z-x)^2}{2\sigma^2}  \bigg\}
\]</span></p>
<p>Ders notları [1]’de iki üstteki formülün nasıl maksimize edilerek bir
<span class="math inline">\(x_{MLE}\)</span> formülüne erişildiğini
görebiliriz.</p>
<p>Formül başındaki sabit kısmının <span
class="math inline">\(L(x)\)</span>’de kullanılmadığını görüyoruz, çünkü
maksimizasyon açısından düşünürsek o kısım tekrar tekrar çarpılacak ve
hesaplamaya çalıştığımız değişkenler açısından bu sürekli tekrar bir
fark yaratmaz.</p>
<p>Bu metot işler. Fakat biz alternatif olarak daha temiz olacak değişik
bir yoldan gideceğiz. Elimizdeki her iki ölçümü iki farklı tek boyutlu
Gaussian yerine <em>2 boyutlu</em> tek bir Gaussian içine koyacağız, iki
ölçümü tek bir 2 boyutlu vektör içinde belirteceğiz yani, ve tek bir
olasılık hesabını <span class="math inline">\(p(z;x,\Sigma)\)</span>’i
baz alacağız. Belirsizlikler ne olacak? Ölçüm belirsizliklerini bu 2D
Gaussian’ın kovaryansında çapraza (diagonal) koyabiliriz, çapraz
dişindaki matris öğeleri sıfır yapılırsa iki ölçümün birbirinden
bağımsızlığını temsil etmiş oluruz. Maksimizasyon? Tek bir ölçümün
olurluğunu maksimize edeceğiz, bu tek bir ölçümün olasılığını
hesaplamaktan ibarettir, ve bu hesap sırasında bilinmeyen değişkenleri
içeren yeni bir formül ortaya çıkacaktır. Maksimize etmeye uğraşacağımız
bu formül olur.</p>
<p>Çok boyutlu Gaussian’ı hatırlayalım (artık <span
class="math inline">\(z,x\)</span> birer vektör),</p>
<p><span class="math display">\[ p(z;x,\Sigma) =
\frac{ 1}{(2\pi)^{k/2} \det(\Sigma)^{1/2}} \exp
\bigg\{
-\frac{ 1}{2}(z-x)^T\Sigma^{-1}(z-x)
\bigg\} \]</span></p>
<p>Kısaca,</p>
<p><span class="math display">\[ =  \frac{ 1}{C} \exp
\bigg\{
-\frac{ 1}{2}(z-x)^T\Sigma^{-1}(z-x)
\bigg\} \]</span></p>
<p>Bir numara, <span class="math inline">\(\exp\)</span> ve parantez içi
negatif ibareden kurtulmak için <span class="math inline">\(-\ln
p\)</span> alalım,</p>
<p><span class="math display">\[ L = -\ln p(z) =
\frac{ 1}{2}(z-x)^T\Sigma^{-1}(z-x)
\]</span></p>
<p>Şimdi iki ölçümü, belirsizliği vektör / matris öğeleri olarak
gösterelim,</p>
<p><span class="math display">\[ = \frac{1}{2}  
\left[\begin{array}{c}
z_1-x \\ z_2-x
\end{array}\right]^T
\left[\begin{array}{cc}
\sigma_1^2 &amp; 0 \\
0 &amp; \sigma_2^2
\end{array}\right]^{-1}
\left[\begin{array}{c}
z_1-x \\ z_2-x
\end{array}\right]
\]</span></p>
<p>Çapraz matrisin tersini almak için çaprazdaki öğelerin tersini almak
yeterlidir,</p>
<p><span class="math display">\[ = \frac{1}{2}  
\left[\begin{array}{c}
z_1-x \\ z_2-x
\end{array}\right]^T
\left[\begin{array}{cc}
\sigma_1^{-2} &amp; 0 \\
0 &amp; \sigma_2^{-2}
\end{array}\right]
\left[\begin{array}{c}
z_1-x \\ z_2-x
\end{array}\right]
\]</span></p>
<p><span class="math display">\[ = \frac{1}{2}  
\left[\begin{array}{cc}
\sigma_1^{-2}(z_1-x) &amp; \sigma_2^{-2} (z_2-x)
\end{array}\right]
\left[\begin{array}{c}
z_1-x \\ z_2-x
\end{array}\right]
\]</span></p>
<p><span class="math display">\[ =
\frac{1}{2}\sigma_1^{-2}(z_1-x)^2 + \frac{1}{2}\sigma_2^{-2} (z_2-x)^2
\]</span></p>
<p>Maksimize etmek için, formül karesel olduğuna göre, bilinmeyen <span
class="math inline">\(x\)</span> değişkenine göre türev alıp sıfıra
eşitleyebiliriz,</p>
<p><span class="math display">\[
\frac{dL}{dx} = \sigma_1^{-2}z_1-\sigma_1^{-2}x +
\sigma_2^{-2}z_2-\sigma_2^{-2}x = 0
\]</span></p>
<p><span class="math inline">\(x\)</span> üzerinden gruplarsak,</p>
<p><span class="math display">\[
-x(\sigma_1^{-2}+\sigma_2^{-2}) + \sigma_1^{-2}z_1+ \sigma_2^{-2}z_2 = 0
\]</span></p>
<p>Gruplanan kısmı eşitliğin sağına alalım,</p>
<p><span class="math display">\[
\sigma_1^{-2}z_1+ \sigma_2^{-2}z_2 = x(\sigma_1^{-2}+\sigma_2^{-2})
\]</span></p>
<p><span class="math display">\[
\frac{\sigma_1^{-2}z_1+ \sigma_2^{-2}z_2 }{\sigma_1^{-2}+\sigma_2^{-2}}=
x_{MLE}
\]</span></p>
<p>Gayet temiz bir şekilde sonuca eriştik.</p>
<p>Örnek</p>
<p>Elimizde belirsizlikleri <span
class="math inline">\(\sigma_1=10,\sigma_2=20\)</span> olan iki
algılayıcı var. Bu algılayıcılar aynı obje hakkında <span
class="math inline">\(z_1=130,z_2=170\)</span> olarak iki ölçüm
gönderiyorlar. Bu ölçümleri birleştirelim. Hatırlarsak <span
class="math inline">\(10^{-2}\)</span> ile çarpmak <span
class="math inline">\(10^{2}\)</span> ile bölmek aynı şey.</p>
<p><span class="math display">\[ x_{MLE} =
\frac{130/10^2 + 170/20^2}{1/10^2 + 1/20^2} = 138.0
\]</span></p>
<p>Sonuç belirsizliği daha az olan ölçüme daha yakın çıktı, bu akla
yatkın bir sonuç.</p>
<p>Çok Boyutlu Gaussian Füzyon</p>
<p>Peki ya elimizdeki ölçümlerin kendisi çok boyutlu ise? Yani <span
class="math inline">\(z_1,z_2\)</span> birer vektör ise?</p>
<p>Yine maksimum olurluk üzerinden bir formül türetebiliriz. Bu durumda
tek olasılık hesabı yetmez, iki ayrı dağılım olmalı,</p>
<p><span class="math display">\[ p(z_1;x,\Sigma_1) =  \frac{ 1}{C_1}
\exp
\bigg\{
-\frac{ 1}{2}(z_1-x)^T\Sigma_1^{-1}(z_1-x)
\bigg\} \]</span></p>
<p><span class="math display">\[ p(z_2;x,\Sigma_2) =  \frac{ 1}{C_2}
\exp
\bigg\{
-\frac{ 1}{2}(z_2-x)^T\Sigma_2^{-1}(z_2-x)
\bigg\} \]</span></p>
<p>Orta nokta <span class="math inline">\(x\)</span> her iki formülde
aynı çünkü değişmeyen olan o; aynı orta nokta için tahmin üretmeye
uğraşıyoruz. Bu durum bildik maksimum olurluk hesaplarına benziyor,
fakat ilk başta belirttiğimiz gibi farklı türden olasılık
fonksiyonlarının (bu sefer çok boyutlu) farklı veri noktaları üzerinden
çarpılması.</p>
<p>Devam edelim. Daha önce <span class="math inline">\(\ln\)</span>
alarak <span class="math inline">\(\exp\)</span>’yi yoketmiştik. Bunun
bir diğer faydası <span class="math inline">\(\ln\)</span> alınınca
çarpımların toplama dönüşmesidir,</p>
<p><span class="math display">\[ L = p(z_1;x,\Sigma_1) p(z_2;x,\Sigma_2)
\]</span></p>
<p><span class="math display">\[ -\ln L = -\ln p(z_1;x,\Sigma_1) -\ln
p(z_2;x,\Sigma_2)
\]</span></p>
<p><span class="math display">\[
\mathcal{L} =
-\ln L =
\frac{ 1}{2}(z_1-x)^T\Sigma_1^{-1}(z_1-x) +
\frac{ 1}{2}(z_2-x)^T\Sigma_2^{-1}(z_2-x)
\]</span></p>
<p>Şimdi eşitliğin sağ tarafının <span
class="math inline">\(x\)</span>’e göre türevini alalım, vektör ve
matris bağlamında türev nasıl alınır? Herhangi bir <span
class="math inline">\(M\)</span>’in simetrik olduğu durumlarda (ki
kovaryans matrisleri her zaman simetriktir, çünkü mesela iki değişkenli
durumda <span class="math inline">\(x_1,x_2\)</span> kovaryansı
-ilişkisi- <span class="math inline">\(x_2,x_1\)</span> kovaryansından
farklı olamaz),</p>
<p><span class="math display">\[ \frac{\partial}{\partial x}[x^TMx] =
2Mx \]</span></p>
<p>olduğunu biliyoruz [2]. O zaman türev sonucu şöyle olur,</p>
<p><span class="math display">\[
\frac{d\mathcal{L}}{dx} =
(z_1-x)^T\Sigma_1^{-1} +  (z_2-x)^T\Sigma_2^{-1}
\]</span></p>
<p>Sıfıra eşitleyip çözelim,</p>
<p><span class="math display">\[
(z_1-x)\Sigma_1^{-1} +  (z_2-x)\Sigma_2^{-1} = 0
\]</span></p>
<p><span class="math display">\[
z_1\Sigma_1^{-1} - x\Sigma_1^{-1} + z_2\Sigma_2^{-1} - x\Sigma_2^{-1} =
0
\]</span></p>
<p>Yine <span class="math inline">\(x\)</span> altında gruplayalım,</p>
<p><span class="math display">\[
-x(\Sigma_1^{-1} + \Sigma_2^{-1}) + z_1\Sigma_1^{-1}  +
z_2\Sigma_2^{-1}  = 0
\]</span></p>
<p><span class="math display">\[
z_1\Sigma_1^{-1}  + z_2\Sigma_2^{-1}  = x(\Sigma_1^{-1} + \Sigma_2^{-1})
\]</span></p>
<p>Eğer iki belirsizliğin toplamını <span
class="math inline">\(\Sigma_x^{-1}\)</span> olarak özetlersek, yani</p>
<p><span class="math display">\[
\Sigma_x^{-1} = \Sigma_1^{-1} + \Sigma_2^{-1}
\]</span></p>
<p>Not: Aslında <span class="math inline">\(\Sigma_x\)</span> te
diyebilirdik, fakat tersi alınmış matrislerin toplamı olduğunu temsil
etmesi için “tersi alınmış bir sembol’’ kullandık. Tabii diğer yandan
tersin tersini alınca ele geçecek <span
class="math inline">\(\Sigma_x\)</span>’in de bir anlamı olduğu iddia
edilebilir, bu <span class="math inline">\(\Sigma_x\)</span> en olası
<span class="math inline">\(x\)</span> tahmininin yeni belirsizliğidir
de bir bakıma.</p>
<p>Simdi ana formule donelim,</p>
<p><span class="math display">\[
z_1\Sigma_1^{-1}  + z_2\Sigma_2^{-1}  = x\Sigma_x^{-1}
\]</span></p>
<p><span class="math display">\[
\Sigma_x (z_1\Sigma_1^{-1}  + z_2\Sigma_2^{-1}) = x_{MLE}
\]</span></p>
<p>Örnek</p>
<p>Elimizde iki tane iki boyutlu ölçüm var,</p>
<p><span class="math display">\[ z_1 = \left[\begin{array}{c}
1 \\ 1
\end{array}\right],
z_2 = \left[\begin{array}{r}
2 \\ -1
\end{array}\right]
\]</span></p>
<p>Ölçümler iki değişik algılayıcıdan geliyor, belirsizlikleri</p>
<p><span class="math display">\[
\Sigma_1 =
\left[\begin{array}{cc}
1 &amp; 0 \\ 0 &amp; 4
\end{array}\right],
\Sigma_2 =
\left[\begin{array}{cc}
4 &amp; 0 \\ 0 &amp; 1
\end{array}\right]
\]</span></p>
<p>Nihai ölçüm nedir?</p>
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> mpl_toolkits.mplot3d <span class="im">import</span> Axes3D</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> matplotlib <span class="im">import</span> cm</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.mlab <span class="im">as</span> mlab</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.arange(<span class="op">-</span><span class="fl">10.0</span>, <span class="fl">10.0</span>, <span class="fl">0.1</span>)</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> np.arange(<span class="op">-</span><span class="fl">10.0</span>, <span class="fl">10.0</span>, <span class="fl">0.1</span>)</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>X, Y <span class="op">=</span> np.meshgrid(x, y)</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>Z1 <span class="op">=</span> mlab.bivariate_normal(X, Y, sigmax<span class="op">=</span><span class="fl">1.0</span>, sigmay<span class="op">=</span><span class="fl">4.0</span>,mux<span class="op">=</span><span class="fl">1.</span>, <span class="op">\</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>     muy<span class="op">=</span><span class="fl">1.</span>,sigmaxy<span class="op">=</span><span class="fl">0.0</span>)</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>Z2 <span class="op">=</span> mlab.bivariate_normal(X, Y, sigmax<span class="op">=</span><span class="fl">4.0</span>, sigmay<span class="op">=</span><span class="fl">1.0</span>,mux<span class="op">=</span><span class="fl">2.</span>, <span class="op">\</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>     muy<span class="op">=-</span><span class="fl">1.</span>,sigmaxy<span class="op">=</span><span class="fl">0.0</span>)</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="co"># iki yuzeyi ayni grafikte birlestirmek icin herhangi iki nokta arasinda</span></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="co"># daha fazla (maksimum) olani al, cunku nihai yuzey olarak onu gormek </span></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="co"># istiyoruz zaten</span></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>Z <span class="op">=</span> np.maximum(Z1,Z2)</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>fig <span class="op">=</span> plt.figure()</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>ax <span class="op">=</span> Axes3D(fig)</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>ax.view_init(elev<span class="op">=</span><span class="fl">50.</span>, azim<span class="op">=</span><span class="dv">80</span>)</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>ax.plot_surface(X,Y,Z,cmap<span class="op">=</span>cm.jet)</span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>plt.savefig(<span class="st">&#39;fusion_1.png&#39;</span>)</span></code></pre></div>
<p><img src="fusion_1.png" /></p>
<p>İki ölçümü Gaussian olarak ekrana bastık, bu Gaussian’ların orta
noktası <span class="math inline">\(z_1,z_2\)</span>, bu durumu maksimum
olurluk için aynı olduğunu farz ettiğimiz <span
class="math inline">\(x\)</span> ile karıştırmayalım; o <span
class="math inline">\(x\)</span> modelleme sırasında olduğunu
farzettiğimiz ideal bir Gaussian idi. Üstte sadece veri noktalarını
ekrana basıyoruz.</p>
<p>Üstten bakışla kontur (contour) olarak gösterirsek</p>
<div class="sourceCode" id="cb2"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>CS <span class="op">=</span> plt.contour(X, Y, Z1,rotation<span class="op">=</span><span class="dv">70</span>)</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>CS <span class="op">=</span> plt.contour(X, Y, Z2,rotation<span class="op">=</span><span class="dv">70</span>)</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>plt.savefig(<span class="st">&#39;fusion_3.png&#39;</span>)</span></code></pre></div>
<p><img src="fusion_3.png" /></p>
<p>Resimde önce ilk ölçüm, sonra onunla yanyana olacak ikinci ölçüm
koyulmuş.</p>
<p><span class="math display">\[ \Sigma_x^{-1} = \Sigma_1^{-1} +
\Sigma_2^{-1}  =
\left[\begin{array}{cc}
1 &amp; 0 \\ 0 &amp; 0.25
\end{array}\right] +
\left[\begin{array}{cc}
0.25 &amp; 0 \\ 0 &amp; 1
\end{array}\right] =
\left[\begin{array}{cc}
1.25 &amp; 0 \\ 0 &amp; 1.25
\end{array}\right]
\]</span></p>
<p>Tersini alalım</p>
<p><span class="math display">\[ \Sigma_x =
\left[\begin{array}{cc}
0.8 &amp; 0 \\ 0 &amp; 0.8
\end{array}\right]
\]</span></p>
<p><span class="math display">\[ x_{MLE} =  \Sigma_x
(z_1\Sigma_1^{-1}  + z_2\Sigma_2^{-1}) \]</span></p>
<p><span class="math display">\[
x_{MLE} =
\left[\begin{array}{cc}
0.8 &amp; 0 \\ 0 &amp; 0.8
\end{array}\right]
\bigg(
\left[\begin{array}{cc}
1 &amp; 0 \\ 0 &amp; 0.25
\end{array}\right]
\left[\begin{array}{c}
1 \\ 1
\end{array}\right]  +
\left[\begin{array}{cc}
0.25 &amp; 0 \\ 0 &amp; 1
\end{array}\right]
\left[\begin{array}{r}
2 \\ -1
\end{array}\right]  
\bigg) =
\left[\begin{array}{r}
1.2 \\ -0.6
\end{array}\right]  
\]</span></p>
<p>Sonuç grafiklenirse suna benzer (ki yeni belirsizlik <span
class="math inline">\(\Sigma_x\)</span>’i de grafikte kullanalım),</p>
<div class="sourceCode" id="cb3"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>Z3 <span class="op">=</span> mlab.bivariate_normal(X, Y, sigmax<span class="op">=</span><span class="fl">0.8</span>, sigmay<span class="op">=</span><span class="fl">0.8</span>,mux<span class="op">=</span><span class="fl">1.2</span>, <span class="op">\</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>     muy<span class="op">=-</span><span class="fl">0.6</span>,sigmaxy<span class="op">=</span><span class="fl">0.0</span>)</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>fig <span class="op">=</span> plt.figure()</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>ax <span class="op">=</span> Axes3D(fig)</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>ax.view_init(elev<span class="op">=</span><span class="fl">40.</span>,azim<span class="op">=</span><span class="dv">80</span>)</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>ax.plot_surface(X,Y,Z3,cmap<span class="op">=</span>cm.jet)</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>plt.savefig(<span class="st">&#39;fusion_2.png&#39;</span>)</span></code></pre></div>
<p><img src="fusion_2.png" /></p>
<p>Yeni tahminimiz böyle çıktı. Çok daha emin olduğumuz bir noktada en
olası ölçümü ortaya çıkardık. Kontur olarak grafiklersek,</p>
<div class="sourceCode" id="cb4"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>CS <span class="op">=</span> plt.contour(X, Y, Z3)</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>plt.savefig(<span class="st">&#39;fusion_4.png&#39;</span>)</span></code></pre></div>
<p><img src="fusion_4.png" /></p>
<p>[1] Zisserman, <em>Lectures 3 &amp; 4: Estimators</em>, <a
href="www.robots.ox.ac.uk/~az/lectures/est/lect34.pdf">www.robots.ox.ac.uk/~az/lectures/est/lect34.pdf</a></p>
<p>[2] Hart, Duda, <em>Pattern Classification</em></p>
<p>
  <a href="..">Yukarı</a>
</p>
</body>
</html>
