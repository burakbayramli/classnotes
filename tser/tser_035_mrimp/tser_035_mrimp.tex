\documentclass[12pt,fleqn]{article}\usepackage{../../common}
\begin{document}
Ortalamaya Dönüþ ile Ýþlem (Trading)

\begin{minted}[fontsize=\footnotesize]{python}
import statsmodels.formula.api as smf
import statsmodels.api as sm
import pandas as pd
df = pd.read_csv('gld_uso.csv')
cols = ['GLD','USO']
\end{minted}

Borsada ortalamaya dönüþ (mean-reversion) ile nasýl iþlem yapýlýr?  Daha
önce örnekleri gördük, Z-skoru yarattýk ve ona ters yönde iþlem
yaptýk. Altta bazý ek noktalar gösterilecek.

Lineer Regresyon ile bulunan yatýrým bölüþtürme oraný (hedge ratio) zaman
serisinin her aný için ``en iyi'' olmayabilir. Bu durumda yatýrýmcý belli
bir pencere üzerinden yakýn tarihe bakýp oraný sürekli tekrar tekrar
hesaplamayý seçebilir. Altta görülen kod bunu yapýyor,

\begin{minted}[fontsize=\footnotesize]{python}
import statsmodels.api as sm

lookback=20;
df['hedgeRatio'] = np.nan

for t in range(lookback,len(df)):
    x = np.array(df['GLD'])[t-lookback:t]
    x = sm.add_constant(x)
    y = np.array(df['USO'])[t-lookback:t]
    df.loc[t,'hedgeRatio'] = sm.OLS(y,x).fit().params[1]

yport = np.ones(df[cols].shape); yport[:,0] = -df['hedgeRatio']
yport = np.sum(yport,axis=1)
data_mean = pd.rolling_mean(yport, window=20)
data_std = pd.rolling_std(yport, window=20)
df['numUnits'] = -1*(yport-data_mean) / data_std
tmp1 = np.ones(df[cols].shape) * np.array([df['numUnits']]).T
tmp2 = np.ones(df[cols].shape); tmp2[:, 0] = -df['hedgeRatio']
positions = pd.DataFrame(tmp1 * tmp2 * df[cols])
pnl = positions.shift(1) * (df[cols] - df[cols].shift(1))  / df[cols].shift(1)
pnl = pnl.sum(axis=1)
ret=pnl / np.sum(np.abs(positions.shift(1)),axis=1)
print 'APR', ((np.prod(1.+ret))**(252./len(ret)))-1
print 'Sharpe', np.sqrt(252.)*np.mean(ret)/np.std(ret)
\end{minted}

\begin{verbatim}
APR 0.233190876207
Sharpe 1.12157265435
\end{verbatim}

Yýllýk getiri yüzde 23 Sharpe oraný 1.12. Fena deðil çünkü bu seri
koentegre bile deðil,

\begin{minted}[fontsize=\footnotesize]{python}
import sys; sys.path.append('../tser_coint')
import pyconometrics
print pyconometrics.cadf(np.matrix(df['GLD']).H,
                         np.matrix(df['USO']).H,0,1)

\end{minted}

\begin{verbatim}
{'adf': -1.5150247935770809, 'alpha': -0.003112483397873777,
'nlag': 1, 'crit': matrix([[-3.88031, -3.35851, -3.03798,
-1.01144, -0.65334,  0.15312]]), 'nvar': 1}
\end{verbatim}

Oran Kullanýmý

Eðer basit bir þekilde $y/x$ ile iki varlýðýný oranýný ``iþlem sinyali''
olarak kullansaydýk ne olurdu? Ayrýca diyelim ki her iki varlýða eþit para
yatýrýyoruz,

\begin{minted}[fontsize=\footnotesize]{python}
df['hedgeRatio'] = df['USO'] / df['GLD']
data_mean = pd.rolling_mean(df['hedgeRatio'], window=20)
data_std = pd.rolling_std(df['hedgeRatio'], window=20)
df['numUnits'] = -1*(df['hedgeRatio']-data_mean) / data_std
positions = df[['numUnits','numUnits']].copy()
positions = positions * np.array([-1., 1.])
pnl = positions.shift(1) * np.array((df[cols] - df[cols].shift(1))  
      / df[cols].shift(1))
pnl = pnl.fillna(0).sum(axis=1)
ret=pnl / np.sum(np.abs(positions.shift(1)),axis=1)
print 'APR', ((np.prod(1.+ret))**(252./len(ret)))-1.
print 'Sharpe', np.sqrt(252.)*np.mean(ret)/np.std(ret)
\end{minted}

\begin{verbatim}
APR -0.140673558863
Sharpe -0.749582932902
\end{verbatim}

\begin{minted}[fontsize=\footnotesize]{python}
plt.plot(np.cumprod(1+ret)-1)
plt.hold(False)
plt.savefig('tser_mrimp_01.png')
plt.hold(False)
\end{minted}

\includegraphics[height=6cm]{tser_mrimp_01.png}

Sonuç iyi deðil. 

Bollinger Bantlarý

Þimdiye kadar gösterilen lineer strateji basit: tek birimlik
duraðanlaþtýrýlmýþ portföy eðer piyasanýn yürüyen ortalama üzerinden olan
fiyatýn üzerine çýkmýþsa, bu çýkýþ oranýnda varlýk al, düþüþte satmaya
baþla. Bölüþtürme oraný iki kere kullanýlýyor yani, ilk önce yürüyen
ortalama fiyatlarýný birleþtirmek için, ve sonra en son piyasa fiyatlarýný
birleþtirmek için. Bu iki serinin birisi duraðan serinin son hali,
ortalamadan sapmayý bu ikinci serinin birincisine oranla ölçüyoruz. 

Bu strateji seçildi çünkü hiçbir dýþ parametre gerektirmeyen bir
strateji. Az parametre iyi bir þey, böylece aþýrý uygunluk (overfitting)
gibi problemlerden biraz daha uzaklaþmýþ oluyoruz (parametreler geçmiþ
veriye aþýrý iyi uyuyor, bu sebeple geleceði tahmin yeteneði kayboluyor). 

Bollinger bantlarý üstteki stratejinin bir uzantýsý, yine ortalamadan
uzaklaþýnca pozisyona giriyoruz, fakat bu uzaklaþmanýn kaç standart sapma
oranýnda olduðuna bakýyoruz. Mesela uzaklaþma 1 standart sapma oranýndan
fazla ise girebiliriz, 0 standart sapma oranýnda ise (yani ortalama
üzerinde) pozisyondan çýkarýz (bu parametre isimleri sýrasýyla
\verb!entryZscore!, \verb!exitZscore!. Ya da \verb!entryZscore=1!,
\verb!exitZscore=-1! diyebilirdik, bu durumda üstte ve altta 1 standart
sapmadan fazla olduðu zaman alým, satým olurdu.

\begin{minted}[fontsize=\footnotesize]{python}
lookback=20;

df['hedgeRatio'] = np.nan
for t in range(lookback,len(df)):
    x = np.array(df['GLD'])[t-lookback:t]
    x = sm.add_constant(x)
    y = np.array(df['USO'])[t-lookback:t]
    df.loc[t,'hedgeRatio'] = sm.OLS(y,x).fit().params[1]   
\end{minted}

\begin{minted}[fontsize=\footnotesize]{python}
cols = ['GLD','USO']

yport = np.ones(df[cols].shape)
yport[:,0] = -df['hedgeRatio']
yport = yport * df[cols]
yport = yport[cols].sum(axis=1)

data_mean = pd.rolling_mean(yport, window=20)
data_std = pd.rolling_std(yport, window=20)
zScore=(yport-data_mean)/data_std

entryZscore=1.
exitZscore=0

longsEntry=zScore < -entryZscore
longsExit=zScore > -exitZscore
shortsEntry=zScore > entryZscore
shortsExit=zScore < exitZscore

numUnitsLong = pd.Series([np.nan for i in range(len(df))])
numUnitsShort = pd.Series([np.nan for i in range(len(df))])
numUnitsLong[0] = 0.
numUnitsShort[0] = 0.

numUnitsLong[longsEntry] = 1.0
numUnitsLong[longsExit] = 0.0
numUnitsLong = numUnitsLong.fillna(method='ffill')

numUnitsShort[shortsEntry] = -1.0
numUnitsShort[shortsExit] = 0.0
numUnitsShort = numUnitsShort.fillna(method='ffill')
df['numUnits'] = numUnitsShort + numUnitsLong

tmp1 = np.ones(df[cols].shape) * np.array([df['numUnits']]).T
tmp2 = np.ones(df[cols].shape); tmp2[:, 0] = -df['hedgeRatio']
positions = pd.DataFrame(tmp1 * tmp2 * df[cols])
pnl = positions.shift(1) * (df[cols] - df[cols].shift(1))  / df[cols].shift(1)
pnl = pnl.sum(axis=1)
ret=pnl / np.sum(np.abs(positions.shift(1)),axis=1)
ret=ret.fillna(0)
print 'APR', ((np.prod(1.+ret))**(252./len(ret)))-1
print 'Sharpe', np.sqrt(252.)*np.mean(ret)/np.std(ret)
\end{minted}

\begin{verbatim}
APR 0.197715854801
Sharpe 1.06408761242
\end{verbatim}

\begin{minted}[fontsize=\footnotesize]{python}
plt.plot(np.cumprod(1+ret)-1)
plt.hold(False)
plt.title(u'Kümülatif Birleþik Getiri')
plt.savefig('tser_mrimp_02.png')
plt.hold(False)
\end{minted}

\includegraphics[height=6cm]{tser_mrimp_02.png}

Kalman Filtreleri ile Dinamik Lineer Regresyon

Gerçekten koentegre halinde olan iki fiyat zaman serisi için yapýlacaklar
basit - bulabildiðin kadar tarihi veri bul, basit lineer regresyon ya da
Johansen test kullanarak özvektörleri bul. Fakat diðer yazýlarda gördüðümüz
gibi pür koentegresyon çok az sayýda fiyat zaman serisinin eriþebildiði bir
mertebe. O zaman, zamana göre deðiþebilecek yatýrým bölüþtürme oranýný
(hedge ratio) nasýl hesaplayacaðýz? Diðer örneklerde gördük, bir geriye
bakýþ penceresi kararlaþtýr, ve oraný sadece bu pencere içindeki tarihe
veriden hesapla. Bu yaklaþýmýn dezavantajý, eðer pencere ufak ise pencere
kaydýrýldýkça yatýrým oraný aþýrý sapmalar gösterebilmesi. Ayný durum
ortalamayý ve standard sapma için yürüyen ortalama ve yürüyen sapma
kullanýrken de ortaya çýkacak. O zaman eðer en sondaki verilere
öncekilerden daha fazla aðýrlýk veren, ve kullanýcýnýn kafasýndan attýðý
bir baþlangýç noktasýna göre pencere oluþturmayan bir yöntem olsa bu bir
ilerleme olurdu. Yatýrým bölüþtürme oranýný Kalman filtresi (KF) kullanarak
hesaplayarak bu ilerlemeyi saðlamayý umuyoruz [1, sf 74].

KF hakkýnda detaylar [2] yazýsýnda bulunabilir; KF formüllerinin
türetilmesi orada anlatýldý. Bu yazýda gereken bölüþtürme oraný, ve yan
ürün olarak bu oranýn ortalamasýný ve uçuculuðunu (volatility) hesaplamak,
o zaman gizli deðiþken bölüþtürme oraný $\beta$, görünen (observable)
deðiþken ise fiyat zaman serisi $y$ olacak, yani daha önce basit lineer
regresyona $y$ olarak verilen fiyat serisi. Tüm KF modeli,

$$ \beta_t = I \cdot \beta_{t-1} + \omega_{t-1}$$

$$ y_t = x_t \beta_t + \epsilon_t $$

$\omega_{t-1},\epsilon_t$ Gaussian gürültü olmak üzere. 

Yukarýda ilginç birkaç ``numara'' yapýldý; aslýnda her iki seriyi de, hem
$x$'i, hem $y$'yi biliyoruz, yani onlar ``görünüyor''. Ama yapmak
istediðimiz numara baðlamýnda onlardan sadece birini görünen yaptýk, ayrýca
gizli deðiþkeni $\beta$ yaptýk, genellikle bu tür bir parametre gizli
deðiþkeni transforme eden matris olarak ele alýnýrdý. Görünen tek veri ise
modele göre $y$. Bu durumda $x$ gizli deðiþkeni transforme eden matris gibi
kullanýlýyor, bu da ilginç. 

Üstteki formüllerden birincisi geçiþ (transition) formülü, ve biz eldeki
tüm verileri temsil eden tek bir $\beta$ aradýðýmýz için bu $\beta$'nin
deðiþmediðini modele söylüyoruz, bu sebeple geçiþ matrisi $I$, yani birim
matris, bu matris çarpýmda hiçbir etki yaratmýyor.

\inputminted[fontsize=\footnotesize]{python}{kf.py}

\begin{minted}[fontsize=\footnotesize]{python}
import pandas as pd, kf
ewdf = pd.read_csv('../tser_coint/ETF.csv')

x = ewdf[['ewa']].copy()
y = ewdf[['ewc']].copy()
x['intercept'] = 1.

x = np.array(x)
y = np.array(y)

beta, e, Q = kf.kalman_filter(x,y)
\end{minted}

\begin{minted}[fontsize=\footnotesize]{python}
plt.plot(beta[0, :].T)
plt.hold(True)
plt.title('EWC(y) ve EWA(x) Arasýndaki Eðim - Beta[0,t]')
plt.savefig('tser_mrimp_03.png')
plt.hold(False)
\end{minted}

\includegraphics[height=6cm]{tser_mrimp_03.png}

\begin{minted}[fontsize=\footnotesize]{python}
plt.plot(beta[1, :].T)
plt.hold(True)
plt.title('Kesi, Beta[1,t]')
plt.savefig('tser_mrimp_04.png')
plt.hold(False)
\end{minted}

\includegraphics[height=6cm]{tser_mrimp_04.png}

Bu modelin güzel yan etkilerinden biri þu oldu: KF'in doðal olarak
hesapladýðý parametreler ile direk bir ortalamaya-dönüþ stratejisi
kodlayabiliriz. $e_t$ içinde ölçüm tahmin hatasý var, ki bu hata
EWC-EWA'nýn tahmin edilen ortalamasýndan sapmasýndan baþka bir þey
deðil. Bu sapmayý satýn alýrýz, eðer çok pozitif ise al-tut yaparýz, çok
negatif ise açýða satýþ. Çok pozitif, çok negatif neye göre belirlenir? Bu
da $e_t$'nin tahmin edilen standart sapmasýndan baþka bir þey deðil, ki bu
bilgi de $\sqrt{Q_t}$ içinde! Her iki parametreyi grafiklersek alttaki
görüntü çýkýyor.

\begin{minted}[fontsize=\footnotesize]{python}
plt.plot(e[2:], 'r')
plt.hold(True)
plt.plot(np.sqrt(Q[2:]))
plt.hold(True)
plt.savefig('tser_mrimp_05.png')
plt.hold(False)
\end{minted}

\includegraphics[height=6cm]{tser_mrimp_05.png}

Geri kalanlar daha önce Bollinger bantlarýnda gördüðümüz gibi.

\begin{minted}[fontsize=\footnotesize]{python}
cols = ['ewa','ewc']
y2 = ewdf[cols]

longsEntry=e < -1*np.sqrt(Q)
longsExit=e > -1*np.sqrt(Q)

shortsEntry=e > np.sqrt(Q)
shortsExit=e < np.sqrt(Q)

numUnitsLong = pd.Series([np.nan for i in range(len(ewdf))])
numUnitsShort = pd.Series([np.nan for i in range(len(ewdf))])
numUnitsLong[0]=0.
numUnitsShort[0]=0.

numUnitsLong[longsEntry]=1.
numUnitsLong[longsExit]=0
numUnitsLong = numUnitsLong.fillna(method='ffill')

numUnitsShort[shortsEntry]=-1.
numUnitsShort[shortsExit]=0
numUnitsShort = numUnitsShort.fillna(method='ffill')

ewdf['numUnits']=numUnitsLong+numUnitsShort

tmp1 = np.tile(np.matrix(ewdf.numUnits).T, len(cols))
tmp2 = np.hstack((-1*beta[0, :].T,np.ones((len(ewdf),1))))
positions = np.array(tmp1)*np.array(tmp2)*y2
positions = pd.DataFrame(positions)

tmp1 = np.tile(np.matrix(ewdf.numUnits).T, len(cols))
tmp2 = np.hstack((-1*beta[0, :].T,np.ones((len(ewdf),1))))
positions = np.array(tmp1)*np.array(tmp2)*y2

positions = pd.DataFrame(positions)

tmp1 = np.array(positions.shift(1))
tmp2 = np.array(y2-y2.shift(1))
tmp3 = np.array(y2.shift(1))
pnl = np.sum(tmp1 * tmp2 / tmp3,axis=1)
ret = pnl / np.sum(np.abs(positions.shift(1)),axis=1)
ret = ret.fillna(0)
print 'APR', ((np.prod(1.+ret))**(252./len(ret)))-1
print 'Sharpe', np.sqrt(252.)*np.mean(ret)/np.std(ret)
\end{minted}

\begin{verbatim}
APR 0.262251943494
Sharpe 2.36194908518
\end{verbatim}

ETF ve ETF'in Öðe Hisseleri Arasýnda Arbitraj

Bir ETF ve onu oluþturan öðe hisseler arasýnda da arbitraj fýrsatlarý
vardýr. Bu portföyü oluþturmak için her öðe hisse ile ETF arasýnda teker
teker koentegrasyon aranýr, diðerleri atýlýr. Bu örneði dünyanýn belki de
en ünlü ETF'i üzerinde göstereceðiz. Standart \& Poors endeksini baz alan
SPY.

Tarihi veri olarak Ocak 1, 2007 ile Aralýk 31, 2007 arasýný seçtik, bu
aralýktaki SPY öðelerinin SPY'in kendisi ile en az yüzde 90 koentegre olma
þartýný Johansen testi ile kontrol edeceðiz. Ardýndan bu seçilen senetlerin
her birine eþit sermaye ayýracaðýz, ve tüm portföy üzerinde tekrar Johansen
testi uygulayýp hala koentegre olup olmadýðýný kontrol edeceðiz. Bu ikinci
test lazým çünkü her öðeye verilen kafamýza göre verdiðimiz (burada eþit)
sermaye aðýrlýðý üzerinden oluþturulmuþ portföyün illa koentegre olacaðý
gibi bir þart yoktur. Bu ikinci test için log fiyat kullanacaðýz, çünkü bu
portföyü her gün tekrar dengeleyeceðimizi bekliyoruz, yani senet miktarý
üzerinden deðil sermaye seviyesini sabit tutacaðýz. 

\begin{minted}[fontsize=\footnotesize]{python}
import pandas as pd, zipfile

with zipfile.ZipFile('SPY3.zip', 'r') as z:
    dfspy3 =  pd.read_csv(z.open('SPY3.csv'),sep=',')

dfspy3 = dfspy3.set_index('Date')
train = dfspy3[(dfspy3.index>=20070101) & (dfspy3.index<=20071231)]
testspy3 = dfspy3[(dfspy3.index > 20071231)]
resdf = pd.DataFrame(index=dfspy3.columns)
resdf['isCoint'] = np.nan

import sys; sys.path.append('../tser_coint')
from johansen import coint_johansen, print_johan_stats

for s in dfspy3.columns: 
   if s == 'SPY': continue
   # johansen cagrisini kullaniyoruz boylece y,x hangisi secmemiz 
   # gerekmiyor
   data = train[[s,'SPY']].dropna()
   if len(data) < 250: continue
   res = coint_johansen(data, 0, 1)
   if res.lr1[0] > res.cvt[0][0]: 
       resdf.loc[s,'isCoint'] = True
print resdf.isCoint.sum()
\end{minted}

\begin{verbatim}
98
\end{verbatim}

98 tane senet koentegre imiþ. Þimdi bu senetlerle portföy oluþturalým, ve
tekrar koentegrasyon testi yapalým,

\begin{minted}[fontsize=\footnotesize]{python}
coint_cols = list(resdf[resdf.isCoint==True].index)
yN = train[coint_cols]
logMktVal_long = np.log(yN).sum(axis=1)
ytest = pd.concat([logMktVal_long, np.log(train.SPY)],axis=1)
res = coint_johansen(ytest, 0, 1)
print_johan_stats(res)
\end{minted}

\begin{verbatim}
trace statistic [ 15.86864835   6.19735725]
critical vals %90,%95,%99
r<=0 [ 13.4294  15.4943  19.9349]
r<=1 [ 2.7055  3.8415  6.6349]

eigen statistic [ 9.6712911   6.19735725]
critical values  %90,%95,%99
r<=0 [ 12.2971  14.2639  18.52  ]
r<=1 [ 2.7055  3.8415  6.6349]

ozdegerler [ 0.0380959   0.02458181]

ozvektorler

[[   1.09386171   -0.27989806]
 [-105.55999232   56.09328286]]
\end{verbatim}

\begin{minted}[fontsize=\footnotesize]{python}
tmp1 = np.ones((len(testspy3),resdf.isCoint.sum()))*res.evec[0,0]
tmp2 = np.ones((len(testspy3),1))*res.evec[1,0]
weights = np.hstack((tmp1,tmp2))
yNplus = testspy3[coint_cols + ['SPY']]
logMktVal = np.sum(weights * np.log(yNplus),axis=1)
lookback=5
data_mean = pd.rolling_mean(logMktVal, window=lookback)
data_std = pd.rolling_std(logMktVal, window=lookback)
numUnits = -1*(logMktVal-data_mean) / data_std

numUnits2 = np.reshape(numUnits, (len(numUnits),1))
positions = pd.DataFrame(np.tile(numUnits2, weights.shape[1]),\
                        columns=yNplus.columns)*weights
tmp1 = np.log(yNplus)-np.log(yNplus.shift(1))
pnl = np.sum(np.array(positions.shift(1)) * np.array(tmp1), axis=1)
ret = pnl / np.sum(np.abs(positions.shift(1)),axis=1)
print 'APR', ((np.prod(1.+ret))**(252./len(ret)))-1
print 'Sharpe', np.sqrt(252.)*np.mean(ret)/np.std(ret)
\end{minted}

\begin{verbatim}
APR 0.0449298745128
Sharpe 1.32310985261
\end{verbatim}

Sonuç ilk deneme için fena sayýlmaz; Bazý basit ilerlemeler mümkündür,
mesela her zaman aralýðý için portföyü oluþturan senetleri deðiþtirmek.

\begin{minted}[fontsize=\footnotesize]{python}
plt.plot(np.cumprod(1+ret)-1)
plt.hold(True)
plt.savefig('tser_mrimp_06.png')
plt.hold(False)
\end{minted}

\includegraphics[height=6cm]{tser_mrimp_06.png}

Trendli Ortalamaya Dönüþ

Bir tane de benden. Finans zaman serilerinin çoðunlukla bir trend'e dönüþ
yaptýðýný görebiliriz. Eðer bu trend'i çýkartýrsak geriye kalan nedir?
Ortalamaya dönüþ yapan, duraðan bir zaman serisi deðil mi? S\&P 500 üzerinde
görelim,

\begin{minted}[fontsize=\footnotesize]{python}
import pandas as pd
df = pd.read_csv('../tser_draw_sharpe/SPY.csv',index_col='Date',parse_dates=True)
df['SPY'] = df[['Adj Close']]
df = df[df.index < '2005-01-01']
df.SPY.plot()
plt.savefig('tser_mrimp_07.png')
\end{minted}

\includegraphics[height=6cm]{tser_mrimp_07.png}

Belli noktalarda geriye dönerek belli bir pencere içindeki zaman seri parçasý
üzerinde lineer regresyon uyguluyoruz. Daha sonra bu uydurduðumuz çizgiyi ileri
dönük tahmin olarak kullanýyoruz, bu tahminin altýna düþüþlerde alým, yukarý
çýkýþlarda satým yapýyoruz. 

\begin{minted}[fontsize=\footnotesize]{python}
import statsmodels.api as sm
lookback = 100; forward = 30
forward_points = range(lookback, len(df), forward)
#print forward_points

x = np.ones((lookback,2))
x[:,1] = np.array(range(lookback))

for t in forward_points:    
    y = df.SPY[t-lookback:t]
    f = sm.OLS(y,x).fit()
    df.loc[df.index[t],'intercept'] = f.params[0]
    df.loc[df.index[t],'slope'] = f.params[1]
    #print t, f.params[0], f.params[1]
    
df['ols'] = np.nan
x_lookback = np.array(range(lookback))
for t in forward_points:
   y = x_lookback * df.ix[t].slope + df.ix[t].intercept
   df.loc[t-lookback:t,'ols'] = y
df[['SPY','ols']].plot()
plt.savefig('tser_mrimp_08.png')
\end{minted}

\includegraphics[height=8cm]{tser_mrimp_08.png}

Trend'i çýkartýnca geriye kalanýn hakikaten duraðan olduðunu görelim,

\begin{minted}[fontsize=\footnotesize]{python}
df['MR'] = df.SPY - df.ols
df.MR.plot()
plt.savefig('tser_mrimp_09.png')
\end{minted}

\includegraphics[height=6cm]{tser_mrimp_09.png}

\begin{minted}[fontsize=\footnotesize]{python}
win=5
data_mean = pd.rolling_mean(df.MR, window=win)
data_std = pd.rolling_std(df.MR, window=win)
df['mktVal'] = -1*(df.MR-data_mean) / data_std
pnl = df['mktVal'].shift(1) * (df['MR']-df['MR'].shift(1))/ df['MR'].shift(1)
ret=pnl.fillna(0) / np.sum(np.abs(df['mktVal'].shift(1)))
print 'APR', ((np.prod(1.+ret))**(252./len(ret)))-1.
print 'Sharpe', np.sqrt(252.)*np.mean(ret)/np.std(ret)
\end{minted}

\begin{verbatim}
APR 0.280181769408
Sharpe 0.888414859744
\end{verbatim}


Kaynaklar

[1] Chan, {\em Algorithmic Trading}

[2] Bayramli, Fizik, {\em Kalman Filtreleri}

\end{document}
