<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
  <title></title>
  <style type="text/css">code{white-space: pre;}</style>
  <style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
  </style>
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>
  
  
  
  
</head>
<body>
<h1 id="sezonsallık-periyotlar">Sezonsallık, Periyotlar</h1>
<p>Zaman serilerini trendini, sezonsallığını nasıl inceleriz, ve trendde değişim varsa bunu nasıl yakalarız?</p>
<p>Bir örnek üzerinde görelim, bir şirketin şampuan satış kazancı, veri [1]'den,</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="im">import</span> pandas <span class="im">as</span> pd
<span class="kw">def</span> parser(x):
    <span class="cf">return</span> pd.datetime.strptime( <span class="st">&#39;190&#39;</span><span class="op">+</span>x, <span class="st">&#39;%Y-%m&#39;</span> )
    
df <span class="op">=</span> pd.read_csv(<span class="st">&#39;shampoo-sales.csv&#39;</span>, header<span class="op">=</span><span class="dv">0</span>, index_col<span class="op">=</span><span class="dv">0</span>, <span class="op">\</span>
     parse_dates<span class="op">=</span><span class="va">True</span>, date_parser<span class="op">=</span>parser)
df.Satis.plot()
plt.savefig(<span class="st">&#39;tser_022_de_07.png&#39;</span>)</code></pre></div>
<div class="figure">
<img src="tser_022_de_07.png" />

</div>
<p>Yukarı doğru bir trend var. Bu trendi veriye bir düz çizgi uydurarak (fit), yani tek değişkenli, ikinci derece lineer regresyon yaparak yakalayabiliriz. Bunu yapmayı pek çok diğer derste gösterdik, <code>statsmodels.regression</code> paketinden, <code>linear_model.OLS</code> ile, <code>statsmodels.formula.api</code> ile, ya da direk Lineer Cebir kullanarak.. Altta <code>polyfit</code> çağrısı kullanılacak.</p>
<p>Modelden gelen katsayıları (coefficients) kullanıp tahmini <span class="math inline">\(y\)</span> değerleri üretmek için alttaki fonksiyon var,</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="kw">def</span> model_compute(X, coef):
   degree <span class="op">=</span> <span class="bu">len</span>(coef)<span class="op">-</span><span class="dv">1</span>
   curve <span class="op">=</span> [np.<span class="bu">sum</span>([coef[<span class="op">-</span><span class="dv">1</span>]] <span class="op">+</span> [x<span class="op">**</span>(degree<span class="op">-</span>d)<span class="op">*</span>c <span class="cf">for</span> d,c <span class="op">\</span>
            <span class="kw">in</span> <span class="bu">enumerate</span>(coef[:<span class="op">-</span><span class="dv">1</span>])]) <span class="cf">for</span> x <span class="kw">in</span> X]
   <span class="cf">return</span> curve</code></pre></div>
<p>Uydurmayı yapıp modeli veri üzerinde gösterelim,</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">X <span class="op">=</span> np.array(<span class="bu">range</span>(<span class="bu">len</span>(df))).reshape(<span class="op">-</span><span class="dv">1</span>)
y <span class="op">=</span> df.values.reshape(<span class="op">-</span><span class="dv">1</span>)
degree <span class="op">=</span> <span class="dv">1</span>
coef <span class="op">=</span> np.polyfit(X, y, degree)
df[<span class="st">&#39;Model&#39;</span>]  <span class="op">=</span> model_compute(X, coef)
df.plot()
plt.savefig(<span class="st">&#39;tser_022_de_01.png&#39;</span>)</code></pre></div>
<div class="figure">
<img src="tser_022_de_01.png" />

</div>
<p>Veriden &quot;trendi çıkartabiliriz''. Bunu basit bir şekilde veriden modeli eksilterek yapabiliriz. Bu durumda geriye kalan sadece trend haricinde olan şeyler olacaktır. Trend çıkartmanın pek çok amacı olabilir, belki trend haricinde olan kalıpları, eğer hala varsa, görmek istiyoruz, ya da modelin artığına (residual) bakarak onun gürültü olup olmadığını anlamak istiyoruz. Bilindiği gibi lineer regresyonun faraziyesi verinin model artı gürültü olduğudur, o zaman model veriden çıkartılınca geriye kalan artık, &quot;tortu'' sadece gürültüdür. Gürültünün matematiksel tanımı Gaussian, ya da Normal dağılımıdır, demek ki artıklar üzerinde normallik testi bir anlamda modelin uyma başarısını da ölçer.</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">detrended <span class="op">=</span> df.Satis<span class="op">-</span>df.Model
detrended.plot()
plt.savefig(<span class="st">&#39;tser_022_de_03.png&#39;</span>)</code></pre></div>
<div class="figure">
<img src="tser_022_de_03.png" />

</div>
<p>Normallik testini uygulayalım,</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="im">from</span> scipy <span class="im">import</span> stats
val,pval <span class="op">=</span> stats.shapiro(detrended)
<span class="bu">print</span> (<span class="st">&#39;p degeri =&#39;</span>, pval)</code></pre></div>
<pre><code>p degeri = 0.09782794862985611</code></pre>
<p>Shapiro-Wilk testinde p-değerinin 0.05'ten küçük olması normalliğin reddedilmesi demektir. Üstte normal olmadığın reddedemedik, demek ki büyük ihtimalle elimizde bir Normal dağılım var.</p>
<p>Sezonsallık</p>
<p>Benzer bir şekilde sezonsallığı da modelleyebiliriz. Sezonsallık bir periyotsallığı ima eder, o zaman en genel şekilde bir sinüs fonksiyonunu veriye uydurabiliriz. Fakat bu sinüs fonksiyonunun benliğini, başlangıç noktasını bilmiyoruz, bu durumlarda [6]'da sinüssel regresyon tekniğini gördük. Fakat belki de daha rahatı veriye bir 4'üncü derece polinom uydurmaktır.</p>
<p>Bu garip gelebilir, polinom uydurmayı çoğunlukla ikinci, üçüncü derecede eğrileri modelleyen çerçevede görmüş olabiliriz, bu yaklaşım fakat periyotsal fonksiyonları da çok rahat temsil edebiliyor. Sebebi herhalde sinüs fonsiyonunun Taylor açılımında [3] gizli, Taylor açılımında sonsuza kadar giden türevler polinom açılımda kullanılır, sinüsün 1'den 4'e kadar olan türevlerine bakarsak,</p>
<p><span class="math inline">\(\sin^{\prime}(x)=\cos(x),\quad\)</span> <span class="math inline">\(\sin^{\prime\prime}(x)=-\sin(x),\quad\)</span>, <span class="math inline">\(\sin^{\prime\prime\prime}(x)=-\cos(x),\quad\)</span>, <span class="math inline">\(\sin^{(4)}(x)=\sin(x)\)</span>.</p>
<p>Dördüncü türevin tekrar <span class="math inline">\(\sin(x)\)</span>'a dönüş yaptığını görüyoruz. Demek ki 4'üncü derece polinom açılımı periyotsal fonksiyonları temsil etmek için yeterlidir.</p>
<p>Altta bir bölgeden alınmış günlük, o günün minimum hava sıcaklığı ölçümlerini görüyoruz. Ona modeli uyduralım,</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="im">import</span> pandas <span class="im">as</span> pd
df <span class="op">=</span> pd.read_csv(<span class="st">&#39;daily-min-temperatures.csv&#39;</span>, header<span class="op">=</span><span class="dv">0</span>,<span class="op">\</span>
                 index_col<span class="op">=</span><span class="dv">0</span>, parse_dates<span class="op">=</span><span class="va">True</span>)
X <span class="op">=</span> [i<span class="op">%</span><span class="dv">365</span> <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">0</span>, <span class="bu">len</span>(df))]
y <span class="op">=</span> df.values
degree <span class="op">=</span> <span class="dv">4</span>
coef <span class="op">=</span> np.polyfit(X, y, degree)
df[<span class="st">&#39;Model&#39;</span>]  <span class="op">=</span> model_compute(X, coef)
df.plot()
plt.savefig(<span class="st">&#39;tser_022_de_02.png&#39;</span>)</code></pre></div>
<div class="figure">
<img src="tser_022_de_02.png" />

</div>
<p>Periyotsallık yakalanmış gibi duruyor. Sezonsallığı veriden çıkartalım,</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">deseasoned <span class="op">=</span> df.Temp<span class="op">-</span>df.Model
deseasoned.plot()
plt.savefig(<span class="st">&#39;tser_022_de_04.png&#39;</span>)</code></pre></div>
<div class="figure">
<img src="tser_022_de_04.png" />

</div>
<p>Artıklar üzerinde normallik testi,</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="im">from</span> scipy <span class="im">import</span> stats
val,pval <span class="op">=</span> stats.shapiro(deseasoned)
<span class="bu">print</span> (<span class="st">&#39;p degeri =&#39;</span>, pval)</code></pre></div>
<pre><code>p degeri = 4.155807920014354e-10</code></pre>
<p>Normal değil. Bunun sebebi veri içinde birden fazla sezonsallık, ya da başka bir örüntünün hala mevcut olması olabilir. Bu senaryoları test etmek ödev olsun.</p>
<p>Sinüssel Regresyon (Sinusoidal Regression)</p>
<p>Alttaki veriye bir veya birden fazla sinüs eğrisi uydurmak istiyoruz.</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="im">import</span> pandas <span class="im">as</span> pd
df <span class="op">=</span> pd.read_csv(<span class="st">&#39;baltic.csv&#39;</span>)
df.plot(x<span class="op">=</span><span class="st">&#39;toy&#39;</span>,y<span class="op">=</span><span class="st">&#39;degs&#39;</span>,kind<span class="op">=</span><span class="st">&#39;scatter&#39;</span>)
plt.savefig(<span class="st">&#39;tser_sinreg_01.png&#39;</span>)</code></pre></div>
<div class="figure">
<img src="tser_sinreg_01.png" />

</div>
<p>Fakat sinüs eğrisini, tek sinüs eğrisi olduğu durumda bile, nasıl yana kaydırarak tam doğru noktayı bulacağız? Ayrıca eğrinin genliği (amplitude) önemli. Tüm bunları kapsayan formül</p>
<p><span class="math display">\[ f(x) = A \sin (x+\varphi) \]</span></p>
<p>Genlik <span class="math inline">\(A\)</span> ile faz ise <span class="math inline">\(\varphi\)</span> ile gösterilmiş, öyle bir <span class="math inline">\(A,\varphi\)</span> bulalım ki sonuç sinüs eğrisi tam veriye uysun. Veriye uydurma deyince akla lineer regresyon geliyor, fakat üstteki formülü olduğu gibi regresyona sokmak mümkün değil, çünkü faz kaydırmak için <span class="math inline">\(\sin\)</span> içindeki parametrenin değişmesi lazım, regresyon bunları yapamaz. Ama regresyona problemi `katsayı çarpı basit formül'' şeklinde sunabilir miyiz acaba? Bir trigonometrik eşitlikten biliyoruz ki</p>
<p><span class="math display">\[  A \sin (x+\varphi) = a\sin(x) + b\cos(x) \]</span></p>
<p>ki <span class="math inline">\(\sin\varphi = \frac{b}{\sqrt{a^2+b^2}}\)</span>, ve <span class="math inline">\(A = \sqrt{a^2+b^2}\)</span> olacak sekilde.</p>
<p>Bu eşitliğin doğru olduğunu kontrol edelim,</p>
<p><span class="math display">\[ a \sin(x) + b \cos(x) = \sqrt{a^2+b^2} \left(\frac{a}{\sqrt{a^2+b^2}} \sin(x) + \frac{b}{\sqrt{a^2+b^2}} \cos(x)\right) \]</span></p>
<p><span class="math display">\[  = A\left[\sin(x)\cos(\varphi) + \cos(x)\sin(\varphi)\right] \]</span></p>
<p><span class="math display">\[ = A\sin(x+\varphi) \]</span></p>
<p>O zaman <span class="math inline">\(a \sin(x) + b \cos(x)\)</span> için regresyon yapabiliriz. Regresyon iki toplam üzerinden tanımlı fonksiyonlar için en uygun <span class="math inline">\(a,b\)</span> katsayılarını hesaplayacak. Önce <span class="math inline">\(\sin\)</span> içinde <span class="math inline">\(2\pi x\)</span> ile başlarız,</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="im">import</span> statsmodels.formula.api <span class="im">as</span> smf
results <span class="op">=</span> smf.ols(<span class="st">&#39;degs ~ np.sin(2*np.pi*toy) + np.cos(2*np.pi*toy)&#39;</span>, data<span class="op">=</span>df).fit()
<span class="bu">print</span> results.summary()</code></pre></div>
<pre><code>                            OLS Regression Results                            
==============================================================================
Dep. Variable:                   degs   R-squared:                       0.969
Model:                            OLS   Adj. R-squared:                  0.968
Method:                 Least Squares   F-statistic:                     704.3
Date:                Fri, 12 May 2017   Prob (F-statistic):           1.10e-34
Time:                        16:01:50   Log-Likelihood:                -63.360
No. Observations:                  48   AIC:                             132.7
Df Residuals:                      45   BIC:                             138.3
Df Model:                           2                                         
Covariance Type:            nonrobust                                         
===========================================================================================
                              coef    std err          t      P&gt;|t|      [95.0% Conf. Int.]
-------------------------------------------------------------------------------------------
Intercept                   8.2917      0.135     61.407      0.000         8.020     8.564
np.sin(2 * np.pi * toy)    -5.9156      0.191    -30.979      0.000        -6.300    -5.531
np.cos(2 * np.pi * toy)    -4.0463      0.191    -21.190      0.000        -4.431    -3.662
==============================================================================
Omnibus:                       28.673   Durbin-Watson:                   1.051
Prob(Omnibus):                  0.000   Jarque-Bera (JB):                4.298
Skew:                          -0.158   Prob(JB):                        0.117
Kurtosis:                       1.569   Cond. No.                         1.41
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.</code></pre>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">a,b <span class="op">=</span> results.params[<span class="dv">1</span>],results.params[<span class="dv">2</span>]
A <span class="op">=</span> (a<span class="op">**</span><span class="dv">2</span><span class="op">+</span>b<span class="op">**</span><span class="dv">2</span>)
<span class="bu">print</span> A, np.rad2deg(np.arcsin(b<span class="op">**</span><span class="dv">2</span> <span class="op">/</span> A))</code></pre></div>
<pre><code>51.3672864144 18.5866613969</code></pre>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">fit1 <span class="op">=</span> results.params[<span class="dv">0</span>] <span class="op">+</span> results.params[<span class="dv">1</span>] <span class="op">*</span> np.sin(<span class="dv">2</span><span class="op">*</span>np.pi<span class="op">*</span>df.toy) <span class="op">+</span> <span class="op">\</span>
       results.params[<span class="dv">2</span>] <span class="op">*</span> np.cos(<span class="dv">2</span><span class="op">*</span>np.pi<span class="op">*</span>df.toy)
plt.scatter(df.toy,df.degs)
plt.hold(<span class="va">True</span>)
plt.plot(df.toy,fit1)
plt.savefig(<span class="st">&#39;tser_sinreg_02.png&#39;</span>)</code></pre></div>
<div class="figure">
<img src="tser_sinreg_02.png" />

</div>
<p>Uyum fena değil. Daha iyi uyum için daha fazla terim ekleyebiliriz, mesela <span class="math inline">\(\sin,\cos\)</span> içinde <span class="math inline">\(2 \pi x\)</span> kullandık, bir de <span class="math inline">\(4 \pi x\)</span>'li terimler ekleyerek,</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="im">import</span> statsmodels.formula.api <span class="im">as</span> smf
formula <span class="op">=</span> <span class="st">&#39;degs ~ np.sin(2*np.pi*toy) + np.cos(2*np.pi*toy) + &#39;</span> <span class="op">+</span> <span class="op">\</span>
          <span class="co">&#39;       np.sin(4*np.pi*toy) + np.cos(4*np.pi*toy)&#39;</span>
results <span class="op">=</span> smf.ols(formula, data<span class="op">=</span>df).fit()
<span class="bu">print</span> results.summary()</code></pre></div>
<pre><code>                            OLS Regression Results                            
==============================================================================
Dep. Variable:                   degs   R-squared:                       0.999
Model:                            OLS   Adj. R-squared:                  0.999
Method:                 Least Squares   F-statistic:                     9519.
Date:                Fri, 23 Sep 2016   Prob (F-statistic):           9.48e-63
Time:                        10:56:56   Log-Likelihood:                 16.130
No. Observations:                  48   AIC:                            -22.26
Df Residuals:                      43   BIC:                            -12.90
Df Model:                           4                                         
Covariance Type:            nonrobust                                         
===========================================================================================
                              coef    std err          t      P&gt;|t|      [95.0% Conf. Int.]
-------------------------------------------------------------------------------------------
Intercept                   8.2917      0.026    314.450      0.000         8.238     8.345
np.sin(2 * np.pi * toy)    -5.9156      0.037   -158.634      0.000        -5.991    -5.840
np.cos(2 * np.pi * toy)    -4.0463      0.037   -108.506      0.000        -4.122    -3.971
np.sin(4 * np.pi * toy)     1.2124      0.037     32.513      0.000         1.137     1.288
np.cos(4 * np.pi * toy)     0.3333      0.037      8.939      0.000         0.258     0.409
==============================================================================
Omnibus:                        0.473   Durbin-Watson:                   2.983
Prob(Omnibus):                  0.790   Jarque-Bera (JB):                0.338
Skew:                          -0.200   Prob(JB):                        0.845
Kurtosis:                       2.909   Cond. No.                         1.41
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.</code></pre>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">fit2 <span class="op">=</span> results.params[<span class="dv">0</span>] <span class="op">+</span> <span class="op">\</span>
       results.params[<span class="dv">1</span>] <span class="op">*</span> np.sin(<span class="dv">2</span><span class="op">*</span>np.pi<span class="op">*</span>df.toy) <span class="op">+</span> <span class="op">\</span>
       results.params[<span class="dv">2</span>]<span class="op">*</span>np.cos(<span class="dv">2</span><span class="op">*</span>np.pi<span class="op">*</span>df.toy) <span class="op">+</span> <span class="op">\</span>
       results.params[<span class="dv">3</span>] <span class="op">*</span> np.sin(<span class="dv">4</span><span class="op">*</span>np.pi<span class="op">*</span>df.toy) <span class="op">+</span> <span class="op">\</span>
       results.params[<span class="dv">4</span>]<span class="op">*</span>np.cos(<span class="dv">4</span><span class="op">*</span>np.pi<span class="op">*</span>df.toy) 
      
plt.scatter(df.toy,df.degs)
plt.hold(<span class="va">True</span>)
plt.plot(df.toy, fit2)
plt.savefig(<span class="st">&#39;tser_sinreg_03.png&#39;</span>)</code></pre></div>
<div class="figure">
<img src="tser_sinreg_03.png" />

</div>
<p>Uyum daha iyi hale geldi.</p>
<p>Bir tane de mutlak değer içeren bir fonksiyon.</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="im">import</span> pandas <span class="im">as</span> pd
x <span class="op">=</span> np.linspace(<span class="dv">0</span>,<span class="dv">10</span>,<span class="dv">400</span>)
y <span class="op">=</span> np.<span class="bu">abs</span>(np.sin(<span class="dv">2</span><span class="op">*</span>np.pi<span class="op">*</span>x)) <span class="op">+</span> np.random.random(<span class="bu">len</span>(x)) <span class="op">*</span> <span class="fl">0.5</span>
df <span class="op">=</span> pd.DataFrame(x)
df[<span class="st">&#39;y&#39;</span>] <span class="op">=</span> y
df.columns <span class="op">=</span> [<span class="st">&#39;x&#39;</span>,<span class="st">&#39;y&#39;</span>]
df.plot(x<span class="op">=</span><span class="st">&#39;x&#39;</span>,y<span class="op">=</span><span class="st">&#39;y&#39;</span>)
plt.savefig(<span class="st">&#39;tser_sinreg_04.png&#39;</span>)</code></pre></div>
<div class="figure">
<img src="tser_sinreg_04.png" />

</div>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="im">import</span> statsmodels.formula.api <span class="im">as</span> smf
results <span class="op">=</span> smf.ols(<span class="st">&#39;y ~ np.abs(np.sin(2*np.pi*x)) + np.abs(np.cos(2*np.pi*x))&#39;</span>, data<span class="op">=</span>df).fit()
<span class="bu">print</span> results.summary()</code></pre></div>
<pre><code>                            OLS Regression Results                            
==============================================================================
Dep. Variable:                      y   R-squared:                       0.830
Model:                            OLS   Adj. R-squared:                  0.829
Method:                 Least Squares   F-statistic:                     967.6
Date:                Fri, 23 Sep 2016   Prob (F-statistic):          2.30e-153
Time:                        17:23:34   Log-Likelihood:                 209.20
No. Observations:                 400   AIC:                            -412.4
Df Residuals:                     397   BIC:                            -400.4
Df Model:                           2                                         
Covariance Type:            nonrobust                                         
=================================================================================================
                                    coef    std err          t      P&gt;|t|      [95.0% Conf. Int.]
-------------------------------------------------------------------------------------------------
Intercept                         0.0995      0.074      1.351      0.177        -0.045     0.244
np.abs(np.sin(2 * np.pi * x))     1.1266      0.059     19.195      0.000         1.011     1.242
np.abs(np.cos(2 * np.pi * x))     0.1125      0.059      1.910      0.057        -0.003     0.228
==============================================================================
Omnibus:                      171.148   Durbin-Watson:                   2.049
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               22.018
Skew:                           0.024   Prob(JB):                     1.66e-05
Kurtosis:                       1.852   Cond. No.                         20.5
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.</code></pre>
<p>Kaynaklar</p>
<p>[1] Cross Validated, <em>How to find a good fit for semi­sinusoidal model in R?</em>, <a href="http://stats.stackexchange.com/questions/60500/how-to-find-a-good-fit-for-semi-sinusoidal-model-in-r" class="uri">http://stats.stackexchange.com/questions/60500/how-to-find-a-good-fit-for-semi-sinusoidal-model-in-r</a></p>
</body>
</html>
