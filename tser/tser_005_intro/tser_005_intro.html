<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
    <script type="text/x-mathjax-config">
    MathJax.Hub.Register.StartupHook("TeX Jax Ready",function () {
      MathJax.Hub.Insert(MathJax.InputJax.TeX.Definitions.macros,{
        cancel: ["Extension","cancel"], cancelto: ["Extension","cancel"]
      });
    });
    </script>  
   
  <title>Zaman Serileri</title>
  <style type="text/css">code{white-space: pre;}</style>
  <style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
  </style>
  <script
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS_HTML-full"
  type="text/javascript"></script>
</head>
<body>
<div id="header">
</div>
<h1 id="zaman-serileri">Zaman Serileri</h1>
<p>Bir zaman serisi <span class="math inline">\(t\)</span> anında belli
bir değeri olan veri noktalarıdır. Finans bağlamında çoğunlukla
birbirini takip eden iki veri noktası arasında bağlantı olduğu
ispatlanmıştır. Altta örnek bir zaman serisi görüyoruz; 500 senetin
ağırlıklı ortalaması olan S&amp;P 500 indisinin zaman göre gidişatı
(düzeltilmiş kapanış hesaplarını baz alarak),</p>
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(<span class="st">&#39;../tser_065_kelly/SPY2.csv&#39;</span>,parse_dates<span class="op">=</span><span class="va">True</span>,index_col<span class="op">=</span><span class="st">&#39;Date&#39;</span>)</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> df.sort_index()</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> df[df.index <span class="op">&gt;</span> <span class="st">&#39;1950-01-01&#39;</span>]</span></code></pre></div>
<div class="sourceCode" id="cb2"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>df[<span class="st">&#39;Adj Close&#39;</span>].plot()</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>plt.savefig(<span class="st">&#39;tser_intro_01.png&#39;</span>)</span></code></pre></div>
<p><img src="tser_intro_01.png" /></p>
<p>Zaman serileri hakkında önemli bir bilgi onların “getirisidir
(returns)’’. Getiri hesabı <span class="math inline">\(t\)</span> ile
<span class="math inline">\(t-1\)</span> arasındaki değişim oranı, yani
<span class="math inline">\(X_{t}-X_{t-1}/X_{t-1}\)</span>. Bu sayıyı
100 ile çarpınca ise yüzde değişimi elde ederiz. Pandas ile,</p>
<div class="sourceCode" id="cb3"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>returns <span class="op">=</span> df[<span class="st">&#39;Adj Close&#39;</span>].pct_change()</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (returns.head())</span></code></pre></div>
<pre class="text"><code>Date
1993-01-29         NaN
1993-02-01    0.007022
1993-02-02    0.002034
1993-02-03    0.010728
1993-02-04    0.004303
Name: Adj Close, dtype: float64</code></pre>
<p>İlk veri noktası <code>NaN</code> oldu çünkü bir önceki veri noktası
yok.</p>
<p>Bu değişim oranı getiri zaman serilerinin doğasına göre bir yukarı
bir aşağı iner, çünkü arz talebe, ya da diğer sebeplere göre senet
fiyatları bazen çıkar, bazen düşer. Bir trend de olabilir tabii, bazen
daha çok çıkabilir, bazen daha çok inebilir. Tamama bakılınca ve bu
<em>getirilerin</em>, dikkat fiyat veri noktalarının değil, frekansını
düşünürsek bu getirilerin bir dağılımdan geldiği kabul edilebilir,
histograma bakalım,</p>
<div class="sourceCode" id="cb5"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>returns.plot(kind<span class="op">=</span><span class="st">&#39;hist&#39;</span>,bins<span class="op">=</span><span class="dv">100</span>)</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>plt.savefig(<span class="st">&#39;tser_intro_02.png&#39;</span>)</span></code></pre></div>
<p><img src="tser_intro_02.png" /></p>
<p>İstatistikten hatırlarsak histogram bize belli değerlerin hangi
frekansla görüldüğünü söylüyor. Bir histogram ile bir olasılık dağılımı
arasında yakın bağlantılar var, histogram bir dağılımın sayısal hali
denebilir. Şekil Gaussian dağılımına benziyor. Fakat genel bağlamda
finans serilerinde tüm getirilerin Gaussian olduğunu direk söylemek
hatalı olur, bu konuyu işleyeceğiz.</p>
<p>Histogramı okurken şöyle çıkarımlar yapabiliriz; mesela yüzdeliklere
bakarız, ve diyelim ki yüzde 5 noktasında (histogram alanının yüzde
5’ine tekabül eden x-eksenindeki nokta) değeri okuruz, bu değer 0.02
civarında gibi duruyor; o zaman varılacak sonuç şöyle seslendirilebilir,
“100 günün 5 gününde %2’lik düşüşler görülebilir’’. Bu mantıklı
herhalde, çünkü bir dağılımdaki belli bir alan o alanın x-eksenindeki
değerlerin ortaya çıkma olasılığını verir. Ortaya çıkma birimi gün ise,
yüzde 5, 100 gün içinde 5 gün demektir.</p>
<p>Çıplak gözle bakmak yerine direk veriden bu hesabı yapabiliriz,</p>
<div class="sourceCode" id="cb6"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (returns.quantile(q<span class="op">=</span><span class="fl">0.05</span>))</span></code></pre></div>
<pre class="text"><code>-0.01775411051963858</code></pre>
<p>Gaussian durumu ilginç; kabaca Gaussian kabulü yapılabilir, fakat
literatürdeki çoğu yazı finans serilerinde düşüşlerin daha sert olduğunu
belirtir, yani Gaussian’da sola, negatif değerlere doğru bir yamukluk
(skew) vardır. Ayrıca fazla sayıda zaman serilerine bakıldığında her iki
yönde aşırı değerlerin Gaussian faraziyesine uymayan şekilde daha fazla
olduğu tespit edilmiştir, yani finans getirilerinin dağlımı “etekleri
kabarık’’ bir Gaussian’dır, daha doğrusu Öğrenci t dağılımıdır. Fakat
basitleştirme amacıyla Gaussian kullanılabilir, tabii bu faraziyenin
sınırlarını bilmek şartıyla.</p>
<p>Oynaklık (Volatility)</p>
<p>Artışların, düşüşlerin ne kadar sert, yüksek boyutta olduğunun iyi
bir göstergesi olarak oynaklık kullanılır, oynaklık üstteki Gaussian
faraziyesinden hareketle getirilerin standart sapması <span
class="math inline">\(\sigma\)</span>’dan (sigma) ibarettir, o zaman
tanıdığımız, bildiğimiz <span class="math inline">\(\sigma\)</span>
hesabı direk burada kullanılabilir,</p>
<div class="sourceCode" id="cb8"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (returns.std())</span></code></pre></div>
<pre class="text"><code>0.010654265586994397</code></pre>
<p>Üstte en soldan yüzde 5 noktasına baktık, her iki yönde tek sigma
büyüklüğünde bir getirinin Gaussian bağlamında alanın yüzde 68’ine
tekabül ettiğini biliyoruz.</p>
<p><img src="gausspercentiles.png" /></p>
<p>Bu demektir ki getiriler Gaussian ile dağılmışsa artı ya da eksi tek
sigmalık (ya da ondan azı olan) değişimlerin olasılığı yüzde 68’dir. İki
sigmalık (ve daha azı) büyüklüğünde getirilerin olasılığı yüzde
95’tır.</p>
<p>Günlükten yıllığa geçmek için getiriler için direk 256 ile çarpılır,
bir yıl içinde aşağı yukarı 256 tane iş günü vardır. Standart sapma
geçişi için <span class="math inline">\(\sqrt{256}\)</span> yani 16 ile
çarpmak gerekir. Bazıları 252 kullanıyor, çünkü NYSE borsasında 252
günde alışveriş yapılabilir. Karekök basitliği sebebiyle bizce 256 daha
uygun.</p>
<p>Niye <span class="math inline">\(\sqrt{252}\)</span> ile çarpıyoruz?
Bu durum varlık fiyat zaman serisinin Brownian yürüyüş olmasıyla
alakalı. BM serilerinde varyans <span class="math inline">\(t\)</span>
ile doğru orantılıdır, yani başlangıç noktasından ne kadar uzaklaşırsak
varyans o kadar büyür, çünkü her adımdaki varyans toplanır (oynaklık
standart sapmadır, ki bu varyansın kareköku o sebeple zamanın kareköku
ile çarpıyoruz). <em>Olasılıksal Calculus</em> yazısında bu matematiği
görüyoruz. Kabaca düşünmek gerekirse BM ‘sarhoş yürüyüşü’ ise ve bu
yürüyüş her adımda rasgele bir hareket yapıyorsa, bu adımlar toplana
toplana tabii ki başlangıç noktasından bizi çok uzak noktalara
taşıyabilir (ve geri getirebilir).</p>
<p>Kabaca borsacılar bilir ki senetlerin yıllık standart sapması %20
civarıdır, daha güvenli olan tahvillerin ise %1.5. Kaldıraç, yani borç
kullanıldığı zaman, mesela 10 kat kaldıraç olduğunu düşünelim, bu
oynaklığı 10 ile çarpmak demektir. Normal bir hisse için 10 kat kaldıraç
sizi yıllık sigma %200’e seviyesine getirir, bu günde %200 / 16 = %12.5
demektir. Eğer getirimiz son derece iyimser bir bakışla yılda %200
olsaydı, bu günlük %0.8 olurdu (256 ile böldük) ve ters yönde bir
sigma’lık düşüş geldiği anda 0.8-12.5=-%11.7’ı görürdük, diğer yönde
0.8+12.5=%13.3. Fakat bu demektir ki günlük getiriler 100 günün 68’inde
-%11.7 ile %13.3 arasında gidip geliyor, 95’inde %-24.2 ile %25.8
arasında gidip geliyor. O zaman günlerin 100-95=%5’inde bu bantın her
iki taraftan dışında (en azdan daha az, en fazladan fazla) rakamlar
göreceğiz demektir, 5/2=%2.5 kadar zamanda %-24.2’dan daha fazla düşüş
olacak demektir bu! 100 günde 2.5 demek, 40/1 oran anlamına geliyor, bir
ay içinde 20 işgünü olduğuna göre bahsedilen olayın aşağı yukarı iki
ayda bir ortaya çıkması muhtemeldir. Yani iki ayda bir günde -%24.2’lik
getiri kaybı! Bu frekans olarak çok ciddi bir kayıptır, ve psikolojik
olarak yatırımcıyı rahatsız edecektir. Bu noktaya nasıl geldiğimizi
hatırlayalım, son derece iyimser bir getiri, 10 kat seviyesinde bir
kaldıraçla başlamıştık.</p>
<p>Sharpe Oranı (Sharpe Ratio)</p>
<p>Sharpe oranı (SO) bir işlem stratejisinin, ya da bir varlığı elde
tutmanın, ki basit olsa bile bu da bir strateji, ne kadar karlı
olacağını ölçek bir hesaptır. Hesaplamak için getirileri riske göre
uyarlarız. Formel olarak getirinin ortalamasını aynı periyottaki
standart sapmaya böleriz. Bu bize günlük SO verir, yıllığı hesaplamak
için <span class="math inline">\(\sqrt{256}\)</span> ile çarpmak
gerekir.</p>
<p>Rasgele Yürüyüş (Random Walk)</p>
<p>Senet fiyatlarının rasgele yürüyüşe göre hareket ettiği söylenir.
Modelin bir şekli</p>
<p><span class="math display">\[ y_t = y_{t-1} + z \]</span></p>
<p>ki <span class="math inline">\(z \sim N(0,\sigma)\)</span>. Formülü
alttaki şekliyle görürsek daha açık olabilir, <span
class="math inline">\(Z_1,Z_2,..,\)</span> bağımsız özdeşçe dağılmış
(independently, identically distributed -iid-), ortalaması <span
class="math inline">\(\mu\)</span>, standart sapması <span
class="math inline">\(\sigma\)</span> olan dağılımlar olsun, ve herhangi
bir başlangıç noktası <span class="math inline">\(X_o\)</span>’dan <span
class="math inline">\(t\)</span> anında gelinen nokta</p>
<p><span class="math display">\[ X_t = X_0 + Z_1 + Z_2 + ... + Z_t , t
\ge 1\]</span></p>
<p>olarak belirtilebilir. Her <span class="math inline">\(t\)</span>
anında bir rasgele değişkene göre bir yere savruluyoruz. Modele dikkat,
önceki veri noktası ile bir korelasyonumuz yok, her noktada zar
atılıyor, başka hiçbir şey yapılmıyor.</p>
<p><span class="math inline">\(X_t\)</span> bu durumda bir rasgele
yürüyüştür, ve adımları <span
class="math inline">\(Z_1,Z_2,..\)</span>’dir. Eğer adımlar normal
olarak dağılmış ise, sürece normal rasgele yürüyüş adı verilir. <span
class="math inline">\(X_0\)</span> verildiği / bilindiği durumda <span
class="math inline">\(X_t\)</span>’nin beklentisi ve varyansı,</p>
<p><span class="math display">\[ E(X_t|X_0) = X_o + \mu t \]</span></p>
<p><span class="math display">\[ Var(X_t|X_0) = \sigma^2 t \]</span></p>
<p>Varyans için bağımsızlık durumunda <span
class="math inline">\(Var(X+Y) = Var(X)+Var(Y)\)</span> olduğunu
hatırlayalım, varyans toplamları <span class="math inline">\(\sigma
t\)</span> olur, sabit <span class="math inline">\(\sigma\)</span>
varyans dışına karesi alınmış olarak çıkar. Sabit <span
class="math inline">\(X_0\)</span> zaten yokolur, onun varyansı
yoktur.</p>
<p>Bu modelin bir diğer ismi Brown Hareketi (Brownian Motion), <span
class="math inline">\(\mu\)</span> parametresi kaymadır (drift), tüm
zaman serisine bir genel yön verir. Kaymanın tanımlandığı duruma Kaymalı
Brown Hareketi (Brownian Motion with Drift) ismi verilir.</p>
<p>Simüle edelim, iki tane <span class="math inline">\(\mu=0\)</span>,
iki tane <span class="math inline">\(\mu=0.5\)</span> ile.</p>
<div class="sourceCode" id="cb10"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> statsmodels.api <span class="im">as</span> sm</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span></code></pre></div>
<div class="sourceCode" id="cb11"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">0</span>)</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> random_walk(i,mu<span class="op">=</span><span class="dv">0</span>):</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>    Z_s <span class="op">=</span> np.random.normal(loc<span class="op">=</span>mu,scale<span class="op">=</span><span class="fl">1.0</span>,size<span class="op">=</span><span class="dv">100</span>)</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>    X_0 <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>    X_t <span class="op">=</span> X_0 <span class="op">+</span> Z_s.cumsum()</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>    plt.plot(X_t)</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="st">&#39;Rasgele Yürüyüş </span><span class="sc">%d</span><span class="st">&#39;</span> <span class="op">%</span> i)</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>    plt.savefig(<span class="st">&#39;tser_stoc_0</span><span class="sc">%d</span><span class="st">.png&#39;</span> <span class="op">%</span> i)</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>random_walk(<span class="dv">1</span>)</span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a>random_walk(<span class="dv">2</span>)</span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a>random_walk(<span class="dv">3</span>,mu<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a>random_walk(<span class="dv">4</span>,mu<span class="op">=</span><span class="fl">0.5</span>)</span></code></pre></div>
<p><img src="tser_stoc_01.png" /> <img src="tser_stoc_02.png" /> <img
src="tser_stoc_03.png" /> <img src="tser_stoc_04.png" /></p>
<p>Görüldüğü gibi rasgele yürüyüş üretimini sağlayan çağrıya <span
class="math inline">\(\mu\)</span> haricinde (bir de dokümantasyon
amaçlı bir indis) haricinde başka hiçbir parametre vermedik, yani aynı
kod arka arkaya dört kez işledi, ama herbirinde aynı başlangıç değeri
olmasına rağmen tamamen farklı görüntüler çıktı. Görüntüler borsadaki
senet fiyatlarını da andırıyor!</p>
<p>Her adımda Gaussian gürültü eklendiği için veri analizi yaparken
Guassian’lığı fiyatların getirisi / farkında görmek mümkündür. Günlük
bazda diyelim artış / azalışın histogramını alırsak, ünlü can eğrisini
elde ederiz. Tabii şunu da eklemek lazım, değişimin dağılımı “tam
olarak’’ Gaussian kabul edilmiyor, bu dağılımın”etekleri daha
kabarıktır’’, yani ekstrem değerler Gaussian’a göre daha muhtemeldir. Bu
dağılımın Öğrenci t (Student t) dağılımı olduğu söylenir. Fakat kolaylık
açısından, kriz şartlarına dikkat etmek koşuluyla, Gaussian
kullanılabilir.</p>
<p>Bağımlılık</p>
<p>Genel İstatistik öğrenirken çoğunlukla veri noktalarının birbirinden
bağımsız olduğunu farzettik, mesela regresyon durumunda eğer <span
class="math inline">\(X_i\)</span> biliniyorsa her <span
class="math inline">\(Y_i\)</span> birbirinden bağımsızdı, ayrıca <span
class="math inline">\(X_i\)</span>’ler birbirinden bağımsızdı. Çok
değişkenli durumda veri noktalarının öğelerinin birbiriyle çetrefil
şekilde alakalı olma durumunda bile veri noktalarının birbirinden
bağımsız olduğunu farzettik. Şimdi bu faraziyeyi gevşeteceğiz, yani ayrı
veri noktaları arasında bağımlılık durumuna bakacağız.</p>
<p>Bağımlı verilere en iyi örnek zaman serileridir, ve bu veri tipi
aynen isminin çağrıştırdığı gibi bir değerin bir zaman süreci içinde
kaydedilmiş değerleri olacaktır. İstatistik uygulamalarında bu durum
çoğunlukla bir <span class="math inline">\(X\)</span> değişkeninin <span
class="math inline">\(t\)</span> anından başlanarak eşit zaman
aralıklarında, mesela <span class="math inline">\(h\)</span>
aralıklarıyla değerinin kaydedilmesiyle ortaya çıkabilir, <span
class="math inline">\(X_t,X_{t+h},X_{t+2h},...\)</span> gibi..</p>
<p>Altta iki tipik zaman serisi görüyoruz. Bunlardan ilki yapay olarak
üretilmiş, ikincisi Kanada’nın bir bölgesinde her sene yakalanan lynx
(orta boylu bir kedi türü) sayısı baz alınarak yaratılmış. Bu verilerin
dalgalanış şekilleri, kabaca gidişatları, vs. aslında birbirlerine çok
benziyor.</p>
<div class="sourceCode" id="cb12"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> logistic_map(x,r<span class="op">=</span><span class="dv">4</span>): <span class="cf">return</span> r<span class="op">*</span>x<span class="op">*</span>(<span class="dv">1</span><span class="op">-</span>x) </span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> logistic_iteration(n,x_init,r<span class="op">=</span><span class="dv">4</span>):</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>   x <span class="op">=</span> [<span class="dv">0</span> <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(n)]</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>   x[<span class="dv">0</span>] <span class="op">=</span> x_init</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>   <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(n<span class="op">-</span><span class="dv">1</span>): x[i<span class="op">+</span><span class="dv">1</span>] <span class="op">=</span> logistic_map(x[i])</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>   <span class="cf">return</span> x</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>n <span class="op">=</span> <span class="dv">1000</span></span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> logistic_iteration(n, x_init<span class="op">=</span><span class="fl">0.01</span>)</span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> x <span class="op">+</span> np.random.normal(size<span class="op">=</span>n,loc<span class="op">=</span><span class="fl">0.</span>,scale<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&#39;Yapay Veri&#39;</span>)</span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>df_artificial <span class="op">=</span> pd.DataFrame()</span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a>df_artificial[<span class="st">&#39;y&#39;</span>] <span class="op">=</span> y</span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a>df_artificial.y[:<span class="dv">100</span>].plot()</span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a>plt.savefig(<span class="st">&#39;tser_stoc_05.png&#39;</span>)</span></code></pre></div>
<p><img src="tser_stoc_05.png" /></p>
<div class="sourceCode" id="cb13"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(<span class="st">&#39;../tser_015_stoc/lynx.csv&#39;</span>,index_col<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>df.plot()</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&#39;Lynx&#39;</span>)</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>plt.savefig(<span class="st">&#39;tser_stoc_06.png&#39;</span>)</span></code></pre></div>
<p><img src="tser_stoc_06.png" /></p>
<p>Soru: Yapay veriyi üretirken niye lojistik harita (logistic map)
kullandık? Cevap: Hoca [1] herhalde hem birbirine bağımlı noktalar
yaratmak, hem de onların biraz “kaotik’’ olmasını istedi, ki lojistik
harita kaos matematiğinde iyi bilinen bir fonksiyondur.</p>
<p>Zaman serisi analizinde yapmaya çalıştığımız İstatistiğin geri
kalanından bize tanıdık: önümüzde gördüğümüz zaman serisini, o seriyi
üreten, görmediğimiz, yarı-rasgele (“stochastic’’) bir süreçten alınmış
bir yansıma / oluş (realization) olarak görmek, önümüzdeki veriyi bu
süreç hakkında tahminler (çıkarsama / inference) yapmak için kullanmak,
ve bu tahminlerin, rasgeleliğini açıkça belirledikten sonra güvenilir
olması için uğraşmak. İşimizi zorlaştıran her gözlemin / veri noktasının
birbiri ile bağlantılı olması; diğer yandan çoğu zaman üzerinde
çıkarsama yapmak istediğimiz şey de aslında bu bağlantının ta
kendisi.</p>
<p>Notasyon</p>
<p>Eşit aralıklı örneklenmiş zaman serisini göstermek için indeks olarak
zamanın kendisini kullanmak yerine (mesela 1920 senesinde, 1921
senesinde, vs demek yerine) her öğenin seri içindeki yerini kullanmak
daha rahattır, <span class="math inline">\(X_1,X_2,..\)</span> gibi.
Buradan hareketle bir kısayol notasyonu şudur: bir zaman blokunu
göstermek için <span class="math inline">\(X_i^j =
(X_i,X_{i+1},...,X_{j-1},X_j)\)</span>.</p>
<p>Durağanlık (Stationarity)</p>
<p>Tablosal dünyamızda durum nasıldı? Her biri birbirinden bağımsız ama
aynı dağılımlı (IID) veri noktalarımız var, bu bize analizde bazı
faydalar sağlıyor. Zaman serileri için de benzer bir aynılık özelliğinin
olması iyi olmaz mıydı? Böyle bir özellik var, ve ismi durağanlık.
Kelimenin anlamı zaman serisinin hiç değişmediği anlamına gelmiyor
tabii, onun <em>dağılımının</em> değişmediği anlamına geliyor.</p>
<p>Daha kesin bir şekilde belirtmek gerekirse, eğer tüm <span
class="math inline">\(k,t\)</span> için <span
class="math inline">\(X_1^k\)</span> ve <span
class="math inline">\(X_t^{t+k-1}\)</span> aynı dağılıma sahipse bu
zaman serisi <span class="math inline">\(X\)</span>’in güçlü durağan
(strongly stationary), ya da kesin durağan (strictly stationary) olduğu
söylenir, yani <span class="math inline">\(k\)</span> büyüklüğündeki
blokların dağılımı zamana bağlı değildir (time-ınvariant). Tekrarlamak
gerekirse bu tüm blokların aynı değerlere sahip olduğu anlamına gelmez,
sadece aynı dağılıma sahip olduğu anlamına gelir.</p>
<p>Çoğunlukla finans zaman serileri durağan olmaz, ama serinin değişimi,
yani <span class="math inline">\(t\)</span> ile <span
class="math inline">\(t-1\)</span> arasındaki fark durağan olabilir,
arada bir log transform da da gerekebilir. İstatistiki modelleme
açısından bu işlemlerin pek negatif bir etkisi yoktur, her halükarda ise
yarar bir model elde ederiz.</p>
<p>Durağan süreçlerin güzel tarafı şudur, onları çok az parametre ile
modelleyebilirsiniz. Mesela her <span class="math inline">\(X_t\)</span>
için farklı bir beklentiye (expectation) ihtiyaç yoktur, hepsinin
beklentisi aynıdır, <span class="math inline">\(\mu\)</span>. Bu
demektir ki <span class="math inline">\(\mu\)</span>’yu <span
class="math inline">\(\bar{X}\)</span> ile doğru doğru bir şekilde
kestirmek (estimate) mümkündür.</p>
<p>Eh bir “güçlü’’ durağanlık varsa, herhalde bir”zayıf’’ durağanlık ta
olmalı.. Hakikaten de bu var. Zayıf durağanlık için tek gereken şartlar
<span class="math inline">\(E(X_1) = E(X_t)\)</span> ve <span
class="math inline">\(Cov(X_1,X_k) = Cov(X_t,X_{t+k-1})\)</span> olması.
Dikkat, bu şart için bloklar üzerinden değil tek veri noktaları
üzerinden bir beyan yapıyoruz. Doğal olarak güçlü durağanlık aynı
zamanda zayıf durağanlık ta olduğunu söyler (bunu egzersiz olarak
doğrulayabilirsiniz) , fakat çoğunlukla bu eşitlik ters yönde geçerli
değildir.</p>
<p>Kendisiyle Korelasyon (Autocorrelation)</p>
<p>Zaman serileri çoğunlukla zincirleme olarak bağlantılıdır, yani <span
class="math inline">\(X_t\)</span> noktası kendinden önceki ve sonraki
tüm değerler ile bağlantılıdır. Fakat bu bağlantı her mesafede aynı
etkide değildir, çoğunlukla bir bağlantı kaybı (decay of dependence)
durumu sözkonusudur (bazen korelasyon kaybı -decay of correlations- ismi
de veriliyor), yani <span class="math inline">\(h \to \infty\)</span>
iken <span class="math inline">\(X_t,X_{t+h}\)</span> değişkenleri
birbirinden gittikçe daha çok neredeyse tam bağımsız hale gelir
(kelimelendirme kritik, hoca tam bağımsız olur demiyor, çok az
bağımlılık hala kalabilir, ama aralık büyüdükçe, hatta sonsuzluğa
yaklaştıkça bağımsızlık artar, neredeyse tam bağımsızlık haline
gelir).</p>
<p>Bu durumu ölçmenin bilinen en eski yöntemi kendisiyle koveryans
(dikkat korelasyon değil) ölçütüdür,</p>
<p><span class="math display">\[ \gamma(h) = Cov(X_t,X_{t+h})
\]</span></p>
<p>Aynı şekilde kendisiyle korelasyon (autocorrelation) da
kullanabilirdik,</p>
<p><span class="math display">\[
\rho(h) = \frac{Cov(X_t,X_{t+h}) }{Var(X_t) } =
\frac{\gamma(h)}{\gamma(0)}
\]</span></p>
<p>Korelasyon tanımından üstteki ilk eşitliğe nasıl geldik? Korelasyon
bilindiği gibi</p>
<p><span class="math display">\[ \frac{Cov(X_t,X_{t+h})
}{\sqrt{Var(X_t)}\sqrt{Var(X_{t+h})} } \]</span></p>
<p>Daha önceki zayıf durağanlık tanımından,</p>
<p><span class="math display">\[ Cov(X_1,X_k) = Cov(X_t,X_{t+k-1})
\]</span></p>
<p>Eğer <span class="math inline">\(k=1\)</span> olsaydı,</p>
<p><span class="math display">\[ Cov(X_1,X_1) = Cov(X_t,X_t) = Var(X_1)
= Var(X_t)\]</span></p>
<p>Bu ifadenin her <span class="math inline">\(t\)</span> için doğru
olması gerektiği için <span class="math inline">\(Var(X_t) =
Var(X_{t+h})\)</span> diyebiliriz. O zaman korelasyon şu hale gelir,</p>
<p><span class="math display">\[
\frac{Cov(X_t,X_{t+h}) }{\sqrt{Var(X_t)}\sqrt{Var(X_t)} }  =
\frac{Cov(X_t,X_{t+h}) }{Var(X_t)}
\]</span></p>
<p>Sağ taraftaki eşitliğe gelelim: sadece <span
class="math inline">\(\gamma\)</span> formu kullanmaya uğraşalım, <span
class="math inline">\(h=0\)</span> dersek <span
class="math inline">\(\gamma(0) = Cov(X_t,X_{t+0}) =
Cov(X_t,X_t)\)</span> elde ediliyor ve bilindiği gibi <span
class="math inline">\(Var(X_t)=Cov(X_t,X_t)\)</span>. O zaman</p>
<p><span class="math display">\[ \frac{Cov(X_t,X_{t+h}) }{Var(X_t)} =
\frac{\gamma(h)}{\gamma(0)} \]</span></p>
<p>Daha önce belirttiğimiz gibi çoğu zaman serisi için <span
class="math inline">\(h \to \infty\)</span> <span
class="math inline">\(\gamma(h) \to 0\)</span>.</p>
<p>Python Pandas ile korelasyon grafiği şöyle basılır,</p>
<div class="sourceCode" id="cb14"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>fig <span class="op">=</span> plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>,<span class="dv">8</span>))</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>ax1 <span class="op">=</span> fig.add_subplot(<span class="dv">211</span>)</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>fig <span class="op">=</span> sm.graphics.tsa.plot_acf(df.values.squeeze(), lags<span class="op">=</span><span class="dv">40</span>, ax<span class="op">=</span>ax1)</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>ax2 <span class="op">=</span> fig.add_subplot(<span class="dv">212</span>)</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>fig <span class="op">=</span> sm.graphics.tsa.plot_pacf(df, lags<span class="op">=</span><span class="dv">40</span>, ax<span class="op">=</span>ax2)</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>plt.savefig(<span class="st">&#39;tser_stoc_07.png&#39;</span>)</span></code></pre></div>
<p><img src="tser_stoc_07.png" /></p>
<div class="sourceCode" id="cb15"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>fig <span class="op">=</span> plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>,<span class="dv">8</span>))</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>ax1 <span class="op">=</span> fig.add_subplot(<span class="dv">211</span>)</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>fig <span class="op">=</span> sm.graphics.tsa.plot_acf(df_artificial.values.squeeze(), lags<span class="op">=</span><span class="dv">40</span>, ax<span class="op">=</span>ax1)</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>ax2 <span class="op">=</span> fig.add_subplot(<span class="dv">212</span>)</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>fig <span class="op">=</span> sm.graphics.tsa.plot_pacf(df_artificial, lags<span class="op">=</span><span class="dv">40</span>, ax<span class="op">=</span>ax2)</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>plt.savefig(<span class="st">&#39;tser_stoc_08.png&#39;</span>)</span></code></pre></div>
<p><img src="tser_stoc_08.png" /></p>
<p>Üstteki her iki verinin de kendisiyle korelasyonunu görüyoruz. İlginç
bir durum ortaya çıktı, yapay zaman serisinin kendisiyle korelasyonu
neredeyse hep sıfır etrafında, yani hangi aralığı baz alırsak alalım,
iki veri noktası arasındaki bağlantı çok az. Bu durum serinin ilk
grafiğini düşününce garip geliyor. Hakikaten bir acaiplik var, bu şeride
bir takım bağlantılar olduğunu <span
class="math inline">\(X_{t+1},X_t\)</span> grafiğini basarak bile
görebiliriz,</p>
<div class="sourceCode" id="cb16"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>df_artificial[<span class="st">&#39;lagged_y&#39;</span>] <span class="op">=</span> df_artificial.y.shift(<span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>df_artificial.plot(kind<span class="op">=</span><span class="st">&#39;scatter&#39;</span>,x<span class="op">=</span><span class="st">&#39;y&#39;</span>,y<span class="op">=</span><span class="st">&#39;lagged_y&#39;</span>)</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&#39;Yapay&#39;</span>)</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>plt.savefig(<span class="st">&#39;tser_stoc_09.png&#39;</span>)</span></code></pre></div>
<p><img src="tser_stoc_09.png" /></p>
<div class="sourceCode" id="cb17"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>df[<span class="st">&#39;lagged_x&#39;</span>] <span class="op">=</span> df.x.shift(<span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>df.plot(kind<span class="op">=</span><span class="st">&#39;scatter&#39;</span>,x<span class="op">=</span><span class="st">&#39;x&#39;</span>,y<span class="op">=</span><span class="st">&#39;lagged_x&#39;</span>)</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&#39;Lynx&#39;</span>)</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>plt.savefig(<span class="st">&#39;tser_stoc_10.png&#39;</span>)</span></code></pre></div>
<p><img src="tser_stoc_10.png" /></p>
<p>Yani kendisiyle korelasyon her zaman gerekli bilgiyi vermeyebilir,
ama bilinmesi iyi olur. Daha genel ölçütler mesela Spearman <span
class="math inline">\(X_{t+h},X_t\)</span> kerte korelasyonu (Spearman
rank-correlation) ya da ortak bilgi (mutual information) gibi
ölçütler.</p>
<p>Ama aslında kendisiyle korelasyonun önemli olmasının 4 sebebi var.
İlki, bu ölçüt istatistikteki en eski ölçütlerden biri, yani “kullanıcı
bazı’’ geniş, herkes kendisiyle korelasyon hakkında birşeyler biliyor,
iletişimde bu kavramı kullanıyorlar, ve gelip size bu ölçüt hakkında
birşeyler soracaklar. İkincisi, son derece nadir bir durum olan Gaussian
süreçleri durumunda kendisiyle korelasyon size hakikaten bilmeniz
gereken <em>herşeyi</em> söyler. Üç, birazcık daha az nadir olan lineer
tahmin durumunda yine bilmemiz gereken herşeyi bize söyler.</p>
<p>Kaynaklar</p>
<p>[1] Carver, <em>Systematic Trading</em></p>
<p>[2] Macrooption, <em>Why Is Volatility Proportional to the Square
Root of Time</em>, <a
href="https://www.macroption.com/why-is-volatility-proportional-to-square-root-of-time/">https://www.macroption.com/why-is-volatility-proportional-to-square-root-of-time/</a></p>
<p>
  <a href="..">Yukarı</a>
</p>
</body>
</html>
