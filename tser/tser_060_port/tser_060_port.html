<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title></title>
  <style type="text/css">code{white-space: pre;}</style>
  <style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
  </style>
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>
  
  
  
  
</head>
<body>
<h1 id="portföy-idaresi">Portföy İdaresi</h1>
<p>Çeşitlendirmenin (diversification), yani portföye farklı enstrümanlar koymanın, farklı sektörlerden olsun, farklı ülkelerden olsun, iyi bir şey olduğu hep tavsiye edilir, kulağa küpe kuralı &quot;yumurtaları aynı sepete koymamak'', teknik anlamda bu söz portföydeki bir enstrümanın tamamen çöktüğü durumda (sepetin düşüp yumurtaların kırılması) kayıpların sınırlanacağı çağrıştırmasını yapar. Mesela [4, sf. 115]'e göre, ABD borsalarında hisselerin artık getirisinin ortalama %3 olduğu bilinir. Eğer yıllık %20 standart sapmayı baz alırsak, Sharpe oranı (SR) %3 bölü %20 = 0.15. Eğer aynı ülkede ama farklı sektörlerde çeşitlendirirsek aşağı yukarı SR = 0.2 elde edebiliriz. Eğer farklı ülkelere çeşitlersek SR 0.25'e çıkabiliriz. Eğer yatırım sınıfını da çeşitlersek, yani tahviller, senetler, baz ürünlere yatırım yapmak üzere, o zaman SR 0.4 elde edebiliriz.</p>
<p>İçinde birbiri ile ilintisi olmayan (uncorrelated) varlıklar olan bir portföyün -ki çeşitlenmiş olmanın teknik tercümesi bu aslında- toplam standart sapması daha düşüktür. Sharpe oranını hesaplarken standart sapmaya böldüğümüz için daha ufak değer daha büyük SR anlamına gelir. Matematiksel olarak sadece bir portföy düşünelim içinde iki varlık olsun, gelecekteki getirilerini <span class="math inline">\(R_1,R_2\)</span>'yi bildiğimizi farzedelim (tarihi veriden kestiriyoruz mesela), bu varlıklar <span class="math inline">\(w_1,w_2\)</span> ağırlıkları üzerinden birleştiriliyor olsun, toplam portföy getirisi,</p>
<p><span class="math display">\[ R_p = w_1 R_1 + w_2 R_2 \]</span></p>
<p><span class="math inline">\(R_1,R_2\)</span> rasgele değişkenler. Tüm portföyün beklentisi,</p>
<p><span class="math display">\[ E(R_p) = E(w_1 R_1 + w_2 R_2) \]</span></p>
<p><span class="math display">\[ = w_1 E(R_1) + w_2 E(R_2) \]</span></p>
<p>Portföyün varyansı için [5, sf. 73],</p>
<p><span class="math display">\[Var(w_1 R_1 + w_2 R_2) = w_1^2Var(R_1) + w_2^2 Var(R_2) + w_1w_2Cov(R_1,R_2)
 \qquad (1)\]</span></p>
<p>Diyelim ki <span class="math inline">\(w_1,w_2\)</span> eşit; O zaman formülden açık bir şekilde görülüyor ki üstteki varyansın azalacağı durumlardan biri iki enstrümanın hiç ilintili olmadığı durumdur, çünkü bu durumda iki getirinin kovaryansı sıfır olur; <span class="math inline">\(Cov(R_1,R_2)=0\)</span>, üstteki formüldeki 3. terim tamamen yokolur, böylece portföy varyansı azalır. Varyans azalınca Sharpe oranı artar.</p>
<p>N Tane Enstrüman</p>
<p>Çok boyutlu hesap için portföy ağırlıkları <span class="math inline">\(w = [w_1,..,w_n]^T\)</span>, getiriler <span class="math inline">\(R = [R_1,..,R_n]^T\)</span> vektörleri içinde olsun,</p>
<p><span class="math display">\[ R_p = w^T R \]</span></p>
<p>Beklenti</p>
<p><span class="math display">\[ E(R_p) = E(w^T R) = w^TE(R) \]</span></p>
<p>Varyans</p>
<p><span class="math display">\[ Var(R_p) = E\big( (R_p-E(R_p))(R-E(R_p))^T  \big) \]</span></p>
<p><span class="math display">\[ = E\big( (R_p-w^TE(R))(R_p-w^TE(R))^T  \big) \]</span></p>
<p><span class="math display">\[ = E\big( (w^TR-w^TE(R))(w^TR-w^TE(R))^T  \big) \]</span></p>
<p><span class="math display">\[ = w^T E\big( (R-E(R))(R-E(R))^Tw  \big) \]</span></p>
<p><span class="math display">\[ = w^T cov (R) w \]</span></p>
<p>Yine iki enstrüman üzerinden matris formunu kontrol edelim, varyanslar için <span class="math inline">\(\sigma_1^2,\sigma_2^2\)</span> kullanırsak,</p>
<p><span class="math display">\[ Var(R_p) = 
\left[\begin{array}{cc} w_1 &amp; w_2  \end{array}\right]
\left[\begin{array}{rr}
\sigma_1^2 &amp; \sigma_{12} \\
\sigma_{2,1}^2 &amp; \sigma_2^2 
\end{array}\right]
\left[\begin{array}{r}
w_1 \\ w_2
\end{array}\right] 
\qquad (2)
\]</span></p>
<p><span class="math display">\[ = \left[\begin{array}{cc} 
w_1 \sigma_1^2 + w_2 \sigma_{2,1} &amp; 
w_1 \sigma_{1,2} + w_2\sigma_2^2  \end{array}\right]
\left[\begin{array}{r}
w_1 \\ w_2
\end{array}\right] 
\]</span></p>
<p><span class="math display">\[ = w_1^2\sigma_1^2 + w_1w_2\sigma_{2,1} + w_1w_2\sigma_{1,2} + w_2^2\sigma_2^2\]</span></p>
<p><span class="math display">\[ = w_1^2\sigma_1^2 + 2 w_1w_2\sigma_{1,2} + w_2^2\sigma_2^2\]</span></p>
<ol style="list-style-type: decimal">
<li>ile benzer sonuca vardık. Her iki durumda da enstrumanlar arasında korelasyon olmaması bir terim eksiltir, ve portföy varyansı azalır. Bunun matris tercümesi <span class="math inline">\(cov (R)\)</span>'nin köşegeni dışındaki öğelerinin sıfır olması anlamına gelir, çünkü bir kovaryans matrisinde her enstrüman arasındaki kovaryanslar köşegen haricinde olan öğelerde tutulur.</li>
</ol>
<p>Portföy Ağırlıklarını Hesaplamak</p>
<p>Portföy varyansını, riskini azaltmak enstrümanlar arası korelasyonu azaltmak ile mümkün, bunu bir yana koyalım. Bir ek yöntem enstrümanlara ayrılmış sermayeyi, yani bölüştürme ağırlıklarını optimal bir seviyeye getirmektir. Matematiksel olarak</p>
<p><span class="math display">\[ \textrm{minimize et } w^T \Sigma w \]</span></p>
<p><span class="math display">\[ R_p^T w = \mu, \quad w^T 1 = 1 \textrm{ şartlarına uyarak }\]</span></p>
<p>ki <span class="math inline">\(\mu\)</span> hedeflenen getiri.</p>
<p>Verimli Sınır (Efficient Frontier)</p>
<p>Markovitz'in buluşlarından biri (getirisinin standart sapması) farklı ağırlıklar üzerinden hesaplanan portföyün riskini ve getirisini grafiklediğinde mümkün tüm getirilerin bir sınır oluşturduğunu görmesiydi, buna verimli sınır ismi verildi. Görsel olarak düşünürsek herhangi verili bir risk için dikey yukarı çıkıp bu sınıra geliyoruz, ve bu sınırdaki risk (ve onu ortaya çıkartan ağırlıklar) elde edebileceğimiz en iyi sonuç. Altta üç şirket üzerinde bu hesabı görebiliriz.</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="im">import</span> pandas <span class="im">as</span> pd
df <span class="op">=</span> pd.read_csv(<span class="st">&quot;companies.csv&quot;</span>,index_col<span class="op">=</span><span class="dv">0</span>,parse_dates<span class="op">=</span><span class="va">True</span>)
<span class="bu">print</span> df.head()</code></pre></div>
<pre><code>                 MSFT       AAPL         KO
Date                                       
2010-01-04  26.045432  28.141855  23.509276
2010-01-05  26.053846  28.190509  23.224888
2010-01-06  25.893956  27.742101  23.216647
2010-01-07  25.624666  27.690818  23.158944
2010-01-08  25.801387  27.874915  22.730305</code></pre>
<p>Şirketler Microsoft, Apple, ve Coca-Cola.</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="im">import</span> scipy <span class="im">as</span> sp
<span class="im">import</span> scipy.optimize <span class="im">as</span> scopt
<span class="im">import</span> scipy.stats <span class="im">as</span> spstats

<span class="kw">def</span> calc_annual_returns(daily_returns):
    grouped <span class="op">=</span> np.exp(daily_returns.groupby(<span class="kw">lambda</span> date: date.year).<span class="bu">sum</span>())<span class="op">-</span><span class="dv">1</span>
    <span class="cf">return</span> grouped

<span class="kw">def</span> calc_portfolio_var(returns, weights):
    sigma <span class="op">=</span> np.cov(returns.T,ddof<span class="op">=</span><span class="dv">0</span>)
    var <span class="op">=</span> (weights <span class="op">*</span> sigma <span class="op">*</span> weights.T).<span class="bu">sum</span>()
    <span class="cf">return</span> var

<span class="kw">def</span> sharpe_ratio(returns, weights, risk_free_rate <span class="op">=</span> <span class="fl">0.015</span>):
    n <span class="op">=</span> returns.columns.size
    var <span class="op">=</span> calc_portfolio_var(returns, weights)
    means <span class="op">=</span> returns.mean()
    <span class="cf">return</span> (means.dot(weights) <span class="op">-</span> risk_free_rate)<span class="op">/</span>np.sqrt(var)

<span class="kw">def</span> negative_sharpe_ratio_n_minus_1_stock(weights,returns,risk_free_rate):
    weights2 <span class="op">=</span> sp.append(weights, <span class="dv">1</span><span class="op">-</span>np.<span class="bu">sum</span>(weights))
    <span class="cf">return</span> <span class="op">-</span>sharpe_ratio(returns, weights2, risk_free_rate)

<span class="kw">def</span> optimize_portfolio(returns, risk_free_rate):
    w0 <span class="op">=</span> np.ones(returns.columns.size<span class="dv">-1</span>,dtype<span class="op">=</span><span class="bu">float</span>) <span class="op">*</span> <span class="fl">1.0</span> <span class="op">/</span> returns.columns.size
    w1 <span class="op">=</span> scopt.fmin(negative_sharpe_ratio_n_minus_1_stock,
                    w0, args<span class="op">=</span>(returns, risk_free_rate))
    final_w <span class="op">=</span> sp.append(w1, <span class="dv">1</span> <span class="op">-</span> np.<span class="bu">sum</span>(w1))
    final_sharpe <span class="op">=</span> sharpe_ratio(returns, final_w, risk_free_rate)
    <span class="cf">return</span> (final_w, final_sharpe)

<span class="kw">def</span> objfun(W, R, target_ret):
    stock_mean <span class="op">=</span> np.mean(R,axis<span class="op">=</span><span class="dv">0</span>)
    port_mean <span class="op">=</span> np.dot(W,stock_mean)
    cov<span class="op">=</span>np.cov(R.T)
    port_var <span class="op">=</span> np.dot(np.dot(W,cov),W.T)
    penalty <span class="op">=</span> <span class="dv">2000</span><span class="op">*</span><span class="bu">abs</span>(port_mean<span class="op">-</span>target_ret)
    <span class="cf">return</span> np.sqrt(port_var) <span class="op">+</span> penalty

<span class="kw">def</span> calc_daily_returns(df):
    <span class="cf">return</span> np.log(df<span class="op">/</span>df.shift(<span class="dv">1</span>))

<span class="kw">def</span> calc_efficient_frontier(returns):
    result_means <span class="op">=</span> []
    result_stds <span class="op">=</span> []
    result_weights <span class="op">=</span> []
    means <span class="op">=</span> returns.mean()
    min_mean, max_mean <span class="op">=</span> means.<span class="bu">min</span>(), means.<span class="bu">max</span>()
    nstocks <span class="op">=</span> returns.columns.size

    <span class="cf">for</span> r <span class="kw">in</span> np.linspace(min_mean, max_mean, <span class="dv">100</span>):
        weights <span class="op">=</span> np.ones(nstocks)<span class="op">/</span>nstocks
    bounds <span class="op">=</span> [(<span class="dv">0</span>,<span class="dv">1</span>) <span class="cf">for</span> i <span class="kw">in</span> np.arange(nstocks)]
    constraints <span class="op">=</span> ({<span class="st">&#39;type&#39;</span>: <span class="st">&#39;eq&#39;</span>,<span class="st">&#39;fun&#39;</span>: <span class="kw">lambda</span> W: np.<span class="bu">sum</span>(W) <span class="op">-</span> <span class="dv">1</span>})
    results <span class="op">=</span> scopt.minimize(objfun, weights, (returns, r),
                                 method<span class="op">=</span><span class="st">&#39;SLSQP&#39;</span>,constraints <span class="op">=</span> constraints,
                                 bounds <span class="op">=</span> bounds)
    <span class="cf">if</span> <span class="kw">not</span> results.success: <span class="cf">raise</span> <span class="pp">Exception</span>(result.message)
    result_means.append(np.<span class="bu">round</span>(r,<span class="dv">4</span>)) <span class="co"># 4 decimal places</span>
    std_<span class="op">=</span>np.<span class="bu">round</span>(np.std(np.<span class="bu">sum</span>(returns<span class="op">*</span>results.x,axis<span class="op">=</span><span class="dv">1</span>)),<span class="dv">6</span>)
    result_stds.append(std_)
    result_weights.append(np.<span class="bu">round</span>(results.x, <span class="dv">5</span>))
    
    <span class="cf">return</span> {<span class="st">&#39;Means&#39;</span>: result_means, <span class="st">&#39;Stds&#39;</span>: result_stds, <span class="st">&#39;Weights&#39;</span>: result_weights}

<span class="kw">def</span> calc_port_perf(w, ret, covs):
    port_ret <span class="op">=</span> np.<span class="bu">sum</span>( ret<span class="op">*</span>w )
    port_std <span class="op">=</span> np.sqrt(np.dot(w.T, np.dot(covs, w)))
    <span class="cf">return</span> port_ret, port_std

<span class="kw">def</span> plot_all_possible_portfolios(ann_rets):
    res <span class="op">=</span> []
    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1000</span>):
        w <span class="op">=</span> np.random.random(<span class="bu">len</span>(df.columns))
        w <span class="op">/=</span> np.<span class="bu">sum</span>(w)
        r,s <span class="op">=</span> calc_port_perf(w, ann_rets.mean(),ann_rets.cov())
        res.append([r,s])
    vw <span class="op">=</span> pd.DataFrame(res,columns<span class="op">=</span>[<span class="st">&#39;return&#39;</span>,<span class="st">&#39;sigma&#39;</span>])
    <span class="cf">return</span> vw
    
    
<span class="kw">def</span> plot_efficient_frontier(ef_data):
    plt.title(<span class="st">u&#39;Verimli Sınır&#39;</span>)
    plt.xlabel(<span class="st">u&#39;Portföy Standart Sapması (Risk))&#39;</span>)
    plt.ylabel(<span class="st">u&#39;Portföy Getirisi&#39;</span>)
    plt.plot(ef_data[<span class="st">&#39;Stds&#39;</span>], ef_data[<span class="st">&#39;Means&#39;</span>], <span class="st">&#39;--&#39;</span>)<span class="op">;</span></code></pre></div>
<p>Günlük getiriler,</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">daily_returns <span class="op">=</span> calc_daily_returns(df)
<span class="bu">print</span> daily_returns.head()</code></pre></div>
<pre><code>                MSFT      AAPL        KO
Date                                    
2010-01-04       NaN       NaN       NaN
2010-01-05  0.000323  0.001727 -0.012171
2010-01-06 -0.006156 -0.016034 -0.000355
2010-01-07 -0.010454 -0.001850 -0.002489
2010-01-08  0.006873  0.006626 -0.018682</code></pre>
<p>Yıllık getiri,</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">annual_returns <span class="op">=</span> calc_annual_returns(daily_returns)
<span class="bu">print</span> annual_returns.head()</code></pre></div>
<pre><code>          MSFT      AAPL        KO
2010 -0.079441  0.507219  0.189366
2011 -0.045157  0.255580  0.094586
2012  0.057989  0.325669  0.065276
2013  0.442980  0.080695  0.172330
2014  0.275646  0.406225  0.052661</code></pre>
<p>Eşit ağırlıklar üzerinden oluşturulmuş portföyün varyansı,</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">eq_weights <span class="op">=</span> np.array([<span class="dv">1</span><span class="op">/</span><span class="fl">3.</span>,<span class="dv">1</span><span class="op">/</span><span class="fl">3.</span>,<span class="dv">1</span><span class="op">/</span><span class="fl">3.</span>])
<span class="bu">print</span> calc_portfolio_var(annual_returns,weights<span class="op">=</span>eq_weights)</code></pre></div>
<pre><code>0.00287954016535</code></pre>
<p>Sharpe Oranı</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="bu">print</span> sharpe_ratio(annual_returns,eq_weights)</code></pre></div>
<pre><code>3.20109292169</code></pre>
<p>Farklı (rasgele) portföy ağırlıklarının oluşturacağı risk / getiri grafiği,</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">vw <span class="op">=</span> plot_all_possible_portfolios(annual_returns)
vw.plot(x<span class="op">=</span><span class="st">&#39;sigma&#39;</span>,y<span class="op">=</span><span class="st">&#39;return&#39;</span>,kind<span class="op">=</span><span class="st">&#39;scatter&#39;</span>)
plt.savefig(<span class="st">&#39;tser_port_04.png&#39;</span>)</code></pre></div>
<div class="figure">
<img src="tser_port_04.png" />

</div>
<p>Şimdi optimizasyon ile global bir optimal nokta bulalım,</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="bu">print</span> optimize_portfolio(annual_returns, <span class="fl">0.0003</span>)</code></pre></div>
<pre><code>Optimization terminated successfully.
         Current function value: -7.829867
         Iterations: 38
         Function evaluations: 74
(array([ 0.02615542,  0.76347385,  0.21037072]), 7.8298669383774486)</code></pre>
<p>Verimli sınır,</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">frontier_data <span class="op">=</span> calc_efficient_frontier(annual_returns)</code></pre></div>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="bu">print</span> frontier_data[<span class="st">&#39;Stds&#39;</span>][:<span class="dv">5</span>]
<span class="bu">print</span> frontier_data[<span class="st">&#39;Means&#39;</span>][:<span class="dv">5</span>]
<span class="cf">for</span> x <span class="kw">in</span> frontier_data[<span class="st">&#39;Weights&#39;</span>][:<span class="dv">5</span>]: <span class="bu">print</span> x</code></pre></div>
<pre><code>[0.055842999999999997, 0.053446, 0.052564, 0.051706000000000002, 0.050871]
[0.1148, 0.1169, 0.11890000000000001, 0.12089999999999999, 0.1229]
[ 0.  0.  1.]
[ 0.06407  0.00512  0.93081]
[ 0.06733  0.01497  0.9177 ]
[ 0.07228  0.02469  0.90303]
[ 0.07493  0.03458  0.89049]</code></pre>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">vw <span class="op">=</span> plot_all_possible_portfolios(annual_returns)
vw.plot(x<span class="op">=</span><span class="st">&#39;sigma&#39;</span>,y<span class="op">=</span><span class="st">&#39;return&#39;</span>,kind<span class="op">=</span><span class="st">&#39;scatter&#39;</span>)
plt.hold(<span class="va">True</span>)
plot_efficient_frontier(frontier_data)
plt.savefig(<span class="st">&#39;tser_port_03.png&#39;</span>)</code></pre></div>
<div class="figure">
<img src="tser_port_03.png" />

</div>
<p>Bootstrap</p>
<p>Dikkat: üstteki optimizasyonu olduğu gibi kullanmak sayısal olarak pek ise yaramayabilir. Mesela, üç yatırım var, S&amp;P 500, NASDAQ ve 20 yıllık ABD tahvili. Bu varlıkları basit bir şekilde kullanacağız, onları sadece alıp elde tutacağız. Eğer tek periyot (eldeki tüm veriyi) Markowitz optimizasyonu üzerinden ağırlıkları hesaplarsak, ağırlıklar çok ekstrem, stabil olmuyor. Çözüm için bootstrap tekniği kullanılır; veriden ardı ardına örneklem alırız, yani veriden yeni veri yaratırız, beklediğimiz o ki örneklemlerin dağılımı &quot;gerçek'' verinin dağılımı ile benzer olacak. Bu işlemin yan etkisi veriyi fazlalaştırmak, ardından yapılan hesabın ortalamasını alınca stabiliteye daha yaklaşmış olmak.</p>
<p>Zaman serisinden örneklem almanın değişik yolları var, bir tanesi blok örneklem yöntemi, kesintisiz zaman seri parçaları almak. Bir diğeri noktalar ardı ardına olsun olmasın verinin rasgele noktalarından örneklem toplamak. Alttaki ikinci yöntemi takip ediyor,</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="im">import</span> zipfile, pandas <span class="im">as</span> pd, util
<span class="im">import</span> numpy <span class="im">as</span> np, random, datetime
<span class="im">from</span> scipy.optimize <span class="im">import</span> minimize

<span class="kw">def</span> create_dull_pd_matrix(dullvalue<span class="op">=</span><span class="fl">0.0</span>, dullname<span class="op">=</span><span class="st">&quot;A&quot;</span>,
                          startdate<span class="op">=</span>pd.datetime(<span class="dv">1970</span>,<span class="dv">1</span>,<span class="dv">1</span>).date(),
                          enddate<span class="op">=</span>datetime.datetime.now().date(), index<span class="op">=</span><span class="va">None</span>):
    <span class="cf">if</span> index <span class="kw">is</span> <span class="va">None</span>:
        index<span class="op">=</span>pd.date_range(startdate, enddate)    
    dullvalue<span class="op">=</span>np.array([dullvalue]<span class="op">*</span><span class="bu">len</span>(index))    
    ans<span class="op">=</span>pd.DataFrame(dullvalue, index, columns<span class="op">=</span>[dullname])    
    <span class="cf">return</span> ans

<span class="kw">def</span> addem(weights):
    <span class="cf">return</span> <span class="fl">1.0</span> <span class="op">-</span> <span class="bu">sum</span>(weights)

<span class="kw">def</span> variance(weights, sigma):
    <span class="cf">return</span> (np.matrix(weights)<span class="op">*</span>sigma<span class="op">*</span>np.matrix(weights).transpose())[<span class="dv">0</span>,<span class="dv">0</span>]

<span class="kw">def</span> neg_SR(weights, sigma, mus):
    estreturn<span class="op">=</span>(np.matrix(weights)<span class="op">*</span>mus)[<span class="dv">0</span>,<span class="dv">0</span>]
    std_dev<span class="op">=</span>(variance(weights,sigma)<span class="op">**</span>.<span class="dv">5</span>)    
    <span class="cf">return</span> <span class="op">-</span>estreturn<span class="op">/</span>std_dev

<span class="kw">def</span> equalise_vols(returns, default_vol):    
    factors<span class="op">=</span>(default_vol<span class="op">/</span><span class="fl">16.0</span>)<span class="op">/</span>returns.std(axis<span class="op">=</span><span class="dv">0</span>)
    facmat<span class="op">=</span>create_dull_pd_matrix(dullvalue<span class="op">=</span>factors,
                                 dullname<span class="op">=</span>returns.columns,
                                 index<span class="op">=</span>returns.index)
    norm_returns<span class="op">=</span>returns<span class="op">*</span>facmat
    norm_returns.columns<span class="op">=</span>returns.columns
    <span class="cf">return</span> norm_returns

<span class="kw">def</span> markosolver(returns, default_vol, default_SR):        
    use_returns<span class="op">=</span>equalise_vols(returns, default_vol)    
    sigma<span class="op">=</span>use_returns.cov().values
    mus <span class="op">=</span> use_returns[asset_name].mean() <span class="cf">for</span> asset_name <span class="kw">in</span> use_returns.columns
    mus<span class="op">=</span>np.array([mus], ndmin<span class="op">=</span><span class="dv">2</span>)
    mus<span class="op">=</span>mus.transpose()
    number_assets<span class="op">=</span>use_returns.shape[<span class="dv">1</span>]
    start_weights<span class="op">=</span>[<span class="fl">1.0</span><span class="op">/</span>number_assets]<span class="op">*</span>number_assets    
    bounds<span class="op">=</span>[(<span class="fl">0.0</span>,<span class="fl">1.0</span>)]<span class="op">*</span>number_assets
    cdict<span class="op">=</span>[{<span class="st">&#39;type&#39;</span>:<span class="st">&#39;eq&#39;</span>, <span class="st">&#39;fun&#39;</span>:addem}]    
    ans<span class="op">=</span>minimize(neg_SR, start_weights,
                 (sigma, mus),
                 method<span class="op">=</span><span class="st">&#39;SLSQP&#39;</span>,
                 bounds<span class="op">=</span>bounds,
                 constraints<span class="op">=</span>cdict,
                 tol<span class="op">=</span><span class="fl">0.00001</span>)
    <span class="cf">return</span> ans[<span class="st">&#39;x&#39;</span>]

<span class="kw">def</span> generate_fitting_dates(data, rollyears):
    start_date<span class="op">=</span>data.index[<span class="dv">0</span>]
    end_date<span class="op">=</span>data.index[<span class="op">-</span><span class="dv">1</span>]
    yearstarts<span class="op">=</span><span class="bu">list</span>(pd.date_range(start_date, end_date, freq<span class="op">=</span><span class="st">&quot;12M&quot;</span>))<span class="op">+</span>[end_date]   
    periods<span class="op">=</span>[]
    <span class="cf">for</span> tidx <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(yearstarts))[<span class="dv">1</span>:<span class="op">-</span><span class="dv">1</span>]:
        period_start<span class="op">=</span>yearstarts[tidx]
        period_end<span class="op">=</span>yearstarts[tidx<span class="op">+</span><span class="dv">1</span>]
        fit_start<span class="op">=</span>start_date            
        fit_end<span class="op">=</span>period_start        
        periods.append([fit_start, fit_end, period_start, period_end])

    <span class="cf">return</span> periods

<span class="kw">def</span> bootstrap_portfolio(returns_to_bs,monte_carlo,
                        monte_length,default_vol,default_SR):
            
    weightlist<span class="op">=</span>[]
    <span class="cf">for</span> unused_index <span class="kw">in</span> <span class="bu">range</span>(monte_carlo):
        bs_idx<span class="op">=</span>[<span class="bu">int</span>(random.uniform(<span class="dv">0</span>,<span class="dv">1</span>)<span class="op">*</span><span class="bu">len</span>(returns_to_bs)) <span class="op">\</span>
                <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(monte_length)]        
        returns<span class="op">=</span>returns_to_bs.iloc[bs_idx,:] 
        weight<span class="op">=</span>markosolver(returns, default_vol<span class="op">=</span>default_vol, default_SR<span class="op">=</span>default_SR)
        weightlist.append(weight)
     
    theweights_mean<span class="op">=</span><span class="bu">list</span>(np.mean(weightlist, axis<span class="op">=</span><span class="dv">0</span>))
    <span class="cf">return</span> theweights_mean

<span class="kw">def</span> optimise_over_periods(data,rollyears, monte_carlo,monte_length):

    fit_periods<span class="op">=</span>generate_fitting_dates(data, rollyears<span class="op">=</span>rollyears)    
    weight_list<span class="op">=</span>[]
    <span class="cf">for</span> fit_tuple <span class="kw">in</span> fit_periods:
        period_subset_data<span class="op">=</span>data[fit_tuple[<span class="dv">0</span>]:fit_tuple[<span class="dv">1</span>]]        
        weights<span class="op">=</span>bootstrap_portfolio(period_subset_data,
                                    monte_carlo<span class="op">=</span>monte_carlo,
                                    monte_length<span class="op">=</span>monte_length,
                                    default_vol<span class="op">=</span><span class="fl">0.2</span>, default_SR<span class="op">=</span><span class="fl">1.0</span> )
        
        dindex<span class="op">=</span>[fit_tuple[<span class="dv">2</span>]<span class="op">+</span>datetime.timedelta(seconds<span class="op">=</span><span class="dv">1</span>),
                fit_tuple[<span class="dv">3</span>]<span class="op">-</span>datetime.timedelta(seconds<span class="op">=</span><span class="dv">1</span>)] 
        weight_row<span class="op">=</span>pd.DataFrame([weights]<span class="op">*</span><span class="dv">2</span>,
                                index<span class="op">=</span>dindex,
                                columns<span class="op">=</span>data.columns) 
        weight_list.append(weight_row)
        
    weight_df<span class="op">=</span>pd.concat(weight_list, axis<span class="op">=</span><span class="dv">0</span>)    
    <span class="cf">return</span> weight_df</code></pre></div>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="im">import</span> zipfile, pandas <span class="im">as</span> pd, random
symbols <span class="op">=</span> [<span class="st">&#39;SP500&#39;</span>,<span class="st">&#39;NASDAQ&#39;</span>,<span class="st">&#39;US20&#39;</span>]
df <span class="op">=</span> pd.DataFrame()
<span class="cf">with</span> zipfile.ZipFile(<span class="st">&#39;../tser_voltar/legacycsv.zip&#39;</span>, <span class="st">&#39;r&#39;</span>) <span class="im">as</span> z:
    <span class="cf">for</span> symbol <span class="kw">in</span> symbols:
        f <span class="op">=</span> <span class="st">&#39;</span><span class="sc">%s</span><span class="st">_price.csv&#39;</span> <span class="op">%</span> symbol
        df[symbol] <span class="op">=</span> pd.read_csv(z.<span class="bu">open</span>(f),sep<span class="op">=</span><span class="st">&#39;,&#39;</span>,
                                 index_col<span class="op">=</span><span class="dv">0</span>,
                                 parse_dates<span class="op">=</span><span class="va">True</span>)[<span class="st">&#39;PRICE&#39;</span>]
    
df[<span class="st">&#39;SP500&#39;</span>] <span class="op">=</span> df.SP500.pct_change()
df[<span class="st">&#39;NASDAQ&#39;</span>] <span class="op">=</span> df.NASDAQ.pct_change()
df[<span class="st">&#39;US20&#39;</span>] <span class="op">=</span> df.US20.pct_change()

df <span class="op">=</span> df[(df.index <span class="op">&gt;=</span> <span class="st">&#39;1999-08-02&#39;</span>) <span class="op">&amp;</span> (df.index <span class="op">&lt;=</span> <span class="st">&#39;2015-04-22&#39;</span>)]
    
random.seed(<span class="dv">0</span>)

w<span class="op">=</span>boot.optimise_over_periods(df)</code></pre></div>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">w.plot()
plt.savefig(<span class="st">&#39;tser_port_01.png&#39;</span>)</code></pre></div>
<div class="figure">
<img src="tser_port_01.png" />

</div>
<p>Bu sonuç [1. sf. 172]'dakine yakın, ağırlıklar çok daha stabil.</p>
<p>Kodda oynaklığın standardize edildiğine dikkat; tüm zaman serilerinin oynaklığı eşitleniyor, ve maksimize edilmeye uğraşılan getiri.</p>
</body>
</html>
