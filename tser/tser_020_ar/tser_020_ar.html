<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
    <script type="text/x-mathjax-config">
    MathJax.Hub.Register.StartupHook("TeX Jax Ready",function () {
      MathJax.Hub.Insert(MathJax.InputJax.TeX.Definitions.macros,{
        cancel: ["Extension","cancel"], cancelto: ["Extension","cancel"]
      });
    });
    </script>  
   
  <title>ARIMA, ARCH, GARCH, Periyotlar, Yürüyen Ortalama</title>
  <style type="text/css">code{white-space: pre;}</style>
  <style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
  </style>
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>
</head>
<body>
<div id="header">
</div>
<h1 id="arima-arch-garch-periyotlar-yürüyen-ortalama">ARIMA, ARCH, GARCH, Periyotlar, Yürüyen Ortalama</h1>
<p>Kendisiyle Regresyon ve Yürüyen Ortalama (Autoregression, Moving Average)</p>
<p>Bir zaman serisi rasgele yürüyüşe (random walk) sahipse <span class="math inline">\(t\)</span> anındaki değeri önceki rasgele hareketlerin birleşimiydi. Diğer alternatif bir serinin {} arada gürültü olmadan bağlantılı olmasıdır. Bu her iki yaklaşımı genelleştirerek ARIMA formunda gösterebiliriz. İlk önce AR formuna bakalım; Birinci seviyede kendisiyle regresyon (autoregression, first order) AR(1)'dır [1, sf. 23],</p>
<p><span class="math display">\[ 
y_t = c + \phi y_{t-1} + \epsilon_t  
\qquad (1) 
\]</span></p>
<p>Daha yüksek seviyeler AR(p) olarak gösterilir,</p>
<p><span class="math display">\[ y_t = c + \phi_1 y_{t-1} +  \phi_2 y_{t-2} + ... +  \phi_p y_{t-p}  + \epsilon_t  \]</span></p>
<p>Bu durumda <span class="math inline">\(t\)</span> anındaki değer önceki <span class="math inline">\(t-1,..,t-p\)</span> anındaki değerlerle (belli oranlar üzerinden tabii) artı gürültüye eşittir.</p>
<p>Bir diğer zaman serisi yürüyen ortalama (moving average) serisidir, bu tür seriler <span class="math inline">\(t\)</span> anını önceki <em>gürültülerin</em> bir ortalaması olarak gösterir. Dikkat, önceki tüm gürültüleri olduğu gibi toplamıyoruz, belli sayıdaki önceki gürültüleri belli ağırlıklar üzerinden topluyoruz. Birinci seviyede bu seriler MA(1) olarak tanımlanır,</p>
<p><span class="math display">\[ y_t = \mu + \epsilon_t + \theta \epsilon_{t-1} \]</span></p>
<p>Daha yüksek seviyeleri MA(q) olarak tanımlarız,</p>
<p><span class="math display">\[ y_t = \mu + \epsilon_t + \theta_1 \epsilon_{t-1} + .. + \theta_q \epsilon_{t-q} \]</span></p>
<p>Pratikte pür birer AR(p) ya da MA(q) serisini tanımlamak zordur, çoğunlukla ikisinin bir karışımı olan ARMA(p,q) serileri test edilir (ya da daha genel olarak, AR<em>I</em>MA)(p,d,q). Ek I sembolü modele bir diferansiyel etkisi sağlıyor, bu eke göre eğer farkı alınmış seri bir ARMA modeli oluyorsa bu model ARIMA kabul ediliyor. Mesela ilk farklar <span class="math inline">\(d=1\)</span> için <span class="math inline">\(y_t - y_{t-1}\)</span> modeli ARMA ise, bu model ARIMA'dır [4, sf. 92].</p>
<p>Rasgele yürüyüş bu genel formda gösterilebilir, rasgele yürüyüş ARIMA(0,1,0) modelidir.</p>
<p>Daha odaklı bir örnek olarak Lynx verisine bakalım [2, sf. 727],</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="im">import</span> pandas <span class="im">as</span> pd
<span class="im">import</span> statsmodels.api <span class="im">as</span> sm
df <span class="op">=</span> pd.read_csv(<span class="st">&#39;../tser_stoc/lynx.csv&#39;</span>)</code></pre></div>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">df.x.plot()
plt.savefig(<span class="st">&#39;tser_ar_01.png&#39;</span>)</code></pre></div>
<div class="figure">
<img src="tser_ar_01.png" />

</div>
<p>Çıplak gözle bakıldığında zaman serisinde 10 senelik kuvvetli bir periyot olduğunu görüyoruz. Acaba hangi ARIMA serisi, hangi <span class="math inline">\(p,q\)</span> parametreleri üzerinden Lynx'i modelleyebilir? Bunun için önce bir kendisiyle korelasyon (autocorrelation) ACF ve kısmi kendisiyle korelasyon PACF analizi yapmak faydalı olabilir. PACF, aynen ACF gibi, seriyi bir ya da daha fazla geriye kaydırarak kendisiyle olan korelasyonunu inceler, ama bunu diğer tüm diğer kaydırılmış serilerin etkisini çıkartarak yapar, böylece gerideki belli bir <span class="math inline">\(t-n\)</span> noktasının etkisi daha açık olarak görülebilir.</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="im">import</span> statsmodels.api <span class="im">as</span> sm
sm.graphics.tsa.plot_acf(df.x.values.squeeze(), lags<span class="op">=</span><span class="dv">40</span>)
plt.savefig(<span class="st">&#39;tser_ar_02.png&#39;</span>)</code></pre></div>
<div class="figure">
<img src="tser_ar_02.png" />

</div>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">sm.graphics.tsa.plot_pacf(df.x, lags<span class="op">=</span><span class="dv">40</span>)
plt.savefig(<span class="st">&#39;tser_ar_03.png&#39;</span>)</code></pre></div>
<div class="figure">
<img src="tser_ar_03.png" />

</div>
<p>ACF/PACF grafiklerinde mavi bölge dışına taşan noktalar istatistiki olarak önemli demektir. ACF'te 10 senelik periyot açık şekilde görülüyor. Hangi evre gecikmesi (lag) daha önemli? PACF grafiğinde 2. evrede güçlü bir negatif korelasyon görülüyor, 1 ve 8'de güçlü pozitif korelasyonlar var, ve 4'te yine negatif.</p>
<p>Şimdi belli ARIMA modellerini test edelim, modelleri birbiri ile kıyaslamak için AIC istatistiğini kullanacağız, daha düşük AIC daha iyi demektir. Ama ondan önce bir AR modelinin nasıl veriye uydurulduğunu düşünelim; (1)'deki formülde <span class="math inline">\(y_t\)</span> ve <span class="math inline">\(y_{t-1}\)</span> arasında lineer bir ilişki görüyoruz. Bu durumda bu iki veri noktasının bir lineer regresyona verirsek, <span class="math inline">\(\phi\)</span> değeri bu regresyondan ortaya çıkacaktır. Regresyonun işlemesi için veri noktalarının bir aşağı kaydırırız, ve bu kaydırılmış değeri asıl değer ile regresyona sokarız,</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="im">import</span> statsmodels.formula.api <span class="im">as</span> smf
df[<span class="st">&#39;x_lag1&#39;</span>] <span class="op">=</span> df.x.shift(<span class="dv">1</span>)
<span class="bu">print</span> (df[[<span class="st">&#39;x&#39;</span>,<span class="st">&#39;x_lag1&#39;</span>]].head(<span class="dv">6</span>), <span class="st">&#39;</span><span class="ch">\n</span><span class="st">&#39;</span>)
results <span class="op">=</span> smf.ols(<span class="st">&#39;x ~ x_lag1&#39;</span>, data<span class="op">=</span>df).fit()
<span class="bu">print</span> (results.params)
<span class="bu">print</span> (<span class="st">&#39;aic&#39;</span>, results.aic)</code></pre></div>
<pre><code>      x  x_lag1
0   269     NaN
1   321   269.0
2   585   321.0
3   871   585.0
4  1475   871.0
5  2821  1475.0 

Intercept    454.151675
x_lag1         0.719712
dtype: float64
aic 1907.7277269856995</code></pre>
<p>Şimdi bir ARIMA paketi ile aynısını yapalım,</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="im">from</span> statsmodels.tsa.arima_model <span class="im">import</span> ARIMA
model10 <span class="op">=</span> ARIMA(df.x, order<span class="op">=</span>(<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">0</span>))
model_fit <span class="op">=</span> model10.fit(disp<span class="op">=</span><span class="dv">0</span>)
<span class="bu">print</span>(model_fit.summary())</code></pre></div>
<pre><code>                              ARMA Model Results                              
==============================================================================
Dep. Variable:                      x   No. Observations:                  114
Model:                     ARMA(1, 0)   Log Likelihood                -960.495
Method:                       css-mle   S.D. of innovations           1100.247
Date:                Tue, 13 Nov 2018   AIC                           1926.991
Time:                        11:45:20   BIC                           1935.199
Sample:                             0   HQIC                          1930.322
                                                                              
==============================================================================
                 coef    std err          z      P&gt;|z|      [0.025      0.975]
------------------------------------------------------------------------------
const       1550.1773    356.690      4.346      0.000     851.078    2249.276
ar.L1.x        0.7173      0.065     11.042      0.000       0.590       0.845
                                    Roots                                    
=============================================================================
                  Real          Imaginary           Modulus         Frequency
-----------------------------------------------------------------------------
AR.1            1.3941           +0.0000j            1.3941            0.0000
-----------------------------------------------------------------------------</code></pre>
<p>Sonuçlar oldukça yakın (gerçi kesi farklı -niye?-, ama katsayı daha önemli).</p>
<p>En İyi Model?</p>
<p>AR, ARIMA, MA, onların dereceleri arasında bir seçim yapmak gerekiyor. Önce sırf AR deneyelim,</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">res <span class="op">=</span> []
res.append(ARIMA(df.x, order<span class="op">=</span>(<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">0</span>)).fit(disp<span class="op">=</span><span class="dv">0</span>))
res.append(ARIMA(df.x, order<span class="op">=</span>(<span class="dv">2</span>,<span class="dv">0</span>,<span class="dv">0</span>)).fit(disp<span class="op">=</span><span class="dv">0</span>))
res.append(ARIMA(df.x, order<span class="op">=</span>(<span class="dv">3</span>,<span class="dv">0</span>,<span class="dv">0</span>)).fit(disp<span class="op">=</span><span class="dv">0</span>))
res.append(ARIMA(df.x, order<span class="op">=</span>(<span class="dv">4</span>,<span class="dv">0</span>,<span class="dv">0</span>)).fit(disp<span class="op">=</span><span class="dv">0</span>))
res.append(ARIMA(df.x, order<span class="op">=</span>(<span class="dv">5</span>,<span class="dv">0</span>,<span class="dv">0</span>)).fit(disp<span class="op">=</span><span class="dv">0</span>))
res.append(ARIMA(df.x, order<span class="op">=</span>(<span class="dv">6</span>,<span class="dv">0</span>,<span class="dv">0</span>)).fit(disp<span class="op">=</span><span class="dv">0</span>))
<span class="cf">for</span> x <span class="kw">in</span> res: <span class="bu">print</span> (x.df_model<span class="op">+</span><span class="dv">1</span>, x.aic)</code></pre></div>
<pre><code>3 1926.9906490207566
4 1878.031850120836
5 1879.9567487161364
6 1874.221797648189
7 1875.2758635012437
8 1876.858328122954</code></pre>
<p>En iyi model AR(4) olarak gözüküyor. Şimdi sadece MA olarak bakalım,</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">lynx <span class="op">=</span> df.x
<span class="op">%</span>R <span class="op">-</span>i lynx
<span class="op">%</span>R model01<span class="op">&lt;-</span>arima(lynx,order<span class="op">=</span>c(<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">1</span>))
<span class="op">%</span>R model02<span class="op">&lt;-</span>arima(lynx,order<span class="op">=</span>c(<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">2</span>))
<span class="op">%</span>R model03<span class="op">&lt;-</span>arima(lynx,order<span class="op">=</span>c(<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">3</span>))
<span class="op">%</span>R model04<span class="op">&lt;-</span>arima(lynx,order<span class="op">=</span>c(<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">4</span>))
<span class="op">%</span>R model05<span class="op">&lt;-</span>arima(lynx,order<span class="op">=</span>c(<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">5</span>))
<span class="op">%</span>R model06<span class="op">&lt;-</span>arima(lynx,order<span class="op">=</span>c(<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">6</span>))
<span class="op">%</span>R <span class="op">-</span>o res res <span class="op">&lt;-</span> AIC(model01,model02,model03,model04,model05,model06)
<span class="bu">print</span> res</code></pre></div>
<pre><code>        df      AIC
model01  3 1917,947
model02  4 1890,061
model03  5 1887,770
model04  6 1888,279
model05  7 1885,698
model06  8 1885,230
</code></pre>
<p>Bu AIC'ler AR'dekilerden yüksek. Belki bir <span class="math inline">\(p,q\)</span> kombinasyonu daha iyidir? En iyi p olan <span class="math inline">\(p=4\)</span>'u tutalım, ve diğer <span class="math inline">\(q\)</span>'leri test edelim,</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">lynx <span class="op">=</span> df.x
<span class="op">%</span>R <span class="op">-</span>i lynx
<span class="op">%</span>R model40<span class="op">&lt;-</span>arima(lynx,order<span class="op">=</span>c(<span class="dv">4</span>,<span class="dv">0</span>,<span class="dv">0</span>))
<span class="op">%</span>R model41<span class="op">&lt;-</span>arima(lynx,order<span class="op">=</span>c(<span class="dv">4</span>,<span class="dv">0</span>,<span class="dv">1</span>))
<span class="op">%</span>R model42<span class="op">&lt;-</span>arima(lynx,order<span class="op">=</span>c(<span class="dv">4</span>,<span class="dv">0</span>,<span class="dv">2</span>))
<span class="op">%</span>R model43<span class="op">&lt;-</span>arima(lynx,order<span class="op">=</span>c(<span class="dv">4</span>,<span class="dv">0</span>,<span class="dv">3</span>))
<span class="op">%</span>R <span class="op">-</span>o res res<span class="op">&lt;-</span>AIC(model40,model41,model42,model43)
<span class="bu">print</span> res</code></pre></div>
<pre><code>        df      AIC
model40  6 1874,222
model41  7 1875,351
model42  8 1862,435
model43  9 1880,432
</code></pre>
<p>Görülüyor ki hareketli ortalama ekine hiç gerek yok, çünkü en iyi AIC <span class="math inline">\(q=0\)</span> için. Ya farklı diferansiyeller, yani ARIMA'nın I'si?</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">lynx <span class="op">=</span> df.x
<span class="op">%</span>R <span class="op">-</span>i lynx
<span class="op">%</span>R model400<span class="op">&lt;-</span>arima(lynx,order<span class="op">=</span>c(<span class="dv">4</span>,<span class="dv">0</span>,<span class="dv">0</span>))
<span class="op">%</span>R model401<span class="op">&lt;-</span>arima(lynx,order<span class="op">=</span>c(<span class="dv">4</span>,<span class="dv">1</span>,<span class="dv">0</span>))
<span class="op">%</span>R model402<span class="op">&lt;-</span>arima(lynx,order<span class="op">=</span>c(<span class="dv">4</span>,<span class="dv">2</span>,<span class="dv">0</span>))
<span class="op">%</span>R model403<span class="op">&lt;-</span>arima(lynx,order<span class="op">=</span>c(<span class="dv">4</span>,<span class="dv">3</span>,<span class="dv">0</span>))
<span class="op">%</span>R <span class="op">-</span>o res res<span class="op">&lt;-</span>AIC(model400,model401,model402,model403)
<span class="bu">print</span> res</code></pre></div>
<pre><code>         df      AIC
model400  6 1874,222
model401  5 1890,961
model402  5 1917,882
model403  5 1946,143
</code></pre>
<p>Diferansiyele de ihtiyaç yok, en iyi diferansiyel <span class="math inline">\(d=0\)</span>. En düşük AIC 1874.22, ve AR'ın gecikmeli evresi 4, ve hiçbir hareketli ortalama ve diferansiyle ihtiyaç yok. <span class="math inline">\(p=4\)</span> deyince tabii ki <span class="math inline">\(t\)</span> anının <span class="math inline">\(p-1,..,p-4\)</span> ile alakası olması hali, yani <span class="math inline">\(t\)</span> anı kendinden önceki 4 nokta ile ilişkide olacaktır. Bu ilişkiler gecikmeli sadece evre 2'deki kısmı korelasyonu değil, 4'teki kısmı korelasyonu da dikkate almak zorundadır yani.</p>
<p>Oynaklık (Volatility) ve GARCH Modelleri</p>
<p>ARCH İngilizce autoregressive conditional heteroskedasticity kelimelerinden geliyor, yani kendisiyle regresyonda olan koşullu değişen varyans serileri. GARCH ise genelleştirilmiş ARCH demektir. Şimdiye kadar gördük ki getiri <span class="math inline">\(r_t\)</span>'ler (returns) tipik olarak <span class="math inline">\(N(0,\sigma^2)\)</span>'den gelmektedir. Fakat finans zaman serilerinde çoğunlukla oynaklığın, matematiksel olarak varyansın zamana göre değişebildiği görülmektedir, varyans <span class="math inline">\(h_t\)</span> belli noktalarda farklı olabilmektedir, hatta belli oynaklık blokları (volatility regions) olabilmektedir. Daha önce ARIMA'nın MA kısmında <span class="math inline">\(t\)</span> anındaki gürültünün önceki zaman noktalarındaki gürültünün bir ortalaması olduğunu görmüştük, burada varyans da bir trend ve kaymaya (drift) sahip olabilmektedir.</p>
<p>ARCH(1) modeli</p>
<p><span class="math display">\[ y_t = \phi + e_t \]</span></p>
<p><span class="math display">\[ e_t \sim N(0,h_t) \]</span></p>
<p><span class="math display">\[ h_t = \alpha_0 + \alpha_1 e_{t-1}^2 \]</span></p>
<p>olarak gösterilir. <span class="math inline">\(\phi,\alpha_0,\alpha_1\)</span> veriden hesaplanacaktır, ya da simulasyon durumunda dışarıdan belirlenecektir.</p>
<p>ARCH(q) modeli üstteki formül üzerinde basit bir uzatma yapar,</p>
<p><span class="math display">\[ h_t = \alpha_0 + \alpha_1 e_{t-1}^2 + ... + \alpha_1 e_{t-q}^2 \]</span></p>
<p>GARCH</p>
<p>Matematiksel olarak GARCH(p,q) <span class="math inline">\(p=1,q=1\)</span> modeli, yani GARCH(1,1)</p>
<p><span class="math display">\[ h_t = \omega + \alpha_1 e_{t-1}^2 + \beta_1 h_{t-1}\]</span></p>
<p>GARCH(1,1) olduğu farzedilen bir finans serisinin parametrelerini bulmak için R <code>tseries</code> paketi kullanılabilir. Veri S&amp;P 500 tüm 90'li yılların düzeltilmiş (adjusted) kapanış fiyatlarını içeriyor, getiri hesabı için <span class="math inline">\(\ln (P_t/P_{t-1})\)</span> ya da <span class="math inline">\(\ln (P_t) - \ln(P_{t-1})\)</span> yapıyoruz, ve bu getiriler üzerinde <code>garch</code> parametrelerini hesaplıyoruz.</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="im">import</span> pandas <span class="im">as</span> pd
dfsp500 <span class="op">=</span> pd.read_csv(<span class="st">&#39;SP500.csv&#39;</span>)
ret <span class="op">=</span> np.log(dfsp500[<span class="st">&#39;Adj Close&#39;</span>]).diff()<span class="op">*</span><span class="fl">100.</span>
ret <span class="op">=</span> ret.fillna(<span class="dv">0</span>)</code></pre></div>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="im">from</span> arch <span class="im">import</span> arch_model
am <span class="op">=</span> arch_model(ret)
res <span class="op">=</span> am.fit(update_freq<span class="op">=</span><span class="dv">5</span>)
<span class="bu">print</span> (res.summary())</code></pre></div>
<pre><code>Iteration:      5,   Func. Count:     41,   Neg. LLF: 3034.2183086575697
Iteration:     10,   Func. Count:     76,   Neg. LLF: 3032.126998485467
Iteration:     15,   Func. Count:    107,   Neg. LLF: 3032.061301642375
Optimization terminated successfully.    (Exit mode 0)
            Current function value: 3032.061301642018
            Iterations: 15
            Function evaluations: 107
            Gradient evaluations: 15
                     Constant Mean - GARCH Model Results                      
==============================================================================
Dep. Variable:              Adj Close   R-squared:                      -0.000
Mean Model:             Constant Mean   Adj. R-squared:                 -0.000
Vol Model:                      GARCH   Log-Likelihood:               -3032.06
Distribution:                  Normal   AIC:                           6072.12
Method:            Maximum Likelihood   BIC:                           6095.46
                                        No. Observations:                 2528
Date:                Tue, Nov 13 2018   Df Residuals:                     2524
Time:                        12:31:10   Df Model:                            4
                                 Mean Model                                 
============================================================================
                 coef    std err          t      P&gt;|t|      95.0% Conf. Int.
----------------------------------------------------------------------------
mu             0.0588  1.466e-02      4.014  5.975e-05 [3.010e-02,8.755e-02]
                               Volatility Model                              
=============================================================================
                 coef    std err          t      P&gt;|t|       95.0% Conf. Int.
-----------------------------------------------------------------------------
omega      5.4768e-03  3.144e-03      1.742  8.155e-02 [-6.861e-04,1.164e-02]
alpha[1]       0.0517  1.700e-02      3.041  2.356e-03  [1.838e-02,8.501e-02]
beta[1]        0.9421  1.858e-02     50.694      0.000      [  0.906,  0.979]
=============================================================================

Covariance estimator: robust</code></pre>
<p>Bu parametreler acaba doğru mu? Parametreler ile verinin kendisinin üretmeye uğraşalım. <span class="math inline">\(\phi=0\)</span> kabul edersek, <span class="math inline">\(y_t = e_t\)</span> olarak alabiliriz,</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">np.random.seed(<span class="dv">1</span>)
<span class="im">import</span> pandas <span class="im">as</span> pd
N <span class="op">=</span> <span class="bu">len</span>(dfsp500)
alpha0<span class="op">=</span><span class="fl">0.0048</span>
alpha1<span class="op">=</span><span class="fl">0.05</span>
beta1 <span class="op">=</span> <span class="fl">0.946773</span>
y <span class="op">=</span> np.zeros(N)
h <span class="op">=</span> np.zeros(N)
w <span class="op">=</span> np.random.standard_normal(N)
<span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>,N): 
    h[i] <span class="op">=</span> alpha0 <span class="op">+</span> alpha1 <span class="op">*</span> (y[i<span class="dv">-1</span>]<span class="op">**</span><span class="dv">2</span>) <span class="op">+</span> beta1 <span class="op">*</span> h[i<span class="dv">-1</span>]
    y[i] <span class="op">=</span> w[i] <span class="op">*</span> np.sqrt(h[i])</code></pre></div>
<p>Gerçek veriyi ve simulasyonu yan yana iki grafikte basalım,</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">dfsp500[<span class="st">&#39;SP500&#39;</span>] <span class="op">=</span> ret
dfsp500[<span class="st">&#39;simulasyon&#39;</span>] <span class="op">=</span> y
dfsp500[<span class="st">&#39;SP500&#39;</span>].plot()
plt.title(<span class="st">&#39;SP500&#39;</span>)
plt.savefig(<span class="st">&#39;tser_ar_04.png&#39;</span>)
dfsp500[<span class="st">&#39;simulasyon&#39;</span>].plot()
plt.title(<span class="st">&#39;Simulasyon&#39;</span>)
plt.savefig(<span class="st">&#39;tser_ar_05.png&#39;</span>)</code></pre></div>
<p><img src="tser_ar_04.png" /> <img src="tser_ar_05.png" /></p>
<p>Bir serinin değişen varyansa sahip olup olmadığını anlamak için bir istatistiki test [3, sf. 355] Breusch-Pagan testi,</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="im">import</span> numpy <span class="im">as</span> np
<span class="im">import</span> statsmodels.api <span class="im">as</span> sm
<span class="im">import</span> scipy <span class="im">as</span> sp

<span class="kw">def</span> breusch_pagan_test(y,x):
     results<span class="op">=</span>sm.OLS(y,x).fit()
     resid<span class="op">=</span>results.resid
     n<span class="op">=</span><span class="bu">len</span>(resid)
     sigma2 <span class="op">=</span> <span class="bu">sum</span>(resid<span class="op">**</span><span class="dv">2</span>)<span class="op">/</span>n
     f <span class="op">=</span> resid<span class="op">**</span><span class="dv">2</span><span class="op">/</span>sigma2 <span class="op">-</span> <span class="dv">1</span>
     results2<span class="op">=</span>sm.OLS(f,x).fit()
     fv<span class="op">=</span>results2.fittedvalues
     bp<span class="op">=</span><span class="fl">0.5</span> <span class="op">*</span> <span class="bu">sum</span>(fv<span class="op">**</span><span class="dv">2</span>)
     df<span class="op">=</span>results2.df_model
     p_value<span class="op">=</span><span class="dv">1</span><span class="op">-</span>sp.stats.chi.cdf(bp,df)
     <span class="cf">return</span> <span class="bu">round</span>(bp,<span class="dv">6</span>), df, <span class="bu">round</span>(p_value,<span class="dv">7</span>)</code></pre></div>
<p>Lynx verisi üzerinde uygulayalım,</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="im">import</span> pandas <span class="im">as</span> pd
<span class="im">import</span> breusch
dflynx <span class="op">=</span> pd.read_csv(<span class="st">&#39;../tser_stoc/lynx.csv&#39;</span>)<span class="op">;</span>
<span class="bu">print</span> breusch.breusch_pagan_test(dflynx.x, <span class="bu">range</span>(<span class="bu">len</span>(dflynx)))</code></pre></div>
<pre><code>(0.429236, 1.0, 0.6677515)</code></pre>
<p>En sondaki değer p-değeridir, 0.05'ten düşüklük varyansın sabit olduğu hipotezinin reddedildiği anlamına gelir, yani değişen varyans durumu vardır. Üstteki sonuçta tezi reddedemedik, demek ki Lynx verisinde varyans değişmiyor.</p>
<p>Basit Yürüyen Ortalama</p>
<p>Kabaca bir zaman serisini pürüzsüzleştirmenin (smoothing) en basit yolu basit bir yürüyen ortalama almaktır. Bir pencere büyüklüğü tanımlarız, bu pencereyi zaman serisinin üzerine koyarız, içine düşen tüm noktaların ortalamasını alırız, ve pencereyi bir yana kaydırarak işlemi tekrarlarız. Tüm zaman serisi için bu yapılınca elimize bir ortalama geçmiş olur,</p>
<p>Yani <span class="math inline">\(x_1,..,x_t\)</span> zaman serisi için</p>
<p><span class="math display">\[ 
y_t = \frac{1}{k} \sum_{n=0}^{k-1} x_{t-n}  
= \frac{x_t + x_{t-1} + ... + x_{t-k+1}}{k} 
\]</span></p>
<p>Burada hiç ağırlık kullanmadık, yani pencere içinde veri noktalarının bazılarına daha fazla, bazılarına daha az ağırlık vermedik. Daha doğrusu ağırlık kullandık, ama tüm noktalara '1' ağırlığı verdik ve bu sebeple k tane '1' ağırlık verilmiş toplamı <span class="math inline">\(k\)</span>'ye böldük. Fakat '1' yerine farklı ağırlıklar da verebilirdik, mesela <span class="math inline">\(w_1,w_2,..\)</span> ki ağırlık toplamı 1 olacak şekilde,</p>
<p><span class="math display">\[ y_t = w_1x_t + w_2x_{t-1} + ... + w_kx_{t-k+1}
\]</span></p>
<p>Ağırlıkların toplamı 1, fakat 1 ile bölmeyi göstermeye gerek yok.</p>
<p>Ya da <span class="math inline">\(0 &lt; \alpha &lt; 1\)</span> olacak şekilde, tüm zaman serisini kullanarak (pencere yok), ağırlıkları <span class="math inline">\((1-\alpha)\)</span>'nin katları olacak şekilde ayarlarsak,</p>
<p><span class="math display">\[ y_t = \frac{x_t + (1-\alpha)x_{t-1} + (1-\alpha)^2x_{t-2} + ... }
{1 + (1-\alpha) + (1-\alpha)^2 + ...} 
\]</span></p>
<p>Üstteki hesaba üstel ağırlıklı yürüyen ortalama (exponentially weighted moving average -EWMA-) deniyor. Verinin tamamı kullanılır, ağırlıklar <span class="math inline">\(x_1\)</span>'e kadar gider. 0 ile 1 arasındaki değerler, ve onların gittikçe artan üstelleri ile çarptığımız için yakın zamandaki verilerin ağırlığı fazladır, eskiye gittikçe hızlı bir şekile bu etki azalmaya başlar. Eğer <span class="math inline">\(1-\alpha=0.2\)</span> ise mesela, önce <span class="math inline">\(0.2\)</span>, sonra <span class="math inline">\(0.2^2=0.04\)</span>, ardından <span class="math inline">\(0.2^3=0.008\)</span>, küçülmenin ne kadar hızlı olduğunu görüyoruz.</p>
<p>Ayrıca bölende olan ifadelerin başlangıcı 1 oranı <span class="math inline">\(1-\alpha\)</span> olan bir geometrik seri olduğunu görelim, bkz [9], o zaman bölen <span class="math inline">\(\frac{1}{1-(1-\alpha)}\)</span>'a yani <span class="math inline">\(\frac{1}{\alpha}\)</span>'ya eşittir,</p>
<p><span class="math display">\[ y_t = \frac{x_t + (1-\alpha)x_{t-1} + (1-\alpha)^2x_{t-2} + ... }
{\frac{1}{\alpha}}
\]</span></p>
<p><span class="math display">\[  = [ x_t + (1-\alpha)x_{t-1} + (1-\alpha)^2x_{t-2} + ... ] \alpha \]</span></p>
<p>Üstteki hesabı özyineli yapmak ta mümkündür, türetmeye devam edersek,</p>
<p><span class="math display">\[  = \alpha x_t + [(1-\alpha)x_{t-1} + (1-\alpha)^2x_{t-2} + ... ]\alpha \]</span></p>
<p><span class="math display">\[  = \alpha x_t + (1-\alpha) [x_{t-1} + (1-\alpha)x_{t-2} + ... ]\alpha \]</span></p>
<p><span class="math inline">\(\alpha\)</span> ile çarpılan köşeli parantezdekiler <span class="math inline">\(y_{t-1}\)</span>'in ta kendisi. O zaman özyineli ifade şu olur [8, sf. 502],</p>
<p><span class="math display">\[ y_t = \alpha x_t + (1-\alpha) y_{t-1}\]</span></p>
<p>Enflasyon</p>
<p>Fiyat seviyesinin (CPI) kendisiyle alakalı bir seri oldugu bilinir, bu mantıklı çünkü ekonomik psikolojisi açısından yüksek fiyat seviyesi daha yüksek fiyatlara gidişi tetikleyebilir. Alışverişte yüksek fiyatlar görüyorsam ben de kendi müşterimden daha yüksek fiyatlar istemeye başlayabilirim. Bu kendisiyle korelasyonu veride nasıl buluruz? Durbin-Watson testi var,</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="im">import</span> pandas <span class="im">as</span> pd
cpi <span class="op">=</span> pd.read_csv(<span class="st">&#39;cpi.csv&#39;</span>,index_col<span class="op">=</span><span class="dv">0</span>)</code></pre></div>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="im">import</span> statsmodels.formula.api <span class="im">as</span> smf
<span class="im">from</span> statsmodels.stats.stattools <span class="im">import</span> durbin_watson
inf <span class="op">=</span> np.log(cpi)
results <span class="op">=</span> smf.ols(<span class="st">&#39;CPIAUCNS ~ 1&#39;</span>, data<span class="op">=</span>inf).fit()
<span class="bu">print</span> (durbin_watson(results.resid))</code></pre></div>
<pre><code>9.222098132626552e-05</code></pre>
<p>Düşük bir değer kendisiyle korelasyon varlığının işareti olabilir. Not: Bu istatistik normal regresyon paketleri tarafından çoğunlukla rapor edilir çünkü basit regresyonun önkabulü kendisiyle korelasyon olmadığıdır, bu sebeple DW korelasyon varlığına işaret ediyorsa analizci için bu önemli bir sinyal olmalı.</p>
<p>Durbin-Watson istatiği 0 ile 4 arasında bir değere sahiptir, 0 ile 2 arasındaki değerler pozitif kendisiyle korelasyonun, 2 ile 4 arası negatif kendisiyle korelasyonun işaretidir. Tam 2 değeri korelasyon yok demektir.</p>
<p>Bir diger test Ljung-Box testi,</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="im">import</span> statsmodels.tsa.stattools <span class="im">as</span> tsa
acf,ci,q,pvalues <span class="op">=</span> tsa.acf(results.resid, nlags<span class="op">=</span><span class="dv">4</span>, alpha<span class="op">=</span><span class="dv">95</span>,qstat<span class="op">=</span><span class="va">True</span>, unbiased<span class="op">=</span><span class="va">True</span>)
<span class="bu">print</span> (acf)
<span class="bu">print</span> (pvalues)</code></pre></div>
<pre><code>[1.         0.99585547 0.99164499 0.98737151 0.98305291]
[1.02286496e-121 5.63735022e-239 0.00000000e+000 0.00000000e+000]</code></pre>
<p>P-değerlerinin hepsinin 0.05'ten küçük olması kendisiyle korelasyon varlığı için bir işaret daha.</p>
<p>Kaynaklar</p>
<p>[1] Pfaff, <em>Analysis of Integrated and Co-Integrated Time Series</em></p>
<p>[2] Crawley, <em>The R Book</em></p>
<p>[3] Hilpisch, <em>Python for Finance</em></p>
<p>[4] Shumway, <em>Time Series Analysis with Applications in R</em></p>
<p>[5] Carter Hill, <em>Principles of Econometrics</em></p>
<p>[6] Metcalfe , <em>Introductory Times Series with R</em></p>
<p>[8] McKinney, <em>Pandas Reference Documentation, 0.17.1</em></p>
<p>[9] Bayramlı, Diferansiyel Denklemler, <em>Seriler</em></p>
<p>
  <a href="..">Yukarı</a>
</p>
</body>
</html>
