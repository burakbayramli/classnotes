<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
    <script type="text/x-mathjax-config">
    MathJax.Hub.Register.StartupHook("TeX Jax Ready",function () {
      MathJax.Hub.Insert(MathJax.InputJax.TeX.Definitions.macros,{
        cancel: ["Extension","cancel"], cancelto: ["Extension","cancel"]
      });
    });
    </script>  
   
  <title>ARIMA, ARCH, GARCH, Periyotlar, Yürüyen Ortalama</title>
  <style type="text/css">code{white-space: pre;}</style>
  <style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
  </style>
  <script
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS_HTML-full"
  type="text/javascript"></script>
</head>
<body>
<div id="header">
</div>
<h1 id="arima-arch-garch-periyotlar-yürüyen-ortalama">ARIMA, ARCH,
GARCH, Periyotlar, Yürüyen Ortalama</h1>
<p>Kendisiyle Regresyon ve Yürüyen Ortalama (Autoregression, Moving
Average)</p>
<p>Bir zaman serisi rasgele yürüyüşe (random walk) sahipse <span
class="math inline">\(t\)</span> anındaki değeri önceki rasgele
hareketlerin birleşimiydi. Diğer alternatif bir serinin {} arada gürültü
olmadan bağlantılı olmasıdır. Bu her iki yaklaşımı genelleştirerek ARIMA
formunda gösterebiliriz. İlk önce AR formuna bakalım; Birinci seviyede
kendisiyle regresyon (autoregression, first order) AR(1)’dır [1, sf.
23],</p>
<p><span class="math display">\[
y_t = c + \phi y_{t-1} + \epsilon_t  
\qquad (1)
\]</span></p>
<p>Daha yüksek seviyeler AR(p) olarak gösterilir,</p>
<p><span class="math display">\[ y_t = c + \phi_1 y_{t-1} +  \phi_2
y_{t-2} + ... +  \phi_p y_{t-p}  + \epsilon_t  \]</span></p>
<p>Bu durumda <span class="math inline">\(t\)</span> anındaki değer
önceki <span class="math inline">\(t-1,..,t-p\)</span> anındaki
değerlerle (belli oranlar üzerinden tabii) artı gürültüye eşittir.</p>
<p>Bir diğer zaman serisi yürüyen ortalama (moving average) serisidir,
bu tür seriler <span class="math inline">\(t\)</span> anını önceki
<em>gürültülerin</em> bir ortalaması olarak gösterir. Dikkat, önceki tüm
gürültüleri olduğu gibi toplamıyoruz, belli sayıdaki önceki gürültüleri
belli ağırlıklar üzerinden topluyoruz. Birinci seviyede bu seriler MA(1)
olarak tanımlanır,</p>
<p><span class="math display">\[ y_t = \mu + \epsilon_t + \theta
\epsilon_{t-1} \]</span></p>
<p>Daha yüksek seviyeleri MA(q) olarak tanımlarız,</p>
<p><span class="math display">\[ y_t = \mu + \epsilon_t + \theta_1
\epsilon_{t-1} + .. + \theta_q \epsilon_{t-q} \]</span></p>
<p>Pratikte pür birer AR(p) ya da MA(q) serisini tanımlamak zordur,
çoğunlukla ikisinin bir karışımı olan ARMA(p,q) serileri test edilir (ya
da daha genel olarak, AR<em>I</em>MA)(p,d,q). Ek I sembolü modele bir
diferansiyel etkisi sağlıyor, bu eke göre eğer farkı alınmış seri bir
ARMA modeli oluyorsa bu model ARIMA kabul ediliyor. Mesela ilk farklar
<span class="math inline">\(d=1\)</span> için <span
class="math inline">\(y_t - y_{t-1}\)</span> modeli ARMA ise, bu model
ARIMA’dır [4, sf. 92].</p>
<p>Rasgele yürüyüş bu genel formda gösterilebilir, rasgele yürüyüş
ARIMA(0,1,0) modelidir.</p>
<p>Daha odaklı bir örnek olarak Lynx verisine bakalım [2, sf. 727],</p>
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> statsmodels.api <span class="im">as</span> sm</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(<span class="st">&#39;../tser_015_stoc/lynx.csv&#39;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb2"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>df.x.plot()</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>plt.savefig(<span class="st">&#39;tser_ar_01.png&#39;</span>)</span></code></pre></div>
<p><img src="tser_ar_01.png" /></p>
<p>Çıplak gözle bakıldığında zaman serisinde 10 senelik kuvvetli bir
periyot olduğunu görüyoruz. Acaba hangi ARIMA serisi, hangi <span
class="math inline">\(p,q\)</span> parametreleri üzerinden Lynx’i
modelleyebilir? Bunun için önce bir kendisiyle korelasyon
(autocorrelation) ACF ve kısmi kendisiyle korelasyon PACF analizi yapmak
faydalı olabilir. PACF, aynen ACF gibi, seriyi bir ya da daha fazla
geriye kaydırarak kendisiyle olan korelasyonunu inceler, ama bunu diğer
tüm diğer kaydırılmış serilerin etkisini çıkartarak yapar, böylece
gerideki belli bir <span class="math inline">\(t-n\)</span> noktasının
etkisi daha açık olarak görülebilir.</p>
<div class="sourceCode" id="cb3"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> statsmodels.api <span class="im">as</span> sm</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>sm.graphics.tsa.plot_acf(df.x.values.squeeze(), lags<span class="op">=</span><span class="dv">40</span>)</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>plt.savefig(<span class="st">&#39;tser_ar_02.png&#39;</span>)</span></code></pre></div>
<p><img src="tser_ar_02.png" /></p>
<div class="sourceCode" id="cb4"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>sm.graphics.tsa.plot_pacf(df.x, lags<span class="op">=</span><span class="dv">40</span>)</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>plt.savefig(<span class="st">&#39;tser_ar_03.png&#39;</span>)</span></code></pre></div>
<p><img src="tser_ar_03.png" /></p>
<p>ACF/PACF grafiklerinde mavi bölge dışına taşan noktalar istatistiki
olarak önemli demektir. ACF’te 10 senelik periyot açık şekilde
görülüyor. Hangi evre gecikmesi (lag) daha önemli? PACF grafiğinde 2.
evrede güçlü bir negatif korelasyon görülüyor, 1 ve 8’de güçlü pozitif
korelasyonlar var, ve 4’te yine negatif.</p>
<p>Şimdi belli ARIMA modellerini test edelim, modelleri birbiri ile
kıyaslamak için AIC istatistiğini kullanacağız, daha düşük AIC daha iyi
demektir. Ama ondan önce bir AR modelinin nasıl veriye uydurulduğunu
düşünelim; (1)’deki formülde <span class="math inline">\(y_t\)</span> ve
<span class="math inline">\(y_{t-1}\)</span> arasında lineer bir ilişki
görüyoruz. Bu durumda bu iki veri noktasının bir lineer regresyona
verirsek, <span class="math inline">\(\phi\)</span> değeri bu
regresyondan ortaya çıkacaktır. Regresyonun işlemesi için veri
noktalarının bir aşağı kaydırırız, ve bu kaydırılmış değeri asıl değer
ile regresyona sokarız,</p>
<div class="sourceCode" id="cb5"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> statsmodels.formula.api <span class="im">as</span> smf</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>df[<span class="st">&#39;x_lag1&#39;</span>] <span class="op">=</span> df.x.shift(<span class="dv">1</span>)</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (df[[<span class="st">&#39;x&#39;</span>,<span class="st">&#39;x_lag1&#39;</span>]].head(<span class="dv">6</span>), <span class="st">&#39;</span><span class="ch">\n</span><span class="st">&#39;</span>)</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> smf.ols(<span class="st">&#39;x ~ x_lag1&#39;</span>, data<span class="op">=</span>df).fit()</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (results.params)</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (<span class="st">&#39;aic&#39;</span>, results.aic)</span></code></pre></div>
<pre class="text"><code>      x  x_lag1
0   269     NaN
1   321   269.0
2   585   321.0
3   871   585.0
4  1475   871.0
5  2821  1475.0 

Intercept    454.151675
x_lag1         0.719712
dtype: float64
aic 1907.7277269856995</code></pre>
<p>Şimdi bir ARIMA paketi ile aynısını yapalım,</p>
<div class="sourceCode" id="cb7"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> statsmodels.tsa.arima.model <span class="im">import</span> ARIMA</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>model10 <span class="op">=</span> ARIMA(df.x, order<span class="op">=</span>(<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">0</span>))</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>model_fit <span class="op">=</span> model10.fit()</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(model_fit.summary())</span></code></pre></div>
<pre class="text"><code>                               SARIMAX Results                                
==============================================================================
Dep. Variable:                      x   No. Observations:                  114
Model:                 ARIMA(1, 0, 0)   Log Likelihood                -960.496
Date:                Mon, 08 Sep 2025   AIC                           1926.992
Time:                        09:41:29   BIC                           1935.201
Sample:                             0   HQIC                          1930.324
                                - 114                                         
Covariance Type:                  opg                                         
==============================================================================
                 coef    std err          z      P&gt;|z|      [0.025      0.975]
------------------------------------------------------------------------------
const       1538.0176    518.209      2.968      0.003     522.346    2553.689
ar.L1          0.7173      0.078      9.155      0.000       0.564       0.871
sigma2      1.214e+06   1.21e+05     10.011      0.000    9.77e+05    1.45e+06
===================================================================================
Ljung-Box (L1) (Q):                  21.87   Jarque-Bera (JB):                35.50
Prob(Q):                              0.00   Prob(JB):                         0.00
Heteroskedasticity (H):               1.70   Skew:                             0.81
Prob(H) (two-sided):                  0.10   Kurtosis:                         5.20
===================================================================================

Warnings:</code></pre>
<p>Sonuçlar oldukça yakın (gerçi kesi farklı -niye?-, ama katsayı daha
önemli).</p>
<p>En İyi Model?</p>
<p>AR, ARIMA, MA, onların dereceleri arasında bir seçim yapmak
gerekiyor. Önce sırf AR deneyelim,</p>
<div class="sourceCode" id="cb9"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>res <span class="op">=</span> []</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>res.append(ARIMA(df.x, order<span class="op">=</span>(<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">0</span>)).fit())</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>res.append(ARIMA(df.x, order<span class="op">=</span>(<span class="dv">2</span>,<span class="dv">0</span>,<span class="dv">0</span>)).fit())</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>res.append(ARIMA(df.x, order<span class="op">=</span>(<span class="dv">3</span>,<span class="dv">0</span>,<span class="dv">0</span>)).fit())</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>res.append(ARIMA(df.x, order<span class="op">=</span>(<span class="dv">4</span>,<span class="dv">0</span>,<span class="dv">0</span>)).fit())</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>res.append(ARIMA(df.x, order<span class="op">=</span>(<span class="dv">5</span>,<span class="dv">0</span>,<span class="dv">0</span>)).fit())</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>res.append(ARIMA(df.x, order<span class="op">=</span>(<span class="dv">6</span>,<span class="dv">0</span>,<span class="dv">0</span>)).fit())</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> x <span class="kw">in</span> res: <span class="bu">print</span> (x.df_model<span class="op">+</span><span class="dv">1</span>, x.aic)</span></code></pre></div>
<pre class="text"><code>4 1926.9924398325463
5 1878.0406372333928
6 1879.9789477534478
7 1874.2668130645723
8 1875.3543450306533
9 1876.9445293129488</code></pre>
<p>En iyi model AR(4) olarak gözüküyor. Şimdi sadece MA olarak
bakalım,</p>
<div class="sourceCode" id="cb11"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>lynx <span class="op">=</span> df.x</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>R <span class="op">-</span>i lynx</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>R model01<span class="op">&lt;-</span>arima(lynx,order<span class="op">=</span>c(<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">1</span>))</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>R model02<span class="op">&lt;-</span>arima(lynx,order<span class="op">=</span>c(<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">2</span>))</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>R model03<span class="op">&lt;-</span>arima(lynx,order<span class="op">=</span>c(<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">3</span>))</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>R model04<span class="op">&lt;-</span>arima(lynx,order<span class="op">=</span>c(<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">4</span>))</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>R model05<span class="op">&lt;-</span>arima(lynx,order<span class="op">=</span>c(<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">5</span>))</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>R model06<span class="op">&lt;-</span>arima(lynx,order<span class="op">=</span>c(<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">6</span>))</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>R <span class="op">-</span>o res res <span class="op">&lt;-</span> AIC(model01,model02,model03,model04,model05,model06)</span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (res)</span></code></pre></div>
<pre><code>        df      AIC
model01  3 1917,947
model02  4 1890,061
model03  5 1887,770
model04  6 1888,279
model05  7 1885,698
model06  8 1885,230
</code></pre>
<p>Bu AIC’ler AR’dekilerden yüksek. Belki bir <span
class="math inline">\(p,q\)</span> kombinasyonu daha iyidir? En iyi p
olan <span class="math inline">\(p=4\)</span>’u tutalım, ve diğer <span
class="math inline">\(q\)</span>’leri test edelim,</p>
<div class="sourceCode" id="cb13"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>lynx <span class="op">=</span> df.x</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>R <span class="op">-</span>i lynx</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>R model40<span class="op">&lt;-</span>arima(lynx,order<span class="op">=</span>c(<span class="dv">4</span>,<span class="dv">0</span>,<span class="dv">0</span>))</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>R model41<span class="op">&lt;-</span>arima(lynx,order<span class="op">=</span>c(<span class="dv">4</span>,<span class="dv">0</span>,<span class="dv">1</span>))</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>R model42<span class="op">&lt;-</span>arima(lynx,order<span class="op">=</span>c(<span class="dv">4</span>,<span class="dv">0</span>,<span class="dv">2</span>))</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>R model43<span class="op">&lt;-</span>arima(lynx,order<span class="op">=</span>c(<span class="dv">4</span>,<span class="dv">0</span>,<span class="dv">3</span>))</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>R <span class="op">-</span>o res res<span class="op">&lt;-</span>AIC(model40,model41,model42,model43)</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (res)</span></code></pre></div>
<pre><code>        df      AIC
model40  6 1874,222
model41  7 1875,351
model42  8 1862,435
model43  9 1880,432
</code></pre>
<p>Görülüyor ki hareketli ortalama ekine hiç gerek yok, çünkü en iyi AIC
<span class="math inline">\(q=0\)</span> için. Ya farklı
diferansiyeller, yani ARIMA’nın I’si?</p>
<div class="sourceCode" id="cb15"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>lynx <span class="op">=</span> df.x</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>R <span class="op">-</span>i lynx</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>R model400<span class="op">&lt;-</span>arima(lynx,order<span class="op">=</span>c(<span class="dv">4</span>,<span class="dv">0</span>,<span class="dv">0</span>))</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>R model401<span class="op">&lt;-</span>arima(lynx,order<span class="op">=</span>c(<span class="dv">4</span>,<span class="dv">1</span>,<span class="dv">0</span>))</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>R model402<span class="op">&lt;-</span>arima(lynx,order<span class="op">=</span>c(<span class="dv">4</span>,<span class="dv">2</span>,<span class="dv">0</span>))</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>R model403<span class="op">&lt;-</span>arima(lynx,order<span class="op">=</span>c(<span class="dv">4</span>,<span class="dv">3</span>,<span class="dv">0</span>))</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>R <span class="op">-</span>o res res<span class="op">&lt;-</span>AIC(model400,model401,model402,model403)</span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (res)</span></code></pre></div>
<pre><code>         df      AIC
model400  6 1874,222
model401  5 1890,961
model402  5 1917,882
model403  5 1946,143
</code></pre>
<p>Diferansiyele de ihtiyaç yok, en iyi diferansiyel <span
class="math inline">\(d=0\)</span>. En düşük AIC 1874.22, ve AR’ın
gecikmeli evresi 4, ve hiçbir hareketli ortalama ve diferansiyle ihtiyaç
yok. <span class="math inline">\(p=4\)</span> deyince tabii ki <span
class="math inline">\(t\)</span> anının <span
class="math inline">\(p-1,..,p-4\)</span> ile alakası olması hali, yani
<span class="math inline">\(t\)</span> anı kendinden önceki 4 nokta ile
ilişkide olacaktır. Bu ilişkiler gecikmeli sadece evre 2’deki kısmı
korelasyonu değil, 4’teki kısmı korelasyonu da dikkate almak zorundadır
yani.</p>
<p>Oynaklık (Volatility) ve GARCH Modelleri</p>
<p>ARCH İngilizce autoregressive conditional heteroskedasticity
kelimelerinden geliyor, yani kendisiyle regresyonda olan koşullu değişen
varyans serileri. GARCH ise genelleştirilmiş ARCH demektir. Şimdiye
kadar gördük ki getiri <span class="math inline">\(r_t\)</span>’ler
(returns) tipik olarak <span
class="math inline">\(N(0,\sigma^2)\)</span>’den gelmektedir. Fakat
finans zaman serilerinde çoğunlukla oynaklığın, matematiksel olarak
varyansın zamana göre değişebildiği görülmektedir, varyans <span
class="math inline">\(h_t\)</span> belli noktalarda farklı
olabilmektedir, hatta belli oynaklık blokları (volatility regions)
olabilmektedir. Daha önce ARIMA’nın MA kısmında <span
class="math inline">\(t\)</span> anındaki gürültünün önceki zaman
noktalarındaki gürültünün bir ortalaması olduğunu görmüştük, burada
varyans da bir trend ve kaymaya (drift) sahip olabilmektedir.</p>
<p>ARCH(1) modeli</p>
<p><span class="math display">\[ y_t = \phi + e_t \]</span></p>
<p><span class="math display">\[ e_t \sim N(0,h_t) \]</span></p>
<p><span class="math display">\[ h_t = \alpha_0 + \alpha_1 e_{t-1}^2
\]</span></p>
<p>olarak gösterilir. <span
class="math inline">\(\phi,\alpha_0,\alpha_1\)</span> veriden
hesaplanacaktır, ya da simulasyon durumunda dışarıdan
belirlenecektir.</p>
<p>ARCH(q) modeli üstteki formül üzerinde basit bir uzatma yapar,</p>
<p><span class="math display">\[ h_t = \alpha_0 + \alpha_1 e_{t-1}^2 +
... + \alpha_1 e_{t-q}^2 \]</span></p>
<p>GARCH</p>
<p>Matematiksel olarak GARCH(p,q) <span
class="math inline">\(p=1,q=1\)</span> modeli, yani GARCH(1,1)</p>
<p><span class="math display">\[ h_t = \omega + \alpha_1 e_{t-1}^2 +
\beta_1 h_{t-1}\]</span></p>
<p>GARCH(1,1) olduğu farzedilen bir finans serisinin parametrelerini
bulmak için R <code>tseries</code> paketi kullanılabilir. Veri S&amp;P
500 tüm 90’li yılların düzeltilmiş (adjusted) kapanış fiyatlarını
içeriyor, getiri hesabı için <span class="math inline">\(\ln
(P_t/P_{t-1})\)</span> ya da <span class="math inline">\(\ln (P_t) -
\ln(P_{t-1})\)</span> yapıyoruz, ve bu getiriler üzerinde
<code>garch</code> parametrelerini hesaplıyoruz.</p>
<div class="sourceCode" id="cb17"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>dfsp500 <span class="op">=</span> pd.read_csv(<span class="st">&#39;SP500.csv&#39;</span>)</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>ret <span class="op">=</span> np.log(dfsp500[<span class="st">&#39;Adj Close&#39;</span>]).diff()<span class="op">*</span><span class="fl">100.</span></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>ret <span class="op">=</span> ret.fillna(<span class="dv">0</span>)</span></code></pre></div>
<div class="sourceCode" id="cb18"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> arch <span class="im">import</span> arch_model</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>am <span class="op">=</span> arch_model(ret)</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>res <span class="op">=</span> am.fit(update_freq<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (res.summary())</span></code></pre></div>
<pre class="text"><code>Iteration:      5,   Func. Count:     37,   Neg. LLF: 503856629.4052248
Iteration:     10,   Func. Count:     67,   Neg. LLF: 3032.10088603183
Iteration:     15,   Func. Count:     92,   Neg. LLF: 3032.061301641462
Optimization terminated successfully    (Exit mode 0)
            Current function value: 3032.061301641112
            Iterations: 15
            Function evaluations: 92
            Gradient evaluations: 15
                     Constant Mean - GARCH Model Results                      
==============================================================================
Dep. Variable:              Adj Close   R-squared:                       0.000
Mean Model:             Constant Mean   Adj. R-squared:                  0.000
Vol Model:                      GARCH   Log-Likelihood:               -3032.06
Distribution:                  Normal   AIC:                           6072.12
Method:            Maximum Likelihood   BIC:                           6095.46
                                        No. Observations:                 2528
Date:                Mon, Sep 08 2025   Df Residuals:                     2527
Time:                        09:42:31   Df Model:                            1
                                 Mean Model                                 
============================================================================
                 coef    std err          t      P&gt;|t|      95.0% Conf. Int.
----------------------------------------------------------------------------
mu             0.0588  1.466e-02      4.014  5.975e-05 [3.010e-02,8.755e-02]
                               Volatility Model                              
=============================================================================
                 coef    std err          t      P&gt;|t|       95.0% Conf. Int.
-----------------------------------------------------------------------------
omega      5.4768e-03  3.144e-03      1.742  8.155e-02 [-6.861e-04,1.164e-02]
alpha[1]       0.0517  1.700e-02      3.041  2.356e-03  [1.838e-02,8.501e-02]
beta[1]        0.9421  1.858e-02     50.694      0.000      [  0.906,  0.979]
=============================================================================

Covariance estimator: robust</code></pre>
<p>Bu parametreler acaba doğru mu? Parametreler ile verinin kendisinin
üretmeye uğraşalım. <span class="math inline">\(\phi=0\)</span> kabul
edersek, <span class="math inline">\(y_t = e_t\)</span> olarak
alabiliriz,</p>
<div class="sourceCode" id="cb20"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">1</span>)</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>N <span class="op">=</span> <span class="bu">len</span>(dfsp500)</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>alpha0<span class="op">=</span><span class="fl">0.0048</span></span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>alpha1<span class="op">=</span><span class="fl">0.05</span></span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>beta1 <span class="op">=</span> <span class="fl">0.946773</span></span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> np.zeros(N)</span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a>h <span class="op">=</span> np.zeros(N)</span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a>w <span class="op">=</span> np.random.standard_normal(N)</span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>,N): </span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a>    h[i] <span class="op">=</span> alpha0 <span class="op">+</span> alpha1 <span class="op">*</span> (y[i<span class="op">-</span><span class="dv">1</span>]<span class="op">**</span><span class="dv">2</span>) <span class="op">+</span> beta1 <span class="op">*</span> h[i<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a>    y[i] <span class="op">=</span> w[i] <span class="op">*</span> np.sqrt(h[i])</span></code></pre></div>
<p>Gerçek veriyi ve simulasyonu yan yana iki grafikte basalım,</p>
<div class="sourceCode" id="cb21"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>dfsp500[<span class="st">&#39;SP500&#39;</span>] <span class="op">=</span> ret</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>dfsp500[<span class="st">&#39;simulasyon&#39;</span>] <span class="op">=</span> y</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>dfsp500[<span class="st">&#39;SP500&#39;</span>].plot()</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&#39;SP500&#39;</span>)</span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>plt.savefig(<span class="st">&#39;tser_ar_04.png&#39;</span>)</span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a>dfsp500[<span class="st">&#39;simulasyon&#39;</span>].plot()</span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&#39;Simulasyon&#39;</span>)</span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a>plt.savefig(<span class="st">&#39;tser_ar_05.png&#39;</span>)</span></code></pre></div>
<p><img src="tser_ar_04.png" /></p>
<p><img src="tser_ar_05.png" /></p>
<p>Bir serinin değişen varyansa sahip olup olmadığını anlamak için bir
istatistiki test [3, sf. 355] Breusch-Pagan testi,</p>
<div class="sourceCode" id="cb22"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> statsmodels.api <span class="im">as</span> sm</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> scipy <span class="im">as</span> sp</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> breusch_pagan_test(y,x):</span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a>     x <span class="op">=</span> np.asarray(x)</span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a>     results<span class="op">=</span>sm.OLS(y,x).fit()</span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a>     resid<span class="op">=</span>results.resid</span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a>     n<span class="op">=</span><span class="bu">len</span>(resid)</span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a>     sigma2 <span class="op">=</span> <span class="bu">sum</span>(resid<span class="op">**</span><span class="dv">2</span>)<span class="op">/</span>n</span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true" tabindex="-1"></a>     f <span class="op">=</span> resid<span class="op">**</span><span class="dv">2</span><span class="op">/</span>sigma2 <span class="op">-</span> <span class="dv">1</span></span>
<span id="cb22-12"><a href="#cb22-12" aria-hidden="true" tabindex="-1"></a>     results2<span class="op">=</span>sm.OLS(f,x).fit()</span>
<span id="cb22-13"><a href="#cb22-13" aria-hidden="true" tabindex="-1"></a>     fv<span class="op">=</span>results2.fittedvalues</span>
<span id="cb22-14"><a href="#cb22-14" aria-hidden="true" tabindex="-1"></a>     bp<span class="op">=</span><span class="fl">0.5</span> <span class="op">*</span> <span class="bu">sum</span>(fv<span class="op">**</span><span class="dv">2</span>)</span>
<span id="cb22-15"><a href="#cb22-15" aria-hidden="true" tabindex="-1"></a>     df<span class="op">=</span>results2.df_model</span>
<span id="cb22-16"><a href="#cb22-16" aria-hidden="true" tabindex="-1"></a>     p_value<span class="op">=</span><span class="dv">1</span><span class="op">-</span>sp.stats.chi2.cdf(bp,df) </span>
<span id="cb22-17"><a href="#cb22-17" aria-hidden="true" tabindex="-1"></a>     <span class="cf">return</span> <span class="bu">round</span>(bp,<span class="dv">6</span>), df, <span class="bu">round</span>(p_value,<span class="dv">7</span>)</span></code></pre></div>
<p>Lynx verisi üzerinde uygulayalım,</p>
<div class="sourceCode" id="cb23"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> breusch</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>dflynx <span class="op">=</span> pd.read_csv(<span class="st">&#39;../tser_015_stoc/lynx.csv&#39;</span>)<span class="op">;</span></span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (breusch.breusch_pagan_test(dflynx.x, np.array(<span class="bu">range</span>(<span class="bu">len</span>(dflynx)))))</span></code></pre></div>
<pre class="text"><code>(0.429236, 1.0, np.float64(0.6677515))</code></pre>
<p>En sondaki değer p-değeridir, 0.05’ten düşüklük varyansın sabit
olduğu hipotezinin reddedildiği anlamına gelir, yani değişen varyans
durumu vardır. Üstteki sonuçta tezi reddedemedik, demek ki Lynx
verisinde varyans değişmiyor.</p>
<p>Basit Yürüyen Ortalama</p>
<p>Kabaca bir zaman serisini pürüzsüzleştirmenin (smoothing) en basit
yolu basit bir yürüyen ortalama almaktır. Bir pencere büyüklüğü
tanımlarız, bu pencereyi zaman serisinin üzerine koyarız, içine düşen
tüm noktaların ortalamasını alırız, ve pencereyi bir yana kaydırarak
işlemi tekrarlarız. Tüm zaman serisi için bu yapılınca elimize bir
ortalama geçmiş olur,</p>
<p>Yani <span class="math inline">\(x_1,..,x_t\)</span> zaman serisi
için</p>
<p><span class="math display">\[
y_t = \frac{1}{k} \sum_{n=0}^{k-1} x_{t-n}  
= \frac{x_t + x_{t-1} + ... + x_{t-k+1}}{k}
\]</span></p>
<p>Burada hiç ağırlık kullanmadık, yani pencere içinde veri noktalarının
bazılarına daha fazla, bazılarına daha az ağırlık vermedik. Daha doğrusu
ağırlık kullandık, ama tüm noktalara ‘1’ ağırlığı verdik ve bu sebeple k
tane ‘1’ ağırlık verilmiş toplamı <span
class="math inline">\(k\)</span>’ye böldük. Fakat ‘1’ yerine farklı
ağırlıklar da verebilirdik, mesela <span
class="math inline">\(w_1,w_2,..\)</span> ki ağırlık toplamı 1 olacak
şekilde,</p>
<p><span class="math display">\[ y_t = w_1x_t + w_2x_{t-1} + ... +
w_kx_{t-k+1}
\]</span></p>
<p>Ağırlıkların toplamı 1, fakat 1 ile bölmeyi göstermeye gerek yok.</p>
<p>Ya da <span class="math inline">\(0 &lt; \alpha &lt; 1\)</span>
olacak şekilde, tüm zaman serisini kullanarak (pencere yok), ağırlıkları
<span class="math inline">\((1-\alpha)\)</span>’nin katları olacak
şekilde ayarlarsak,</p>
<p><span class="math display">\[ y_t = \frac{x_t + (1-\alpha)x_{t-1} +
(1-\alpha)^2x_{t-2} + ... }
{1 + (1-\alpha) + (1-\alpha)^2 + ...}
\]</span></p>
<p>Üstteki hesaba üstel ağırlıklı yürüyen ortalama (exponentially
weighted moving average -EWMA-) deniyor. Verinin tamamı kullanılır,
ağırlıklar <span class="math inline">\(x_1\)</span>’e kadar gider. 0 ile
1 arasındaki değerler, ve onların gittikçe artan üstelleri ile
çarptığımız için yakın zamandaki verilerin ağırlığı fazladır, eskiye
gittikçe hızlı bir şekile bu etki azalmaya başlar. Eğer <span
class="math inline">\(1-\alpha=0.2\)</span> ise mesela, önce <span
class="math inline">\(0.2\)</span>, sonra <span
class="math inline">\(0.2^2=0.04\)</span>, ardından <span
class="math inline">\(0.2^3=0.008\)</span>, küçülmenin ne kadar hızlı
olduğunu görüyoruz.</p>
<p>Ayrıca bölende olan ifadelerin başlangıcı 1 oranı <span
class="math inline">\(1-\alpha\)</span> olan bir geometrik seri olduğunu
görelim, bkz [9], o zaman bölen <span
class="math inline">\(\frac{1}{1-(1-\alpha)}\)</span>’a yani <span
class="math inline">\(\frac{1}{\alpha}\)</span>’ya eşittir,</p>
<p><span class="math display">\[ y_t = \frac{x_t + (1-\alpha)x_{t-1} +
(1-\alpha)^2x_{t-2} + ... }
{\frac{1}{\alpha}}
\]</span></p>
<p><span class="math display">\[  = [ x_t + (1-\alpha)x_{t-1} +
(1-\alpha)^2x_{t-2} + ... ] \alpha \]</span></p>
<p>Üstteki hesabı özyineli yapmak ta mümkündür, türetmeye devam
edersek,</p>
<p><span class="math display">\[  = \alpha x_t + [(1-\alpha)x_{t-1} +
(1-\alpha)^2x_{t-2} + ... ]\alpha \]</span></p>
<p><span class="math display">\[  = \alpha x_t + (1-\alpha) [x_{t-1} +
(1-\alpha)x_{t-2} + ... ]\alpha \]</span></p>
<p><span class="math inline">\(\alpha\)</span> ile çarpılan köşeli
parantezdekiler <span class="math inline">\(y_{t-1}\)</span>’in ta
kendisi. O zaman özyineli ifade şu olur [8, sf. 502],</p>
<p><span class="math display">\[ y_t = \alpha x_t + (1-\alpha)
y_{t-1}\]</span></p>
<p>Etkili Örneklem Büyüklüğü</p>
<p>EWMA hesabı en son değerlere ağırlık verir ve eskiler bir süre sonra
unutulur. Acaba bu “en son” ve “eski” kavramlarını bir şekilde somut
hale getirebilir miyiz? Bu mümkün, üstte kullanılan <span
class="math inline">\(\alpha\)</span> değeri ile bir etkili örneklem
büyüklüğü (effective sample size) hesaplamak mümkün, yani EWMA’nın bir
nevi önceden tanımlı pencere içinde etkili bir hareket eden ortalama
(moving average) gibi işlediğini düşünebiliriz, ve bu sanal EWMA
penceresinin büyüklüğü, <span class="math inline">\(N_{eff}\)</span>
diyelim, hesaplanabilir. Gördük ki,</p>
<p><span class="math display">\[
y_t=\frac{x_t+(1-\alpha)x_{t-1}+(1-\alpha)^2x_{t-2}+\cdots}{1+(1-\alpha)+(1-\alpha)^2+\cdots}.
\]</span></p>
<p>Bölen geometrik seri olduğu için <span
class="math inline">\(\frac{1}{\alpha}\)</span>.</p>
<p>O zaman <span class="math inline">\(k\)</span> anındaki normalize
edilmiş ağırlık</p>
<p><span class="math display">\[
w_k=\alpha(1-\alpha)^k,\qquad k=0,1,2,\dots,
\]</span></p>
<p>Elimizde bir tahmin edici <span
class="math inline">\(\hat{\mu}\)</span> olsun,</p>
<p><span class="math inline">\(\hat\mu=\sum_i w_i x_i\)</span>, ki <span
class="math inline">\(\sum_i w_i=1\)</span> ve birbirinden bağımsız,
tıpatıp aynı <span class="math inline">\(x_i\)</span>’lar için <span
class="math inline">\(Var(x_i)=\sigma^2\)</span>, o zaman <span
class="math inline">\(Var(\hat\mu)=\sigma^2\sum_i w_i^2\)</span>.</p>
<p>Bu durumda şöyle bir hesap ta yapılabilir <span
class="math inline">\(Var(\bar x)=\sigma^2/N\)</span>, ki bu örneklem
ortalaması (ve onun varyansı).</p>
<p>Şimdi şu soru sorulur, “hangi <span
class="math inline">\(N_{eff}\)</span> penceresi için ağırlıklı
ortalama, basit averaj ile aynı varyansa sahiptir?”. Bunun için son iki
formülü birbirine eşitleyip <span class="math inline">\(N_{eff}\)</span>
için çözeriz,</p>
<p><span class="math display">\[
\sigma^2\sum_i w_i^2 = \frac{\sigma^2}{N_{\text{eff}}}
\quad\Rightarrow\quad
N_{\text{eff}}=\frac{1}{\sum_i w_i^2}.
\]</span></p>
<p><span class="math inline">\(w_k\)</span> formülü ile açalım,</p>
<p><span class="math display">\[
\sum_{k=0}^\infty w_k^2
= \sum_{k=0}^\infty \alpha^2(1-\alpha)^{2k}
= \alpha^2\sum_{k=0}^\infty \big((1-\alpha)^2\big)^k
= \alpha^2\cdot\frac{1}{1-(1-\alpha)^2}.
\]</span></p>
<p><span class="math inline">\(1-(1-\alpha)^2 = 1 - (1 - 2\alpha +
\alpha^2) = 2\alpha - \alpha^2\)</span> olduğu için,</p>
<p><span class="math display">\[
\sum_{k=0}^\infty w_k^2 =
\frac{\alpha^2}{2\alpha-\alpha^2}=\frac{\alpha}{2-\alpha}.
\]</span></p>
<p><span class="math display">\[
N_{\text{eff}} \equiv \frac{1}{\sum w_k^2}
= \frac{2-\alpha}{\alpha} = \frac{2}{\alpha}-1.
\]</span></p>
<p>Yani <span class="math inline">\(\alpha\)</span>’dan yola çıkarak
onun kabaca tekabül ettiği basit pencereli ortalama hesabının pencere
büyüklüğünü bulmuş oluyoruz.</p>
<p>Enflasyon</p>
<p>Fiyat seviyesinin (CPI) kendisiyle alakalı bir seri oldugu bilinir,
bu mantıklı çünkü ekonomik psikolojisi açısından yüksek fiyat seviyesi
daha yüksek fiyatlara gidişi tetikleyebilir. Alışverişte yüksek fiyatlar
görüyorsam ben de kendi müşterimden daha yüksek fiyatlar istemeye
başlayabilirim. Bu kendisiyle korelasyonu veride nasıl buluruz?
Durbin-Watson testi var,</p>
<div class="sourceCode" id="cb25"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>cpi <span class="op">=</span> pd.read_csv(<span class="st">&#39;cpi.csv&#39;</span>,index_col<span class="op">=</span><span class="dv">0</span>)</span></code></pre></div>
<div class="sourceCode" id="cb26"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> statsmodels.formula.api <span class="im">as</span> smf</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> statsmodels.stats.stattools <span class="im">import</span> durbin_watson</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>inf <span class="op">=</span> np.log(cpi)</span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> smf.ols(<span class="st">&#39;CPIAUCNS ~ 1&#39;</span>, data<span class="op">=</span>inf).fit()</span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (durbin_watson(results.resid))</span></code></pre></div>
<pre><code>9.222098132626552e-05</code></pre>
<p>Düşük bir değer kendisiyle korelasyon varlığının işareti olabilir.
Not: Bu istatistik normal regresyon paketleri tarafından çoğunlukla
rapor edilir çünkü basit regresyonun önkabulü kendisiyle korelasyon
olmadığıdır, bu sebeple DW korelasyon varlığına işaret ediyorsa analizci
için bu önemli bir sinyal olmalı.</p>
<p>Durbin-Watson istatiği 0 ile 4 arasında bir değere sahiptir, 0 ile 2
arasındaki değerler pozitif kendisiyle korelasyonun, 2 ile 4 arası
negatif kendisiyle korelasyonun işaretidir. Tam 2 değeri korelasyon yok
demektir.</p>
<p>Bir diger test Ljung-Box testi,</p>
<div class="sourceCode" id="cb28"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> statsmodels.tsa.stattools <span class="im">as</span> tsa</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>acf,ci,q,pvalues <span class="op">=</span> tsa.acf(results.resid, nlags<span class="op">=</span><span class="dv">4</span>, alpha<span class="op">=</span><span class="dv">95</span>,qstat<span class="op">=</span><span class="va">True</span>, adjusted<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (acf)</span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (pvalues)</span></code></pre></div>
<pre><code>[1.         0.99585547 0.99164499 0.98737151 0.98305291]
[1.02286496e-121 5.63735022e-239 0.00000000e+000 0.00000000e+000]</code></pre>
<p>P-değerlerinin hepsinin 0.05’ten küçük olması kendisiyle korelasyon
varlığı için bir işaret daha.</p>
<p>Kaynaklar</p>
<p>[1] Pfaff, <em>Analysis of Integrated and Co-Integrated Time
Series</em></p>
<p>[2] Crawley, <em>The R Book</em></p>
<p>[3] Hilpisch, <em>Python for Finance</em></p>
<p>[4] Shumway, <em>Time Series Analysis with Applications in R</em></p>
<p>[5] Carter Hill, <em>Principles of Econometrics</em></p>
<p>[6] Metcalfe , <em>Introductory Times Series with R</em></p>
<p>[8] McKinney, <em>Pandas Reference Documentation, 0.17.1</em></p>
<p>[9] Bayramlı, Diferansiyel Denklemler, <em>Seriler</em></p>
<p>
  <a href="..">Yukarı</a>
</p>
</body>
</html>
